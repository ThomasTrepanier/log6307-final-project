\section{Introcution}
\label{sec:introduction}
The rise of ChatGPT in the last year has led to many questions as to the quality of the answers it provides, and a lot of worry that bad answers may find their way in official products because of a lack of wariness.

This worry does not escape developers who have been using ChatGPT to answer their code related question more and more in the past year. In order to adress this problem, as part of the MSR2024 Mining Challenge \cite{msr-2024}, this study aims at evaluating the quality of the code generated by ChatGPT using the DevGPT dataset from the challenge. \\

It is important to qualify the quality of the code generated by ChatGPT, because its usage has been on the rise and the inclusion of low quality code in production code bases could lead to serious issues down the line.

For example, Spadini \textit{et. al.} \cite{spadini-2018} found that test smells could lead to more defect-prone production code, and knowing that many developers use ChatGPT to generate unit tests, it is important to know if such tests smells, or other kinds of code smells could be found in ChatGPT's answers.

Furthemore, knowing what kind of code smells are present in ChatGPT's answers may help developers identify and remove them before integrating such code into their projects. \\

In order to evaluate the quality of the code generated by ChatGPT, we will use \textit{Pyscent} , an automatic code smell detection tool for Python, to analyse all the Python code snippets in the DevGPT dataset. Then, to get a baseline for the amount of code smells found in other online resources, we will compare these results with the code smells found in code snippets extracted from Python related questions on Stack Overflow. This will help us evaluate the quality of ChatGPT compared to other online resources. \\

The presence of code smells has been shown to be related to some software qualities such as maintainability by Yamashita and Moonen \cite{yamashita-2012}, espacially for small code snippets. It is therefore why we believe it to be a reasonable approach to measure the code quality of ChatGPT's answers.\\

More precisely, this paper will try to answer the following research questions: \\

\begin{itemize}
  \item \textbf{RQ1:} How prevalent are code smells in ChatGPT's code snippets?

  \item \textbf{RQ2:} How does ChatGPT's code quality compares to Stack Overflow's answers? \\

\end{itemize}

The rest of this paper is organized as follows: Section \ref{sec:related-work} presents the related work, Section \ref{sec:methodology} presents the methodology used to conduct this study, Section \ref{sec:results} presents the results of the study, Section \ref{sec:discussion} discusses the results, Section \ref{sec:threats-to-validity} presents the threats to validity of this study and Section \ref{sec:conclusion} concludes this paper.

