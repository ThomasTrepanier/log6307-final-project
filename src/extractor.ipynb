{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract all conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from conversation_extractor import ConversationExtractor\n",
    "import os\n",
    "\n",
    "extractor = ConversationExtractor()\n",
    "\n",
    "for subdir, dirs, files in os.walk(f\"../data/raw\"):\n",
    "    for file in files:\n",
    "        if (extractor.is_csv_file(file)):\n",
    "            continue\n",
    "\n",
    "        path = os.path.join(subdir, file)\n",
    "        print(f\"Extracting conversations from {path}...\")\n",
    "        conversations_by_url = extractor.extract_conversations_by_url(\n",
    "            path, print_process=False)\n",
    "        extractor.save_conversations(path, conversations_by_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from conversation_filter import ConversationFilter\n",
    "import os\n",
    "\n",
    "conversation_filter = ConversationFilter()\n",
    "print_process = False\n",
    "\n",
    "conversations_with_code = {}\n",
    "python_conversation = {}\n",
    "js_conversation = {}\n",
    "ts_conversation = {}\n",
    "java_conversation = {}\n",
    "\n",
    "# Read every file of the data/interim/conversations folder\n",
    "for subdir, dirs, files in os.walk(f\"../data/interim/conversations\"):\n",
    "    for file in files:\n",
    "        path = os.path.join(subdir, file)\n",
    "        print(f\"Filtering conversations from {path}...\")\n",
    "        conversations_by_url = conversation_filter.load_conversations(path)\n",
    "\n",
    "        new_conversations_with_code = conversation_filter.get_conversations_with_code(\n",
    "            conversations_by_url, print_process)\n",
    "        new_python_conversation = conversation_filter.get_python_conversations(\n",
    "            conversations_by_url, print_process)\n",
    "        new_js_conversation = conversation_filter.get_js_conversations(\n",
    "            conversations_by_url, print_process)\n",
    "        new_ts_conversation = conversation_filter.get_ts_conversations(\n",
    "            conversations_by_url, print_process)\n",
    "        new_java_conversation = conversation_filter.get_java_conversations(\n",
    "            conversations_by_url, print_process)\n",
    "        \n",
    "        conversations_with_code.update(new_conversations_with_code)\n",
    "        python_conversation.update(new_python_conversation)\n",
    "        js_conversation.update(new_js_conversation)\n",
    "        ts_conversation.update(new_ts_conversation)\n",
    "        java_conversation.update(new_java_conversation)\n",
    "\n",
    "\n",
    "conversation_filter.save_conversations(\n",
    "    conversations_with_code, 'with-code')\n",
    "conversation_filter.save_conversations(python_conversation, 'python')\n",
    "conversation_filter.save_conversations(js_conversation, 'javascript')\n",
    "conversation_filter.save_conversations(ts_conversation, 'typescript')\n",
    "conversation_filter.save_conversations(java_conversation, 'java')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Code Snippets as Source Code files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting 653 source codes to ../data/interim/chatgpt/src/python\n",
      "Deleting 126.py\n",
      "Deleting 127.py\n",
      "Deleting 128.py\n",
      "Deleting 129.py\n",
      "Deleting 130.py\n",
      "Deleting 131.py\n",
      "Deleting 132.py\n",
      "Deleting 176.py\n",
      "Deleting 203.py\n",
      "Deleting 212.py\n",
      "Deleting 223.py\n",
      "Deleting 226.py\n",
      "Deleting 303.py\n",
      "Deleting 307.py\n",
      "Deleting 308.py\n",
      "Deleting 309.py\n",
      "Deleting 311.py\n",
      "Deleting 33.py\n",
      "Deleting 368.py\n",
      "Deleting 399.py\n",
      "Deleting 400.py\n",
      "Deleting 401.py\n",
      "Deleting 440.py\n",
      "Deleting 465.py\n",
      "Deleting 488.py\n",
      "Deleting 489.py\n",
      "Deleting 55.py\n",
      "Deleting 572.py\n",
      "Deleting 573.py\n",
      "Deleting 624.py\n",
      "Deleting 635.py\n",
      "Deleting 72.py\n",
      "Deleting 76.py\n",
      "Deleting 77.py\n",
      "Deleting 78.py\n",
      "Deleting 79.py\n",
      "Deleting 95.py\n",
      "Deleting 96.py\n"
     ]
    }
   ],
   "source": [
    "from conversation_io import ConversationIO\n",
    "from source_code_extractor import SourceCodeExtractor\n",
    "\n",
    "conversation_io = ConversationIO()\n",
    "source_code_extractor = SourceCodeExtractor()\n",
    "\n",
    "url = \"../data/interim/filtered-conversations\"\n",
    "origin = \"chatgpt\"\n",
    "type = \"python\"\n",
    "print_process = False\n",
    "\n",
    "conversations_by_url = conversation_io.load_conversations(f\"{url}/conversations-{type}.json\")\n",
    "\n",
    "source_codes = source_code_extractor.extract(conversations_by_url)\n",
    "\n",
    "source_code_extractor.export_source_code(origin, source_codes, type)\n",
    "\n",
    "source_code_extractor.delete_invalid_files(origin, type)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetch Questions from Stack Overflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from so_extractor import StackOverflowExtractor\n",
    "\n",
    "raw_dir = \"../data/raw/stackoverflow\"\n",
    "interim_dir = \"../data/interim/stackoverflow\"\n",
    "so_extractor = StackOverflowExtractor(raw_dir, interim_dir)\n",
    "\n",
    "type = \"python\"\n",
    "number_of_answer = 5\n",
    "has_accepted_answer = True\n",
    "nb_of_views = 1000\n",
    "\n",
    "so_extractor.fetch_search(type, number_of_answer, has_accepted_answer, nb_of_views)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Answers from fetched Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from so_extractor import StackOverflowExtractor\n",
    "\n",
    "raw_dir = \"../data/raw/stackoverflow\"\n",
    "interim_dir = \"../data/interim/stackoverflow\"\n",
    "so_extractor = StackOverflowExtractor(raw_dir, interim_dir)\n",
    "\n",
    "type = \"python\"\n",
    "\n",
    "question_ids = so_extractor.extract_question_ids(type)\n",
    "\n",
    "so_extractor.fetch_answers(question_ids, type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Code Snippets from Answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting code from ../data/raw/stackoverflow/answers\\so_answers_python_0.json...\n",
      "Extracting code from ../data/raw/stackoverflow/answers\\so_answers_python_1.json...\n",
      "Extracting code from ../data/raw/stackoverflow/answers\\so_answers_python_2.json...\n",
      "Extracting code from ../data/raw/stackoverflow/answers\\so_answers_python_3.json...\n",
      "Extracting code from ../data/raw/stackoverflow/answers\\so_answers_python_4.json...\n"
     ]
    }
   ],
   "source": [
    "from so_extractor import StackOverflowExtractor\n",
    "import os\n",
    "\n",
    "raw_dir = \"../data/raw/stackoverflow\"\n",
    "interim_dir = \"../data/interim/stackoverflow\"\n",
    "so_extractor = StackOverflowExtractor(raw_dir, interim_dir)\n",
    "\n",
    "type = \"python\"\n",
    "\n",
    "for subdir, dirs, files in os.walk(f\"{raw_dir}/answers\"):\n",
    "    for i, file in enumerate(files):\n",
    "        path = os.path.join(subdir, file)\n",
    "        print(f\"Extracting code from {path}...\")\n",
    "\n",
    "        so_extractor.extract_code_from_answers(path, i, type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export Valid Code Snippets to Python Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15688\\2052292480.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0msubdir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdirs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfiles\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwalk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{interim_dir}/snippets\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "from itertools import chain\n",
    "from source_code_extractor import SourceCodeExtractor\n",
    "import json\n",
    "import os\n",
    "\n",
    "source_code_extractor = SourceCodeExtractor()\n",
    "raw_dir = \"../data/raw/stackoverflow\"\n",
    "interim_dir = \"../data/interim/stackoverflow\"\n",
    "\n",
    "origin = \"stackoverflow\"\n",
    "type = \"python\"\n",
    "\n",
    "for subdir, dirs, files in os.walk(f\"{interim_dir}/snippets\"):\n",
    "    for i, file in enumerate(files):\n",
    "        path = os.path.join(subdir, file)\n",
    "        print(f\"Exporting code from {path}...\")\n",
    "\n",
    "        with open(path) as f:\n",
    "            snippets = json.load(f)\n",
    "            snippets = list(chain(*map(list, snippets)))\n",
    "\n",
    "            valid_snippets = source_code_extractor.filter_valid_source_code(snippets, type)\n",
    "\n",
    "            source_code_extractor.export_source_code(origin, valid_snippets, type, i)\n",
    "\n",
    "source_code_extractor.delete_invalid_files(origin, type)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
