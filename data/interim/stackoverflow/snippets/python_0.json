[["from selenium import webdriver\nimport undetected_chromedriver as uc\n\nmy_options = webdriver.ChromeOptions()\nmy_options.add_argument( '--log-level=3' )\nmy_options.add_argument( '--no-sandbox' )\nmy_options.add_argument( '--disable-dev-shm-usage' )\nmy_options.add_argument( '--disable-blink-features=AutomationControlled' )\nmy_options.add_argument( 'user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/109.0.0.0 Safari/537.36' )\nmy_options.add_argument( '--no-first-run' ) # this might be specific to undetected_chromedriver.v2 only\nmy_options.add_argument( '--no-service-autorun' ) # this might be specific to undetected_chromedriver.v2 only\nmy_options.add_argument( '--password-store=basic' ) # this might be specific to undetected_chromedriver.v2 only\n#my_options.add_experimental_option( 'useAutomationExtension', False )\n#my_options.add_experimental_option( 'excludeSwitches', ( 'enable-automation', ) )\nmy_options.add_argument( '--start-maximized' )\nmy_options.add_argument( '--blink-settings=imagesEnabled=false' )\nmy_options.headless = False\nmy_options.page_load_strategy = 'normal'\n\nmy_driver = uc.Chrome( options = my_options, version_main = 109 )\nmy_driver.get( 'about:blank' )\nmy_driver.execute_script( \"Object.defineProperty(navigator, 'webdriver', {get: () => undefined})\" )\nmy_driver.get( ..............\n"], ["pip install pipwin \npipwin install pyaudio\n"], [], [], ["model_checkpoint = ModelCheckpoint(\n    filepath=\"tmp_file.keras\",\n    options=None\n)\n"], ["    cd /usr/.local/lib/python3.5/site-packages/virtualenv-16.1.0.dist-info/\n    \n    touch METADATA\n"], ["class ModelBase(pydantic.BaseModel):\n  a: int\n  b: str\n\n\nclass ModelCreate(ModelBase):\n  pass\n\n# Make all fields optional\n@make_optional()\nclass ModelUpdate(ModelBase):\n  pass\n"], ["from typing_extensions import Annotated\nfrom datetime import datetime, timezone\nfrom pydantic import BaseModel, PlainSerializer, BeforeValidator\n\n\nCustomDatetime = Annotated[\n    datetime,\n    BeforeValidator(lambda x: datetime.strptime(x, '%Y-%m-%dT%H:%M%z').astimezone(tz=timezone.utc)),\n    PlainSerializer(lambda x: x.strftime('%Y-%m-%dT%H:%M:%SZ'))\n]\n\n\nclass MyModel(BaseModel):\n    datetime_in_utc_with_z_suffix: CustomDatetime\n\n\nif __name__ == \"__main__\":\n    special_datetime = MyModel(datetime_in_utc_with_z_suffix=\"2042-3-15T12:45+01:00\")  # note the different timezone\n\n    # input conversion\n    print(special_datetime.datetime_in_utc_with_z_suffix)  # 2042-03-15 11:45:00+00:00\n\n    # output conversion\n    print(special_datetime.model_dump_json())  # {\"datetime_in_utc_with_z_suffix\": \"2042-03-15T11:45:00Z\"}\n"], [], ["conda install -c conda-forge prophet\n"], ["def add_translatable_field_to_model(model, field_name, field):\n    \"\"\"\n    This is functionally identical, except usage syntax.\n\n    Example usage:\n\n        # models.py\n        class Acme(models.Model):\n            code = models.CharField()\n\n        add_translatable_field_to_model(Acme, \"name\", models.CharField(blank=True, verbose_name=_(\"common name\")))\n        add_translatable_field_to_model(Acme, \"description\", models.TextField())\n    \"\"\"\n    for code, name in settings.LANGUAGES:\n        field.clone().contribute_to_class(model, f\"{field_name}_{code}\")\n\n    def local_translation_getter(self):\n        language_code = get_language_code()\n        return getattr(self, f\"{field_name}_{language_code}\", \"\")\n\n    setattr(model, field_name, property(local_translation_getter))\n", "def get_language_code():\n    \"\"\"\n    Gets the two letter code of the currently selected language, or the default \n   language if none specified, set by Django LocaleMiddleware.\n    \"\"\"\n    language = translation.get_language()\n    if language is None:\n        return settings.DEFAULT_LANGUAGE\n    available_language_codes = set(code for code, _ in settings.LANGUAGES)\n    if language not in available_language_codes and \"-\" in language:\n        language = language.split(\"-\")[0]\n    if language in available_language_codes:\n        return language\n    return settings.DEFAULT_LANGUAGE\n"], ["libdevice not found at ./libdevice.10.bc\n         [[{{node Adam/StatefulPartitionedCall_88}}]] [Op:__inference_train_function_10134]\n"], [], [], ["user_grade = int(input())\n\nif 9 <= user_grade <= 12:\n\n    print('in high school')\n\nelse:\n\n    print('not in high school')\n"], ["conda install -n base conda-libmamba-solver\n", "conda install tensorflow --solver=libmamba\n", "conda config --set solver libmamba\n"], [], [], ["import urllib.request\nimport ssl\n\n# Create a secure SSL context\nssl_context = ssl.SSLContext(ssl.PROTOCOL_TLS)  # Use the appropriate protocol\n\nurl = \"https://example.com\"  # Replace with your URL\nresponse = urllib.request.urlopen(url, context=ssl_context)\n\n# Read and process the response\ndata = response.read().decode(\"utf-8\")\n"], [], ["custom_ssl_context = ssl.create_default_context(ssl.Purpose.SERVER_AUTH)\ncustom_ssl_context.options |= 0x00040000 # OP flag SSL_OP_ALLOW_UNSAFE_LEGACY_RENEGOTIATION\n\nconnector = aiohttp.TCPConnector(ssl=custom_ssl_context)\n\nasync with aiohttp.ClientSession(connector=connector) as session:\n    async with session.get(url) as response:\n        return await response.text()\n", "custom_ssl_context.check_hostname = False\ncustom_ssl_context.verify_mode = ssl.CERT_NONE\n"], ["documents = SimpleDirectoryReader('../news').load_data()\nindex = GPTVectorStoreIndex.from_documents(documents)\n\nquery_engine = index.as_query_engine()\nr = query_engine.query(\"how did the pandemic effect business\")\nprint(r)\n"], ["RuntimeError: cannot reuse already awaited coroutine\n", "def auth_required(func):\n    @wraps(func)\n    async def wrapper(*args, **kwargs):\n        return func(*args, **kwargs) #DO NOT WAIT\n    return wrapper\n\n@app.post(\"/\")\n@auth_required # Custom decorator\ndef root(payload: SampleModel): #NOT ASYNC\n    return {\"message\": \"Hello World\", \"payload\": payload}\n"], ["\"python.pythonPath\": \"python3\",\n\"code-runner.executorMap\": {\n    \"python3\": \"/usr/bin/python3\"\n}\n", "\"python.pythonPath\": \"python3\",\n\"code-runner.executorMap\": {\n    \"python\": \"/usr/bin/python3\"\n}\n"], ["def fix_field_types(self):\n    for key, value in self.asdict().items():\n        field = self.__dataclass_fields__[key]\n        if not field.type == type(value):\n            new_value = field.type.__call__(value)\n            self.__setattr__(field.name, new_value)\n"], ["pip uninstall imblearn --yes\n", "conda install -c conda-forge imbalanced-learn\n"], ["FOR /F \"usebackq delims=\" %G IN (requirements.txt) DO poetry add --lock %G\n"], [], ["from selenium import webdriver \nfrom selenium.webdriver.chrome.options import Options\n\nchrome_options = Options()\n# chrome_options.add_argument(\"--disable-extensions\")\n# chrome_options.add_argument(\"--disable-gpu\")\n# chrome_options.add_argument(\"--no-sandbox\") # linux only\nchrome_options.add_argument(\"--headless=new\") # for Chrome >= 109\n# chrome_options.add_argument(\"--headless\")\n# chrome_options.headless = True # also works\ndriver = webdriver.Chrome(options=chrome_options)\nstart_url = \"https://duckgo.com\"\ndriver.get(start_url)\nprint(driver.page_source.encode(\"utf-8\"))\n# b'<!DOCTYPE html><html xmlns=\"http://www....\ndriver.quit()\n"], [], ["list_of_lists = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\nflattened_list = [element for sublist in list_of_lists for element in sublist]\nprint(flattened_list)\n", "list_of_lists = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\nflattened_list = list(itertools.chain(*list_of_lists))\nprint(flattened_list)\n", "list_of_lists = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\nflattened_list = sum(list_of_lists, [])\nprint(flattened_list)\n", "[1, 2, 3, 4, 5, 6, 7, 8, 9]\n"], ["df['ab_weighted'] = df.groupby('c').transform(pd.Series.sum, axis=0).apply(lambda x: x.a/x.b, axis=1)\n\n   a   b  c  ab_weighted\n0  1   7  q    0.294118\n1  2   8  q    0.294118\n2  3   9  q    0.294118\n3  4  10  q    0.294118\n4  5  11  w    0.478261\n5  6  12  w    0.478261\n", "df.groupby('c')[['a','b']].sum().assign(ab_weighted = lambda x: x.a/x.b)\n\n    a   b  ab_weighted\nc                     \nq  10  34     0.294118\nw  11  23     0.478261\n"], [], [], [], ["pip uninstall decouple\n", "pip install python-decouple\n"], [], [], ["kosinkie_l@Fedora ~/project/build $ python -c \"import tensorflow as tf; x = [[2.]]; print('tensorflow version', tf.__version__); print('hello, {}'.format(tf.matmul(x, x)))\"\n\n2022-08-09 15:31:03.414926: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\ntensorflow version 2.10.0-rc0\nhello, Tensor(\"MatMul:0\", shape=(1, 1), dtype=float32)\nkosinkie_l@Fedora ~/project/build $\n", "131 #ifndef __AVX__\n132     CheckIfFeatureUnused(CPUFeature::AVX, \"AVX\", missing_instructions);\n133 #endif  // __AVX__\n134 #ifndef __AVX2__\n135     CheckIfFeatureUnused(CPUFeature::AVX2, \"AVX2\", missing_instructions);\n136 #endif  // __AVX2__\n...\n192     if (!missing_instructions.empty()) {\n193       LOG(INFO) << \"This TensorFlow binary is optimized with \"\n194                 << \"oneAPI Deep Neural Network Library (oneDNN) \"\n195                 << \"to use the following CPU instructions in performance-\"\n196                 << \"critical operations: \" << missing_instructions << std::endl\n197                 << \"To enable them in other operations, rebuild TensorFlow \"\n198                 << \"with the appropriate compiler flags.\";\n199     }\n"], [], ["##++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n## Function to check all elements in a df column is same\n##+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\ndef check_all_are_equal_in_a_column_df(data_frame, column_name):\n    data_list = data_frame[column_name].unique()\n    data_set = set(data_list)\n    if((len(data_set)) == 1):\n        return_data = 1\n    else:\n        return_data = 0\n    return return_data\n"], [], [], [], [], [], ["sudo apt-get install python3-dev default-libmysqlclient-dev build-essential pkg-config\n"], [], [], [], ["n = int(input())\n\nfor x in range(1,n+1,1):\n    y = 3 * x + 2\n    if y % 4 != 0:\n       print(y)\n"], [], [], ["    str1 := \"bash\"\n    str2 := \"-c\"\n    str3 := \"pip install --no-cache -r requirements.txt -t /asset-output && cp -au . /asset-output\"\n    command := []*string{&str1, &str2, &str3}\n\n    lambdaFn := awslambda.NewFunction(stack, jsii.String(\"foo\"), &awslambda.FunctionProps{\n        Runtime: awslambda.Runtime_PYTHON_3_9(),\n        Handler: jsii.String(\"index.lambda_handler\"),\n        Timeout: awscdk.Duration_Seconds(jsii.Number(900)),\n        Code: awslambda.Code_FromAsset(jsii.String(\"lambda/foo/blah\"), &awss3assets.AssetOptions{\n            Bundling: &awscdk.BundlingOptions{\n                Image:   awslambda.Runtime_PYTHON_3_9().BundlingImage(),\n                Command: &command,\n            },\n        }),\n    })\n"], [], ["from selenium import webdriver\ndriver = webdriver.Chrome()\ndriver.get(\"https://www.selenium.dev/selenium/web/web-form.html\")\n", "from selenium import webdriver\nchrome_driver_path = 'C:/Users/Morteza/Documents/Dev/chromedriver.exe'\ndriver = webdriver.Chrome(executable_path=chrome_driver_path)\n\nurl = \"https://www.google.com\"\ndriver.get(url)\n", "from selenium import webdriver\nfrom selenium.webdriver.chrome.service import Service\n\ns=Service('C:/Users/Morteza/Documents/Dev/chromedriver.exe')\nbrowser = webdriver.Chrome(service=s)\nurl='https://www.google.com'\nbrowser.get(url)\n"], ["    options = ChromeOptions()\n    options.add_argument(\"start-maximized\")\n    options.binary_location = \"/opt/brave.com/brave/brave\"\n\n    browser = Chrome(options=options)\n"], [], ["import plotly.io as pio\n\npio.write_image(fig, \"figname.png\") \n"], ["ax.set_xticks(ax.get_xticks())\nax.set_yticks(ax.get_yticks())\n"], [], ["import pandas as pd\ndf = pd.DataFrame(df_list, columns=['{column_name1}','{column_name2}'])\n"], [], ["pip3 install tensorflow[and-cuda]\n"], ["if not files_present:\n    pd.to_csv(filename)\nelse:\n    print 'WARNING: This file already exists!'\n"], [], ["py -m ensurepip --upgrade\n"], [], [], [], ["def solution(A, K):\n    n = len(A)\n    return [A[(i-K)%n] for i in range(n)]\n"], ["{\n  .\n  .\n  \"autopep8.args\": [\"--max-line-length\", \"180\"]\n  .\n  .\n}\n"], ["    def push_pd_to_bq(self, df: pd.DataFrame, tabel: str, project: str, mode: str = 'append'):\n    df = df.copy()\n    df['commit_timestamp'] = pd.Timestamp('now', tz='Europe/Helsinki')\n    table_schema = [] # [{'name': 'col1', 'type': 'STRING'},...]\n    for col in df.columns:\n        if 'object' in str(df[col].dtype):\n             table_schema.append({'name': col, 'type': 'STRING'})\n        elif 'float' in str(df[col].dtype):\n            table_schema.append({'name': col, 'type': 'FLOAT64'})\n        elif 'datetime' in str(df[col].dtype):\n            table_schema.append({'name': col, 'type': 'TIMESTAMP'})\n        elif 'date' in col.lower():\n             table_schema.append({'name': col, 'type': 'DATE'})\n    df.to_gbq(destination_table=tabel, \n              if_exists=mode, \n              project_id=project, \n              table_schema=table_schema, \n              location='europe-north1')\n"], ["color_1 = int(input())\ncolor_2 = int(input())\ncolor_3 = int(input())\ngray = 50\nmini = 0\n\nmini= (min(color_1, color_2, color_3))\n\ncolor_1 = color_1 - mini\ncolor_2 = color_2 - mini\ncolor_3 = color_3 - mini\n\nprint(color_1, color_2, color_3)\n"], ["from setuptools import setup, find_packages\n\nsetup(\n    ...\n    packages=find_packages('src', exclude=['test']),\n    package_dir = {\"\": \"src\"},\n    ...\n)\n"], [], [], [], [], ["sudo pkill 'uvicorn'\n"], ["from werkzeug.contrib.fixers import ProxyFix\n", "from werkzeug.middleware.proxy_fix import ProxyFix\n"], [], ["from playwright.sync_api import Playwright, sync_playwright\nimport time\n\n\ndef run(playwright: Playwright) -> None:\n    browser = playwright.chromium.launch(headless=False)\n    context = browser.new_context()\n\n    # Open new page\n    page = context.new_page()\n\n    page.goto('https://www.youtube.com/')\n\n    # page.mouse.wheel(horizontally, vertically(positive is \n    # scrolling down, negative is scrolling up)\n    for i in range(5): #make the range as long as needed\n        page.mouse.wheel(0, 15000)\n        time.sleep(2)\n        \n    \n    time.sleep(15)\n    # ---------------------\n    context.close()\n    browser.close()\n\n\nwith sync_playwright() as playwright:\n    run(playwright)\n"], ["embed = discord.Embed(title=\"Title here\", description=\"\",\n                              timestamp=datetime.utcnow(),\n                              color=0x26ad00)\n\nfile = discord.File(f\"images/{msg.id}.png\")\nembed.set_image(url=f\"attachment://{msg.id}.png\")\nawait msg.edit(embed=embed, attachments=[file])\n"], ["sudo apt update\nsudo apt install python3.X-dev\n"], ["from sklearn.preprocessing import LabelEncoder, StandardScaler\n\nX = lbl_encoder_1.fit_transform(X)\n", "sc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.fit_transform(X_test)\n", "model.fit(X_train, y_train, batch_size = 10, epochs = 100)\n", "x_train = np.asarray(x_train).astype(np.float32)\n"], [], ["from . import widgets \nFile \"C:\\Users\\my_folder\\flask_env\\lib\\site-packages\\flask_wtf\\recaptcha\\widgets.py\", line 6, in <module>\nJSONEncoder = json.JSONEncoder\nAttributeError: module 'flask.json' has no attribute 'JSONEncoder'\n"], [], [], ["\"pylint.args\": [\n\"\\\"--generated-members\\\", \\\"torch.*\\\"\"\n"], ["pip install setuptools==58.2.0\n"], [], ["pip install keras --upgrade \n"], ["brew install mariadb\npip install mariadb\n"], [], ["    client.execute(\n        'SELECT * FROM test',\n        settings={'allow_experimental_object_type': 1}\n )\n[({'b': 1}, {'x': 2})]\n"], [], [], [], ["write_videofile(result_path, bitrate=bitrate, threads=64, verbose=False, preset='ultrafast', ffmpeg_params=['-loglevel', 'panic'], codec=\"libx264\")\n"], [], [], [], [], [], ["pip install aiohttp==3.9.0b0\n"], ["connexion[swagger-ui]<3\nflask>=2.0  \nWerkzeug>=2.0\ngunicorn>=20.0\n", "Successfully installed Werkzeug-2.2.3 connexion-2.14.2 flask-2.2.5\n"], [], ["torch.cuda.empty_cache()\ngc.collect()\n", "import os\nos.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:1024\"\n", "def __getitem__(self, i_dex, resize_=(320,480)):\n        transforms_ = transforms.Compose([\n                                        transforms.PILToTensor(),\n                        transforms.ConvertImageDtype(torch.float32),\n                                        ])\n        im_ = Image_.open(self.data_paths[i_dex])\n        if im_.mode !='RGB':\n            im_ = im_.convert('RGB')\n        im_ = im_.resize(resize_)\n      \n        return transforms_(im_), labels[i_dex]\n"], [" export FLASK_APP=main( name of your python file where you are running the app)\nexport FLASK_ENV=development\n\nflask db migrate -m \"Your migration message\"\n"], [], ["pip install aiohttp==3.9.0b0\n"], [], ["list_of_dfs = [df1, df2, dfx]\n# now remove all columns from the dataframes which are empty or have all-NA \ncleaned_list_of_dfs = [df.dropna(axis=1, how='all') for df in list_of_dfs]\noutput_df = pd.concat(cleaned_list_of_dfs)\n", "output_df= pd.concat(df.dropna(axis=1, how='all') for df in [df1, df2])\n"], [], [], ["for /f %i in (requirements.txt) do (poetry add %i)\n"], [], ["\"python.condaPath\": \"C:\\\\apps\\\\Anaconda3\\\\Scripts\\\\\",\n\"python.venvPath\": \"C:\\\\apps\\\\Anaconda3\\\\envs\",\n\"terminal.integrated.defaultProfile.windows\": \"Command Prompt\",\n", "\"python.condaPath\": \"C:\\\\apps\\\\Anaconda3\\\\Scripts\\\\\",\n\"python.venvPath\": \"C:\\\\apps\\\\Anaconda3\\\\envs\",\n"], ["pip install setuptools\n"], [], [], [], ["callbacks = [\nkeras.callbacks.ModelCheckpoint(\n    filepath=\"convnet_from_scratch.tf\",\n    save_best_only=True,\n    monitor=\"val_loss\",\n    save_format=\"tf\")\n]\nhistory = model.fit(\n    train_dataset,\n    epochs=30,\n    validation_data=validation_dataset,\n    callbacks=callbacks)\n", "test_model = keras.models.load_model(\"convnet_from_scratch.tf\")\ntest_loss, test_acc = test_model.evaluate(test_dataset)\nprint(f\"Test accuracy: {test_acc:.3f}\")\n"], [], [], ["\"[python]\": {\n        \"editor.defaultFormatter\": \"ms-python.autopep8\",\n        \"autopep8.args\": [\n            \"--max-lin-length\",\n            \"120\",\n            \"--experimental\"\n        ]\n  }\n"], ["aiohttp==3.9.0b0\n"], [], [], [], [], ["# FixedFormatter should only be used together with FixedLocator. \n# Otherwise, one cannot be sure where the labels will end up.\n", "from matplotlib import ticker\n\npositions = [0, 1, 2, 3, 4, 5]\nlabels = ['A', 'B', 'C', 'D', 'E', 'F']\nax.xaxis.set_major_locator(ticker.FixedLocator(positions))\nax.xaxis.set_major_formatter(ticker.FixedFormatter(labels))\n", "# FuncFormatter can be used as a decorator\n@ticker.FuncFormatter\ndef major_formatter(x, pos):\n    return f'{x:.2f}'\n", "ax.xaxis.set_major_locator(ticker.LogLocator(base=10, numticks=5))\nax.xaxis.set_major_formatter(major_formatter)\n"], [], ["\"jupyter.interactiveWindow.textEditor.executeSelection\": true\n"], ["#region conda initialize\n# !! Contents within this block are managed by 'conda init' !!\n(& \"C:\\Users\\USER\\anaconda3\\Scripts\\conda.exe\" \"shell.powershell\" \"hook\") | Out-String | Invoke-Expression\n#endregion\n"], ["df1 = pd.DataFrame({\"A\": [.1, .2, .3]})\ndf2 = pd.DataFrame(columns=[\"A\"], dtype=\"object\")\n\nout = pd.concat([df1, df2]) ; print(out)\n\n     A\n0  0.1\n1  0.2\n2  0.3\n", "out = (df1.copy() if df2.empty else df2.copy() if df1.empty\n       else pd.concat([df1, df2]) # if both DataFrames non empty\n      )\n", "out = pd.concat([df1.astype(df2.dtypes), df2.astype(df1.dtypes)])\n"], ["query_enginge = index.as_query_engine()\nresponse = query_engine.query(\"My query\")\n"], ["from PIL import Image as pil\nfrom pkg_resources import parse_version\nif parse_version(pil.__version__)>=parse_version('10.0.0'):\n    Image.ANTIALIAS=Image.LANCZOS\n"], [], [], ["user_grade = int(input())\n\nif 9 <= user_grade and user_grade <= 12:\n    print('in high school')\nelse:\n    print('not in high school')\n"], [], [], ["import threading\n\nclass RunThread(threading.Thread):\n    def __init__(self, func, args, kwargs):\n        self.func = func\n        self.args = args\n        self.kwargs = kwargs\n        self.result = None\n        super().__init__()\n\n    def run(self):\n        self.result = asyncio.run(self.func(*self.args, **self.kwargs))\n\ndef run_async(func, *args, **kwargs):\n    try:\n        loop = asyncio.get_running_loop()\n    except RuntimeError:\n        loop = None\n    if loop and loop.is_running():\n        thread = RunThread(func, args, kwargs)\n        thread.start()\n        thread.join()\n        return thread.result\n    else:\n        return asyncio.run(func(*args, **kwargs))\n", "async def test(name):\n    await asyncio.sleep(5)\n    return f\"hello {name}\"\n\nrun_async(test, \"user\")  # blocks for 5 seconds and returns \"hello user\"\n"], ["mkdir layer\ncp requirements.txt layer/requirements.txt\ndocker run -ti -v $(pwd)/layer:/app -w /app --entrypoint /bin/bash public.ecr.aws/lambda/python:3.11 -c \"pip3 install --target ./python -r requirements.txt\"\n"], ["def as_form(cls):\n    new_params = [\n        inspect.Parameter(\n            field_name,\n            inspect.Parameter.POSITIONAL_ONLY,\n            default=model_field.default,\n            annotation=Annotated[model_field.annotation, *model_field.metadata, Form()],\n        )\n        for field_name, model_field in cls.model_fields.items()\n    ]\n\n    cls.__signature__ = cls.__signature__.replace(parameters=new_params)\n\n    return cls\n", "def before_validate_int(value: int) -> int:\n    raise ValueError('before int')\n\n\nMyInt = Annotated[int, BeforeValidator(before_validate_int)]\n\n\n@as_form\nclass User(BaseModel):\n    age: MyInt\n\n\n@app.post(\"/postdata\")\ndef postdata(user: User = Depends()):\n    return {\"age\": user.age}\n", "{\n  \"detail\": [\n    {\n      \"type\": \"value_error\",\n      \"loc\": [\n        \"body\",\n        \"age\"\n      ],\n      \"msg\": \"Value error, before int\",\n      \"input\": \"12\",\n      \"ctx\": {\n        \"error\": {}\n      },\n      \"url\": \"https://errors.pydantic.dev/2.3/v/value_error\"\n    }\n  ]\n}\n\n"], [], [], ["python3 --version\npython3 -m pip install ipykernel\npython3 -m ipykernel install --user\n", "python3 -m pip install <package_name>\n"], [], ["from imblearn.combine import SMOTETomek\nfrom imblearn.under_sampling import NearMiss\n"], [], [], [], [], ["packages=find_packages(\n    where='src',\n    include=['mypackage'],\n),\n", "[tool.setuptools.packages.find]\nwhere = [\"src\"]\ninclude = [\"mypackage*\"]\n"], ["    data_types = {'program_type':'string','program_number':'int64','program_isan':'string','program_title':'string'}\n    df = pd.read_csv(local_file_path, dtype=data_types)\n"], ["FROM python:alpine\napk update && apk upgrade; \\\napk add pkgconfig; \\\napk add --no-cache gcc musl-dev mariadb-dev mariadb-connector-c-dev; \\\n"], ["same_val = np.amax(x) == np.amin(x) and len(x) > 1\n"], ["pip uninstall scikit-learn\n", "pip install scikit-learn==1.2.2\n"], [], ["class AllOptional(ModelMetaclass):\ndef __new__(self, name, bases, namespaces, **kwargs):\n    annotations = namespaces.get('__annotations__', {})\n    for base in bases:\n        optionals = {\n            key: Optional[value] if not key.startswith('__') else value for key, value in base.__annotations__.items()\n        }\n        annotations.update(optionals)\n\n    namespaces['__annotations__'] = annotations\n    return super().__new__(self, name, bases, namespaces, **kwargs)\n"], [], ["class AllOptional(pydantic.main.ModelMetaclass):\n    def __new__(mcls, name, bases, namespaces, **kwargs):\n        cls = super().__new__(mcls, name, bases, namespaces, **kwargs)\n        for field in cls.__fields__.values():\n            field.required=False\n        return cls\n"], ["pip install python-dotenv\n", "apt install python3-dotenv\n"], [], [], ["d0: 2021-01-01 00:00:00+00:00, timezone: UTC\n\nd1: 2021-01-01 00:00:00+00:00, timezone: UTC\n\nd2: 2021-01-01 00:00:00+00:00, timezone: UTC\n\nd3: 1 validation error for Datapoint\ntimestamp\n  Input should have timezone info [type=timezone_aware, input_value='2021-01-01T00:00:00', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.3/v/timezone_aware\n\nd4: 1 validation error for Datapoint\ntimestamp\n  Value error, Timezone must be UTC [type=value_error, input_value='2021-01-01T00:00:00+02:00', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.3/v/value_error\n"], ["from pydantic import BaseModel, create_model\n\nclass Item(BaseModel):\n    name: str\n    description: str\n    price: float\n    tax: float\n\nUpdateItem = create_model(\n    'UpdateItem',\n    __base__=Item,\n    **{k: (v.annotation, None) for k, v in Item.model_fields.items()}\n)\n", "In [410]: Item.model_fields\nOut[410]: \n{'name': FieldInfo(annotation=str, required=True),\n 'description': FieldInfo(annotation=str, required=True),\n 'price': FieldInfo(annotation=float, required=True),\n 'tax': FieldInfo(annotation=float, required=True)}\n\nIn [411]: UpdateItem.model_fields\nOut[411]: \n{'name': FieldInfo(annotation=str, required=False),\n 'description': FieldInfo(annotation=str, required=False),\n 'price': FieldInfo(annotation=float, required=False),\n 'tax': FieldInfo(annotation=float, required=False)}\n\nIn [412]: UpdateItem()\nOut[412]: UpdateItem(name=None, description=None, price=None, tax=None)\n"], ["{\n    \"key\": \"ctrl+enter\",\n    \"command\": \"extension.pycmd\",\n    \"when\": \"editorTextFocus && editorLangId == 'python'\"\n}\n"], [" ax2.xaxis.set_major_locator(mdates.DayLocator(bymonthday=ttick_solar))\n ax2.set_xticklabels(label_solar)\n"], [], [], ["!sudo apt-get install python<your-python-version>-distutils\n", "sudo apt-get install python3.8-distutils\n"], [], [], [], [], [], [], ["pip uninstall urllib3\npip install 'urllib3<2.0'\n"], [], [], [], [], [], ["python -m build  # builds both sdist and wheel\n"], [], [], [], [], [], ["brew uninstall youtube-dl\nbrew install --HEAD youtube-dl    \n"], ["docker ps # to get the CONTAINER ID\ndocker stop <CONTAINER ID>\n"], [], [], [], ["import os\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '1' \n\nimport tensorflow as tf\n"], [], ["sudo apt update && sudo apt install pkg-config\n"], [], [], ["def save_model_checkpoint(epoch, logs):\n    if logs['val_loss'] < save_model_checkpoint.best_val_loss:\n        save_model_checkpoint.best_val_loss = logs['val_loss']\n        model.save_weights(new_base_dir / 'model_checkpoint')\n        print('Model checkpoint saved.')\n\nsave_model_checkpoint.best_val_loss = float('inf')\n\n# Initialize your model here\n\nmodel.fit(\n    # Other model.fit arguments...\n    callbacks=[tf.keras.callbacks.LambdaCallback(on_epoch_end=save_model_checkpoint)]\n )\n"], [], ["FROM python:3.11-alpine\nWORKDIR /usr/src/app\nCOPY requirements.txt .\nRUN apk add --no-cache --virtual build-deps gcc musl-dev libffi-dev2 pkgconf mariadb-dev && \\\n    apk add --no-cache mariadb-connector-c-dev && \\\n    pip install --no-cache-dir -r requirements.txt && \\\n    apk del build-deps\nCOPY . .\nCMD [\"python\", \"manage.py\", \"runserver\", \"0.0.0.0:8000\"]\n", "mysqlclient==2.2.0\nDjango~=4.2.0\n"], ["img = cv2.resize(img,(int(model_height*ratio),model_height),interpolation=Image.ANTIALIAS)AttributeError: module 'PIL.Image' has no attribute 'ANTIALIAS'\n", "pip uninstall Pillow\npip install Pillow==9.5.0\n"], ["keras.callbacks.ModelCheckpoint(\n        filepath=\"convnet_from_scratch.keras\",\n        ..)\n", "keras.callbacks.ModelCheckpoint(\n        filepath=\"convnet_from_scratch.x\",\n        ..)\n"], [], ["FROM python:3.11.3-slim-bullseye\n\nRUN apt-get update \\\n    && apt-get upgrade -y \\\n    && apt-get install -y gcc default-libmysqlclient-dev pkg-config \\\n    && rm -rf /var/lib/apt/lists/*\n\nWORKDIR /usr/src/app\nCOPY . .\n\nRUN pip install --upgrade pip \\\n    && pip install mysqlclient \\\n    && pip install -r requirements.txt\n\nCMD [\"python\", \"manage.py\", \"runserver\", \"0.0.0.0:8000\"]\n"], [], [], [], ["import PIL\nimport numpy as np\n\n# Gradient image with a sharp color boundary across the diagonal\nlarge_arr = np.fromfunction(lambda x, y, z: (x+y)//(z+1),\n                            (256, 256, 3)).astype(np.uint8)\nlarge_img = PIL.Image.fromarray(large_arr)\n\n# Resize it: PIL.Image.LANCZOS also works here\nsmall_img = large_img.resize((128, 128), PIL.Image.Resampling.LANCZOS)\nprint(small_img.size)\n\nlarge_img.show()\nsmall_img.show()\n\n"], [], ["from llama_index import GPTVectorStoreIndex, ..\n"], [], [], ["    # Latex/Mactex needed \n    # To install on macOS:\n    # brew install --cask mactex\n    # eval \"$(/usr/libexec/path_helper)\"\n    jupyter nbconvert --to pdf my_notebook.ipynb\n"], ["python -m venv venv\n"], [], ["urllib3<2\n"], [], ["import os\n\nimage_width = 1280\nimage_height = 720\n\ndef yolo_to_voc_convertion(input_file, output_file):\n    with open(input_file, 'r') as f:\n        lines = f.readlines()\n\n    new_lines = list()\n    for line in lines:\n        data = line.strip().split(' ')\n\n        class_id = int(data[0])\n        x_center = float(data[1])\n        y_center = float(data[2])\n        width = float(data[3])\n        height = float(data[4])\n\n        x_min = int((x_center - (width / 2)) * image_width)\n        y_min = int((y_center - (height / 2)) * image_height)\n        x_max = int((x_center + (width / 2)) * image_width)\n        y_max = int((y_center + (height / 2)) * image_height)\n\n        new_data = f'{class_id} {x_min} {y_min} {x_max} {y_max}\\n'\n        new_lines.append(new_data)\n\n    with open(output_file, 'w') as f:\n        f.writelines(new_lines)\n\ninput_folder = '..' # folder that includes .txt files\noutput_folder = '..' # output folder that will be included new format ann files\n\nfor filename in os.listdir(input_folder):\n    if filename.endswith('.txt'):\n        input_file = os.path.join(input_folder, filename)\n        output_file = os.path.join(output_folder, filename)\n\n        yolo_to_voc_convertion(input_file, output_file)\n"], ["conda create -n <environment_name> python=3.8.3\n\nconda activate <environment_name>\n", "code\n"], [], ["sudo apt install git\n", "sudo apt install pip\n", "sudo pip install --upgrade --force-reinstall \"git+https://github.com/ytdl-org/youtube-dl.git\"\n"], ["driver = webdriver.Chrome(ChromeDriverManager().install())\n\n# Or\ns = Service('C:/Users/Downloads/chromedriver/chromedriver.exe')\ndriver = webdriver.Chrome(service=s)\n\n# Or\ndriver = webdriver.Chrome('/path/to/chromedriver')\n", "from selenium import webdriver\n\ndriver = webdriver.Chrome()\ndriver.get(\"https://www.google.com\")\n"], [], [], ["from typing import Optional, Type, Any, Tuple\nfrom copy import deepcopy\n\nfrom pydantic import BaseModel, create_model\nfrom pydantic.fields import FieldInfo\n\n\ndef partial_model(model: Type[BaseModel]):\n    def make_field_optional(field: FieldInfo, default: Any = None) -> Tuple[Any, FieldInfo]:\n        new = deepcopy(field)\n        new.default = default\n        new.annotation = Optional[field.annotation]  # type: ignore\n        return new.annotation, new\n    return create_model(\n        f'Partial{model.__name__}',\n        __base__=model,\n        __module__=model.__module__,\n        **{\n            field_name: make_field_optional(field_info)\n            for field_name, field_info in model.__fields__.items()\n        }\n    )\n", "@partial_model\nclass Model(BaseModel):\n    i: int\n    f: float\n    s: str\n\n\nModel(i=1)\n"], ["FROM python:3.11-alpine\nWORKDIR /usr/src/app\nCOPY requirements.txt .\nRUN apk update\nRUN apk add pkgconfig\nRUN apk add --no-cache gcc musl-dev mariadb-connector-c-dev \nRUN pip install --no-cache-dir -r requirements.txt\nCOPY . .\nCMD [\"python\", \"manage.py\", \"runserver\", \"0.0.0.0:8000\"]\n"], [], ["requests==2.28.2\n"], ["conda activate venv\n"], ["# Set OP_LEGACY_SERVER_CONNECT option\nOpenSSL::SSL::SSLContext::DEFAULT_PARAMS[:options] |= OpenSSL::SSL::OP_LEGACY_SERVER_CONNECT\n\n# Make a request\nuri = URI('https://example.com')\nres = Net::HTTP.post(uri, {}.to_json)\n\n# Unset OP_LEGACY_SERVER_CONNECT option\nOpenSSL::SSL::SSLContext::DEFAULT_PARAMS[:options] &= ~OpenSSL::SSL::OP_LEGACY_SERVER_CONNECT\n"], [], ["pip uninstall Flask  \n", "pip install Flask==2.2.3 \n"], ["pip install .\n"], ["def solution(A): \n     \n    num = 0\n\n    for i in range(len(A)): \n        num = num ^ A[i]        \n         \n    return num\n"], [], [], [">>> PatchPoll()\nPatchPoll(id=UUID('dcd80011-e81e-41fb-872b-4f82839a2a76'), subject='', description='')\n>>> PatchPoll().__fields_set__\nset()\n>>> PatchPoll(subject=\"jskdlfjk\").__fields_set__\n{'subject'}\n", "def remove_defaults(baseclass: Type[T]) -> Type[T]:\n    validators = {\"__validators__\": baseclass.__validators__}\n    fields = baseclass.__fields__\n\n    def remove_default(item: pydantic.fields.ModelField) -> pydantic.fields.FieldInfo:\n        info = item.field_info\n        if info.default == pydantic.fields.Undefined and not info.default_factory:\n            raise RuntimeError(\"Field has no default\")\n\n        # Funny enough, if we don't keep the default for Optional types,\n        # openapi-generator will not make it optional at all.\n        if item.allow_none:\n            return copy.copy(item.field_info)\n\n        return pydantic.Field(\n            alias=item.field_info.alias,\n            title=item.field_info.title,\n            description=item.field_info.description,\n            exclude=item.field_info.exclude,\n            include=item.field_info.include,\n            const=item.field_info.const,\n            gt=item.field_info.gt,\n            ge=item.field_info.ge,\n            lt=item.field_info.lt,\n            le=item.field_info.le,\n            multiple_of=item.field_info.multiple_of,\n            allow_inf_nan=item.field_info.allow_inf_nan,\n            max_digits=item.field_info.max_digits,\n            decimal_places=item.field_info.decimal_places,\n            min_items=item.field_info.min_items,\n            max_items=item.field_info.max_items,\n            unique_items=item.field_info.unique_items,\n            min_length=item.field_info.min_length,\n            max_length=item.field_info.max_length,\n            allow_mutation=item.field_info.allow_mutation,\n            regex=item.field_info.regex,\n            discriminator=item.field_info.discriminator,\n            repr=item.field_info.repr,\n        )\n\n    nondefault_fields = {\n        key: (item.type_, remove_default(item)) for key, item in fields.items()\n    }\n\n    return pydantic.create_model(\n        __model_name=f\"{baseclass.__name__}Optional\",\n        __base__=baseclass,\n        __validators__=validators,\n        **nondefault_fields,\n    )\n\n\nclass PatchPoll(pydantic.BaseModel):\n    id: UUID = pydantic.Field(default_factory=uuid4)\n    subject: str = pydantic.Field(max_length=1024, default=\"\")\n    description: Optional[str] = pydantic.Field(max_length=1024 * 1024, default=\"\")\n\n\nclass Poll(remove_defaults(PatchPoll)):\n    ...\n"], [], ["def solution(A, K):\n\n        n = len(A)`enter code here`\n        K = K % n # Ensure K is within the range of array size \n        rotated_arr = A[K:] + A[:K] # Rotating from end to the starting\n        return rotated_arr\n    A = [1, 2, 3, 4]\n    K = int(input())\n    rotated_arr = solution(A, K)\n    print(rotated_arr)\n"], [], ["async scrollIntoView (locator : Locator) {\n        let i = 0;\n        while(await locator.isHidden()) {\n            await this.page.locator('your locator goes here').click();\n            await this.page.mouse.wheel(0, 300);\n            i++;\n            if (await locator.isVisible()) { return; }\n            else if (i >= 5) { return; }\n        }\n    }\n"], ["sudo apt-get install python3-dev\n"], [], ["from selenium import webdriver\nfrom selenium.webdriver.chrome.service import Service\nservice = Service(r\"C:\\chromedriver.exe\")\noptions = webdriver.ChromeOptions()\ndriver = webdriver.Chrome(service=service, options=options)\n"], ["from json import JSONEncoder\n"], ["from flask_wtf import FlaskForm\n", "Flask-WTF~=1.1.1\n"], ["python3 -m pip install --force-reinstall https://github.com/yt-dlp/yt-dlp/archive/master.tar.gz\n", "python3 /Library/Frameworks/Python.framework/Versions/3.7/bin/yt-dlp --no-check-certificate \"https://www.youtube.com/watch?v=QvkQ1B3FBqA\"\n"], [], [], [], [], [], [], [], [], ["nvidia-smi\n", ">>> import torch\n>>> torch.zeros(1).cuda()\n"], ["sudo apt install cuda-11-8\n"], ["$ conda install pytorch torchvision torchaudio cudatoolkit=11.1\n", "$ conda list pytorch\npytorch                   2.0.0               py3.9_cpu_0    pytorch\npytorch-mutex             1.0                         cpu    pytorch\ncudatoolkit               11.1.1              heb2d755_10    conda-forge\n", "$ conda install pytorch torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia\n$ conda install -c anaconda cudatoolkit\n", "$ conda list pytorch\npytorch                   2.0.0           py3.9_cuda11.8_cudnn8_0    pytorch\npytorch-cuda              11.8                 h24eeafa_3    pytorch\npytorch-mutex             1.0                        cuda    pytorch\ncudatoolkit               11.3.1               h59b6b97_2    anaconda\n"], [], ["for /f \"tokens=*\" %%i in (requirements.txt) do (\n    poetry add %%i\n)\n"], [], [], ["import ssl\nimport urllib.request\n\nurl = 'http://....'\n\n# Set up SSL context to allow legacy TLS versions\nctx = ssl.create_default_context(ssl.Purpose.SERVER_AUTH)\nctx.options |= 0x4  # OP_LEGACY_SERVER_CONNECT\n\n# Use urllib to open the URL and read the content\nresponse = urllib.request.urlopen(url, context=ctx)\n"], [], [], [], [], ["sudo apt-get install cuda-toolkit\n"], [], [], ["python3 -m venv --system-site-packages /c/python/python39/python39_venv\ncd /c/python/python39/python39_venv\nsource /c/python/python39/python39_venv/source/bin/activate\npip install {module of choice}=={version of choice}\n", "/c/Python/Python39/Scripts/python.exe -m venv --system-site-packages /c/python/python39/python39_venv\n", "View > Command Palette > type: \"Python: Select Interpreter\" > type \"C:/Python/Python39/python39_venv/Scripts/python.exe\"\n"], ["openssl_conf = openssl_init\n\n[openssl_init]\nssl_conf = ssl_sect\n\n[ssl_sect]\nsystem_default = system_default_sect\n\n[system_default_sect]\nOptions = UnsafeLegacyRenegotiation\n", "OPENSSL_CONF=/path/to/custom/openssl.cnf python your_scraper.py\n", "export OPENSSL_CONF=/path/to/custom/openssl.cnf\npython your_scraper.py\n", "OPENSSL_CONF=/path/to/custom/openssl.cnf\n"], [], ["def render_template(template):\n    \"\"\"decorator to render a template with a context\"\"\"\n    def decorator(func):\n        @wraps(func)\n        def wrapper(*args, **kwargs):\n\n            # access request object\n            request = kwargs.get('request')\n\n            context = func(*args, **kwargs)\n            if context is None:\n                context = {}\n            return templates.TemplateResponse(template, {**context, 'request': request})\n        return wrapper\n    return decorator\n"], ["#!/usr/bin/python3\n"], ["    ydl = youtube_dl.YoutubeDL({'outtmpl': '%(id)s%(ext)s'})\n    from __future__ import unicode_literals\n    import youtube_dl\n    ydl_opts = {\n         'format': 'bestaudio/best',\n        'postprocessors': [{\n            'key': 'FFmpegExtractAudio',\n            'preferredcodec': 'mp3',\n            'preferredquality': '192'\n        }],\n        'postprocessor_args': [\n            '-ar', '16000'\n        ],\n        'prefer_ffmpeg': True,\n        'keepvideo': True\n    }\n    with youtube_dl.YoutubeDL(ydl_opts) as ydl:\n        ydl.download(['link'])\n\nuse this:\nfrom pytube import YouTube\nimport os\n\nyt = YouTube('link')\n\nvideo = yt.streams.filter(only_audio=True).first()\n\nout_file = video.download(output_path=\".\")\n\nbase, ext = os.path.splitext(out_file)\nnew_file = base + '.mp3'\nos.rename(out_file, new_file)\n"], ["flask --app flask_app_directory_name db init\n"], ["df = df.astype(str)\n"], [], [], ["import torch\nimport time\nimport gc\nfrom pynvml import nvmlInit, nvmlDeviceGetHandleByIndex, nvmlDeviceGetMemoryInfo\n\ndef clear_gpu_memory():\n    torch.cuda.empty_cache()\n    gc.collect()\n    del variables\n\ndef wait_until_enough_gpu_memory(min_memory_available, max_retries=10, sleep_time=5):\n    nvmlInit()\n    handle = nvmlDeviceGetHandleByIndex(torch.cuda.current_device())\n\n    for _ in range(max_retries):\n        info = nvmlDeviceGetMemoryInfo(handle)\n        if info.free >= min_memory_available:\n            break\n        print(f\"Waiting for {min_memory_available} bytes of free GPU memory. Retrying in {sleep_time} seconds...\")\n        time.sleep(sleep_time)\n    else:\n        raise RuntimeError(f\"Failed to acquire {min_memory_available} bytes of free GPU memory after {max_retries} retries.\")\n\n# Usage example\nmin_memory_available = 2 * 1024 * 1024 * 1024  # 2GB\nclear_gpu_memory()\nwait_until_enough_gpu_memory(min_memory_available)\n"], [], [">>> tf.sysconfig.get_build_info() \nOrderedDict([('cpu_compiler', '/usr/bin/x86_64-linux-gnu-gcc-11'), \n('cuda_compute_capabilities', ['compute_86']), \n('cuda_version', '12.0'), ('cudnn_version', '8'), \n('is_cuda_build', True), ('is_rocm_build', False), ('is_tensorrt_build', True)])\n"], [], [], [], ["# Create conda environment\nconda create --name cuda_venv\nconda activate cuda_venv\n\n# Install pytorch following commands from https://pytorch.org/get-started/locally/ \nconda install pytorch torchvision torchaudio pytorch-cuda=11.6 -c pytorch -c nvidia\n", "import torch\nprint(torch.cuda.is_available()) \n"], [], [], [], ["file_timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\ndf.to_csv(file_name + '_' + file_timestamp + '.csv')\n", "file_timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\ndf.to_csv(file_name + '_' + file_timestamp + '.csv')\n"], [], [], ["options.add_argument(\"--headless=new\")\n"], ["   Requires-Dist: aiohttp (==3.8.1)\n", "   Requires-Dist: aiohttp (==3.8.4)\n", " python -pip instal (file_location)/alpaca_trade_api-2.3.0-py3-none-any.whl \n"], [], ["python3 -m pip install --force-reinstall https://github.com/yt-dlp/yt-dlp/archive/master.tar.gz\n", "yt-dlp URL\n", "import yt_dlp as youtube_dl\n"], [], ["kill -9 $(ps -ef | grep uvicorn  | awk '{print $2}')\n", "alias uvicornprocess=\"kill -9 $(ps -ef | grep uvicorn  | awk '{print $2}')\" \n"], [], ["from werkzeug.middleware.profiler import ProfilerMiddleware\napp = ProfilerMiddleware(app)\n"], [], ["!pip install cython\n", "!pip install --force-reinstall virtualenv\n"], ["docker pull selenium/standalone-chrome\ndocker run --rm -d -p 4444:4444 --shm-size=2g selenium/standalone-chrome\n", "driver = webdriver.Remote('http://localhost:4444/wd/hub', webdriver.DesiredCapabilities.CHROME)\ndriver.set_window_size(1280, 1024)\ndriver.get('https://www.google.com')\n"], ["def make_partial_model(model: Type[BaseModel], optional_fields: Optional[list[str]] = None) -> Type[BaseModel]:\n    class NewModel(model):\n        ...\n\n    for field in NewModel.__fields__.values():\n        if not optional_fields or field in optional_fields:\n            field.required = False\n\n    NewModel.__name__ = f'Partial{model.__name__}'\n    return NewModel\n\nPartialRequest = cast(Type[RequestModel], make_partial_model(RequestModel))\n"], [], [], ["pip wheel --no-deps -w dist .\n", "python setup.py bdist_wheel\n"], [], [], [], ["import itertools\n\ndef all_equal(iterable):\n    \"Returns True if all elements are equal\"\n    g = itertools.groupby(iterable)\n    next(g, None)\n    try:\n        return not next(g, False)\n    except TypeError:  # pd.NA next to a different value?\n        return False\n\nall_equal(df.counts)\n", "constant_columns = df.columns[df.apply(all_equal)]\n", "df.counts.min() == df.counts.max()\n"], ["options.add_argument(\"--headless\")\n", "options.add_argument(\"--no-sandbox\");\noptions.add_argument(\"--disable-dev-shm-usage\");\noptions.add_argument(\"--disable-renderer-backgrounding\");\noptions.add_argument(\"--disable-background-timer-throttling\");\noptions.add_argument(\"--disable-backgrounding-occluded-windows\");\noptions.add_argument(\"--disable-client-side-phishing-detection\");\noptions.add_argument(\"--disable-crash-reporter\");\noptions.add_argument(\"--disable-oopr-debug-crash-dump\");\noptions.add_argument(\"--no-crash-upload\");\noptions.add_argument(\"--disable-gpu\");\noptions.add_argument(\"--disable-extensions\");\noptions.add_argument(\"--disable-low-res-tiling\");\noptions.add_argument(\"--log-level=3\");\noptions.add_argument(\"--silent\");\n"], ["{\n\n    \"version\": \"2.0.0\",\n    \"tasks\": [\n        {\n            \"label\": \"Build Python Env\",\n            \"type\": \"shell\",\n            \"group\": {\n                \"kind\": \"build\",\n                \"isDefault\": true\n            },\n            \"linux\": {\n                \"options\": {\n                    \"cwd\": \"${workspaceFolder}\"\n                },\n                \"command\": \"python3 -m venv py_venv && source py_venv/bin/activate && python3 -m pip install --upgrade pip && python3 -m pip install -r requirements.txt && deactivate py_venv\"\n            },\n            \"osx\": {\n                \"options\": {\n                    \"cwd\": \"${workspaceFolder}\"\n                },\n                \"command\": \"python3 -m venv py_venv && source py_venv/bin/activate && python3 -m pip install --upgrade pip && python3 -m pip install -r requirements.txt && deactivate py_venv\"\n            },\n            \"windows\": {\n                \"options\": {\n                    \"shell\": {\n                        \"executable\": \"C:\\\\Windows\\\\system32\\\\cmd.exe\",\n                        \"args\": [\n                            \"/d\",\n                            \"/c\"\n                        ]\n                    },\n                    \"cwd\": \"${workspaceFolder}\"\n                },\n                \"command\": \"(if not exist py_venv py -m venv py_venv) && .\\\\py_venv\\\\Scripts\\\\activate.bat && py -m pip install --upgrade pip && py -m pip install -r requirements.txt && deactivate py_venv\"\n            },\n            \"problemMatcher\": []\n        }\n    ]\n}\n"], [], [], ["from pydantic import BaseModel, create_model\nfrom typing import Optional\nfrom functools import lru_cache\n\n@lru_cache(maxsize=None) # avoids creating many classes with same name\ndef make_optional(baseclass: Type[BaseModel]) -> Type[BaseModel]:\n    # Extracts the fields and validators from the baseclass and make fields optional\n    fields = baseclass.__fields__\n    validators = {'__validators__': baseclass.__validators__}\n    optional_fields = {key: (Optional[item.type_], None)\n                       for key, item in fields.items()}\n    return create_model(f'{baseclass.__name__}Optional', **optional_fields,\n                        __validators__=validators)\n\nclass Item(BaseModel):\n    name: str\n    description: str\n    price: float\n    tax: float\n\nItemOptional = make_optional(Item)\n", "> Item.__fields__\n\n{'name': ModelField(name='name', type=str, required=True),\n 'description': ModelField(name='description', type=str, required=True),\n 'price': ModelField(name='price', type=float, required=True),\n 'tax': ModelField(name='tax', type=float, required=True)}\n\n> ItemOptional.__fields__\n\n{'name': ModelField(name='name', type=Optional[str], required=False, default=None),\n 'description': ModelField(name='description', type=Optional[str], required=False, default=None),\n 'price': ModelField(name='price', type=Optional[float], required=False, default=None),\n 'tax': ModelField(name='tax', type=Optional[float], required=False, default=None)}\n", "@app.post(\"/items\", response_model=Item)\nasync def post_item(item: Item = Depends()):\n    ...\n\n@app.patch(\"/items/{item_id}\", response_model=Item)\nasync def update_item(item_id: str, item: make_optional(Item) = Depends()):\n    ...\n", "def make_optional_no_id(baseclass):\n    ... # same as make optional\n    optional_fields = {key: (Optional[item.type_], None) \n                       for key, item in fields.items() if key != 'ID'} # take out here ID\n    ... # you can also take out also validators of ID\n\n@app.patch(\"/items/{item_id}\", response_model=Item)\nasync def update_item(item: make_optional_no_id(Item) = Depends()):\n"], ["data = my_series.to_numpy()\n", "data = my_series.to_list()\n", "dataset = tf.data.Dataset.from_tensor_slices((data, labels))\n"], [], [], [], ["pip install numpy==1.24.1\n"], ["sudo apt-get install python3.10-distutils\n"], [], ["\"code-runner.executorMap\": {\n    ...\n    \"python\": \"python -u\"\n    ...\n}\n", "\"code-runner.executorMap\": {\n    ...\n    \"python\": \"python3 -u\"\n    ...\n}\n"], [], ["import requests\nimport urllib3\nimport ssl\n\n\nclass CustomHttpAdapter (requests.adapters.HTTPAdapter):\n    # \"Transport adapter\" that allows us to use custom ssl_context.\n\n    def __init__(self, ssl_context=None, **kwargs):\n        self.ssl_context = ssl_context\n        super().__init__(**kwargs)\n\n    def init_poolmanager(self, connections, maxsize, block=False):\n        self.poolmanager = urllib3.poolmanager.PoolManager(\n            num_pools=connections, maxsize=maxsize,\n            block=block, ssl_context=self.ssl_context)\n\n\ndef get_legacy_session():\n    ctx = ssl.create_default_context(ssl.Purpose.SERVER_AUTH)\n    ctx.options |= 0x4  # OP_LEGACY_SERVER_CONNECT\n    session = requests.session()\n    session.mount('https://', CustomHttpAdapter(ctx))\n    return session\n", "get_legacy_session().get(\"some-url\")\n"], [], ["pip install setuptools==58.2.0\n"], ["sudo apt-get install python3.9-distutils\n"], [], ["heatmap = sb.heatmap(pd.DataFrame(full_dict).T.fillna(0), annot=True, linewidths=1, xticklabels=1, yticklabels=1, annot_kws={'rotation': 90})\ncbar = heatmap.collections[0].colorbar\ncbar.ax.set_yticklabels(cbar.ax.get_yticklabels(), rotation=90, va='center')\n", "heatmap = sb.heatmap(pd.DataFrame(full_dict).T.fillna(0), annot=True, linewidths=1, xticklabels=1, yticklabels=1, annot_kws={'rotation': 90})\ncbar = heatmap.collections[0].colorbar\ncbar.ax.tick_params(axis='y', labelrotation=90)\n"], [], [], [], [">> nvidia-smi -mig 0\n"], [], [], ["    ```` conda uninstall pytorch \n     conda install pytorch torchvision cudatoolkit=11.3 -c pytorch -c conda-forge ````\n"], ["aiohttp==3.8.1\nyarl==1.4.2\nfrozenlist==1.3.0\n", "aiohttp==3.8.2\nyarl==1.8.1\nfrozenlist==1.3.1\n"], [], [], ["import aiohttp\nconn = aiohttp.TCPConnector(limit_per_host=5)\n\nasync with aiohttp.ClientSession(connector=conn) as session:\n"], [], ["from dataclasses import dataclass, fields\n\n@dataclass()\nclass Test:\n    value: int\n\n    def __post_init__(self):\n        for field in fields(self):\n            setattr(self, field.name, field.type(getattr(self, field.name)))\n", ">>> test = Test('1')\n>>> type(test.value)\n<class 'int'>\n"], ["message = await message.channel.send('Live') \nwhile True:\n    mss().shot(output=\"foo.png\") #mss is used to make a screenshot but the basic concept is you have to update the image file but keep the filename\n    await message.add_files(discord.File(fp=\"foo.png\"))\n    \n\n"], ["import os\nimport pybboxes as pbx\nimport cv2\n\nDATA_PATH = \"<data_path>\"\n                                                  \nfor i in sorted(os.listdir(DATA_PATH)):\n    print(i)\n    if i[-1]==\"g\":\n        img = cv2.imread(os.path.join(DATA_PATH, i))\n        print(os.path.join(DATA_PATH, i))\n\n        fl = open(os.path.join(DATA_PATH, f\"{i[:-3]}txt\"), 'r')\n        data = fl.readlines()\n        fl.close()\n\n        H, W = img.shape[:2]\n\n        for dt in data:\n            _, x, y, w, h = map(float, dt.split(' '))\n            box_voc = pbx.convert_bbox((x,y,w,h), from_type=\"yolo\", to_type=\"voc\", image_size=(W,H))\n\n            cv2.rectangle(img, (box_voc[0], box_voc[1]), (box_voc[2], box_voc[3]), (0, 0, 255), 3)\n        cv2.imshow(i, img)\n        cv2.waitKey(0)\n        cv2.destroyAllWindows()\n\n\n"], ["--max-line-length\n", "120\n", "--experimental\n"], [], ["## pip install pybboxes \nimport pybboxes as pbx\n\nyolo_normalized = (0.048765432089567184, 0.6583333611488342, 0.09753086417913437, 0.29814815521240234) \n\nH, W = img.shape[:2]\n\nbox_voc = pbx.convert_bbox(yolo_normalized, from_type=\"yolo\", to_type=\"voc\", image_size=(W,H))\n\nprint(box_voc)\n\n# [Out]: (0, 153, 29, 242)\n\n## for plotting:\n\ncv2.rectangle(img, (box_voc[0], box_voc[1]), (box_voc[2], box_voc[3]), (0, 0, 255), 1)\n"], [], ["###############################\n# 1. Install extension \"macros\" in Visual Code\n#\n# Hit View on top menu\n# Search for extension named \"macros\" (by geddski)\n# Install \"macros\" extension\n#\n###############################\n\n\n###############################\n# 2. Add code below to keybindings.json\n#\n# Hit <Ctrl> + <Shift> + <P>\n# Enter in search bar: JSON\n# Select Open keyboard shortcuts\n#\n###############################\n\n{\n        \"key\": \"ctrl+enter\",\n        \"command\": \"macros.pythonExecSelectionAndCursorDown\",\n        \"when\": \"editorTextFocus && editorLangId == 'python'\"\n    }\n\n\n###############################\n# 3. Add code below to settings.json\n#\n# Hit <Ctrl> + <Shift> + <P>\n# Enter in search bar: JSON\n# Select Open settings \n#\n###############################\n\n\"macros\": {  // Note: this requires macros extension by publisher:\"geddski\" \n        \"pythonExecSelectionAndCursorDown\": [\n            \"python.execSelectionInTerminal\", \n            \"cursorDown\" \n        ]\n    }\n"], [], ["sudo apt install python-is-python3\n"], [], [], [], [], ["pipenv install\n"], [], [], [], [], ["Test(value=1)\nTest(value=12)\ninvalid literal for int() with base 10: '3.21'\n"], ["class IntConversionDescriptor:\n\n    def __set_name__(self, owner, name):\n        self._name = \"_\" + name\n\n    def __get__(self, instance, owner):\n        return getattr(instance, self._name)\n\n    def __set__(self, instance, value):\n        setattr(instance, self._name, int(value))\n\n\n@dataclass\nclass Test:\n    value: IntConversionDescriptor = IntConversionDescriptor()\n", ">>> test = Test(value=1)\n>>> type(test.value)\n<class 'int'>\n\n>>> test = Test(value=\"12\")\n>>> type(test.value)\n<class 'int'>\n\ntest.value = \"145\"\n>>> type(test.value)\n<class 'int'>\n\ntest.value = 45.12\n>>> type(test.value)\n<class 'int'>\n"], ["$env:XLA_FLAGS=\"--xla_gpu_cuda_data_dir='C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v11.7'\"\n"], ["from io import StringIO\n# temporarily store the dataframe as a csv in a string variable\ntemp_csv_string = df.to_csv(sep=\";\", index=False)\ntemp_csv_string_IO = StringIO(temp_csv_string)\n# create new dataframe from string variable\nnew_df = pd.read_csv(temp_csv_string_IO, sep=\";\")\n# this new df can be uploaded to BQ with no issues\nnew_df.to_gbq(table_id, project_id, if_exists=\"append\")\n"], ["poetry add redis --group=extras\n", "[tool.poetry.group.extras.dependencies]\n"], ["    while page.locator(\"span\",has_text=\"End of results\").is_visible() is False:\n        page.mouse.wheel(0,100)\n        #page.keyboard.down(PageDown) also works\n"], [], [], [], [], [], [], [], ["class AnyForm(BaseModel):\n    any_param: str\n    any_other_param: int = 1\n\n    @classmethod\n    def as_form(\n        cls,\n        any_param: str = Form(...),\n        any_other_param: int = Form(1)\n    ) -> AnyForm:\n        return cls(any_param=any_param, any_other_param=any_other_param)\n\n@router.post('')\nasync def any_view(form_data: AnyForm = Depends(AnyForm.as_form)):\n        ...\n", "import inspect\nfrom typing import Type\n\nfrom fastapi import Form\nfrom pydantic import BaseModel\nfrom pydantic.fields import ModelField\n\ndef as_form(cls: Type[BaseModel]):\n    new_parameters = []\n\n    for field_name, model_field in cls.__fields__.items():\n        model_field: ModelField  # type: ignore\n\n        new_parameters.append(\n             inspect.Parameter(\n                 model_field.alias,\n                 inspect.Parameter.POSITIONAL_ONLY,\n                 default=Form(...) if model_field.required else Form(model_field.default),\n                 annotation=model_field.outer_type_,\n             )\n         )\n\n    async def as_form_func(**data):\n        return cls(**data)\n\n    sig = inspect.signature(as_form_func)\n    sig = sig.replace(parameters=new_parameters)\n    as_form_func.__signature__ = sig  # type: ignore\n    setattr(cls, 'as_form', as_form_func)\n    return cls\n", "@as_form\nclass Test(BaseModel):\n    param: str\n    a: int = 1\n    b: str = '2342'\n    c: bool = False\n    d: Optional[float] = None\n\n\n@router.post('/me', response_model=Test)\nasync def me(request: Request, form: Test = Depends(Test.as_form)):\n    return form\n"], ["n= int(input())\ncount=0\nx=1\nwhile(count<n):\n    y=3*x+2\n    if(y%4!=0):\n        print(y, end=' ')\n        count=count+1\n    x=x+1\n"], ["\"jupyter.sendSelectionToInteractiveWindow\": true\n"], [], [], ["def solution(A):    \n    for i in set(A):\n    if A.count(i) == 1:\n        return i\n", "from collections import Counter\ndef solution(A): \n    c = Counter(A)\n    final = [k for k, v in c.items() if v == 1]\n    return final[0]\n", "def solution(A):\n    A.sort()\n    A.append(-1) #Just to make list even and run till last but not match with existing integers\n    for i in range(0,len(A),2):\n        if A[i]!=A[i+1]:\n            return A[I]\n"], ["async def edit_attachments(message: discord.Message, files: File):\n    await message.remove_attachments(message.attachments)\n    await message.add_files(files)\n"], ["from functools import reduce\n\nmy_list = [[1, 2], [10, 5], [-4, 5]]\n\nreduce(lambda a, b: a + b, my_list)\n"], ["blankIndex=[''] * len(df)\ndf.index=blankIndex\ndf\n\n"], ["import plotly.express as px\n\n# a sample scatter plot figure created\nfig = px.scatter(x=range(10), y=range(10))\nfig.write_html(\"path/to/file.html\")\n"], ["page.evaluate(\n    \"\"\"\n    var intervalID = setInterval(function () {\n        var scrollingElement = (document.scrollingElement || document.body);\n        scrollingElement.scrollTop = scrollingElement.scrollHeight;\n    }, 200);\n\n    \"\"\"\n)\nprev_height = None\nwhile True:\n    curr_height = page.evaluate('(window.innerHeight + window.scrollY)')\n    if not prev_height:\n        prev_height = curr_height\n        time.sleep(1)\n    elif prev_height == curr_height:\n        page.evaluate('clearInterval(intervalID)')\n        break\n    else:\n        prev_height = curr_height\n        time.sleep(1)\n"], ["# Note that this dockerfile is only used to build the lambda asset - the\n# lambda still just runs with a zip source, not a docker image.\n# See the docstring for aws_lambda.Code.from_docker_build\nFROM public.ecr.aws/lambda/python:3.9.2022.04.27.10-x86_64\n\nCOPY index.py /asset/\nCOPY requirements.txt /tmp/\nRUN pip3 install -r /tmp/requirements.txt -t /asset\n"], [], ["from selenium import webdriver\nfrom selenium.webdriver.chrome.options import Options\nchrome_options = Options()\nchrome_options.add_argument(\"--headless\")\ndriver = webdriver.Chrome(executable_path=r\"C:\\Program \nFiles\\Google\\Chrome\\Application\\chromedriver.exe\", options=chrome_options)\n"], ["pip install prophet --no-cache-dir\n"], ["@dataclasses.dataclass\nclass Test:\n    value: int\n\n    def __post_init__(self):\n        self.value = int(self.value)\n", ">>> test = Test(\"42\")\n>>> type(test.value)\n<class 'int'>\n", "@attr.define\nclass Test:\n    value: int = attr.field(converter=int)\n", ">>> test = Test(\"42\")\n>>> type(test.value)\n<class 'int'>\n", "@dataclasses.dataclass\nclass Test:\n    value: int\n", ">>> test = cattrs.structure({\"value\": \"42\"}, Test)\n>>> type(test.value)\n<class 'int'>\n", "class Test(pydantic.BaseModel):\n    value: int\n", ">>> test = Test(value=\"42\")\n>>> type(test.value)\n<class 'int'>\n"], [], [], [], ["ax.set_xticks([1,2,3])\nax.set_xtickslabels(['Label1', 'Label2', 'Label3'])\n"], [], ["with torch.no_grad():\n  for m in self.children():\n    m.cuda()\n    m.eval()\n    x = m(x)\n    m.cpu()\n    torch.cuda.empty_cache()\n"], [], ["{\n    \"key\": \"ctrl+enter\",\n    \"command\": \"macros.pythonExecSelectionAndCursorDown\",\n    \"when\": \"editorTextFocus && editorLangId == 'python' && resourceExtname == '.py'\"\n}\n"], [], ["from pathlib import Path\n\nwith Path(\"myfile.html\").open(\"w\") as f:\n    f.write(fig.to_html())\n"], ["unique = df.apply(lambda row: len(row.unique()) == 1, axis=1)\n"], ["df.set_index('CLASS').isna().groupby(level=0).sum()\n", "# Will be deprecated soon.. do not use. You should use above statement instead.\ndf.set_index('CLASS').isna().sum(level=0)\n", "       FEATURE1  FEATURE2  FEATURE3\nCLASS                              \nX           1.0       1.0       2.0\nB           0.0       0.0       0.0\n"], [], ["if resp.status_code == 200:\n    print ('OK!')\nelse:\n    print ('Boo!')\n", "if resp.ok:\n    print ('OK!')\nelse:\n    print ('Boo!')\n"], ["! LaTeX Error: File `ucharcat.sty' not found\n"], [], [], ["pip install --upgrade pip setuptools wheel\n"], [], [], ["from selenium.webdriver.chrome.service import Service\n\nchrome_executable = Service(executable_path='chromedriver.exe', log_path='NUL')\ndriver = webdriver.Chrome(service=chrome_executable)\n"], ["if 200 <= resp.status_code <= 299:\n    print ('OK!') \nelse:\n    print ('Boo!')\n"], [], [], [], ["function solution($a){\n      $result  = array_count_values($a);\n     $result = array_filter($result , function($a){\n           return ($a  % 2) && 1;\n     });\n    return key($result);   \n}\n"], [], [], ["sudo apt-get install --reinstall python3.7-distutils\n"], ["cd path\\pyproject\npath\\myproject> py -3 -m venv venv\npath\\myproject> venv\\Scripts\\activate\n"], [], [], ["$ poeareq --help\n\nusage: poeareq [-h] [-D] [requirements.txt files ...]\n\nAdd dependencies specified in requirements.txt to your Poetry project\n\npositional arguments:\n  requirements.txt file(s)\n                        Path(s) to your requirements.txt file(s) (default: requirements.txt)\n\noptions:\n  -h, --help            show this help message and exit\n  -D, --dev             Add to development dependencies (default: False)\n"], [], [], ["from fastapi.testclient import TestClient\nfrom fastapi import FastAPI, Depends, Form\nfrom pydantic import BaseModel\n\n\napp = FastAPI()\n\n\ndef form_body(cls):\n    cls.__signature__ = cls.__signature__.replace(\n        parameters=[\n            arg.replace(default=Form(...))\n            for arg in cls.__signature__.parameters.values()\n        ]\n    )\n    return cls\n\n\n@form_body\nclass Item(BaseModel):\n    name: str\n    another: str\n\n\n@app.post('/test', response_model=Item)\ndef endpoint(item: Item = Depends(Item)):\n    return item\n\n\ntc = TestClient(app)\n\n\nr = tc.post('/test', data={'name': 'name', 'another': 'another'})\n\nassert r.status_code == 200\nassert r.json() == {'name': 'name', 'another': 'another'}\n"], [], ["conda install -c anaconda cudatoolkit\n"], [], ["X_train =t ensorflow.convert_to_tensor(X_train, dtype=tensorflow.float32)\ny_train = tensorflow.convert_to_tensor(y_train, dtype=tensorflow.float32)\nX_test = tensorflow.convert_to_tensor(X_test, dtype=tensorflow.float32)\ny_test = tensorflow.convert_to_tensor(y_test, dtype=tensorflow.float32)\n"], [], ["error: Can't find libdevice directory ${CUDA_DIR}/nvvm/libdevice\n", "$ find / -type d -name nvvm 2>/dev/null\n/usr/lib/cuda/nvvm\n$ cd /usr/lib/cuda/nvvm\n/usr/lib/cuda/nvvm$ ls\nlibdevice\n/usr/lib/cuda/nvvm$ cd libdevice\n/usr/lib/cuda/nvvm/libdevice$ ls\nlibdevice.10.bc\n", "export XLA_FLAGS=--xla_gpu_cuda_data_dir=/usr/lib/cuda\n"], [], ["ax.set_xticklabels(ax.get_xticklabels(), rotation=45)\nax.xaxis.set_major_locator(dates.DayLocator())\n", "ax.tick_params(axis='x', labelrotation = 45)\n"], ["{\n\"workbench.colorTheme\": \"Default Dark+\",\n\"code-runner.executorMap\": {\n\n    \"javascript\": \"node\",\n    \"java\": \"cd $dir && javac $fileName && java $fileNameWithoutExt\",\n    \"c\": \"cd $dir && gcc $fileName -o $fileNameWithoutExt && $dir$fileNameWithoutExt\",\n    \"cpp\": \"cd $dir && g++ $fileName -o $fileNameWithoutExt && $dir$fileNameWithoutExt\",\n    \"objective-c\": \"cd $dir && gcc -framework Cocoa $fileName -o $fileNameWithoutExt && $dir$fileNameWithoutExt\",\n    \"php\": \"php\",\n    \"python\": \"python -u\",\n    \"perl\": \"perl\",\n    \"perl6\": \"perl6\",\n    \"ruby\": \"ruby\",\n    \"go\": \"go run\",\n    \"lua\": \"lua\",\n    \"groovy\": \"groovy\",\n    \"powershell\": \"powershell -ExecutionPolicy ByPass -File\",\n    \"bat\": \"cmd /c\",\n    \"shellscript\": \"bash\",\n    \"fsharp\": \"fsi\",\n    \"csharp\": \"scriptcs\",\n    \"vbscript\": \"cscript //Nologo\",\n    \"typescript\": \"ts-node\",\n    \"coffeescript\": \"coffee\",\n    \"scala\": \"scala\",\n    \"swift\": \"swift\",\n    \"julia\": \"julia\",\n    \"crystal\": \"crystal\",\n    \"ocaml\": \"ocaml\",\n    \"r\": \"Rscript\",\n    \"applescript\": \"osascript\",\n    \"clojure\": \"lein exec\",\n    \"haxe\": \"haxe --cwd $dirWithoutTrailingSlash --run $fileNameWithoutExt\",\n    \"rust\": \"cd $dir && rustc $fileName && $dir$fileNameWithoutExt\",\n    \"racket\": \"racket\",\n    \"scheme\": \"csi -script\",\n    \"ahk\": \"autohotkey\",\n    \"autoit\": \"autoit3\",\n    \"dart\": \"dart\",\n    \"pascal\": \"cd $dir && fpc $fileName && $dir$fileNameWithoutExt\",\n    \"d\": \"cd $dir && dmd $fileName && $dir$fileNameWithoutExt\",\n    \"haskell\": \"runhaskell\",\n    \"nim\": \"nim compile --verbosity:0 --hints:off --run\",\n    \"lisp\": \"sbcl --script\",\n    \"kit\": \"kitc --run\",\n    \"v\": \"v run\",\n    \"sass\": \"sass --style expanded\",\n    \"scss\": \"scss --style expanded\",\n    \"less\": \"cd $dir && lessc $fileName $fileNameWithoutExt.css\",\n    \"FortranFreeForm\": \"cd $dir && gfortran $fileName -o $fileNameWithoutExt && $dir$fileNameWithoutExt\",\n    \"fortran-modern\": \"cd $dir && gfortran $fileName -o $fileNameWithoutExt && $dir$fileNameWithoutExt\",\n    \"fortran_fixed-form\": \"cd $dir && gfortran $fileName -o $fileNameWithoutExt && $dir$fileNameWithoutExt\",\n    \"fortran\": \"cd $dir && gfortran $fileName -o $fileNameWithoutExt && $dir$fileNameWithoutExt\"\n}\n", "\"python\": \"python -u\",\n", "\"python\": \"python3\",\n"], ["@Before\npublic void setup() {\n    WebDriverManager.chromedriver().setup();\n    ChromeOptions options = new ChromeOptions();\n    // Bypass Cloudflare checks\n    options.setExperimentalOption(\"useAutomationExtension\", false);\n    options.addArguments(\"--disable-blink-features=AutomationControlled\");\n    driver = new ChromeDriver(options);\n    driver.manage().window().maximize();\n}\n"], ["export SYSTEM_VERSION_COMPAT=1\n"], [], ["client.query_dataframe(sql).to_json(orient='records',default_handler=str)\n"], ["DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n", "pip3 install -U selenium\n", "pip3 install webdriver-manager\n", "from selenium import webdriver\nfrom selenium.webdriver.chrome.service import Service\nfrom webdriver_manager.chrome import ChromeDriverManager\n\ndriver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\ndriver.get(\"https://www.google.com\")\n", "[WDM] - ====== WebDriver manager ======\n[WDM] - Current google-chrome version is 96.0.4664\n[WDM] - Get LATEST driver version for 96.0.4664\n[WDM] - Driver [C:\\Users\\Admin\\.wdm\\drivers\\chromedriver\\win32\\96.0.4664.45\\chromedriver.exe] found in cache\n", "from selenium import webdriver\nfrom selenium.webdriver.chrome.options import Options\nfrom selenium.webdriver.chrome.service import Service\nfrom webdriver_manager.chrome import ChromeDriverManager\n\noptions = Options()\noptions.add_argument(\"start-maximized\")\ndriver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\ndriver.get(\"https://www.google.com\")\n"], [], ["import tensorflow.compat.v1 as tf\ntf.disable_v2_behavior()\n"], [], ["import asyncio\nfrom aiohttp import ClientSession\n\n\nasync def main():\n    url = \"https://stackoverflow.com/\"\n\n    async with ClientSession() as session:\n        async with session.get(url, ssl=False) as resp:\n            print(resp.status)\n\nasyncio.run(main())\n"], [], [], [], ["XLA_FLAGS=--xla_gpu_cuda_data_dir=/usr/local/cuda-11.4\n"], ["import torch\ntorch.cuda.empty_cache()\n", "import gc\ndel variables\ngc.collect()\n", "torch.cuda.memory_summary(device=None, abbreviated=False)\n"], [], [], ["from selenium.webdriver import Firefox\nfrom selenium import webdriver\nfrom selenium.webdriver.firefox.service import Service\nfrom selenium.webdriver.firefox.options import Options\n\nprofile_path = r'C:\\Users\\Admin\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\s8543x41.default-release'\noptions=Options()\noptions.set_preference('profile', profile_path)\noptions.set_preference('network.proxy.type', 1)\noptions.set_preference('network.proxy.socks', '127.0.0.1')\noptions.set_preference('network.proxy.socks_port', 9050)\noptions.set_preference('network.proxy.socks_remote_dns', False)\nservice = Service('C:\\\\BrowserDrivers\\\\geckodriver.exe')\ndriver = Firefox(service=service, options=options)\ndriver.get(\"https://www.google.com\")\ndriver.quit()\n", "from selenium import webdriver\nfrom selenium.webdriver.firefox.options import Options\nfrom selenium.webdriver.chrome.service import Service\n\noptions = Options()\noptions.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\noptions.add_experimental_option('excludeSwitches', ['enable-logging'])\noptions.add_experimental_option('useAutomationExtension', False)\noptions.add_argument('--disable-blink-features=AutomationControlled')\ns = Service('C:\\\\BrowserDrivers\\\\geckodriver.exe')\ndriver = webdriver.Chrome(service=s, options=options)\n", "from selenium.webdriver import Firefox  \nfrom selenium import webdriver\nfrom selenium.webdriver.firefox.service import Service\nfrom selenium.webdriver.firefox.options import Options\nimport os\n\ntorexe = os.popen(r'C:\\Users\\username\\Desktop\\Tor Browser\\Browser\\TorBrowser\\Tor\\tor.exe')\nprofile_path = r'C:\\Users\\username\\Desktop\\Tor Browser\\Browser\\TorBrowser\\Data\\Browser\\profile.default'\nfirefox_options=Options()\nfirefox_options.set_preference('profile', profile_path)\nfirefox_options.set_preference('network.proxy.type', 1)\nfirefox_options.set_preference('network.proxy.socks', '127.0.0.1')\nfirefox_options.set_preference('network.proxy.socks_port', 9050)\nfirefox_options.set_preference(\"network.proxy.socks_remote_dns\", False)\nfirefox_options.binary_location = r'C:\\Users\\username\\Desktop\\Tor Browser\\Browser\\firefox.exe'\nservice = Service('C:\\\\BrowserDrivers\\\\geckodriver.exe')\ndriver = webdriver.Firefox(service=service, options=firefox_options)\ndriver.get(\"https://www.tiktok.com/\")\n"], ["ctx = ssl.create_default_context(ssl.Purpose.SERVER_AUTH)\nctx.options |= 0x4\nsession.mount('https://', CustomHttpAdapter(ctx))\n"], ["git clone https://github.com/Microsoft/vcpkg.git\ncd vcpkg\n./bootstrap-vcpkg.sh\n./vcpkg integrate install\n./vcpkg install sentencepiece:x64-windows-static\n"], ["pip install webdriver-manager\n", "from selenium.webdriver.firefox.service import Service\nfrom webdriver_manager.firefox import GeckoDriverManager\ndriver = webdriver.Firefox(service=Service(executable_path=GeckoDriverManager().install()))\n"], ["def solution(A,K):        \n    for k in np.arange(K):\n        B=[]\n        for i in range(len(A)):\n            B.append(A[i-1])\n        A=B\n    return B\n"], ["vs_buildtools.exe --norestart --passive --downloadThenInstall --includeRecommended --add Microsoft.VisualStudio.Workload.NativeDesktop --add Microsoft.VisualStudio.Workload.VCTools --add Microsoft.VisualStudio.Workload.MSBuildTools\n"], [], ["from pyvirtualdisplay import Display\ndisplay = Display(visible=0, size=(800, 800))  \ndisplay.start()\n", "    #Display in order to avoid CloudFare bot detection\n    display = Display(visible=0, size=(800, 800))  \n    display.start()\n  \n    options = webdriver.ChromeOptions()\n    options.add_argument('--no-sandbox')\n    options.add_argument('start-maximized')\n    options.add_argument('enable-automation')\n    options.add_argument('--disable-infobars')\n    options.add_argument('--disable-dev-shm-usage')\n    options.add_argument('--disable-browser-side-navigation')\n    options.add_argument(\"--remote-debugging-port=9222\")\n    # options.add_argument(\"--headless\")\n    options.add_argument('--disable-gpu')\n    options.add_argument(\"--log-level=3\")\n    driver = webdriver.Chrome(ChromeDriverManager().install(), chrome_options=options)\n"], [], [], [], ["def solution(A):\n    cloned = []\n    A.sort()\n    if len(A) > 1:\n       for itr in A:\n          if itr in cloned:\n             itrindex = cloned.index(itr)\n             cloned.pop(itrindex)\n          else:\n             cloned.append(itr)\n    else:\n        return A[0]\n\n    return cloned[0]\n"], [">>> import pystan\n>>> model_code = 'parameters {real y;} model {y ~ normal(0,1);}'\n>>> model = pystan.StanModel(model_code=model_code)\n>>> y = model.sampling().extract()['y']\n>>> y.mean()  # with luck the result will be near 0\n"], [], ["conda activate <NAME_OF_VENV>\npip install notebook\nconda install nbconvert\nconda install pandoc\nconda deactivate\n", "sudo apt install texlive-xetex\n"], ["K = range(2,10)\n\nfor k in K:\n\n  kmeanModel = KMeans(n_clusters=k)\n\n  kmeanModel.fit(data)\n\n  distortions.append(kmeanModel.inertia_)\n"], [], ["from itertools import islice, count\n\nN = 10\nl = list(islice((x for i in count(start=1) if (x:=3*i+2)%4), N))\n"], ["limit = 10\ncounter = 0\nn = 0\n\nwhile counter != limit:\n    n += 1\n    statement = (3*n)+2\n    if (statement % 4 != 0) and (statement > 4):\n        print(statement)\n    counter += 1\n"], ["n = int (input())\ncounter = 0\nfor x in range (1, n + 1, 1):\n    for y in range (1, 100, 1):\n        z = 3 * y + 2\n        if counter >= 10:\n            break\n        if z % 4 != 0:\n            print(z, end=' ')\n            counter += 1\n"], [], [], ["{\n   {\n     \"python.pythonPath\": \"VirtualEnPath/bin/python3.6\"\n   }\n}\n"], ["$ cat requirements.txt | xargs poetry add\n"], [], ["from datetime import datetime\n\ntime_expected = datetime.now()\ntime_actual = datetime.strptime(time_actual.isoformat(), \"%Y-%m-%dT%H:%M:%S.%f\")\nassert time_actual == time_expected\n", "from datetime import datetime\n\ntime_expected = datetime.now()\ntime_actual = datetime.fromisoformat(time_expected.isoformat())\nassert time_actual == time_expected\n"], [], [], [], [], [], [], [], [], [], [], [], ["def slice(A):\n    B = []\n    for i  in range(0,len(A)) :\n        B.append(A[-1+i])\n    return B \n\ndef solution(A, K):\n    for i in range (1,K+1):\n        A = slice(A)\n    return A\n"], [], []]