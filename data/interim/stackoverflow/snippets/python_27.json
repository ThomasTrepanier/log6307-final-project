[[], [], [], ["pip install pipwin\n\npipwin install cairocffi\n"], ["def n_elements_per_call(iterable, n=100):\n    buffer = []\n    for i in iterable:\n        buffer.append(i)\n        if len(buffer) < n:\n            continue\n        yield buffer\n        buffer.clear()\n    if buffer:\n        yield buffer\n\nmy_list = list(range(959))\nfor nums in n_elements_per_call(my_list):\n    print(nums)\n\n"], ["@bot.command()\nasync def userprofile(ctx, member:discord.Member):\n    await ctx.send(member.avatar)\n"], [], [], ["python -m pip install --upgrade pip\n"], [" # define a basic city class\n    class City:\n        name = \"\"\n        country = \"\"\n        elevation = 0 \n        population = 0\n\n# create a new instance of the City class and\n# define each attribute\ncity1 = City()\ncity1.name = \"Cusco\"\ncity1.country = \"Peru\"\ncity1.elevation = 3399\ncity1.population = 358052\n\n# create a new instance of the City class and\n# define each attribute\ncity2 = City()\ncity2.name = \"Sofia\"\ncity2.country = \"Bulgaria\"\ncity2.elevation = 2290\ncity2.population = 1241675\n\n# create a new instance of the City class and\n# define each attribute\ncity3 = City()\ncity3.name = \"Seoul\"\ncity3.country = \"South Korea\"\ncity3.elevation = 38\ncity3.population = 9733509\n\ndef max_elevation_city(min_population):\n    # Initialize the variable that will hold \n# the information of the city with \n# the highest elevation \n    return_city = City()\n\n    # Evaluate the 1st instance to meet the requirements:\n    # does city #1 have at least min_population and\n    # is its elevation the highest evaluated so far?\n    if city1.population > min_population and city1.elevation > return_city.elevation:\n        return_city = city1\n    # Evaluate the 2nd instance to meet the requirements:\n    # does city #2 have at least min_population and\n    # is its elevation the highest evaluated so far?\n    if city2.population > min_population and city2.elevation > return_city.elevation:\n        return_city = city2\n    # Evaluate the 3rd instance to meet the requirements:\n    # does city #3 have at least min_population and\n    # is its elevation the highest evaluated so far?\n    if city3.population > min_population and city3.elevation > return_city.elevation:\n        return_city = city3\n\n    #Format the return string\n    if return_city.name:\n        return \"{}, {}\".format(return_city.name, return_city.country)\n    else:\n        return \"\"\n\nprint(max_elevation_city(100000)) # Should print \"Cusco, Peru\"\nprint(max_elevation_city(1000000)) # Should print \"Sofia, Bulgaria\"\nprint(max_elevation_city(10000000)) # Should print \"\"\n"], ["model.compile(optimizer='adam',\n              loss='binary_crossentropy',\n              metrics=['accuracy',tf.keras.metrics.Precision(),tf.keras.metrics.Recall()])\n"], [">>> list_c = [-14, 7, -9, 2]\n>>> print(max(enumerate(list_c), key=lambda x: x[1]))\n(1, 7)\n"], [], ["import seaborn as sns\nimport matplotlib.pyplot as plt\n\n# legend and other functionalities will be controlled by matplotlib.pyplot\nfig, ax = plt.subplots()\n\n# your plot (it is generated by seaborn)\nsns.relplot(...)\n\n# position your legend\nlgd = ax.legend(loc = 'upper center', bbox_to_anchor = (0.5, -0.13),\n          fancybox = True, shadow = True, ncol = 2)\n\n# here bbox_extra_artists and bbox_inches = 'tight' will make sure the saved figure is not trimming the legend if it goes outside of the figure\nplt.savefig(\"plot.jpg\", bbox_extra_artists = (lgd,), bbox_inches = 'tight')\n"], [], [], ["from urllib import request\nfrom bs4 import BeautifulSoup\nimport re\nimport os\nimport urllib\n\n# connect to website and get list of all pdfs\nurl=\"http://openclassroom.stanford.edu/MainFolder/DocumentPage.php?course=Compilers&doc=docs/slides.html\"\npdfPath = \"http://openclassroom.stanford.edu/MainFolder/courses/Compilers/docs/\"\nresponse = request.urlopen(url).read()\nsoup= BeautifulSoup(response, \"html.parser\")     \nlinks = soup.find_all('a', href=re.compile(r'(.pdf)'))\n\n\n# clean the pdf link names\nurl_list = []\nfor el in links:\n    if(el['href'].startswith('http')):\n        url_list.append(el['href'])\n    else:\n        url_list.append(pdfPath + el['href'])\n\nprint(f'url_list: {url_list}\\n')\n\n\n# download the pdfs to a specified location\nfor url in url_list:\n    print(f'urL: {url}\\n')\n    fullfilename = os.path.join(r'standfordPdfs', url.replace(pdfPath, \"\"))\n    print(f'fullfilename: {fullfilename}')\n    request.urlretrieve(url, fullfilename)\n    \n"], ["lst = [1, 2, 3]\n\nans = list(map(lambda x: x ** 2, filter(lambda x: x % 2 != 0, lst)))\n\nprint(ans)\n"], [], [">pip show numpy\n", "import tensorflow as tf\nprint(tf.__version__)\nimport numpy as np\nprint(np.__version__)\n", "pip uninstall numpy # (till you uninstall all versions)\npip install numpy==1.16.4\n", "import tensorflow as tf\nprint(tf.__version__)\nimport numpy as np\nprint(np.__version__)\n"], ["keccak256(\n  abi.encodePacked(\n    hex'ff',\n    factory,\n    keccak256(abi.encode(key.token0, key.token1, key.fee)),\n    POOL_INIT_CODE_HASH\n  )\n)\n", "encoded_internal_data = abi.encode(['address', 'address', 'uint24'], (token0, token1, fee))\nkey_hash = web3.solidityKeccak(['bytes'], [encoded_internal_data])\nencoded_full_data = encode_abi_packed(\n    [\"bytes1\", \"address\", \"bytes\", \"bytes\"],\n    (HexBytes('ff'), UNISWAPV3_FACTORY_ADDRESS, key_hash, HexBytes(UNISWAPV3_POOL_INIT_CODE_HASH))\n)\npair_address = web3.solidityKeccak(['bytes'], [encoded_full_data])[12:].hex()\n"], ["#import numpy methods\nfrom numpy import *\n\n#initialize two array\narr1 = array([2, 6, 8, 1, 3])\narr2 = array([1, 6, 2, 1, 5])\n\n#declare an empty array\narr3=([])\n\n#find length of first array\nn=len(arr1)\n\n#traverse using for loop\nfor i in range(0,n):\n        #append sum of both array in final array\n        arr3.append(arr1[i]+arr2[i])\n\n#print final array\nprint(arr3)\n"], [], ["from timeit import default_timer as timer\nstart = timer()\nlist1 = [\"apple\", \"banana\", \"cherry\"]\nprint(list1)\nstop =timer()\nprint(stop-start)\n\nstart =timer()\nthislist = list((\"apple\", \"banana\", \"cherry\"))\nprint (thislist)\nstop =timer()\nprint(stop-start)\n"], ["import re\nn_rows = 50\n\npath_ = 'your_file_location'\n\nwith open(path_,'r') as f:\n    data = []\n    for i in range(n_rows): # read only 50 rows here. \n        for line in f:\n            if re.match('^#',line):\n                data.append(line)\n\nstart_col = max(enumerate(data))[0]\n\n\ndf = pd.read_csv(path_,sep='\\s+',skiprows=start_col) # use your actual delimiter.\n\n          #      Time            Cd        Cs        Cl    CmRoll   CmPitch  \\\n0  0.000005  1.899018  1.491993e-11  2.195012 -0.011086 -1.086380  0.009591   \n1  0.000010  2.142851  1.004511e-08  2.505163 -0.012652 -1.236757  0.010822   \n\n      CmYaw     Cd(f)     Cd(r)     Cs(f)     Cs(r)     Cl(f)  Cl(r)  \n0  0.938423  0.960595  0.009591 -0.009591  0.011126  2.183886    NaN  \n1  1.058773  1.084078  0.010822 -0.010822  0.015825  2.489338    NaN  \n", "df = pd.read_csv(path_,sep='\\s+',skiprows=start_col + 1, header=None)\ndf.columns = pd.read_csv(path_,sep='\\s+',skiprows=start_col,nrows=0).columns[1:]\n\nprint(df)\n\n       Time        Cd            Cs        Cl    CmRoll   CmPitch     CmYaw  \\\n0  0.000005  1.899018  1.491993e-11  2.195012 -0.011086 -1.086380  0.009591   \n1  0.000010  2.142851  1.004511e-08  2.505163 -0.012652 -1.236757  0.010822   \n\n      Cd(f)     Cd(r)     Cs(f)     Cs(r)     Cl(f)     Cl(r)  \n0  0.938423  0.960595  0.009591 -0.009591  0.011126  2.183886  \n1  1.058773  1.084078  0.010822 -0.010822  0.015825  2.489338 \n"], [" # cd /usr/lib\n # sudo ln ./libcrypt.so libcrypt.so.1\n # docker-compose -v\n\n docker-compose version 1.29.2, build 5becea4c\n"], ["compiler:\n solc:\n  version: '0.8.4'\n"], [], ["ValueError: setting an array element with a sequence\nValueError: 'transform' must be an instance of 'matplotlib.transform.Transform'\n"], [], ["# from dbutils import FileInfo # Not required in databricks\n# from dbruntime.dbutils import FileInfo # may work for some people\n\ndef get_size_of_path(path):\n    return sum([file.size for file in get_all_files_in_path(path)])\n\ndef get_all_files_in_path(path, verbose=False):\n    nodes_new = []\n\n    nodes_new = dbutils.fs.ls(path)\n    files = []\n\n    while len(nodes_new) > 0:\n        current_nodes = nodes_new\n        nodes_new = []\n        for node in current_nodes:\n            if verbose:\n                print(f\"Processing {node.path}\")\n            children = dbutils.fs.ls(node.path)\n            for child in children:\n                if child.size == 0 and child.path != node.path:\n                    nodes_new.append(child)\n                elif child.path != node.path:\n                    files.append(child)\n    return files\n\npath = \"s3://some/path/\"\n\nprint(f\"Size of {path} in gb: {get_size_of_path(path) / 1024 / 1024 / 1024}\")\n"], ["def solution(data, n):\nndata = []\nfor i in data:\n    c = data.count(i)\n    if c <= n:\n        ndata.append(i)\nreturn ndata\n"], ["df['target_col'] = df['key_col'].map(dict).fillna(df['target_col'])\n\n[Out]:\n\n  key_col target_col\n0       w          a\n1       c          B\n2       z          4\n"], ["tf.keras.utils.to_categorical(\n    y, num_classes=None, dtype='float32'\n)\n", "y = [0, 1, 2, 0, 2, 2, 1, 0, 1, 1, 0, 0, 1, 0, 2, 2, 0] # we have 3 classes  0, 1 & 2\n\ny = tf.keras.utils.to_categorical(y, num_classes=3, dtype='int')\n\ny\n\narray([[1, 0, 0],\n       [0, 1, 0],\n       [0, 0, 1],\n       [1, 0, 0],\n       [0, 0, 1],\n       [0, 0, 1],\n       [0, 1, 0],\n       [1, 0, 0],\n       [0, 1, 0],\n       [0, 1, 0],\n       [1, 0, 0],\n       [1, 0, 0],\n       [0, 1, 0],\n       [1, 0, 0],\n       [0, 0, 1],\n       [0, 0, 1],\n       [1, 0, 0]])\n"], ["pip install attrs==19.1.0\n"], ["project_id = os.environ.get(\"GOOGLE_CLOUD_PROJECT\")\nclient = secretmanager.SecretManagerServiceClient()\nsecret_name = \"service_account_credentials\"\nsecret_path = f\"projects/{project_id}/secrets/{secret_name}/versions/latest\"\ncredentials_json = client.access_secret_version(name=secret_path).payload.data.decode(\"UTF-8\")\nservice_account_info = json.loads(credentials_json)\ngoogle_service_credentials = service_account.Credentials.from_service_account_info(\n        service_account_info)\n"], ["import sys\nprint(sys.executable)\n"], ["import * as chromey from 'selenium-webdriver/chrome.js';\nconst chromeOptions = new chromey.Options();\nchromeOptions.addArguments(\n    '--ignore-certificate-errors',\n    '--no-sandbox',\n    // '--headless',\n    'disable-gpu',\n);\nconst driver = new Builder()\n    .forBrowser('chrome')\n    .setChromeOptions(chromeOptions)\n    .setCapability(\"acceptInsecureCerts\", true)\n    .build();\n"], ["hour = float(input('Enter hours: '))\nrate = float(input('Enter rates: '))\n\ndef compute_pay(hours, rates):\n\n    if hours <= 40:\n        pay = hours * rates\n        return pay\n    elif hours > 40:\n        pay = ((hours * rate) - 40 * rate) * 1.5 + 40 * rate\n        return pay\n\npay = compute_pay(hour, rate)\nprint(pay)\n"], ["hour = float(input('Enter hours: '))\n\nrate = float(input('Enter rates: '))\n\n\ndef compute_pay(hours, rates):\n\nif hours <= 40:\n\n    print(hours * rates)\n\nelif hours > 40:\n\n    print(((hours * rate) - 40 * rate) * 1.5 + 40 * rate)\n\n\n\ncompute_pay(hour, rate )\n"], ["python3.10 -m venv venv\nsource venv/bin/activate\npip install .\n"], [], ["\"\"\"\nI kept your function the same besides removing the invalid conditional branch and adding a \nprint statement\n\"\"\"\ndef determineGrade (studentScore):\n    print(\"Student earned the following grade: \", end = \" \")\n    \n    if studentScore <= 40:\n        print ('F')\n    elif studentScore <= 50:\n        print ('D')\n    elif studentScore <= 60:\n        print ('C')\n    elif studentScore <= 70:\n        print ('B')\n    elif studentScore <= 100:\n        print ('A')\n\n\"\"\"\nI kept this function very similar as well except I used a list initialized in main so you have a \nhistory of all student scores input and how many passed or failed. I also put the fail and passing\nvariables here for readability and to avoid scope problems.\n\"\"\"\ndef determinePass (score_list):\n    fail = 0\n    passing = 0\n    \n    for i in range(len(score_list)):\n        if score_list[i] <= 40:\n            fail += 1\n        else:\n            passing += 1\n            \n    print(\"Students passing: {}\".format(passing))\n    print(\"Students failing: {}\".format(fail))\n\n\"\"\"\nI finished this function by using basic list functions that calculate the average. In the future,\nuse the keyword pass or a stub in your definition if not finished so you can still test it :)\n\"\"\"\ndef classAverage (score_list):\n    avg = sum(score_list) / len(score_list)\n    \n    print(\"Class Average: {}\".format(avg))\n\n\"\"\" MAIN \"\"\"\nif  __name__ == \"__main__\":\n    # Makes sentinel value known to the user (any negative number).\n    print(\"Welcome. Input a negative integer at any time to exit.\")\n    # Wrapped input in float() so input only accepts whole and decimal point numbers. \n    studentScore = float(input(\"Grade for a student: \"))\n    # Declares an empty list. Remember that they are mutable meaning they can change even in functions.\n    score_list = []\n    \n    # Anything below 0 is considered a sentinel value or what terminates the loop. \n    while studentScore >= 0:\n        # If input score is between 0-100:\n        if studentScore <= 100:\n            # Input score is added to our list for use in the functions.\n            score_list.append(studentScore)\n            \n            determineGrade(studentScore)\n            determinePass(score_list)\n            classAverage(score_list)\n        # If a number beyond 100 is input as a score.\n        else:\n            print(\"Invalid. Score must be between 0-100\")\n        \n        # Used to avoid infinite loop and allow as many valid inputs as desired.\n        print(\"Welcome. Input a negative integer at any time to exit.\")\n        studentScore = float(input(\"Grade for a student: \"))\n"], [], [], ["import requests\nfrom requests_html import HTMLSession\nsession = HTMLSession()\nnum_currencies=250\nresp = session.get(f\"https://finance.yahoo.com/crypto?offset=0&count={num_currencies}\")\ntables = pd.read_html(resp.html.raw_html)               \ndf = tables[0].copy()\nsymbols_yf = df.Symbol.tolist()\nprint(symbols_yf[:15])\nprint(df.head(5))\n"], ["from binance import Client\nfrom tqdm.autonotebook import tqdm\nimport pandas as pd\nimport numpy as np\n\ndef get_binance_data(ticker, interval='4h', start='1 Jan 2018', end=None):\n  client = Client()\n  intervals = {\n      '15m': Client.KLINE_INTERVAL_15MINUTE,\n      '1h':  Client.KLINE_INTERVAL_1HOUR,      \n      '4h':  Client.KLINE_INTERVAL_4HOUR,\n      '1d':  Client.KLINE_INTERVAL_1DAY\n  }\n  interval = intervals.get(interval, '4h')\n#   print(f'Historical interval {interval}')\n  klines = client.get_historical_klines(symbol=ticker, interval=interval, start_str=start, end_str=end)\n  data = pd.DataFrame(klines)\n  data.columns = ['open_time','open', 'high', 'low', 'close', 'volume','close_time', 'qav','num_trades','taker_base_vol','taker_quote_vol', 'ignore']\n  data.index = [pd.to_datetime(x, unit='ms').strftime('%Y-%m-%d %H:%M:%S') for x in data.open_time]\n  usecols=['open', 'high', 'low', 'close', 'volume', 'qav','num_trades','taker_base_vol','taker_quote_vol']\n  data = data[usecols]\n  data = data.astype('float')\n  return data\n\n\nclient = Client()\nexchange_info = client.get_exchange_info()\nsymbols=[s['symbol'] for s in exchange_info['symbols'] if s['status'] == 'TRADING']\nticker_list = symbols[:50]\n# tiker_list = np.random.choice(symbols, size=50)\nprint('Number of crypto pairs: ', len(symbols))\nprint('First 50 pairs: ', *ticker_list)\n\n# collect pair closes in one dataframe\ncoins = []\nfor ticker in tqdm(ticker_list):\n    try:\n        close_price = get_binance_data(ticker, interval='1d', start='1 Jan 2018', end='1 Jul 2022')['close'].to_dict()\n        info = {'name': ticker}\n        info.update(close_price)\n        coins.append(info)\n    except Exception as err:\n        print(err)\n        continue\n\ncoins = pd.DataFrame(coins)\n# print(coins.head())\ncoins.head()\n"], ["import xarray as xr\nxr.open_dataset(\"this_file_does_not_exist.nc\")\n"], [], [], [], [], ["In [1]: import numpy as np\n\nIn [2]: np.random.choice([0,1], size=(3,4))\nOut[2]: array([[1, 0, 0, 0],\n               [0, 1, 1, 0],\n               [1, 1, 1, 1]])\n"], ["pip install pybluez2\n"], [], [], ["from datetime import date\nfrom dateutil.relativedelta import relativedelta\n", "date.today() + relativedelta(day=31)\n", "date.today() + relativedelta(day=31) + relativedelta(days=1)\n"], ["import random\n\nclass De(models.Model):\n\n    fr = models.BooleanField(\"[...]\")\n    de = models.SmallIntegerField(\"[...]\")\n    gd = models.SmallIntegerField(\"[...]\")\n    na = models.SmallIntegerField(\"[...]\")\n    # [several_attributes, Meta, __str__() removed for readability]\n\n    def s_d(self):\n        \"\"\"\n        Just as example: adds a perturbation so it is not possible\n        to inherit ordering by db columns\n        \"\"\"\n        X = random.randrange(128)\n        if self.fr:\n            return self.de*X\n        else:\n            return self.gd*X + self.na\n    s_d.admin_order_field = 'cielcio_to_be_removed'\n    s_d = property(s_d)\n", "from django.contrib import admin\nfrom django.contrib.admin.views.main import ChangeList\n\nclass DeChangeList(ChangeList):\n\n    def get_ordering(self, request, queryset):\n        \"\"\"\n        Removes the fake field used to show upper\n        and lower arrow in changelist table header\n        \"\"\"\n        ordering = super().get_ordering(request, queryset)\n        if 'cielcio_to_be_removed' in ordering:\n            ordering.remove('cielcio_to_be_removed')\n        if '-cielcio_to_be_removed' in ordering:\n            ordering.remove('-cielcio_to_be_removed')\n        return ordering\n\n\nclass DeAdmin(admin.ModelAdmin):\n\n    list_display = (\"[...]\", \"s_d\", \"gd\", \"na\", \"de\", \"fr\" )\n\n    def get_changelist(self, request, **kwargs):\n        return DeChangeList\n\n    def get_paginator(self, request, queryset, per_page, orphans=0, allow_empty_first_page=True):\n        \"\"\"\n        Intercepts queryset and order by values with 'sorted'\n        \"\"\"\n\n        index_s_p = self.list_display.index('s_p')\n        ordering = request.GET.get('o', \"99999\")\n\n        instances = []\n        for nf in ordering.split(\".\"):\n            reverse = int(nf) < 0\n            if abs(int(nf)) == index_s_p+1:\n                instances = sorted(\n                    queryset,\n                    key=lambda a: (a.s_p is not None if reverse else a.s_p is None, a.s_p),\n                    reverse=reverse\n                )\n\n        return super().get_paginator(\n                request, instances or queryset,\n                per_page, orphans, allow_empty_first_page)\n"], ["const chainId = await wallet.getChainId();\nconsole.log(\"chain Id\",chainId);\n"], [], [], [], [], [], ["s = {}\nprint('Please type the number, when you\\'re done please type \"Done\":')\nwhile True:\n    a = input()\n    if a == 'Done':\n        break\n    else:\n        try:\n            s.add(int(a))\n        except:\n            print('Integer only, please re-type:')\nprint(s)\n"], [], [], ["Building wheels for collected packages: scikit-learn\n  Building wheel for scikit-learn (pyproject.toml) ... done\n  Created wheel for scikit-learn: filename=scikit_learn-1.0.1-cp38-cp38-macosx_12_0_arm64.whl size=6364030 sha256=0b0cc9a21af775e0c8077ee71698ff62da05ab62efc914c5c15cd4bf97867b31\nSuccessfully built scikit-learn\nInstalling collected packages: scipy, scikit-learn\nSuccessfully installed scikit-learn-1.0.1 scipy-1.7.3\n", "Collecting click>=7.0\n  Downloading click-8.0.3-py3-none-any.whl\n"], [], ["\"\"\"AWS DataSync an aws service to move/copy large amounts of data.\"\"\"\nimport logging\nimport os\n\nimport boto3\nimport tenacity\nfrom botocore import waiter\nfrom botocore.exceptions import WaiterError\n\n\nlogger = logging.getLogger(__name__)\n\n\nclass SourceDirEmptyException(Exception):\n    \"\"\"\n    Exception for when data sync runs on an emtpy source directory.\n    This only occurs when 'PreserveDeletedFiles'='REMOVE and the\n    source directory prefix is empty. The data sync task will fail and continue \n    to retry, this exception prevents retries as they contiue to fail.\n    \"\"\"\n\nclass DataSyncWaiter(object):\n    \"\"\"A AWS Data sync waiter class.\"\"\"\n    def __init__(self, client):\n        \"\"\"Init.\"\"\"\n        self._client = client\n        self._waiter = waiter\n\n    def wait_for_finished(self, task_execution_arn):\n        \"\"\"Wait for data sync to finish.\"\"\"\n        model = self._waiter.WaiterModel({\n            \"version\": 2,\n            \"waiters\": {\n                \"JobFinished\": {\n                    \"delay\":\n                    1,\n                    \"operation\":\n                    \"DescribeTaskExecution\",\n                    \"description\":\n                    \"Wait until AWS Data Sync starts finished\",\n                    \"maxAttempts\":\n                    1000000,\n                    \"acceptors\": [\n                        {\n                            \"argument\": \"Status\",\n                            \"expected\": \"SUCCESS\",\n                            \"matcher\": \"path\",\n                            \"state\": \"success\",\n                        },\n                        {\n                            \"argument\": \"Status\",\n                            \"expected\": \"ERROR\",\n                            \"matcher\": \"path\",\n                            \"state\": \"failure\",\n                        },\n                    ],\n                }\n            },\n        })\n        self._waiter.create_waiter_with_client(\"JobFinished\", model,\n                                               self._client).wait(TaskExecutionArn=task_execution_arn)\n\n\nclass DataSyncClient:\n    \"\"\"A AWS DataSync client.\"\"\"\n    def __init__(self, client, role_arn, waiter: DataSyncWaiter = None) -> None:\n        \"\"\"Init.\"\"\"\n        self._client: boto3.client = client\n        if waiter is None:\n            waiter = DataSyncWaiter(client=client)\n        self._waiter: DataSyncWaiter = waiter\n        self._role_arn = role_arn\n\n    def _delete_task(self, task_arn):\n        \"\"\"Delete a AWS DataSync task.\"\"\"\n        response = self._client.delete_task(TaskArn=task_arn)\n        return response\n\n    def _list_s3_locations(self):\n        \"\"\"List AWS DataSync locations.\"\"\"\n        locations = self._client.list_locations(MaxResults=100)\n        if \"Locations\" in locations:\n            return [x for x in locations[\"Locations\"] if x[\"LocationUri\"].startswith(\"s3://\")]\n        return []\n\n    def _create_datasync_s3_location(self, bucket_name: str, subdirectory: str = \"\"):\n        \"\"\"Create AWS DataSync location.\"\"\"\n        return self._client.create_location_s3(\n            Subdirectory=subdirectory,\n            S3BucketArn=f\"arn:aws:s3:::{bucket_name}\",\n            S3StorageClass=\"STANDARD\",\n            S3Config={\"BucketAccessRoleArn\": self._role_arn},\n        )\n\n    def _find_location_arn(self, bucket_name, subdirectory: str, locations_s3):\n        \"\"\"Find AWS DataSync LocationArn based on bucketname.\"\"\"\n        for x in locations_s3:\n            # match the s3 location\n            if bucket_name in x[\"LocationUri\"] and subdirectory in x[\"LocationUri\"]:\n                # match the roles, these do not update frequently\n                location_metadata = self._client.describe_location_s3(LocationArn=x[\"LocationArn\"])\n                if location_metadata['S3Config']['BucketAccessRoleArn'] == self._role_arn:\n                    return x[\"LocationArn\"]\n        return self._create_datasync_s3_location(bucket_name=bucket_name, subdirectory=subdirectory)[\"LocationArn\"]\n\n\n    def move_data(self,\n              task_name: str,\n              source_bucket_name: str,\n              dest_bucket_name: str,\n              subdirectory: str,\n              preserve_deleted_files: Literal['PRESERVE', 'REMOVE'] = \"REMOVE\") -> bool:\n        \"\"\"Move data using AWS DataSync tasks.\"\"\"\n        current_locations = self._list_s3_locations()\n        source_s3_location_response = self._find_location_arn(bucket_name=source_bucket_name,\n                                                              locations_s3=current_locations,\n                                                              subdirectory=subdirectory)\n        dest_s3_location_response = self._find_location_arn(bucket_name=dest_bucket_name,\n                                                            locations_s3=current_locations,\n                                                            subdirectory=subdirectory)\n        logger.info(\"Moving data from SRC:{source} DEST:{dest}\".format(\n            source=os.path.join(source_bucket_name, subdirectory), dest=os.path.join(dest_bucket_name, subdirectory)))\n        task = self._client.create_task(\n            SourceLocationArn=source_s3_location_response,\n            DestinationLocationArn=dest_s3_location_response,\n            Name=f\"{task_name}-sync\",\n            Options={\n                \"VerifyMode\": \"POINT_IN_TIME_CONSISTENT\",\n                \"OverwriteMode\": \"ALWAYS\",\n                \"PreserveDeletedFiles\": preserve_deleted_files,\n                # 'TransferMode': # 'CHANGED'|'ALL'\n            },\n        )\n        self.start_task_waiting_for_complete(task_arn=task[\"TaskArn\"])\n        self._delete_task(task_arn=task[\"TaskArn\"])\n        return True\n\n    @tenacity.retry(\n        retry=tenacity.retry_if_exception_type(exception_types=(WaiterError)),\n        wait=tenacity.wait_random_exponential(multiplier=0.5),\n        stop=tenacity.stop_after_attempt(max_attempt_number=60),\n        reraise=True,\n        after=tenacity.after_log(logger, logging.INFO),\n    )\n    def start_task_waiting_for_complete(self, task_arn: str):\n        \"\"\"Start data move task, with retry because sometimes not all files get\n        moved.\n\n        It is not clear if this is because of eventual consistency in S3\n        or the AWS service just does not handle constistency well.\n        \"\"\"\n\n        try:\n            task_started = self._client.start_task_execution(TaskArn=task_arn)\n            self._waiter.wait_for_finished(task_execution_arn=task_started[\"TaskExecutionArn\"])\n         except Exception as ex:\n            # last_response.Result.ErrorDetail': 'DataSync could not detect any objects in the source S3 bucket\n            if type(ex) == WaiterError and ex.last_response['Result']['ErrorCode'] == 'SourceDirEmpty':\n                # we do not want datasync continuing to fail\n                # only occurs when 'PreserveDeletedFiles'='REMOVE\n                raise SourceDirEmptyException(ex.last_response['Result']['ErrorDetail'])\n            raise ex\n\n\n\ndef data_sync_move_data(task_name: str,\n                        data_sync_role_arn: str,\n                        source_bucket: str,\n                        destination_bucket: str,\n                        subdirectory: str,\n                        datasync_client: boto3.client = None,\n                        preserve_deleted_files: Literal['PRESERVE', 'REMOVE'] = \"REMOVE\"):\n    \"\"\"Move data from source bucket to destition bucket.\"\"\"\n    logger.info(f\"DataSync: Moving all the data from {source_bucket} -> {destination_bucket}\")\n    if datasync_client is None:\n        datasync_client = _utils.get_boto_client(\"datasync\")\n    datasync_client = DataSyncClient(client=datasync_client, role_arn=data_sync_role_arn)\n    datasync_client.move_data(task_name=task_name,\n                              source_bucket_name=source_bucket,\n                              dest_bucket_name=destination_bucket,\n                              subdirectory=subdirectory,\n                              preserve_deleted_files=preserve_deleted_files)\n", "DATA_SYNC_ROLE_ARN = {\n    \"sand\": \"arn:aws:iam::123456789:role/Bucket-and-DataSync-Access-sand\",\n    \"dev\": \"arn:aws:iam::123456789:role/Bucket-and-DataSync-Access-dev\",\n    \"stg\": \"arn:aws:iam::123456789:role/Bucket-and-DataSync-Access-stg\",\n    \"prod\": \"arn:aws:iam::123456789:role/Bucket-and-DataSync-Access-prod\",\n}\ndata_sync_move_data(task_name=\"migrate_data\",\n                        data_sync_role_arn=DATA_SYNC_ROLE_ARN[env],\n                        source_bucket=\"old-bucket-name\",\n                        destination_bucket=\"new-bucket-name,\n                        subdirectory=\"\", # this is whole bucket\n                        datasync_client=boto3.client('datasync'),                               \n                        preserve_deleted_files='REMOVE'  # 'PRESERVE', 'REMOVE'\n)\n", "  Role:\n    Type: AWS::IAM::Role\n    Properties:\n      RoleName: !Sub \"Bucket-and-DataSync-Access-${Environment}\"\n      AssumeRolePolicyDocument:\n        Version: \"2012-10-17\"\n        Statement:\n          - Effect: \"Allow\"\n            Principal:\n              Service:\n                - \"datasync.amazonaws.com\"\n            Action:\n              - \"sts:AssumeRole\"\n    ...<s3 bucket access and encryption>\n"], [], [], [], ["--extra-index-url https://download.pytorch.org/whl/cpu\ntorch\ntorchvision\n"], ["python = \"^3.7\"\n"], [], ["@dataclass\nclass Specs1:\n    a: str\n    b: str = field(default='Bravo')\n    c: str = field(default='Charlie')\n"], ["class LogRequestsMiddleware:\ndef __init__(self, app:ASGIApp) -> None:\n    self.app = app\n\nasync def __call__(self, scope: Scope, receive: Receive, send: Send) -> None:\n    receive_cached_ = await receive()\n    async def receive_cached():\n        return receive_cached_\n    request = Request(scope, receive = receive_cached)\n        \n    # do what you need here\n\n    await self.app(scope, receive_cached, send)\n\napp.add_middleware(LogRequestsMiddleware)\n"], [], ["import re\n\n   def check_zip_code (text):\n\n   result = re.search(r\" \\d{5}(-\\d{4})?\", text)\n\n   return result != None\n\nprint(check_zip_code(\"The zip codes for New York are 10001 thru 11104.\")) # True\nprint(check_zip_code(\"90210 is a TV show\")) # False\nprint(check_zip_code(\"Their address is: 123 Main Street, Anytown, AZ 85258-0001.\")) # True\nprint(check_zip_code(\"The Parliament of Canada is at 111 Wellington St, Ottawa, ON K1A0A9.\")) # False\n", "True\nFalse\nTrue\nFalse\n"], [], ["def solution(N, A):\nglobal_max = 0\ncurrent_max = 0\nresult = [0] * N\ncanUpdate = True\nfor i in A:\n    if i <= N:\n        if result[i-1] <= global_max:\n            result[i-1] = global_max + 1\n        else:\n            result[i-1] += 1\n        current_max = max(current_max, result[i-1])\n        canUpdate = True\n    elif canUpdate:\n        canUpdate = False\n        global_max = current_max\n    # print(result)\nfor i, val in enumerate(result):\n    if val < global_max:\n        result[i] = global_max\nreturn result\n"], ["pip install pymysql\n"], [], [], ["fig = px.scatter_matrix(M25C_df, dimensions=['PRECO_ES', '1_Mean', '2_Mean', '3_Mean', 'Eolica_Mean', 'Nuclear_Mean', 'Carvao_Mean', 'CCombinado_Mean', 'Hidro_Mean', 'IntInter_Mean', 'Solar_Mean'], color='PRECO_ES')\n\nfig.show()\n", "fig = px.scatter_matrix(M25C_df, dimensions=['PRECO_ES', '1_Mean', '2_Mean', '3_Mean', 'Eolica_Mean', 'Nuclear_Mean', 'Carvao_Mean', 'CCombinado_Mean', 'Hidro_Mean', 'IntInter_Mean', 'Solar_Mean'], color='PRECO_ES')\n\nfig.update_layout(width=2000, height=2500)\n\nfig.show()\n"], ["def pig_latin(text):\n  # Separate the text into words\n  words = text.split()\n  list1 = []\n  for word in words:\n    # Create the pig latin word and add it to the list\n    pig_latin = word[0] + \"ay\"\n    mod_word = word.replace(word[0],\"\")\n    mod_word2 = mod_word + pig_latin\n    list1.append(mod_word2)\n    # Turn the list back into a phrase\n  return \" \".join(list1)\n        \nprint(pig_latin(\"hello how are you\")) # Should be \"ellohay owhay reaay ouyay\"\nprint(pig_latin(\"programming in python is fun\")) # Should be \"rogrammingpay niay ythonpay siay unfay\"\n\n"], [], ["num_inputs = int(input())\nnum_list = []\n\nfor n in range(num_inputs):\n    integer = input()\n    num_list.append(integer)\nthreshold = int(input())\nfor n in num_list:\n    if int(n) <= threshold:\n        print(n + ',', end = '')\n"], [], [], [" UserWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n  warnings.warn(\"find_element_by_* commands are deprecated. Please use find_element() instead\")\n", "from selenium.webdriver.common.by import By\n", "driver.find_element_by_xpath(\"//*[@id='search']\").click()\n", "driver.find_element(By.XPATH, \"//*[@id='search']\").click()\n", "element = find_element_by_class_name(\"element_class_name\")\n", "element = driver.find_element(By.CLASS_NAME, \"element_class_name\")\n", "element = find_element_by_id(\"element_id\")\n", "element = driver.find_element(By.ID, \"element_id\")\n", "element = find_element_by_name(\"element_name\")\n", "element = driver.find_element(By.NAME, \"element_name\")\n", "element = find_element_by_link_text(\"element_link_text\")\n", "element = driver.find_element(By.LINK_TEXT, \"element_link_text\")\n", "element = find_element_by_partial_link_text(\"element_partial_link_text\")\n", "element = driver.find_element(By.PARTIAL_LINK_TEXT, \"element_partial_link_text\")\n", "element = find_element_by_tag_name(\"element_tag_name\")\n", "element = driver.find_element(By.TAG_NAME, \"element_tag_name\")\n", "element = find_element_by_css_selector(\"element_css_selector\")\n", "element = driver.find_element(By.CSS_SELECTOR, \"element_css_selector\")\n"], ["from selenium.webdriver.common.by import By\n\ndriver.find_element(By.XPATH, '//input[@id='search']')\n"], ["driver.find_element_by_id('search')\n"], ["driver.findElement(By.id(\"search\"))\n"], ["driver = webdriver.Chrome(executable_path=\"C:\\New folder\\chromedriver.exe\",chrome_options=chrome_options)\nurl = 'http://www.youtube.com'\ndriver.get(url)\ndriver.maximize_window()\nwait = WebDriverWait(driver, 20)\n\nelement = wait.until(EC.presence_of_element_located((By.XPATH, \"//form[@id='search-form']//div[@id='container']//div[@id='search-input']//input\")))\n\nactionChains = ActionChains(driver)\nactionChains.move_to_element(element).click().perform()\nactionChains.move_to_element(element).send_keys(\"Test\",Keys.RETURN).perform()\n", "from selenium.webdriver.support import expected_conditions as EC\nfrom selenium.webdriver.common.by import By\nfrom selenium.webdriver.support.ui import WebDriverWait\n"], ["--disable-features=DefaultPassthroughCommandDecoder\n"], [], ["import numpy as np\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n\ndef mergecells(table, cells):\n    '''\n    Merge N matplotlib.Table cells\n\n    Parameters\n    -----------\n    table: matplotlib.Table\n        the table\n    cells: list[set]\n        list of sets od the table coordinates\n        - example: [(0,1), (0,0), (0,2)]\n\n    Notes\n    ------\n    https://stackoverflow.com/a/53819765/12684122\n    '''\n    cells_array = [np.asarray(c) for c in cells]\n    h = np.array([cells_array[i+1][0] - cells_array[i][0] for i in range(len(cells_array) - 1)])\n    v = np.array([cells_array[i+1][1] - cells_array[i][1] for i in range(len(cells_array) - 1)])\n\n    # if it's a horizontal merge, all values for `h` are 0\n    if not np.any(h):\n        # sort by horizontal coord\n        cells = np.array(sorted(list(cells), key=lambda v: v[1]))\n        edges = ['BTL'] + ['BT' for i in range(len(cells) - 2)] + ['BTR']\n    elif not np.any(v):\n        cells = np.array(sorted(list(cells), key=lambda h: h[0]))\n        edges = ['TRL'] + ['RL' for i in range(len(cells) - 2)] + ['BRL']\n    else:\n        raise ValueError(\"Only horizontal and vertical merges allowed\")\n\n    for cell, e in zip(cells, edges):\n        table[cell[0], cell[1]].visible_edges = e\n        \n    txts = [table[cell[0], cell[1]].get_text() for cell in cells]\n    tpos = [np.array(t.get_position()) for t in txts]\n\n    # transpose the text of the left cell\n    trans = (tpos[-1] - tpos[0])/2\n    # didn't had to check for ha because I only want ha='center'\n    txts[0].set_transform(mpl.transforms.Affine2D().translate(*trans))\n    for txt in txts[1:]:\n        txt.set_visible(False)\n\n\ncontents = (\n    (\"Apple\", \"Banana\", \"Strawberry\", \"Melon\"),\n    (\"Apple\", \"Banana\", \"Strawberry\", \"Melon\"),\n    (\"Apple\", \"Banana\", \"Strawberry\", \"Melon\")\n)\nbg_colors = (\n    (\"r\", \"y\", \"r\", \"g\"),\n    (\"r\", \"y\", \"r\", \"g\"),\n    (\"r\", \"y\", \"r\", \"g\")\n)\n\n\n\n# ///////////////////////////////////////////////////////\n# Figure 1: Just merging cells resulting in weired color\nfig1 = plt.figure()\nax1 = fig1.add_subplot(111)\nax1.axis(\"off\")\nax1.set_title(\"Figure 1\")\ntable = ax1.table(cellText=contents, bbox=[0, 0, 1, 1], cellLoc=\"center\", cellColours=bg_colors)\nmergecells(table, [(0, 1), (1, 1), (2, 1)])\n# ///////////////////////////////////////////////////////\n\n\n\n# ///////////////////////////////////////////////////////\n# Figure 2: Overlap empty table only for cells color\nfig2 = plt.figure()\nax2 = fig2.add_subplot(111)\nax2.axis(\"off\")\nax2.set_title(\"Figure 2\")\n# 'table_bg' is a background table without any contents\n# Set background color of this as you want\ntable_bg = ax2.table(bbox=[0, 0, 1, 1], cellColours=bg_colors)\nfor cell in table_bg._cells.values():\n    cell.set_edgecolor(\"none\")\n# 'table' contatins cell texts\n# Sset its color to 'none' then merge\nbg_none = (\n    (\"none\", \"none\", \"none\", \"none\"),\n    (\"none\", \"none\", \"none\", \"none\"),\n    (\"none\", \"none\", \"none\", \"none\")\n)\ntable = ax2.table(cellText=contents, bbox=[0, 0, 1, 1], cellLoc=\"center\", cellColours=bg_none)\nmergecells(table, [(0, 1), (1, 1), (2, 1)])\n# ///////////////////////////////////////////////////////\n\n\nplt.show()\n"], [], [], ["pip uninstall opencv-python\npip install opencv-python-headless\n"], [], [], [], [], [], [], [], [], [], [], ["def compute_pool_address(self, token_address_a, token_address_b):\n    pair_traded = [token_address_a.lower(), token_address_b.lower()]\n    pair_traded.sort()\n    hexadem = '0x00fb7f630766e6a796048ea87d01acd3068e8ff67d078148a3fa3f4a84f69bd5'\n    abiEncoded_1 = encode_abi_packed(['address', 'address'], (pair_traded[0], pair_traded[1]))\n    salt_ = self.web3.solidityKeccak(['bytes'], ['0x' + abiEncoded_1.hex()])\n    abiEncoded_2 = encode_abi_packed(['address', 'bytes32'], (PANCAKE_FACTORY_ADDRESS, salt_))\n    return self.web3.toChecksumAddress(self.web3.solidityKeccak(['bytes', 'bytes'], ['0xff' + abiEncoded_2.hex(), hexadem])[12:])\n"], ["Token Contract:  {'CONTRACT': '0xe56842ed550ff2794f010738554db45e60730371'}\nBNB-LP Address:  0xdbb161367d9a2a852ebeef3cbfcbf2c43b85064b\n"], [], [], ["r\"[\\s][\\d]{5}\"\n"], [], ["transaction = SimpleStorage.constructor().buildTransaction(\n{\n    \"gasPrice\": w3.eth.gas_price,\n    \"chainId\": int(chain_id),\n    \"from\": my_address,\n    \"nonce\": nonce,\n}\n"], ["sudo apt install libgdbm-dev build-essential libnss3-dev libreadline-dev libffi-dev libsqlite3-dev libbz2-dev libncurses5-dev libssl-dev zlib1g-dev\ncd /tmp\nwget https://www.python.org/ftp/python/3.9.14/Python-3.9.14.tgz\ntar -xf Python-3.9.14.tgz\ncd Python-3.9.14 \n./configure --enable-optimizations\n\n## if you want to run in parallel set -j to how many cpus you have\n## I subtracted 2 so my machine wouldn't have a stroke\n# lscpu | egrep 'CPU\\(s\\)'\n# make -j <cpus you are comfortable with>\nmake\n\n## Super important to run altinstall to not overwrite\nsudo make altinstall\n\n## I updated the pyproject.toml to ^3.9\npoetry env use /usr/local/bin/python3.9\n"], ["from selenium import webdriver\nfrom selenium.webdriver.common.action_chains import ActionChains\n\ndriver = webdriver.Firefox(executable_path=\"\")\ndriver.get(\"https://UrlToOpen\")   \naction = ActionChains(driver)\n\nfirstLevelMenu = driver.find_element_by_id(\"menu\")\nfirstLevelMenu.click()\n"], [], ["# define a basic city class\nclass City:\n    name = \"\"\n    country = \"\"\n    elevation = 0 \n    population = 0\n\n# create a new instance of the City class and\n# define each attribute\ncity1 = City()\ncity1.name = \"Cusco\"\ncity1.country = \"Peru\"\ncity1.elevation = 3399\ncity1.population = 358052\n\n# create a new instance of the City class and\n# define each attribute\ncity2 = City()\ncity2.name = \"Sofia\"\ncity2.country = \"Bulgaria\"\ncity2.elevation = 2290\ncity2.population = 1241675\n\n# create a new instance of the City class and\n# define each attribute\ncity3 = City()\ncity3.name = \"Seoul\"\ncity3.country = \"South Korea\"\ncity3.elevation = 38\ncity3.population = 9733509\n\ndef max_elevation_city(min_population):\n    # Initialize the variable that will hold \n# the information of the city with \n# the highest elevation \n    return_city = City()\n\n    # Evaluate the 1st instance to meet the requirements:\n    # does city #1 have at least min_population and\n    # is its elevation the highest evaluated so far?\n    if city1.population >= min_population:\n        return_city = city1\n    # Evaluate the 2nd instance to meet the requirements:\n    # does city #2 have at least min_population and\n    # is its elevation the highest evaluated so far?\n    if city2.population >= min_population and city2.elevation > return_city.elevation:\n        return_city = city2\n    # Evaluate the 3rd instance to meet the requirements:\n    # does city #3 have at least min_population and\n    # is its elevation the highest evaluated so far?\n    if city3.population >= min_population and city3.elevation > return_city.elevation:\n        return_city = city3\n\n    #Format the return string\n    if return_city.name:\n        return f\"{return_city.name}, {return_city.country}\" \n    else:\n        return \"\"\n"], [], ["conda activate myenv\nconda install scipy\n"], [], [], [], ["   pip uninstall pytz\n   pip install pytz==2022.2.1\n   pip uninstall tzdata\n   pip install tzdata==2022.2\n"], [], ["# upgrade pytz up to the latest pytz-2022.2.1\npip install pytz --upgrade\n# upgarde tzdata up to tzdata-2022.2\npip install tzdata --upgrade\n"], ["def pig_latin(text):\n  say = \"\"\n  # Separate the text into words\n  words = text.split()\n  last = words[-1]\n  for word in words:\n    if word == last:\n        say += word[1:]+word[0]+\"ay\"\n    else:\n         say += word[1:]+word[0]+\"ay \"\n  return say\n\nprint(pig_latin(\"hello how are you\")) # Should be \"ellohay owhay reaay ouyay\"\nprint(pig_latin(\"programming in python is fun\")) # Should be \"rogrammingpay niay ythonpay siay unfay\"\n"], [], ["RUN cp /usr/local/lib/python3.10/site-packages/tzdata/zoneinfo/Asia/Aden /usr/local/lib/python3.10/site-packages/tzdata/zoneinfo/Asia/Hanoi && \\\ncp /usr/local/lib/python3.10/site-packages/tzdata/zoneinfo/Europe/Moscow /usr/local/lib/python3.10/site-packages/tzdata/zoneinfo/Europe/Kyiv\n"], [], [" SimpleStorage.constructor().buildTransaction( {\n    \"gasPrice\": w3.eth.gas_price, \n    \"chainId\": chain_id, \n    \"from\": my_address, \n    \"nonce\": nonce, \n"], [], ["transaction = SimpleStorage.constructor().buildTransaction({ \"gasPrice\": w3.eth.gas_price, \"chainId\" : chain_id, \"from\": my_address, \"nonce\": nonce})\nprint(transaction)\n"], ["pip3 install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu116\n", "--extra-index-url https://download.pytorch.org/whl/cu116\ntorch\ntorchvision\ntorchaudio\n"], [], ["pip install pip-20.2.4-py2.py3-none-any.whl\n"], [], [], ["driver.execute_script(\"arguments[0].click();\", button)\n\n"], ["import matplotlib as mpl\nmpl.rcParams['figure.figsize'] = [10, 10]\n"], ["def computepay(hours, rate) :\n   return hours * rate\ndef invalid_input() :\n   print(\"Input Numeric Value\")\nwhile True :\n   try :\n      regular_rate = float(input(\"Hourly rate in dollars: \"))\n      break\n   except :\n      invalid_input()\n      continue\nwhile True :\n   try :\n      regular_hours = float(input(\"Regular Hours Worked: \"))\n      break\n   except :\n      invalid_input()\n      continue\nwhile True :\n   try :\n      overtime_hours = float(input(\"Overtime hours worked :\"))\n      break\n   except :\n      invalid_input()\n      continue\novertime_rate = regular_rate * 1.5\n\nregular_pay = computepay(regular_hours, regular_rate)\novertime_pay = computepay(overtime_hours, overtime_rate)\ntotal_pay = regular_pay + overtime_pay\n\nprint(\"PAY : \", total_pay)\n"], [], [], [], ["def pig_latin(text):\n    say = \"ay\"\n    # Separate the text into words\n    words = text.split()\n    newtext = []\n    # Create the pig latin word and add it to the list\n    for newword in words:\n        newlist = newword[1:] + newword[0] + say\n        newtext.append(newlist)\n    return \" \".join(newtext)\n"], [], [], [], ["def pig_latin(text):\n  say = \"\"\n  words = text.split()\n  for word in words:\n    word = str(word[1])+str(word[2:] + str(word[0:1]).lower() + 'ay')\n    say = say + word + \" \"\n  return say\n\nprint(pig_latin(\"hello how are you\")) \n# Should be \"ellohay owhay reaay ouyay\"\nprint(pig_latin(\"programming in python is fun\"))\n # Should be \"rogrammingpay niay ythonpay siay unfay\"\n"], [], [], [], [], [], [], ["class Clothing:\n  stock={ 'name': [],'material' :[], 'amount':[]}\n  def __init__(self,name):\n    material = \"\"\n    self.name = name\n  def add_item(self, name, material, amount):\n    Clothing.stock['name'].append(self.name)\n    Clothing.stock['material'].append(self.material)\n    Clothing.stock['amount'].append(amount)\n  def Stock_by_Material(self, material):\n    count=0\n    n=0\n    for item in Clothing.stock['amount']:\n      # if item == material:\n        count += Clothing.stock['amount'][n]\n        n+=1\n    return count\n\nclass shirt(Clothing):\n  material=\"Cotton\"\nclass pants(Clothing):\n  material=\"Cotton\"\n  \npolo = shirt(\"Polo\")\nsweatpants = pants(\"Sweatpants\")\npolo.add_item(polo.name, polo.material, 4)\nsweatpants.add_item(sweatpants.name, sweatpants.material, 6)\ncurrent_stock = polo.Stock_by_Material(\"Cotton\")\nprint(current_stock)\n"], ["chain_id = 5777\n", " chain_id = 1377\n"], ["conda install --channel=conda-forge scikit-learn\n"], [], [], ["def pr_auc_score(y, y_pred, **kwargs):\n  classes = list(range(y_pred.shape[1]))\n  if len(classes) == 2:\n      precision, recall, _ = precision_recall_curve(y, y_pred[:,1],\n                                                    **kwargs)\n  else:\n    Y = label_binarize(y, classes=classes)\n    precision, recall, _ = precision_recall_curve(Y.ravel(), y_pred.ravel(),\n                                                  **kwargs)\n  return auc(recall, precision)\n"], [], [], [], ["hexadem_= '0x00fb7f630766e6a796048ea87d01acd3068e8ff67d078148a3fa3f4a84f69bd5'  ## Pancake SWAP\n"], ["import random\n\n# generate list with N elements, each of which is a random integer in [0, 99]\nN = 57\nrandom.seed()\nmyList = [random.randint(0, 99) for i in range(0, N)]\n\n# Calculate total number of prints before there will be less than num_elem\n# elements remaining in the list.\nnum_elem = 10\ntotal_prints = len(myList) // num_elem\n\nfor i in range(0, total_prints):\n    index = i * num_elem\n    print(sum(myList[index:index + num_elem]))\n\n# if there are remaining elements, print their sum\nif (len(myList) % num_elem) != 0:\n    print(sum(myList[index + num_elem:]))\n"], ["for k in range(0, len(mylist), 100):\n  print(sum(mylist[k:k+100]))\n"], ["index = 1\nslicesize = 100\n\nstart = 0\nend = 100\n\nmyList = range(1, 958)\n\nwhile True:\n    myslice = myList[start:end]\n    \n    index += 1\n    start = end\n    end = index * slicesize\n    if start > len(myList):\n        break\n"], [], ["total = 0\nfor i, item in enumerate(myList, 1):\n    total += item\n    if i % 100 == 0:\n        print(total)\n        total = 0\n# Print the final group\nif i % 100 != 0:\n    print(total)\n"], ["from itertools import zip_longest\n\n\ndef grouper(iterable, n, *, incomplete='fill', fillvalue=None):\n    \"Collect data into non-overlapping fixed-length chunks or blocks\"\n    # grouper('ABCDEFG', 3, fillvalue='x') --> ABC DEF Gxx\n    # grouper('ABCDEFG', 3, incomplete='strict') --> ABC DEF ValueError\n    # grouper('ABCDEFG', 3, incomplete='ignore') --> ABC DEF\n    args = [iter(iterable)] * n\n    if incomplete == 'fill':\n        return zip_longest(*args, fillvalue=fillvalue)\n    if incomplete == 'strict':\n        return zip(*args, strict=True)\n    if incomplete == 'ignore':\n        return zip(*args)\n    else:\n        raise ValueError('Expected fill, strict, or ignore')\n\n\nfor century in grouper(myList, 100, fillvalue=0):\n    print(sum(century))\n"], [], [], [], [], [], [], [], [], ["pip install netCDF4 \n"], [], [], [], ["transaction = SimpleStorage.constructor().buildTransaction(\n{\n    \"gasPrice\": w3.eth.gas_price,\n    \"chainId\": w3.eth.chain_id,\n    \"from\": my_address,\n    \"nonce\": nonce,\n}\n"], ["<a class=\"services-button\"  href=\"desired url\">\n", "<a class=\"services-button\"  onclick=\"location.href='{% url \"desired url\" %}'\";\">\n"], [], ["pip install --upgrade pip\n", "RUN pip install --upgrade pip\n"], ["$ sudo rm -r /usr/local/bin/docker-compose\n", "$ sudo pip install docker-compose\n"], ["$ gpg --keyserver keyserver.ubuntu.com --recv-key 678CE3FEE430311596DB8C16F52E98007594C21D\n"], ["Python 3.9.10 (main, Jan 15 2022, 11:40:53) \n[Clang 13.0.0 (clang-1300.0.29.3)] on darwin\npip 22.0.3\n", "brew install openblas gfortran\nOPENBLAS=\"$(brew --prefix openblas)\" pip install numpy==1.19.3\nOPENBLAS=\"$(brew --prefix openblas)\" pip install scipy==1.7.2\n", "pip install cython\nbrew install libomp\nexport CC=/usr/bin/clang\nexport CXX=/usr/bin/clang++\nexport CPPFLAGS=\"$CPPFLAGS -Xpreprocessor -fopenmp\"\nexport CFLAGS=\"$CFLAGS -I/opt/homebrew/Cellar/libomp/13.0.1/include\"\nexport CXXFLAGS=\"$CXXFLAGS -I/opt/homebrew/Cellar/libomp/13.0.1/include\"\nexport LDFLAGS=\"$LDFLAGS -L/opt/homebrew/Cellar/libomp/13.0.1/lib -lomp\"\nexport DYLD_LIBRARY_PATH=/opt/homebrew/Cellar/libomp/13.0.1/lib\npip install scikit-learn==0.21.3\n"], [], ["s = set()\nprint('Please type the number, when you\\'re done please type \"Done\":')\nwhile True:\n    try:\n        a = input()\n        if a == \"Done\":\n            break\n        s.add(int(a))\n    except:\n        if a == \"Done\":\n            break\n        else:\n            print('Integer only, please re-type:')\n            continue\nprint(s)\n"], ["s = set()\n# Notice also correct quoting\nprint(\"Please type the number, when you're done please type 'Done':\")\nwhile True:\n    a = input()\n    try:\n        n = int(a)\n        s.add(n)\n    # Avoid blanket except\n    except ValueError:\n        if a == \"Done\":\n            break\n        else:\n            print('Integer only, please re-type:')\n            continue\nprint(s)\n"], [], ["s = set()\ndef get_input():\n    return input('''Please type the number, when you're done please type \"Done\": ''')\n\nfor x in iter(get_input, \"Done\"):\n    # x is guaranteed to *not* be Done here, or the loop\n    # would have already exited.\n    try:\n        a = int(x)\n    except ValueError:\n        print(\"Integer only, please re-type\")\n        continue\n    s.add(a)\n", "s = {int(x) for x in iter(get_input, \"Done\")}\n"], ["class MyRequestLoggingRoute(APIRoute):\n    def get_route_handler(self) -> Callable:\n        original_route_handler = super().get_route_handler()\n\n        async def custom_route_handler(request: Request) -> Response:\n            body = await request.body()\n            if body:\n               logger.info(...)  # log request with body\n            else:\n               logger.info(...)  # log request without body\n            try:\n\n                return await original_route_handler(request)\n            except RequestValidationError as exc:\n               detail = {\"errors\": exc.errors(), \"body\": body.decode()}\n               raise HTTPException(status_code=422, detail=detail)\n\n        return custom_route_handler\n"], [], [], [], ["def product(*args, repeat=1):\n    pools = [tuple(pool) for pool in args] * repeat\n    result = [[]]\n    for pool in pools:\n        result = [x+[y] for x in result for y in pool]\n    for prod in result:\n        yield tuple(prod)\n\na = [[1,2,3],[3,4,5],[5,6,7,8]]\n\nprint(list(product(*a)))\n", "[(1, 3, 5), (1, 3, 6), (1, 3, 7), (1, 3, 8), (1, 4, 5), (1, 4, 6), (1, 4, 7), (1, 4, 8), (1, 5, 5), (1, 5, 6), (1, 5, 7), (1, 5, 8), (2, 3, 5), (2, 3, 6), (2, 3, 7), (2, 3, 8), (2, 4, 5), (2, 4, 6), (2, 4, 7), (2, 4, 8), (2, 5, 5), (2, 5, 6), (2, 5, 7), (2, 5, 8), (3, 3, 5), (3, 3, 6), (3, 3, 7), (3, 3, 8), (3, 4, 5), (3, 4, 6), (3, 4, 7), (3, 4, 8), (3, 5, 5), (3, 5, 6), (3, 5, 7), (3, 5, 8)]\n", "results = list(product(*a))\n\nprint('\\n'.join([','.join(list(map(str, res))) for res in results]))\n", "1,3,5\n1,3,6\n1,3,7\n1,3,8\n1,4,5\n1,4,6\n1,4,7\n1,4,8\n1,5,5\n1,5,6\n1,5,7\n1,5,8\n2,3,5\n2,3,6\n2,3,7\n2,3,8\n2,4,5\n2,4,6\n2,4,7\n2,4,8\n2,5,5\n2,5,6\n2,5,7\n2,5,8\n3,3,5\n3,3,6\n3,3,7\n3,3,8\n3,4,5\n3,4,6\n3,4,7\n3,4,8\n3,5,5\n3,5,6\n3,5,7\n3,5,8\n"], ["def comb(arrs, i=0, numbs=[]):\n    if i == len(arrs):\n        print(*numbs)\n        return\n    for j in arrs[i]:\n        comb(arrs, i + 1, numbs + [j])\n\narrs = [[1,2,3],[3,4,5],[5,6,7,8]]\ncomb(arrs)\n", "1 3 5\n1 3 6\n1 3 7\n1 3 8\n1 4 5\n1 4 6\n1 4 7\n1 4 8\n1 5 5\n1 5 6\n1 5 7\n1 5 8\n2 3 5\n2 3 6\n2 3 7\n2 3 8\n2 4 5\n2 4 6\n2 4 7\n2 4 8\n2 5 5\n2 5 6\n2 5 7\n2 5 8\n3 3 5\n3 3 6\n3 3 7\n3 3 8\n3 4 5\n3 4 6\n3 4 7\n3 4 8\n3 5 5\n3 5 6\n3 5 7\n3 5 8\n"], ["import itertools\na = [[1,2,3],[3,4,5],[5,6,7,8]]\nlist(itertools.product(*a))\n#output\n[(1, 3, 5),\n (1, 3, 6),\n (1, 3, 7),\n (1, 3, 8),\n (1, 4, 5),\n (1, 4, 6),\n (1, 4, 7),\n (1, 4, 8),\n (1, 5, 5),\n (1, 5, 6),\n (1, 5, 7),\n (1, 5, 8),\n (2, 3, 5),\n (2, 3, 6),\n (2, 3, 7),\n (2, 3, 8),\n (2, 4, 5),\n (2, 4, 6),\n (2, 4, 7),\n (2, 4, 8),\n (2, 5, 5),\n (2, 5, 6),\n (2, 5, 7),\n (2, 5, 8),\n (3, 3, 5),\n (3, 3, 6),\n (3, 3, 7),\n (3, 3, 8),\n (3, 4, 5),\n (3, 4, 6),\n (3, 4, 7),\n (3, 4, 8),\n (3, 5, 5),\n (3, 5, 6),\n (3, 5, 7),\n (3, 5, 8)]\n"], [], [], [], ["// SPDX-License-Identifier: MIT\npragma solidity >=0.6.0 <0.9.0;\n"], ["def output_ints_less_than_or_equal_to_threshold(user_values, upper_threshold):\n   for value in user_values:\n       if value <= upper_threshold:\n           print(value, end=\",\" ) \ndef get_user_values():\n   n = int(input())\n   lst = []\n   for i in range(n):\n       lst.append(int(input()))\n   return lst  \nif __name__ == '__main__':\n   userValues = get_user_values()\n   upperThreshold = int(input())\n   output_ints_less_than_or_equal_to_threshold(userValues, upperThreshold)\n   \n"], ["PyJWT==2.3.0\ncryptography==36.0.1\n", "import jwt\njwt.encode(payload, private_key, algorithm=\"RS256\")\n"], ["python3 -m pip install --upgrade pip\n", "python2 -m pip install --upgrade pip\n"], [], ["def solution(data, n):\n    from collections import OrderedDict\n    dict1 = OrderedDict()\n\n    for ele in data:\n        dict1[ele] = dict1.get(ele,0)+1\n\n    new_list = [k for k,v in dict1.items() if v<=n]\n    return new_list\n"], ["sudo apt-get update\nsudo apt-get install libpython3-dev\nsudo apt-get install python3-venv\npython3.8 -m venv whatever\n"], ["from binance import Client \n\ninfo = client.get_exchange_info()\nsymbols = [x['symbol'] for x in info['symbols']]\n"], [">>> pipenv shell\n>>> pipenv --venv\n\nC:\\Users\\gasma\\.virtualenvs\\dungeon-generator-MV179gUf\n"], ["transaction = \n SimpleStorage.constructor().buildTransaction( {\n    \"gasPrice\": w3.eth.gas_price, \n    \"chainId\": chain_id, \n    \"from\": my_address, \n    \"nonce\": nonce, \n})\nprint(transaction)\n"], ["import pandas as pd\nfrom pandas.tseries.offsets import MonthBegin, MonthEnd\n\ndate_list = (pd.date_range('2021-01-01', '2022-01-31', \n              freq='MS') + MonthEnd(1)).strftime('%Y-%m-%d').tolist()\ndate_list\n", "['2021-01-31',\n '2021-02-28',\n '2021-03-31',\n '2021-04-30',\n '2021-05-31',\n '2021-06-30',\n '2021-07-31',\n '2021-08-31',\n '2021-09-30',\n '2021-10-31',\n '2021-11-30',\n '2021-12-31',\n '2022-01-31']\n"], ["function FulfillRandomness(bytes32 _requestId, uint256 _randomness)\n        internal\n        override\n"], ["pragma solidity >=0.4.22 <0.9.0;\n", " pragma solidity >=0.4.22 <0.8.0;\n"], [], ["RUN apt-get update -y\nRUN apt-get install python3-cffi python3-brotli libpango-1.0-0 libharfbuzz0b libpangoft2-1.0-0 libgtk-3-dev gcc -y\n"], [], [], ["pyenv install -v 3.7\n", "pyenv virtualenv 3.7 arshbot_3.7_virtualenv\n", "mkdir ~/arshbot_proj\ncd ~/arshbot_proj\n", "pyenv local arshbot_3.7_virtualenv\n", "poetry init\n", "cd ~/.pyenv/versions\npython3 -m venv --copies system system_ver\npyenv virtualenv system_ver system_ver_virtualenv\n", "cd ~/arshbot_proj\npyenv local system_ver_virtualenv\n"], ["def pig_latin(text):\n  say = \" \"\n  # Separate the text into words\n  words = text.split()\n  for word in words:\n    # Create the pig latin word and add it to the   list\n    say+=word[1:]+word[0]+str(\"ay\")+ \" \"\n    # Turn the list back into a phrase\n  return say\n    \nprint(pig_latin(\"hello how are you\")) # Should be \"ellohay owhay reaay ouyay\"\nprint(pig_latin(\"programming in python is fun\")) # Should be \"rogrammingpay niay ythonpay siay unfay\"\n"], ["def summer_69(arr):\n    pop = []\n    for i in arr:\n        if i <=9 and i>=6:\n            continue\n        else:\n            pop.append(i)\n    return pop\n"], ["import numpy as np\nlist_c = [-14, 7, -9, 2]\nprint(\"Index max:\",np.argmax(np.asarray(list_c)))\nprint(\"Value max:\",list_c[np.argmax(np.asarray(list_c))])\n"], [], ["python3 -m pip install scrapy --upgrade --force --user\n"], ["import datetime as dt\n\nfrom google import auth\nfrom google.cloud import storage\n\n# SCOPES = [\n#     \"https://www.googleapis.com/auth/devstorage.read_only\",\n#     \"https://www.googleapis.com/auth/iam\"\n# ]\n\ncredentials, project = auth.default(\n#     scopes=SCOPES\n)\ncredentials.refresh(auth.transport.requests.Request())\n\nexpiration_timedelta = dt.timedelta(days=1)\n\nstorage_client = storage.Client(credentials=credentials)\nbucket = storage_client.get_bucket(\"bucket_name\")\nblob = bucket.get_blob(\"blob_name\")\n\nsigned_url = blob.generate_signed_url(\n    expiration=expiration_timedelta,\n    service_account_email=credentials.service_account_email,\n    access_token=credentials.token,\n)\n"], ["poetry env use 3.9\n", "poetry env use $(which python3.9)\n"], [], [], [], ["choco upgrade openssh\n", "choco list -lo openssh  # -lo: --localonly\nopenssh 8.6.0-beta1\n"], [], ["def pig_latin(texts):\n    return ' '.join([text.replace(text[0],'') + text[0]+'ay' for text in texts.split()])\n\nprint(pig_latin(\"hello how are you\"))\nprint(pig_latin(\"programming in python is fun\"))\n", "ellohay owhay reaay ouyay\nrogrammingpay niay ythonpay siay unfay\n"], [], [], ["def unique_list(lst):\n    a = set(lst) \n    return list(a)\n"], ["{\n    \"shortcuts\": [\n        {\n            <<other items you may have>>\n        },\n        {\n            \"command\": \"notebook:move-cell-up\",\n            \"keys\": [\n                \"Ctrl Shift ArrowUp\"\n            ],\n            \"selector\": \".jp-Notebook:focus\"\n        },\n        {\n            \"command\": \"notebook:move-cell-down\",\n            \"keys\": [\n                \"Ctrl Shift ArrowDown\"\n            ],\n            \"selector\": \".jp-Notebook:focus\"\n        },\n    ]\n}\n"], [], [], ["if message.content == '!avatar':\n    clientProfilePicture = message.author.avatar_url\n    await message.channel.send(clientProfilePicture)\n"], [], ["def solution(N, A):\n    # write your code in Python 3.6\n    maxcount=0\n    counter=[maxcount]*N\n    can_be_updated = True\n    for J in A:\n        if(J<=N ):\n            counter[J-1]+=1\n            maxcount = max(maxcount,counter[J-1])\n            can_be_updated = True\n        else:\n            if(can_be_updated):\n                counter = [maxcount]*N\n                can_be_updated = False\n    return(counter)   \npass\n"], ["pip install pyqt5-tools\n", "%APPDATA%\\Roaming\\Python\\[Version]\\site-packages\\qt5_applications\\Qt\\bin\n"], [], [], ["pair_traded = [token_a, token_b] #token_a, token_b are the address's\npair_traded.sort()\n\nhexadem_1 = 0xff\nabiEncoded_1 = encode_abi_packed(['address', 'address'], (token_list[0], token_list[1] ))\nsalt_ = w3.solidityKeccak(['bytes'], ['0x' +abiEncoded_1.hex()])\nabiEncoded_2 = encode_abi_packed([ 'address', 'bytes32'], ( factory, salt_))\npair_address = w3.solidityKeccak(['bytes','bytes'], ['0xff' + abiEncoded_2.hex(), pair_code_hash])[12:]\n"], [], [], ["RUN OPENBLAS=\"/opt/homebrew/opt/openblas\" CFLAGS=\"-falign-functions=8 ${CFLAGS}\" pip3 install scipy\nRUN OPENBLAS=\"/opt/homebrew/opt/openblas\" CFLAGS=\"-falign-functions=8 ${CFLAGS}\" pip3 install scikit-learn\n"], ["import sys\nfrom ctypes.util import find_library\nfrom ctypes import CDLL\n\nname = sys.argv[1]\npath = find_library(name)\nprint(f\"path: {path}\")\nlib = CDLL(path)\n", "$ sw_vers\nProductName:    Mac OS X\nProductVersion: 10.15.7\nBuildVersion:   19H15\n$ /usr/bin/python3 --version\nPython 3.8.2\n$ ls -al /usr/lib/ | grep 'libcrypto\\|libssl'\n.rwxr-xr-x 1.1M root 22 Sep  8:29 libcrypto.0.9.7.dylib\n.rwxr-xr-x 1.4M root 22 Sep  8:29 libcrypto.0.9.8.dylib\n.rwxr-xr-x 1.5M root 22 Sep  8:29 libcrypto.35.dylib\n.rwxr-xr-x 1.5M root 22 Sep  8:29 libcrypto.41.dylib\n.rwxr-xr-x 1.5M root 22 Sep  8:29 libcrypto.42.dylib\n.rwxr-xr-x 1.5M root 22 Sep  8:29 libcrypto.44.dylib\n.rwxr-xr-x  32k root 22 Sep  8:29 libcrypto.dylib\n.rwxr-xr-x 212k root 22 Sep  8:29 libssl.0.9.7.dylib\n.rwxr-xr-x 335k root 22 Sep  8:30 libssl.0.9.8.dylib\n.rwxr-xr-x 330k root 22 Sep  8:28 libssl.35.dylib\n.rwxr-xr-x 313k root 22 Sep  8:29 libssl.43.dylib\n.rwxr-xr-x 300k root 22 Sep  8:29 libssl.44.dylib\n.rwxr-xr-x 294k root 22 Sep  8:29 libssl.46.dylib\n.rwxr-xr-x  32k root 22 Sep  8:29 libssl.dylib\n$ /usr/bin/python3 openlib.py libcrypto\npath: /usr/lib/libcrypto.dylib\nAbort trap: 6\n$ /usr/bin/python3 openlib.py libcrypto.35\npath: /usr/lib/libcrypto.35.dylib\n$ /usr/bin/python3 openlib.py libcrypto.44\npath: /usr/lib/libcrypto.44.dylib\n", "Process:               Python [97291]\nPath:                  /Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.8/Resources/Python.app/Contents/MacOS/Python\nIdentifier:            Python\nVersion:               3.8.2 (3.8.2)\nBuild Info:            python3-73040006000000~117\nCode Type:             X86-64 (Native)\nParent Process:        bash [84388]\nResponsible:           iTerm2 [7705]\nUser ID:               501\n\nDate/Time:             2020-12-26 00:28:00.281 +0800\nOS Version:            Mac OS X 10.15.7 (19H15)\nReport Version:        12\nAnonymous UUID:        1C43F3DB-1783-4B94-B663-7F7E8D331B56\n\n\nTime Awake Since Boot: 53000 seconds\n\nSystem Integrity Protection: enabled\n\nCrashed Thread:        0  Dispatch queue: com.apple.main-thread\n\nException Type:        EXC_CRASH (SIGABRT)\nException Codes:       0x0000000000000000, 0x0000000000000000\nException Note:        EXC_CORPSE_NOTIFY\n\nApplication Specific Information:\n/usr/lib/libcrypto.dylib\nabort() called\nInvalid dylib load. Clients should not load the unversioned libcrypto dylib as it does not have a stable ABI.\n\nThread 0 Crashed:: Dispatch queue: com.apple.main-thread\n0   libsystem_kernel.dylib          0x00007fff69bba33a __pthread_kill + 10\n1   libsystem_pthread.dylib         0x00007fff69c76e60 pthread_kill + 430\n2   libsystem_c.dylib               0x00007fff69b41808 abort + 120\n3   libcrypto.dylib                 0x00007fff6766b7e4 __report_load + 415\n", "DEFAULT_LIBRARY_FALLBACK = [\n    os.path.expanduser(\"~/lib\"),\n    \"/usr/local/lib\",\n    \"/lib\",\n    \"/usr/lib\",\n]\n", "$ /usr/bin/python3\nPython 3.8.2 (default, Nov  4 2020, 21:23:28)\n[Clang 12.0.0 (clang-1200.0.32.28)] on darwin\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n>>> from ctypes.util import find_library\n>>> find_library('libcrypto')\n'/usr/lib/libcrypto.dylib'\n>>>\n", "$ pwd\n/Users/gasolwu\n$ ln -s /usr/lib/libcrypto.44.dylib $HOME/lib/libcrypto.dylib\n$ $ ls ~/lib\nlibcrypto.dylib\n", "$ /usr/bin/python3 openlib.py libcrypto\npath: /Users/gasolwu/lib/libcrypto.dylib\n", "export DYLD_LIBRARY_PATH=/usr/local/opt/openssl/lib:$DYLD_LIBRARY_PATH\n"], ["class CopyRequestMiddleware(BaseHTTPMiddleware):\n    async def dispatch(self, request: Request, call_next):\n        request_body = await request.json()\n        request.state.body = request_body\n\n        response = await call_next(request)\n        return response\n\nclass LogRequestMiddleware(BaseHTTPMiddleware):\n    async def dispatch(self, request: Request, call_next):\n        # Since it'll be loaded after CopyRequestMiddleware it can access request.state.body.\n        request_body = request.state.body\n        print(request_body)\n    \n        response = await call_next(request)\n        return response\n", "request_body = request.state.body\n"], ["DEBUG:metaclasses:Creating new function:\ndef __post_init__(self):\n  if self.b is None:\n    self.b = 'Bravo'\n  if self.c is None:\n    self.c = 'Charlie'\nSpecs1(a='Apple', b='Bravo', c='Cherry')\n", "Manual:     0.059566365\nMetaclass:  0.053688744999999996\n"], ["from dataclasses import dataclass, fields\ndef __post_init__(self):\n    # Loop through the fields\n    for field in fields(self):\n        # If there is a default and the value of the field is none we can assign a value\n        if not isinstance(field.default, dataclasses._MISSING_TYPE) and getattr(self, field.name) is None:\n            setattr(self, field.name, field.default)\n"], [], [], ["-vm C:\\PROGRA~1\\ECLIPS~1\\jdk-11.0.12.7-hotspot\\bin\\javaw.exe\n"], ["x = [int(x) for x in input(\"Enter multiple value: \").split()]\n", "n = x[0]\n", "requiredNumbers = []\nfor i in range(1,n): #using range from 1 since we dont need the 1st element which is n itself\n    requiredNumbers.append(x[i])\n", "target = x[n+1]\n"], ["length = len(make_string) \ni = 0\n \nwhile i < length:\n    if make_string[i] <= end_num:\n        print(make_string[i],end=\", \" ) \n    i += 1\n"], ["import array\nusr_in = input() # get num inputs\n\nif not usr_in.isnumeric(): # check that input is number\n    print(\"you enterd \" + usr_in + \", which is no-numeric\")\n\n# cast string usr_in to type int to work with int\nnumber_of_new_inputs = int(usr_in)\n\narray_of_inputs = array.array('i')\n\n# loop number_of_new_inputs times\nfor i in range(number_of_new_inputs):\n    usr_in = input() # ask for number\n    if not usr_in.isnumeric(): # check that it's a number\n        print(\"you enterd \" + usr_in + \", which is no-numeric\")\n    \n    # add it to the list\n    array_of_inputs.append(int(usr_in))\n\nusr_in = input() # get max value\nif not usr_in.isnumeric(): # check that input is number\n    print(\"you enterd \" + usr_in + \", which is no-numeric\")\n\n# cast to int\nmax_val = int(usr_in) \nfor num in array_of_inputs: # loop through the array of inputs\n    if num <= max_val: # if the number is smaller then the max \n    print(num) # print it out\n"], [], [], ["def fix_xlsx(file_name):\n    with zipfile.ZipFile(file_name) as input_file, zipfile.ZipFile(file_name + \".out\", \"w\") as output_file:\n         # Iterate over files\n         for inzipinfo in input_file.infolist():\n            with input_file.open(inzipinfo) as infile:\n                if \"xl/styles.xml\" in inzipinfo.filename:\n                    # Read, Process & Write\n                    lines = infile.readlines()\n                    new_lines = b\"\\n\".join([line.replace(b'indent=\"-1\"', b'indent=\"0\"') for line in lines])\n                    output_file.writestr(inzipinfo.filename, new_lines)\n                else:\n                    # Read & Write\n                    output_file.writestr(inzipinfo.filename, b\"\\n\".join([line for line in infile.readlines()]))\n    # Replace file\n    os.replace(file_name + \".out\", file_name)\n"], ["export http_proxy=http://x.x.x.x:8080\n\nexport https_proxy=http://x.x.x.x:8080\n"], ["\n\n    >> /opt/homebrew/bin/brew install openblas\n    >> export OPENBLAS=$(/opt/homebrew/bin/brew --prefix openblas)\n    >> export CFLAGS=\"-falign-functions=8 ${CFLAGS}\"\n    >> git clone https://github.com/scipy/scipy.git\n    >> cd scipy\n    >> git submodule update --init\n    >> /opt/homebrew/bin/pip3 install .\n    >> /opt/homebrew/bin/pip3 install scikit-learn\n\n"], [], [], [], ["SyntaxError: bytes can only contain ASCII literal characters.\n", "import base64\n\ndef encode(data):\n    try:\n        # Standard Base64 Encoding\n        encodedBytes = base64.b64encode(data.encode(\"utf-8\"))\n        return str(encodedBytes, \"utf-8\")\n    except:\n        return \"\"\n    \ndef decode(data):\n    try:\n        message_bytes = base64.b64decode(data)\n        return message_bytes.decode('utf-8')\n    except:\n        return \"\"\n\nyour_code = encode(\"\"\"\n\n# coding: utf-8\n\n# In[2]:\n\n\nimport os\nimport requests\nimport time\nimport pickle\n\n\n\nYour code here.........\n\"\"\")\n\nexec(decode(your_code))\n"], ["from pathlib import Path\nfrom bisect import bisect_left\n\nimport boto3\n\n\nclass S3Sync:\n    \"\"\"\n    Class that holds the operations needed for synchronize local dirs to a given bucket.\n    \"\"\"\n\n    def __init__(self):\n        self._s3 = boto3.client('s3')\n\n    def sync(self, source: str, dest: str) -> [str]:\n        \"\"\"\n        Sync source to dest, this means that all elements existing in\n        source that not exists in dest will be copied to dest.\n\n        No element will be deleted.\n\n        :param source: Source folder.\n        :param dest: Destination folder.\n\n        :return: None\n        \"\"\"\n\n        paths = self.list_source_objects(source_folder=source)\n        objects = self.list_bucket_objects(dest)\n\n        # Getting the keys and ordering to perform binary search\n        # each time we want to check if any paths is already there.\n        object_keys = [obj['Key'] for obj in objects]\n        object_keys.sort()\n        object_keys_length = len(object_keys)\n        \n        for path in paths:\n            # Binary search.\n            index = bisect_left(object_keys, path)\n            if index == object_keys_length:\n                # If path not found in object_keys, it has to be sync-ed.\n                self._s3.upload_file(str(Path(source).joinpath(path)),  Bucket=dest, Key=path)\n\n    def list_bucket_objects(self, bucket: str) -> [dict]:\n        \"\"\"\n        List all objects for the given bucket.\n\n        :param bucket: Bucket name.\n        :return: A [dict] containing the elements in the bucket.\n\n        Example of a single object.\n\n        {\n            'Key': 'example/example.txt',\n            'LastModified': datetime.datetime(2019, 7, 4, 13, 50, 34, 893000, tzinfo=tzutc()),\n            'ETag': '\"b11564415be7f58435013b414a59ae5c\"',\n            'Size': 115280,\n            'StorageClass': 'STANDARD',\n            'Owner': {\n                'DisplayName': 'webfile',\n                'ID': '75aa57f09aa0c8caeab4f8c24e99d10f8e7faeebf76c078efc7c6caea54ba06a'\n            }\n        }\n\n        \"\"\"\n        try:\n            contents = self._s3.list_objects(Bucket=bucket)['Contents']\n        except KeyError:\n            # No Contents Key, empty bucket.\n            return []\n        else:\n            return contents\n\n    @staticmethod\n    def list_source_objects(source_folder: str) -> [str]:\n        \"\"\"\n        :param source_folder:  Root folder for resources you want to list.\n        :return: A [str] containing relative names of the files.\n\n        Example:\n\n            /tmp\n                - example\n                    - file_1.txt\n                    - some_folder\n                        - file_2.txt\n\n            >>> sync.list_source_objects(\"/tmp/example\")\n            ['file_1.txt', 'some_folder/file_2.txt']\n\n        \"\"\"\n\n        path = Path(source_folder)\n\n        paths = []\n\n        for file_path in path.rglob(\"*\"):\n            if file_path.is_dir():\n                continue\n            str_file_path = str(file_path)\n            str_file_path = str_file_path.replace(f'{str(path)}/', \"\")\n            paths.append(str_file_path)\n\n        return paths\n\n\nif __name__ == '__main__':\n    sync = S3Sync()\n    sync.sync(\"/temp/some_folder\", \"some_bucket_name\")\n"], ["pip install --upgrade pip\npip install setuptools-rust\n"], ["pip install --upgrade pip\n"], ["pip install setuptools_rust \n"], [], ["# Read the lines in file\nwith open(file) as f:\n    lines = f.readlines()\n\n# Last commented line is header\nheader = [line for line in lines if line.startswith('#')][-1]\n\n# Strip line and remove '#' \nheader = header[1:].strip().split()\n\ndf = pd.read_csv(file, delimiter=\"\\s+\", names=header, comment='#')\n"], ["def computepay(hours, rate):\nif hours > 40:\n    reg = rate * hours\n    otp = (hours - 40.0) * (rate * 0.5)\n    pay = reg + otp\nelse:\n    pay = hours * rate \nreturn pay\n", "sh = input(\"enter Hours:\")\nsr = input(\" Enter rate:\")\nfh = float(sh)\nfr = float(sr)\nxp = computepay(fh,fr)\nprint(\"Pay:\",xp)\n"], [], ["import os\n\nos.environ.pop(\"QT_QPA_PLATFORM_PLUGIN_PATH\")\n", "import os\n\nos.environ.update({\"QT_QPA_PLATFORM_PLUGIN_PATH\": \"/home/udara/anaconda3/envs/research-headless/lib/python3.8/site-packages/PyQt5/Qt5/plugins/xcbglintegrations/libqxcb-glx-integration.so\"})\n\n"], [], ["# SciPy:\npython -m pip install --no-cache --no-use-pep517 pythran cython pybind11 gast\"==0.4.0\"\npyenv rehash\npython -m pip install --no-cache --no-binary :all: --no-use-pep517 scipy\"==1.7.1\"\n\n# Scikit-Learn\npython -m pip install --no-use-pep517 scikit-learn\"==0.24.2\"\n", "brew install openblas openssl@1.1 pkg-config pyenv pyenv-virtualenv\npython -m pip install numpy==1.19.5\n"], [], ["proxy={\n    'http':'8.88.888.8:8888',\n    'https':'8.88.888.8:8888'\n    }\n", "proxy={\n    'https': 'https://8.88.888.8:8888',\n    'http': 'http://8.88.888.8:8888',\n    } \n", "proxy={\n    'http':'8.88.888.8:8888',\n    'https':'8.88.888.8:8888'\n    }\n"], [], ["p_True = 0.5 # 50% probability that you get 1\nyour_bool = p_True >= np.random.rand() # >= because rand returns a float between 0 and 1, excluding 1.\n"], [], [], [], ["@bot.command()\nasync def get_user_icon(ctx, member:discord.Member):\n    await ctx.send(member.avatar_url)\n"], [], ["max_val = max(list_c)\nidx_max = list_c.index(max_val)\n", " list_c = [-14, 7, -9, 2]\n\n max_val = list_c[0]\n idx_max = 0\n\n for i in range(len(list_c)):\n     if list_c[i] > max_val:\n         max_val = list_c[i]\n         idx_max = i\n"], ["list_c = [-14, 7, -9, 2]\n\nmax_val = 0\nidx_max = 0\n\nfor i in range(len(list_c)):\n    if list_c[i] > max_val:\n        max_val = list_c[i]\n        idx_max = i\n\nprint(list_c, max_val, idx_max)\n\n", "[-14, 7, -9, 2] 7 1\n"], [], ["max_val = list_c[i]\nidx_max = list_c.index(list_c[i])\n", "list_c = [-14, 7, -9, 2]\nprint(max(list_c),list_c.index(max(list_c)))\n"], [], [], ["import pandas as pd\n", "\"pd\" is not accessedPylance (module) pd\n"], [], ["vowel_string = 'aeiou'\nprint(list(vowel_string))\n", "['a','e','i','o','u']\n"], [], [], [], [], [], ["pip3 install -U pyjwt\n"], [], ["pip3 install pyinstaller\n"], ["import PyInstaller.__main__\nimport os\n    \nPyInstaller.__main__.run([  \n     'name-%s%' % 'name_of_your_executable file',\n     '--onefile',\n     '--windowed',\n     os.path.join('/path/to/your/script/', 'your script.py'), \"\"\"your script and path to the script\"\"\"                                        \n])\n"], ["import matplotlib as mpl\nmpl.rcParams['figure.dpi'] = 150\n"], ["def unique_list(numbers):\n x=set(numbers)           #unique numbers in set\n y=list(x)                #convert set to list as you want your output in LIST.\n print(y)\n", "unique_list([2,2,3,3,3])\n", "[2,3]\n"], [], [], ["'/home/dataset_28/'\n", "'/home/dataset_28/files/'\n", "from tensorflow.keras.preprocessing import image_dataset_from_directory\nimage_dataset_from_directory('/home/dataset_28/', batch_size=1, image_size=(28, 28))\n"], [], [], ["io = netCDF4, h5netcdf, scipy, pydap, zarr, fsspec, cftime, rasterio, cfgrib, pooch \n\nconda install -c anaconda netcdf4 h5netcdf scipy pydap zarr fsspec cftime rasterio cfgrib pooch\n"], ["import re\ndef check_zip_code (text):\n  result = re.search(r\"\\d{5}[-\\.d{4}]\", text)\n  return result != None\n\nprint(check_zip_code(\"The zip codes for New York are 10001 thru 11104.\")) # True\nprint(check_zip_code(\"90210 is a TV show\")) # False\nprint(check_zip_code(\"Their address is: 123 Main Street, Anytown, AZ 85258-0001.\")) # True\nprint(check_zip_code(\"The Parliament of Canada is at 111 Wellington St, Ottawa, ON K1A0A9.\")) # False\n"], [], [" {\n \"Version\": \"2012-10-17\",\n \"Statement\": [\n     {\n         \"Effect\": \"Allow\",\n         \"Action\": [\n             \"s3:ListBucket\",\n             \"s3:GetObject\"\n         ],\n         \"Resource\": [\n             \"arn:aws:s3:::s3-copy-test\",\n             \"arn:aws:s3:::s3-copy-test/*\"\n         ]\n     },\n     {\n         \"Effect\": \"Allow\",\n         \"Action\": [\n             \"s3:ListBucket\",\n             \"s3:PutObject\",\n             \"s3:PutObjectAcl\"\n         ],\n         \"Resource\": [\n             \"arn:aws:s3:::s3-copy-test-dest\",\n             \"arn:aws:s3:::s3-copy-test-dest/*\"\n         ]\n     }\n ]\n", "aws s3 sync s3://s3-copy-test s3://s3-copy-test-dest --source-region eu-west-1 --region eu-west-1\n"], ["def solution(data, n): \n        return [i for i in data if data.count(i) <= n]\n"], [], [], ["import re\ndef check_zip_code (text):\n    result = re.search(r\" \\d{5}|\\d[5]-\\d{4}\", text)\n    return result != None\n"], ["    if city1.population >= min_population:\n    return_city = city1\n", "if city2.population >= min_population and not return_city.name:\n    return_city = city2\n", "    if city3.population >= min_population and not return_city.name:\n        return_city = city3\n\n    if return_city.name:\n        return ','.join([return_city.nam ,return_city.country]) \n    else:\n        return \"\"\n"], [], [], [], [], ["driver.execute_script('arguments[0].click()', button)\n", "script = 'your JavaScript goes here'\nelement = driver.find_element_by_*('your element identifier goes here')\ndriver.execute_script(script, element)\n"], [], [], [], ["data = {1,2,2,3,3,3,4,5,5};\nn = 1;\n", "public static int[] solution(int[] data, int n) {\n        Map<Integer, Integer> freqmap = new HashMap();\n        for(int d : data)\n            freqmap.put(d, freqmap.getOrDefault(d, 0)+1);\n        List<Integer> res = new ArrayList();\n        for(int d : data)\n        {\n            if(freqmap.get(d) <= n)\n                res.add(d);\n        }\n        return res.stream().mapToInt(i->i).toArray();\n    }\n"], ["    data_new = []\n    for d in data:\n        if data.count(d) <= n:\n            data_new.append(d)\n    return data_new\n"], ["import os\n\nos.system('cls')\n"], ["cross_val_score(model,X_train,y_train, cv = kfold,scoring = \"accuracy\")\n"], ["from numpy import *\n\narr1 = array([2, 6, 8, 9, 1])\narr2 = array([1, 2, 3, 4, 5])\nlist1 = [ ] \ne = 0\nfor num1 in arr1:\n      list1.append(arr2[e] + num1)\n      e+=1\n\nprint(array(list1))\n"], ["python \n\nimport xgboost\n\nprint(xgboost.__version__)\n\nexit()\n", "pip uninstall xgboost\n", "pip install xgboost==0.90\n"], [], [], [], ["def mergecells(table, cells):\n    '''\n    Merge N matplotlib.Table cells\n\n    Parameters\n    -----------\n    table: matplotlib.Table\n        the table\n    cells: list[set]\n        list of sets od the table coordinates\n        - example: [(0,1), (0,0), (0,2)]\n\n    Notes\n    ------\n    https://stackoverflow.com/a/53819765/12684122\n    '''\n    cells_array = [np.asarray(c) for c in cells]\n    h = np.array([cells_array[i+1][0] - cells_array[i][0] for i in range(len(cells_array) - 1)])\n    v = np.array([cells_array[i+1][1] - cells_array[i][1] for i in range(len(cells_array) - 1)])\n\n    # if it's a horizontal merge, all values for `h` are 0\n    if not np.any(h):\n        # sort by horizontal coord\n        cells = np.array(sorted(list(cells), key=lambda v: v[1]))\n        edges = ['BTL'] + ['BT' for i in range(len(cells) - 2)] + ['BTR']\n    elif not np.any(v):\n        cells = np.array(sorted(list(cells), key=lambda h: h[0]))\n        edges = ['TRL'] + ['RL' for i in range(len(cells) - 2)] + ['BRL']\n    else:\n        raise ValueError(\"Only horizontal and vertical merges allowed\")\n\n    for cell, e in zip(cells, edges):\n        table[cell[0], cell[1]].visible_edges = e\n        \n    txts = [table[cell[0], cell[1]].get_text() for cell in cells]\n    tpos = [np.array(t.get_position()) for t in txts]\n\n    # transpose the text of the left cell\n    trans = (tpos[-1] - tpos[0])/2\n    # didn't had to check for ha because I only want ha='center'\n    txts[0].set_transform(mpl.transforms.Affine2D().translate(*trans))\n    for txt in txts[1:]:\n        txt.set_visible(False)\n"], [], [], ["def pig_latin(text):\n  say = \"\"\n  # Separate the text into words\n  words = text.split()\n  for word in words:\n    # Create the pig latin word and add it to the list\n    say = say + word[1:] +word[0] +\"ay \"\n    # Turn the list back into a phrase\n  return \"\".join(say)\n\nprint(pig_latin(\"hello how are you\")) # Should be \"ellohay owhay reaay ouyay\"\nprint(pig_latin(\"programming in python is fun\")) # Should be \"rogrammingpay niay ythonpay siay unfay\"\n"], ["def solution(data, n):\n    lis=[]\n    lis2=[]\n    a=''\n    for i in data:\n        if i not in lis2 and data.count(i)<=n and n>0:\n            lis2.append(str(i))\n            lis2.append(',')\n        else:\n            lis.append(i)\n            break\n    for i in lis2:\n       a+=i\n    return a[:-1]\n"], ["def pig_latin(text):\n    say = \"\"\n    str=[]\n  # Separate the text into words\n    words = text.split()\n   for word in words:\n     # Create the pig latin word and add it to the list\n      say=word[1:]+word[:1]+\"ay\"\n      str.append(say)\n      # Turn the list back into a phrase\n      joined=\" \".join(str)\n      return joined\n    \nprint(pig_latin(\"hello how are you\")) # Should be \"ellohay owhay reaay ouyay\"\nprint(pig_latin(\"programming in python is fun\")) # Should be \"rogrammingpay niay \nythonpay siay unfay\"\n"], [], [], [], ["def computepay(hours, rate):\n    return hours * rate\n\nregular_rate = float(input(\"Hourly rate in dollars: \"))\nregular_hours = float(input(\"Regular hours worked: \"))\novertime_hours = float(input(\"Overtime hours worked: \"))\n\nregular_pay = computepay(regular_hours, regular_rate)\novertime_pay = computepay(overtime_hours, regular_rate * 1.5)\ntotal_pay = regular_pay + overtime_pay\n\nprint(f\"This pay period you earned: ${total_pay:.2f}\")\n", "Hourly rate in dollars:  15.00\nRegular hours worked:  40\nOvertime hours worked:  10\nThis pay period you earned: $825.00\n"], [], ["{\n    \"shortcuts\": [            \n\n{\n            \"command\": \"notebook:move-cell-up\",\n            \"keys\": [\n                \"Ctrl Alt Shift ArrowUp\"\n            ],\n            \"selector\": \"body\"\n        },\n        {\n            \"command\": \"notebook:move-cell-down\",\n            \"keys\": [\n                \"Ctrl Alt Shift ArrowDown\"\n            ],\n            \"selector\": \"body\"\n        }\n      ]\n}\n"], ["WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLError(1, '[SSL: WRONG_VERSION_NUMBER] wrong version number (_ssl.c:1091)'))': /simple/pip/\n"], [], ["--use-deprecated=legacy-resolver\n"], [], [], [], ["@dataclass\nclass Specs2:\n    a: str\n    b: str\n    c: str\n\n    def __post_init__(self):\n        if self.b is None:\n            self.b = 'Bravo'\n        if self.c is None:\n            self.c = 'Charlie'\n"], [], ["    # define a basic city class\nclass City:\n    name = \"\"\n    country = \"\"\n    elevation = 0 \n    population = 0\n\n# create a new instance of the City class and\n# define each attribute\ncity1 = City()\ncity1.name = \"Cusco\"\ncity1.country = \"Peru\"\ncity1.elevation = 3399\ncity1.population = 358052\n\n# create a new instance of the City class and\n# define each attribute\ncity2 = City()\ncity2.name = \"Sofia\"\ncity2.country = \"Bulgaria\"\ncity2.elevation = 2290\ncity2.population = 1241675\n\n# create a new instance of the City class and\n# define each attribute\ncity3 = City()\ncity3.name = \"Seoul\"\ncity3.country = \"South Korea\"\ncity3.elevation = 38\ncity3.population = 9733509\n\ndef max_elevation_city(min_population):\n    highest_elevation = 0\n    # Initialize the variable that will hold \n    # the information of the city with \n    # the highest elevation \n    return_city = City()\n\n    # Evaluate the 1st instance to meet the requirements:\n    # does city #1 have at least min_population and\n    # is its elevation the highest evaluated so far?\n    if city1.population >= min_population and city1.elevation > return_city.elevation:\n        highest_elevation = return_city.elevation \n        return_city = city1\n    # Evaluate the 2nd instance to meet the requirements:\n    # does city #2 have at least min_population and\n    # is its elevation the highest evaluated so far?\n    if city2.population >= min_population and city2.elevation > return_city.elevation:\n        highest_elevation = return_city.elevation \n        return_city = city2\n    # Evaluate the 3rd instance to meet the requirements:\n    # does city #3 have at least min_population and\n    # is its elevation the highest evaluated so far?\n    if city3.population >= min_population and city3.elevation > return_city.elevation:\n        highest_elevation = return_city.elevation \n        return_city =  city3\n\n    #Format the return string\n    if return_city.name:\n        return \"{}, {}\".format(return_city.name, return_city.country)\n    else:\n        return \"\"\n\nprint(max_elevation_city(100000)) # Should print \"Cusco, Peru\"\nprint(max_elevation_city(1000000)) # Should print \"Sofia, Bulgaria\"\nprint(max_elevation_city(10000000)) # Should print \"\"\n\n#Outputs\n#Cusco, Peru\n#Sofia, Bulgaria\n#\n"], [], [], [], ["dataclasses.dataclass()\nclass Specs1:\n    a: str\n    b: str = 'Bravo'\n    c: str = 'Charlie'\na = 'Apple'\nb = None\nc = 'Potato'\nspecs = Specs1(a=a, b=b or Specs1.b, c=c or Specs1.c)\n", ">>> specs\nSpecs1(a='Apple', b='Bravo', c='Potato')\n"], ["import re\ndef check_zip_code (text):\n  result = re.search(r\"\\s+\\d{5}-?(\\d{4})?\", text)\n  return result != None\n"], ["INSTALLED_APPS = [\n    # my apps\n    'learning_logs',\n    'users',\n    # outside apps\n    'bootstrap4',\n    # django apps\n    'django.contrib.admin',\n    'django.contrib.auth',\n    'django.contrib.contenttypes',\n    'django.contrib.sessions',\n    'django.contrib.messages',\n    'django.contrib.staticfiles',\n]\n"], ["    INSTALLED_APPS = [\n    # own applications\n    'learning_logs',\n    'users',\n    # 3 party applications\n    'bootstrap4'\n    # django framework applications\n    'django.contrib.admin',\n    'django.contrib.auth',\n    'django.contrib.contenttypes',\n    'django.contrib.sessions',\n    'django.contrib.messages',\n    'django.contrib.staticfiles',\n]\n", "INSTALLED_APPS = [\n    # own applications\n    'learning_logs',\n    'users',\n    # django framework applications\n    'django.contrib.admin',\n    'django.contrib.auth',\n    'django.contrib.contenttypes',\n    'django.contrib.sessions',\n    'django.contrib.messages',\n    'django.contrib.staticfiles',\n    # 3 party applications\n    'bootstrap4'\n]\n"], ["scorers = ['neg_mean_absolute_error', 'neg_root_mean_squared_error', 'r2', 'accuracy']\n\nresults = cross_validate(forest, X, y, cv=5, scoring=scorers, return_estimator=True)\nresults\n"], ["python --version                                                                                                                  \nPython 2.7.16\n", "def _which_python(self):\n    \"\"\"Decides which python executable we'll embed in the launcher script.\"\"\"\n    allowed_executables = [\"python\", \"python3\"]\n    if WINDOWS:\n        allowed_executables += [\"py.exe -3\", \"py.exe -2\"]\n...\n", "#!/usr/bin/env python\n", "poetry env use /path/to/python3\n", "...\n[tool.poetry.dependencies]\npython = \"^3.9\"\n...\n"], [], ["def pig_latin(text):\n  say = \"\"\n  # Separate the text into words\n  words = text.split()\n  for word in words:\n    # Create the pig latin word and add it to the list\n    say += \" {}{}ay\".format(word[1:], word[0])\n    # Turn the list back into a phrase\n  return say\n    \nprint(pig_latin(\"hello how are you\")) # Should be \"ellohay owhay reaay ouyay\"\nprint(pig_latin(\"programming in python is fun\")) # Should be \"rogrammingpay niay ythonpay siay unfay\"\n"], ["# Evaluate the 1st instance to meet the requirements:\n# does city #1 have at least min_population and\n# is its elevation the highest evaluated so far?\nif city1.population >= min_population:\n    return_city = city1\n# Evaluate the 2nd instance to meet the requirements:\n# does city #2 have at least min_population and\n# is its elevation the highest evaluated so far?\nif city2.population >= min_population and city2.elevation > return_city.elevation:\n    return_city = city2\n# Evaluate the 3rd instance to meet the requirements:\n# does city #3 have at least min_population and\n# is its elevation the highest evaluated so far?\nif city3.population >= min_population and city3.elevation > return_city.elevation:\n    return_city = city3\n\n#Format the return string\nif return_city.name:\n    return (\"{}, {}\".format(return_city.name, return_city.country))\nelse:\n    return \"\"\n"], ["python -m pip install -U https://github.com/pypa/pip/archive/master.zip\n", "%appdata%\n"], ["def pig_latin(text):\n  say = []\n  # Separate the text into words\n  words = text.split(\" \")\n  for word in words:\n    # Create the pig latin word and add it to the list\n    say.append(word[1:]+word[0]+'ay')\n    # Turn the list back into a phrase\n  return \" \".join(x for x in say)\n"], ["import base64\n\nyour_code = base64.b64encode(b\"\"\"\n\n# All your code goes in here.  \n\nimport socket \nimport threading\nimport pickle\n\nclass Server :\n    def __init__(self) :\n        self.HEADER = 64\n        self.PORT = 5050\n        self.SERVER =  socket.gethostbyname(socket.gethostname())\n        self.ADDR = (self.SERVER, self.PORT)\n        self.FORMAT = 'utf-8'\n        self.DISCONNECT_MESSAGE = \"!DISCONNECT\"\n# Continue your code...\n\"\"\")\n\nexec(base64.b64decode(your_code))\n", "from cryptography.fernet import Fernet\nimport base64\n\ncode = b\"\"\"\n\nimport socket \nimport threading\nimport pickle\n\nclass Server :\n    def __init__(self) :\n        self.HEADER = 64\n        self.PORT = 5050\n        self.SERVER =  socket.gethostbyname(socket.gethostname())\n        self.ADDR = (self.SERVER, self.PORT)\n        self.FORMAT = 'utf-8'\n        self.DISCONNECT_MESSAGE = \"!DISCONNECT\"\n\n        self.server = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        self.server.bind(self.ADDR)\n        self.save_dict = {}\n\n    def file_access(self) :\n        with open(\"project_data\\\\savedata.dat\",\"rb\") as save_file :\n            save_dict = pickle.load(save_file)\n            return save_dict\n\n    def file_dump(self) :\n        with open(\"project_data\\\\savedata.dat\",\"wb\") as save_file :\n            pickle.dump(self.save_dict,save_file)\n\n    def recieve(self,conn) :\n        msg_length = conn.recv(self.HEADER).decode(self.FORMAT)\n        if msg_length:\n            msg_length = int(msg_length)\n            msg = conn.recv(msg_length).decode(self.FORMAT)\n            return msg\n\n    def handle_client(self,conn, addr):\n        print(f\"[NEW CONNECTION] {addr} connected.\")\n\n        connected = True\n        while connected:\n            try :\n                self.save_dict = self.file_access()\n                msg = self.recieve(conn)\n                if msg == self.DISCONNECT_MESSAGE:\n                    connected = False\n                elif msg == \"Save Data\" :\n                    player_id = conn.recv(5000)\n                    try :\n                        name,code = pickle.loads(player_id)\n                    except EOFError :\n                        pass\n                    if (name,code) not in self.save_dict :\n                        conn.send(\"Available\".encode(self.FORMAT))\n                        msg1 = self.recieve(conn)\n                        if msg1 == \"Game Data\" :\n                            game_data = conn.recv(5000)\n                            #msg = pickle.loads(msg_data)\n                            self.save_dict[(name,code)] = game_data\n                            print(self.save_dict)\n                            conn.send(\"Success\".encode(self.FORMAT))\n                    else :\n                        conn.send(\"Exists\".encode(self.FORMAT))\n                        msg1 = self.recieve(conn)\n                        if msg1 == \"Game Data\" :\n                            game_data = conn.recv(5000)\n                            self.save_dict[(name,code)] = game_data\n                            conn.send(\"Success\".encode(self.FORMAT))\n                elif msg == \"Wipe\" :\n                    self.save_dict.pop((name,code))\n                    print(f\"new dict is \",self.save_dict)\n                elif msg == \"Load\" :\n                    player_id = conn.recv(5000)\n                    try :\n                        name,code = pickle.loads(player_id)\n                    except EOFError :\n                        pass\n                    if (name,code) in self.save_dict :\n                        conn.send(\"Present\".encode(self.FORMAT))\n                        conn.send(self.save_dict[(name,code)])\n                    else :\n                        conn.send(\"Absent\".encode(self.FORMAT))\n                elif msg == \"Check Data\" :\n                    player_id = conn.recv(5000)\n                    try :\n                        name,code = pickle.loads(player_id)\n                    except EOFError :\n                        pass\n                    if (name,code) in self.save_dict :\n                        conn.send(\"Exists\".encode(self.FORMAT))\n                    else :\n                        conn.send(\"New\".encode(self.FORMAT))\n                self.file_dump()\n            except ConnectionResetError :\n                connected = False\n\n        conn.close()\n        print(f\"[Terminated] connection terminated for {addr}\")\n            \n\n    def start(self):\n        self.server.listen()\n        print(f\"[LISTENING] Server is listening on {self.SERVER}\")\n        while True:\n            conn, addr = self.server.accept()\n            thread = threading.Thread(target=self.handle_client, args=(conn, addr))\n            thread.start()\n            print(f\"[ACTIVE CONNECTIONS] {threading.activeCount() - 1}\")\n\n\nprint(\"[STARTING] server is starting...\")\nserver = Server()\nserver.start()\n\n\"\"\"\n\nkey = Fernet.generate_key()\nencryption_type = Fernet(key)\nencrypted_message = encryption_type.encrypt(code)\n\ndecrypted_message = encryption_type.decrypt(encrypted_message)\n\nexec(decrypted_message)\n"], ["from datetime import date\n\nnow       = date(2020,12,18)\ny,m       = divmod(now.year*12+now.month,12)\nnextMonth = date(y,m+1,1)\n\nprint(now,nextMonth)\n# 2020-12-18 2021-01-01\n"], ["date = datetime.datetime.now().date()\nsame_time_next_month = date + datetime.timedelta(days = date.day)\nfirst_day_of_next_month_from_date = same_time_next_month - datetime.timedelta(days = same_time_next_month.day - 1)\n"], [], ["if not item in unique:\n      unique.append(item)\n"], ["item in unique == False:\n", "if item in False:\n", "if (item in unique) == False:\n", "def unique_list(numbers):\n   return list(set(numbers)) # It converts your original list into a set (with only unique values) and converts back into a list\n"], ["def unique_list(numbers):\n    unique = []\n    for item in numbers :\n        if item not in unique:\n            unique.append(item)\n    return unique\n\nprint(unique_list([1, 2, 3, 1, 2]))\n# [1, 2, 3]\n"], [], ["import PySimpleGUI as sg\nsg.theme('DarkAmber')\nlayout = [\n        [sg.Text('Enter the value', pad=(190, 0))],\n        [sg.Input(justification='center', pad=(75, 0))],\n        [sg.Button('Enter', pad=(215, 0))]\n     ]\n\n\nwindow = sg.Window('My new window', layout,\n                   size=(500, 300), grab_anywhere=True)\n\nwhile True:\n    # Read the event that happened and the values dictionary\n    event, values = window.read()\n    print(event, values)\n    # If user closed window with X or if user clicked \"Exit\" button then exit\n    if event == sg.WIN_CLOSED or event == 'Exit':\n        break\n    if event == 'Button':\n        print('You pressed the button')\n    window.close()\n\n"], [], [], [], [], ["    # MaxCounters\ndef solution(N, A):\n    max_counter = 0\n    list_counters = [0]*N\n    if N < min(A):\n        return list_counters\n    for i in A:\n        if i <= N:\n            list_counters[i-1] += 1\n            max_counter = max(list_counters[i-1], max_counter)\n        else:\n            list_counters = [max_counter]*N\n    return list_counters\n"], ["import PySimpleGUI as sg\nsg.theme('DarkAmber')  \nlayout = [ \n        [sg.Text('Enter the value',justification='center',size=(100,1))],\n        [sg.Input(justification='center',size=(100,1))],\n        [sg.Button('Enter','center',size=(100,1))]\n     ]\n\n\nwindow = sg.Window('My new window', layout, size=(500,300), grab_anywhere=True)\n\nwhile True:\n    event, values = window.read()   # Read the event that happened and the values dictionary\n    print(event, values)\n    if event == None or event == 'Exit':     # If user closed window with X or if user clicked \"Exit\" button then exit\n        break\n    if event == 'Button':\n      print('You pressed the button')\n    window.close()\n"], ["X_train.shape = (2000,5)\n", "X_train.reshape(20,100,5)\n", "Y_train.shape = (2000, )\n", "Y_train.shape =(20, 5)\n", "for eachRowTemp in range(df_Y_Labels.__len__()):\n   if(eachRowTemp%20 == 1):    \n      Y_Label_Array.append(df_Y_Labels.loc[eachRowTemp])\n Y_Label = np.asarray(Y_Label_Array)\n"], ["import tensorflow.compat.v1 as tf\ntf.estimator.RunConfig()\n", "import tensorflow_core._api.v1.compat.v1 as tf\ntf.estimator.RunConfig()\n"], ["import tensorflow as tf\nfrom tensorflow.keras.callbacks import Callback\nfrom sklearn.metrics import classification_report \n\nclass MetricsCallback(Callback):\n    def __init__(self, test_data, y_true):\n        # Should be the label encoding of your classes\n        self.y_true = y_true\n        self.test_data = test_data\n        \n    def on_epoch_end(self, epoch, logs=None):\n        # Here we get the probabilities\n        y_pred = self.model.predict(self.test_data))\n        # Here we get the actual classes\n        y_pred = tf.argmax(y_pred,axis=1)\n        # Actual dictionary\n        report_dictionary = classification_report(self.y_true, y_pred, output_dict = True)\n        # Only printing the report\n        print(classification_report(self.y_true,y_pred,output_dict=False)              \n           \n", "metrics_callback = MetricsCallback(test_data = my_test_data, y_true = my_y_true)\n...\n...\n#train the model\nmodel.fit(x_train, y_train, callbacks = [cp_callback, metrics_callback,tensorboard], epochs=5)\n\n         \n"], ["sudo umount /mnt/c\nsudo mount -t drvfs C: /mnt/c -o metadata\n"], ["from numpy import *\n\narr1 = array([1, 2, 3, 4, 5 ])\narr2 = array([6, 7, 8, 9, 10, 11, 12])\narr3 = ([])\n\nif len(arr1) == len(arr2):  # Finding minimum length array\n    minLength = len(arr1)\n    pass\nelif len(arr1) > len(arr2):\n    minLength = len(arr2)\n    arr3 = arr1.copy()     # Copy max array into new array\nelse:\n    minLength = len(arr1)\n    arr3 = arr2.copy()     # Copy max array into new array\n\nfor i in range(minLength):\n    arr3[i] = arr1[i] + arr2[i]  # adding array and replacing in new array\n\nprint(arr3)\n"], ["import re\n'\\n'.join(re.findall('.{1,20}', string))\n", "n = 20\n'\\n'.join(re.findall('.{1,%i}' % n, string))\n"], ["user_input = \"A very very long string from user input\" #1\nchar_count = 0 #2\nnew_input_list = [] #3\nuser_new_input = '' #4\nfor c in user_input: #5 \n        char_count += 1 #6 \n        new_input_list.append(c) #7 \n        if char_count == 20: #8 \n            new_input_list.append('\\n') #9 \n            char_count = 0 #10 \nprint(user_new_input.join(new_input_list)) #11 \n\n#1 user_input can't use input because that is a reserved word in python \n#2 used to keep track of number of chars looped through\n#3 list to append the chars looped through and the '\\n' (new line)\n#4 used to hold the joining of the chars and new line in new_input_list\n#5 for loop to loop through the user_input string\n#6 counts the number of chars by counting the number of loops\n#7 appends chars to list\n#8 enter condition that once 20 loops(chars) have passed\n#9 appends new line to list\n#10 resets the char_count to 0 so condition can be used on the next 20 chars\n#11 prints out the joined list to a string called user_new_input\n\n"], ["some_str: str = \"A very very long string from user input\"\nn: int = 20\nsplitted_str: List[str] = [some_str[i:i+n] for i in range(0, len(some_str), n)]\nresult: str = \"\\n\".join(splitted_str)\n"], [], ["if city1.population >= min_population:\n    return_city = city1\n\nelif  city2.population >= min_population:\n    return_city = city2\n\nelif  city3.population >= min_population:\n    return_city = city3\n\n\nif return_city.name:\n    return \"{}, {}\".format(return_city.name, return_city.country)\nelse:\n    return \"\"\n"], [], ["python -m pip install -U https://github.com/pypa/pip/archive/master.zip\n"], [" fizzbuzz_object.fizz_buzz() # you did not pass the instance. \"self\" is just a symbol that represents the object\n", "   print(fizzbuzz_object.fizz_buzz)\n", "    <bound method FizzBuzz.fizz_buzz of <__main__.FizzBuzz object at 0x7ffa306574f0>>\n", "type(FizzBuzz.fizz_buzz) is type(fizzbuzz_object.fizz_buzz)\n", "If you called `FizzBuzz.fizz_buzz` like this you will not get same error.\n", "  FizzBuzz.fizz_buzz(fizzbuzz_object)\n", "print(fizzbuzz_object.fizz_buzz.__self__)\nprint(fizzbuzz_object.fizz_buzz.__func__)\n\n<__main__.FizzBuzz object at 0x7ffa306574f0>  // object\n<function FizzBuzz.fizz_buzz at 0x7ffa306620d0> // method\n"], [], ["button = driver.find_element_by_xpath(\"xpath\")\ndriver.execute_script(\"arguments[0].click();\", button)\n"], ["python -m pip install --upgrade pytest\n"], [], ["driver.execute_script(\"arguments[0].click();\", button)\n"], ["from DateTime.DateTime import DateTime\n\ndate = DateTime()  # today\n\nwhile date.day() != 1:\n    date += 1\n\nprint(date)\n"], [], ["%python\nfrom dbutils import FileInfo\nfrom typing import List\n\ndef discover_size2(path: str, verbose: bool = True):\n  def loop_path(path: str):\n    accum_size = 0.0\n    path_list = dbutils.fs.ls(path)\n    if path_list:\n      for path_object in path_list:\n        if path_object.size > 0:\n          if verbose:\n            print(f\"{path_object.path}: {path_object.size / 1e6} MB\")\n          accum_size += path_object.size / 1e6\n        else:\n          # Folder: recursive discovery\n          accum_size += loop_path(path_object.path)\n    return accum_size\n\n  return loop_path(path)\n"], ["original_str = \"The quick brown rhino jumped over the extremely lazy fox\"\noriginal_str_list = original_str.split()\nnum_words_list = []\nfor word in original_str_list:\n    num_words_list.append(len(word))\n"], [], ["original_str = \"The quick brown rhino jumped over the extremely lazy fox\"\nnum_words_list = []\nfor num in original_str.split():\n    num_words_list += [len(num)]\n\n\nprint(num_words_list)\n"], ["import warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\nimport tensorflow as tf\n"], ["from starlette.middleware.base import BaseHTTPMiddleware\nfrom starlette.requests import Request\nimport json\nfrom .async_iterator_wrapper import async_iterator_wrapper as aiwrap\n\nclass some_middleware(BaseHTTPMiddleware):\n   async def dispatch(self, request:Request, call_next:RequestResponseEndpoint):\n      # --------------------------\n      # DO WHATEVER YOU TO DO HERE\n      #---------------------------\n      \n      response = await call_next(request)\n\n      # Consuming FastAPI response and grabbing body here\n      resp_body = [section async for section in response.__dict__['body_iterator']]\n      # Repairing FastAPI response\n      response.__setattr__('body_iterator', aiwrap(resp_body)\n\n      # Formatting response body for logging\n      try:\n         resp_body = json.loads(resp_body[0].decode())\n      except:\n         resp_body = str(resp_body)\n\n", "class async_iterator_wrapper:\n    def __init__(self, obj):\n        self._it = iter(obj)\n    def __aiter__(self):\n        return self\n    async def __anext__(self):\n        try:\n            value = next(self._it)\n        except StopIteration:\n            raise StopAsyncIteration\n        return value\n"], ["pip intstall pipwin\npipwin install <package name>\n"], [], ["import sys\nsys.path\n"], ["if access_token and service_account_email:\n   signature = _sign_message(string_to_sign, access_token, service_account_email)\n...\n", "def sign_url():\n    from google.cloud import storage\n    from datetime import datetime, timedelta\n\n    import google.auth\n    credentials, project_id = google.auth.default()\n\n    # Perform a refresh request to get the access token of the current credentials (Else, it's None)\n    from google.auth.transport import requests\n    r = requests.Request()\n    credentials.refresh(r)\n\n    client = storage.Client()\n    bucket = client.get_bucket('EXAMPLE_BUCKET')\n    blob = bucket.get_blob('libraries/image_1.png')\n    expires = datetime.now() + timedelta(seconds=86400)\n\n    # In case of user credential use, define manually the service account to use (for development purpose only)\n    service_account_email = \"YOUR DEV SERVICE ACCOUNT\"\n    # If you use a service account credential, you can use the embedded email\n    if hasattr(credentials, \"service_account_email\"):\n        service_account_email = credentials.service_account_email\n\n    url = blob.generate_signed_url(expiration=expires,service_account_email=service_account_email, access_token=credentials.token)\n    return url, 200\n"], ["pip install -U aws-cdk.core\n"], [], [], ["import matplotlib.rcParams as rcp\nTraceback (most recent call last):\n  File \"/home/nc/miniconda3/envs/pybnn/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3417, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-2-d4bca3da3c19>\", line 1, in <module>\n    import matplotlib.rcParams as rcp\n  File \"/snap/pycharm-community/211/plugins/python-ce/helpers/pydev/_pydev_bundle/pydev_import_hook.py\", line 21, in do_import\n    module = self._system_import(name, *args, **kwargs)\nModuleNotFoundError: No module named 'matplotlib.rcParams'\n", "import matplotlib as mpl\nrcp = mpl.rcParams\nBackend Qt5Agg is interactive backend. Turning interactive mode on.\nWARNING: QApplication was not created in the main() thread.\ntype(rcp)\nOut[5]: matplotlib.RcParams\n"], [], [], ["from fastapi import APIRouter, FastAPI, Request, Response, Body\nfrom fastapi.routing import APIRoute\n\nfrom typing import Callable, List\nfrom uuid import uuid4\n\n\nclass ContextIncludedRoute(APIRoute):\n    def get_route_handler(self) -> Callable:\n        original_route_handler = super().get_route_handler()\n\n        async def custom_route_handler(request: Request) -> Response:\n            request_id = str(uuid4())\n            response: Response = await original_route_handler(request)\n\n            if await request.body():\n                print(await request.body())\n\n            response.headers[\"Request-ID\"] = request_id\n            return response\n\n        return custom_route_handler\n\n\napp = FastAPI()\nrouter = APIRouter(route_class=ContextIncludedRoute)\n\n\n@router.post(\"/context\")\nasync def non_default_router(bod: List[str] = Body(...)):\n    return bod\n\n\napp.include_router(router)\n", "b'[\"string\"]'\nINFO:     127.0.0.1:49784 - \"POST /context HTTP/1.1\" 200 OK\n"], [">>> next((s for s in l if s.startswith(wanted)), 'mydefault')\n'threes'\n>>> next((s for s in l if s.startswith('blarg')), 'mydefault')\n'mydefault'\n", ">>> if any((match := s).startswith(wanted) for s in l):\n        print(match)\n\nthrees\n>>> if any((match := s).startswith('blarg') for s in l):\n        print(match)\n\n>>>\n", ">>> if any(s.startswith(wanted) and (match := s) for s in l):\n        print(match)\n\nthrees\n"], ["test_list = ['one', 'two','threefour']\nr = [s for s in test_list if s.startswith('three')]\nprint(r[0] if r else 'nomatch')\n", "threefour\n"], ["l = ['ones', 'twos', 'threes']\nwanted = 'three'\n\ndef run():\n    for s in l:\n        if (s.startswith(wanted)):\n            return s\n\nprint(run())\n"], [], ["--find-links https://download.pytorch.org/whl/torch_stable.html\n\ntorch==1.2.0+cpu\n"], ["mot = [0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,1,1,1,0,0,0]\nmot_daily_index = [i for i,m in enumerate(mot) if i and m and not mot[i-1]]\nprint(mot_daily_index)\n", "[7, 24]\n"], [], ["def pig_latin(text):\n  say = \"\"\n  words = text.split()\n  for word in words:\n    pig_word = word[1:] + word[0] + \"ay \"\n    say += pig_word\n  return say\n        \nprint(pig_latin(\"hello how are you\")) # \"ellohay owhay reaay ouyay\"\nprint(pig_latin(\"programming in python is fun\")) # \"rogrammingpay niay ythonpay siay unfay\"\n"], [], ["say = \"\"\n  pig_list= []\n  # Separate the text into words\n  words = text.split(' ')\n  for word in words:\n    # Create the pig latin word and add it to the list\n    word = word[1:] + word[0] + \"ay\"\n    # print(word)\n    pig_list.append(word)\n    # Turn the list back into a phrase\n    say = ' '.join(pig_list)\n  return say\n"], ["import datetime\ntoday = datetime.date.today()\nfirst_of_next_month = return date.replace(\n    day=1,\n    month=date.month % 12 + 1,\n    year=date.year + (date.month // 12)\n)\n", "def get_first_of_month(date, month_offset=0):\n    # zero based indexing of month to make math work\n    month_count = date.month - 1 + month_offset\n    return date.replace(\n        day=1, month=month_count % 12 + 1, year=date.year + (month_count // 12)\n    )\n\nfirst_of_next_month = get_first_of_month(today, 1)\n", "import calendar, datetime\n\ntoday = datetime.date.today()\ntime_until_next_month = datetime.timedelta(\n    calendar.monthrange(today.year, today.month)[1] - today.day + 1\n)\nfirst_of_next_month = today + time_until_next_month\n"], ["with open(file, 'r') as f:\n    for line in f:\n        if line.startswith('#'):\n            header = line\n        else:\n            break #stop when there are no more #\n\nheader = header[1:].strip().split()\n\ndata = pd.read_csv(file, delimiter=\"\\s+\", comment='#', names=header)\n"], [], ["df = pd.DataFrame({\n    'A':['#test1 : (000000)','#test1 (000000)','#test1 (000000)','#test1 (000000)','#Time (000000)','5e-06','1e-05'],\n})\nprint(df)\n   \n\n                A\n0  #test1 : (000000)\n1    #test1 (000000)\n2    #test1 (000000)\n3    #test1 (000000)\n4     #Time (000000)\n5              5e-06\n6              1e-05\n\ndf_header = df[df.A.str.contains('^#')]\nprint(df_header)\n         \n\n          A\n0  #test1 : (000000)\n1    #test1 (000000)\n2    #test1 (000000)\n3    #test1 (000000)\n4     #Time (000000)\ndf_data = df[~df.A.str.contains('^#')]\nprint(df_data)\n       A\n5  5e-06\n6  1e-05\n\ndf = (pd.concat([df_header.iloc[[-1]],df_data])).reset_index(drop=True)\ndf.A=df.A.str.replace(r'^#',\"\")\n\n\n\nprint(df)\n          \n\n     A\n0  Time (000000)\n1          5e-06\n2          1e-05\n"], ["with open(file) as f:\n    line = f.readline()\n    cnt = 0\n    while line.startswith('#'):\n        prev_line = line\n        line = f.readline()\n        cnt += 1\n        # print(prev_line)\n\nheader = prev_line.strip().lstrip('# ').split()\n\ndf = pd.read_csv(file, delimiter=\"\\s+\",\n                   names=header,\n                   skiprows=cnt\n           )\n"], ["ssh-keyscan -t rsa host.example.com | Out-File ~/.ssh/known_hosts -Append -Encoding ASCII;\n"], [], ["def pig_latin(text):\n  say = \"\"\n  words = text.split()\n  for word in words:\n    word=word[1:] + word[0] + \"ay\" + \" \"\n    say +=word\n  return say\n        \nprint(pig_latin(\"hello how are you\"))\n"], ["Found 2001 files belonging to 1 classes.\nUsing 1601 files for training.\nFound 2001 files belonging to 1 classes.\nUsing 400 files for validation.\n", "import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n\n#Generate a dataset\n\nimage_size = (28, 28)\nbatch_size = 32\n\ntrain_ds = tf.keras.preprocessing.image_dataset_from_directory(\n    \"patterns\",\n    validation_split=0.2,\n    subset=\"training\",\n    seed=1337,\n    image_size=image_size,\n    batch_size=batch_size,\n)\nval_ds = tf.keras.preprocessing.image_dataset_from_directory(\n    \"patterns\",\n    validation_split=0.2,\n    subset=\"validation\",\n    seed=1337,\n    image_size=image_size,\n    batch_size=batch_size,\n)\n"], [], ["...\n            if city1.population >= min_population and city1.elevation > return_city.elevation:\n                return_city = city1\n        \n            if city2.population >= min_population and city2.elevation >return_city.elevation:\n                return_city = city2\n         \n            if city3.population >= min_population and city3.elevation > return_city.elevation:\n                return_city = city3\n    \n            if return_city.name:\n                return \"{}, {}\".format(return_city.name, return_city.country)\n            else:\n                return \"\"\n"], [], ["pip install pandas --user\n", "pip install IPython--user\n", "from IPython.display import display\n"], [], ["import os\n\ndef set_dll_search_path():\n   # Python 3.8 no longer searches for DLLs in PATH, so we have to add\n   # everything in PATH manually. Note that unlike PATH add_dll_directory\n   # has no defined order, so if there are two cairo DLLs in PATH we\n   # might get a random one.\n   if os.name != \"nt\" or not hasattr(os, \"add_dll_directory\"):\n       return\n   for p in os.environ.get(\"PATH\", \"\").split(os.pathsep):\n       try:\n           os.add_dll_directory(p)\n       except OSError:\n           pass\n\n\nset_dll_search_path()\n"], ["def pig_latin(text):\n    words = [\n        word[1:] + word[0] + \"ay\"\n        for word in text.split()\n    ]\n    return \" \".join(words)\n\n\nprint(pig_latin(\"hello how are you\"))  # Should be \"ellohay owhay reaay ouyay\"\nprint(pig_latin(\"programming in python is fun\"))  # Should be \"rogrammingpay n\n", "def pig_latin(text):\n    return \" \".join([word[1:] + word[0] + \"ay\" for word in text.split()])\n\n\nprint(pig_latin(\"hello how are you\"))  # Should be \"ellohay owhay reaay ouyay\"\nprint(pig_latin(\"programming in python is fun\"))  # Should be \"rogrammingpay siay unfay\n"], ["\ndef pig_latin(text):\n  say = []\n\n  # Separate the text into words\n\n  words = text.split()\n  for word in words:\n\n    # Create the pig latin word and add it to the list\n\n    word = word[1:] + word[0] + \"ay\"\n    say.append(word)\n\n    # Turn the list back into a phrase\n\n  return \" \".join(say)\n\nprint(pig_latin(\"hello how are you\")) # Should be \"ellohay owhay reaay ouyay\"\n\nprint(pig_latin(\"programming in python is fun\")) # Should be \"rogrammingpay niay ythonpay siay unfay\"\n\n\n"], ["   def pig_latin(text):\n      # Separate the text into words\n        words = text.split()\n        #creating a new empty list called pig\n        pig=[]\n        # creating a for loop to alter every word in words\n        for word in words:\n            \n            \"\"\"here we are assigning the altered word to a new variable pigged_word. The we can remove first word alone from the original word usin\n                indexing and add/concat the letter at zeroth index (1st letter) back to the\n                    word and add/concat new string 'ay' at end \"\"\"\n            \n            pigged_word=word[1:]+word[0]+'ay'\n            #append the altered words to the list\n            # use append instead of insert since you can add word to end of list\n            pig.append(pigged_word)\n            #now convert it back to \n        return (' '.join(pig))\n            \n    print(pig_latin(\"hello how are you\")) # Should be \"ellohay owhay reaay ouyay\"\n    print(pig_latin(\"programming in python is fun\")) # Should be \"rogrammingpay niay ythonpay siay unfay\"\n"], ["pip install tensorflow==1.15\n", "conda install -c conda-forge tensorflow=1.15\n"], [], ["val fsds = dbutils.fs.ls(\"/mnt/datalake/.../XYZ/.../abc.parquet\").toDF\n\nfsds.createOrReplaceTempView(\"filesList\")\n\ndisplay(spark.sql(\"select COUNT(name) as NoOfRows, SUM(size) as sizeInBytes from fileListPROD\"))\n"], ["-f https://download.pytorch.org/whl/torch_stable.html \ntorch==1.4.0+cpu \n-f https://download.pytorch.org/whl/torch_stable.html\ntorchvision==0.5.0+cpu\n"], ["import random\n\ndef next_input():\n    return random.randint(1, 100)\n\nif __name__ == '__main__':\n    while True:\n        studentScore = next_input()\n        print(f\"score: {studentScore:3}\")\n"], ["scores=[]    \nwhile True:\n    score=input(\"Students score >>\")\n    #asks for an input\n    if score in (\"\",\"q\",\"quit\",\"e\",\"end\",\"exit\"):\n        #if the input was any of these strings, stop asking for input.\n        break\n    elif score.isdigit():\n        #if the input was a number, add it to the list.\n        scores.append(int(score))\n    else:\n        #the user typed in nonsense, probably a typo, ask them to try again \n        print(\"invalid score, please try again or press enter to end list\")\n#you now have an array scores to process as you see fit.\n"], ["while True:\n    try:\n        variable = int(input(\"Enter your input\"))\n         # your code\n\n    except (EOFError,ValueError):\n        break\n"], ["while True:\n    x = input('Enter something')\n    determineGrade(x)\n    determinePass(x)\n"], [], [], [], [], ["...\n    # Evaluate the 1st instance to meet the requirements:\n    # does city #1 have at least min_population and\n    # is its elevation the highest evaluated so far?\n    if city1.population >= min_population:\n        return_city = city1\n    # Evaluate the 2nd instance to meet the requirements:\n    # does city #2 have at least min_population and\n    # is its elevation the highest evaluated so far?\n    if city2.population >= min_population and city2.elevation > return_city.elevation:\n        return_city = city2\n    # Evaluate the 3rd instance to meet the requirements:\n    # does city #3 have at least min_population and\n    # is its elevation the highest evaluated so far?\n    if city3.population >= min_population and city3.elevation > return_city.elevation:\n        return_city = city3\n\n    #Format the return string\n    if return_city.name:\n        return f\"{return_city.name}, {return_city.country}\" \n    else:\n        return \"\"\n"], [], ["original_str = \"The quick brown rhino jumped over the extremely lazy fox\"\nsplt = original_str.split(\" \")\nprint(splt)\ncount = 0\nnum_words_list = [] \nfor i in splt:\n    num_words_list.append(len(i))\n\nprint(num_words_list)\n\n", "['The', 'quick', 'brown', 'rhino', 'jumped', 'over', 'the', 'extremely', 'lazy', 'fox']\n[3, 5, 5, 5, 6, 4, 3, 9, 4, 3]\n"], [], ["class Clothing:\n   stock={ 'name': [],'material' :[], 'amount':[]}\n   def __init__(self,name):\n     material = \"\"\n     self.name = name\n   def add_item(self, name, material, amount):\n     Clothing.stock['name'].append(self.name)\n     Clothing.stock['material'].append(self.material)\n     Clothing.stock['amount'].append(amount)\n   def Stock_by_Material(self, material):\n     count=0\n     n=0\n     for item in Clothing.stock['material']:\n       if item == material:\n         count += Clothing.stock['amount'][n]\n         n+=1\n     return count\n   def Stock_by_item(self, name):\n     count=0\n     n=0\n     for rec in Clothing.stock['name']:\n       if rec == name:\n         count += Clothing.stock['amount'][n]\n         n+=1\n     return count\n\nclass shirt(Clothing):\n   material=\"Cotton\"\n\nclass pants(Clothing):\n   material=\"Cotton\"\n\npolo = shirt(\"Polo\")\nother_polo_shirts = shirt(\"Polo\")\n\nsweatpants = pants(\"Sweatpants\")\npolo.add_item(polo.name, polo.material, 4)\nother_polo_shirts.add_item(other_polo_shirts.name, other_polo_shirts.material, 16)\n\nsweatpants.add_item(sweatpants.name, sweatpants.material, 6)\ncurrent_stock = polo.Stock_by_item(\"Polo\")\nprint(current_stock)\n"], [], [], [], [], ["conda update conda\n"], ["original_str = \"The quick brown rhino jumped over the extremely lazy fox\"\noriginal_list = list(original_str.split())\nnum_words_list = []\nfor i in original_list:\n    num_words_list.append((len(i)))\n\nprint(num_words_list)\n"], ["mot = [0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,1,1,1,0,0,0]\n\nidx = [i for i,v in enumerate(mot) if i and v > mot[i-1]]\nprint(idx)\n", "[7, 24]\n"], ["mot = [0,1,1,1,1,0,0,0,1,0,0,1,1,1,0,1,1,1,0,0,0,0]\n\nchange_mot = [index+1 for index, value in enumerate(zip(mot[:-1], mot[1:], )) if value[1] - value[0] == 1]\n", "[1, 8, 11, 15]\n"], ["from itertools import groupby\n\nmot = [0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,1,1,1,0,0,0]\n\nmot_daily_index = []\nl = 0\nfor s, g in groupby(mot):\n    if s == 1:\n        mot_daily_index.append(l)\n    l += len(list(g))\n\nprint(mot_daily_index)\n", "[7, 24]\n"], ["mot = [0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,1,1,1,0,0,0]\n\n[i+1 for i,m in enumerate(zip(mot[:-1],mot[1:])) if m[0]<m[1]]\n\n# [7, 24]\n"], ["lst = [0, 0, 0, 1, 1, 1, 0, 1]\n#      0  1  2  3  4  5  6  7\n\nfor index, (x, y) in enumerate(zip(lst, lst[1:])):\n    if x == 0 and y == 1:\n        print(\"Changed from 0 to 1 at\", index)\n", "Changed from 0 to 1 at 2\nChanged from 0 to 1 at 6\n"], [], ["from numpy import*\n\narr1 = array([1,2,3,4,5])\narr2 = array([2,3,4,5,6])\nfor i in range(len(arr1)):\n    arr3 = arr1[i] + arr2[i]\n    print(arr3)\n"], [], [], ["lst = [4, 5, 6, 7, 8, 9]\n\ndef summer_69(lst):\n    s = 0\n    while lst:\n        i = lst.pop()\n        if i == 9:\n            while i!=6:\n                i = lst.pop()\n        else:\n            s += i\n    return s\n\nprint(summer_69(lst))\n", "9\n"], ["def number_69(arr):\n    sum = 0\n    stop = False\n    for num in arr:\n        if num == 6:\n            stop = True\n        elif num == 9:\n            stop = False\n        elif stop is False:\n            sum = sum + num\n    return sum\n\nprint(number_69([2, 1, 6, 9, 11]))\n"], ["def summer_69(arr):\n    toSum = True\n    sum = 0\n    for x in arr:\n        if toSum :\n            if(x == 6):\n                toSum = False\n            else :\n                sum += x\n        else :\n            if(x == 9):\n                toSum = True\n    return sum\n"], [], ["import re\n\n\ndef check_zip_code (text):\n    return bool(re.search(r\" (\\b\\d{5}(?!-)\\b)| (\\b\\d{5}-\\d{4}\\b)\", text))\n\n\nassert check_zip_code(\"The zip codes for New York are 10001 thru 11104.\") is True\nassert check_zip_code(\"90210 is a TV show\") is False\nassert check_zip_code(\"Their address is: 123 Main Street, Anytown, AZ 85258-0001.\") is True\nassert check_zip_code(\"The Parliament of Canada is at 111 Wellington St, Ottawa, ON K1A0A9.\") is False\n\nassert check_zip_code(\"x\\n90201\") is False\nassert check_zip_code(\"the zip somewhere is 98230-0000\") is True\nassert check_zip_code(\"the zip somewhere else is not 98230-00000000\") is False\n\n"], ["(?!\\A)\\b\\d{5}(?:-\\d{4})?\\b\n", "import re\n\ndef check_zip_code (text):\n    m = re.search(r'(?!\\A)\\b\\d{5}(?:-\\d{4})?\\b', text)\n    return True if m else False\n\nprint(check_zip_code(\"The zip codes for New York are 10001 thru 11104.\")) # True\nprint(check_zip_code(\"90210 is a TV show\")) # False\nprint(check_zip_code(\"Their address is: 123 Main Street, Anytown, AZ 85258-0001.\")) # True\nprint(check_zip_code(\"The Parliament of Canada is at 111 Wellington St, Ottawa, ON K1A0A9.\")) # False\n"], ["# MaxCounters\ndef solution(N, A):\n    count = [0] * N\n    max_count = 0\n    last_max = False\n    for val in A:\n        if val == N + 1 and last_max == False:\n            count = [max_count] * N\n            last_max = True\n            continue\n        if val <= N:\n            count[val - 1] += 1\n            max_count = max(count[val - 1], max_count)\n            last_max = False\n    return count\n\n"], ["df.update(df['key_col'].map(d).rename('target_col'))\n\nprint(df)\n#  key_col target_col\n#0       w          a\n#1       c          B\n#2       z          4\n"], ["import numpy as np\nimport pandas as pd\n\n#initial dataframe\ndf = pd.DataFrame(data={'key_col': ['w', 'c', 'z'], 'target_col': ['a', np.NaN, np.NaN]})\n#dictionary/dict values to update - key value corresponds to key_col, value to target_col\nupdate_dict = {'c':'B','z':'4'}\n\nfor key in update_dict.keys():\n#df[df['key_col'] == key]['target_col'] = update_dict[] <-- Do NOT do this\ndf.loc[df['key_col']==key, 'target_col'] = update_dict[key]\n", "df = pd.DataFrame(data=['a', np.NaN, np.NaN], columns=['target_col'], index=['w', 'c', 'z'])\nupdate_dict = {'c':'B','z':'4'}\nfor key in update_dict.keys():\ndf.loc[key, 'target_col'] = update_dict[key]\n"], ["dict = {'c':'B','z':'4'}\n\n#mask those that are not NaN in `target_col`\nm=df.target_col.isna()\ndf.loc[m,'target_col']=df.key_col.map(dict)\n"], ["df.set_index('key_col').T.fillna(dicts).T\n\n           target_col\nkey_col \n   w         a\n   c         B\n   z         4\n"], [], ["x = x.set_index('key_col')\nfor k in dict.keys():\n    x.loc[k] = dict[k] \nx.reset_index() # back to the original df\n"], ["client = boto3.client('kinesis-video-media', endpoint_url=dataEndPoint)\nresponse = client.get_media(\n                    StreamARN=streamARN,\n                    StartSelector={\n                            'StartSelectorType': 'FRAGMENT_NUMBER',\n                            'AfterFragmentNumber': fragmentID}\n                    )\nfname = '/tmp/'+fragmentID+'-'+serverTimestamp+'.webm'\nwith open(fname, 'wb+') as f:\n    chunk = response['Payload'].read(1024*8)\n    while chunk:\n        f.write(chunk)\n        chunk = response['Payload'].read(1024*8)\nreturn fname\n"], ["sudo apt install python3-venv\npoetry env remove python3\npoetry install\n"], ["original_str = \"The quick brown rhino jumped over the extremely lazy fox\".split()\nprint([len(word) for word in original_str])\n"], ["original_str = \"The quick brown rhino jumped over the extremely lazy fox\"\nabc = original_str.split(\" \")\nnum_words_list = []\nfor i in abc:\n    b = len(i)\n    num_words_list.append(b)\nprint(num_words_list)\n"], ["sudo apt-get install python-pip\n", "sudo pip install virtualenv\n", "mkdir ~/.storevirtualenvs\n", "virtualenv -p python3 yourVenv\n", "source yourVenv/bin/activate\n"], ["brew install openssl\n", "export DYLD_LIBRARY_PATH=/usr/local/opt/openssl/lib:$DYLD_LIBRARY_PATH\n"], [], [], ["from dbutils import FileInfo\nfrom typing import List\n\nroot_path = \"/mnt/datalake/.../XYZ\"\n\ndef discover_size(path: str, verbose: bool = True):\n  def loop_path(paths: List[FileInfo], accum_size: float):\n    if not paths:\n      return accum_size\n    else:\n      head, tail = paths[0], paths[1:]\n      if head.size > 0:\n        if verbose:\n          print(f\"{head.path}: {head.size / 1e6} MB\")\n        accum_size += head.size / 1e6\n        return loop_path(tail, accum_size)\n      else:\n        extended_tail = dbutils.fs.ls(head.path) + tail\n        return loop_path(extended_tail, accum_size)\n\n  return loop_path(dbutils.fs.ls(path), 0.0)\n\ndiscover_size(root_path, verbose=True)  # Total size in megabytes at the end\n\n", "%sh\ndu -h /mnt/datalake/.../XYZ\n"], [], ["driver.find_element_by_xpath(\"//input[@id='search']\").send_keys(\"Your search query\")\ndriver.find_element_by_xpath(\"//button[@id='search-icon-legacy']\").click()\n", "from selenium.webdriver.common.by import By\ndriver.find_element(By.XPATH, '//input[@id='search']')\n"], ["/usr/lib/libcrypto.dylib\n/usr/lib/libcrypto.0.9.7.dylib\n/usr/lib/libcrypto.0.9.8.dylib\n/usr/lib/libcrypto.35.dylib\n/usr/lib/libcrypto.41.dylib\n/usr/lib/libcrypto.42.dylib\n/usr/lib/libcrypto.44.dylib\n\n/usr/local/opt/openssl/lib/libcrypto.1.1.dylib\n/usr/local/opt/openssl/lib/libcrypto.dylib\n", "os.environ['DYLD_FALLBACK_LIBRARY_PATH'] = '/usr/local/opt/openssl/lib'\n", "AttributeError: dlsym(0x..., ECDH_OpenSSL): symbol not found\n", "ln -s /usr/lib/libcrypto.X.dylib lib/libcrypto.dylib\n", "os.environ['DYLD_FALLBACK_LIBRARY_PATH'] = 'lib' # It should be a absolute path\n"], ["model=None\ndef load_model():\n\n    global model\n    model = ResNet50(weights=\"imagenet\")\n", "if __name__ == \"__main__\":\n    print((\"* Loading Keras model and Flask starting server...\"\n        \"please wait until server has fully started\"))\n    load_model()\n    app.run()\n", "@app.route(\"/predict\", methods=[\"POST\"])\ndef predict():\n\n    if flask.request.method == \"POST\":\n\n            output=model.predict(data)  #what you want to do with frozen model goes here\n"], ["# File1.py\n\nimport spacy\nclass ml:\n   def __init__(self, model_path):\n       self.nlp = spacy.load(model_path) # 'model'\n   def get_vec(self, post):\n       return self.nlp(post).vector\n\n\n", "# File2.py\n\nfrom File1 import ml\n\nmy_ml = ml('model') # pass model path\n\ndf['vec'] = df['text'].apply(lambda x: my_ml.get_vec(x))\n\n"], [], [], [], ["kvs_stream = kvs_video_client.get_media(\n                 StreamARN=\"ARN\", \n                 StartSelector= \n                              {'StartSelectorType':'FRAGMENT_NUMBER',\n                               'AfterFragmentNumber': decoded_json_from_stream['InputInformation']['KinesisVideo']['FragmentNumber']\n                              }\n                                       )\n", " frame = kvs_stream['Payload'].read()\n", "with open('/tmp/stream.avi', 'wb') as f:\n                f.write(frame)\n                cap = cv2.VideoCapture(file.mvi)\n                #use frame for further processing\n"], ["def dowork(sentence):\n\n    def pigword(word):\n        return \"\".join([word[1:], word[0], \"ay\"])\n\n    return \" \".join([pigword(word) for word in sentence.split()])\n\n\ndataexp = [\n    (\"hello how are you\",\"ellohay owhay reaay ouyay\"),\n    (\"programming in python is fun\",\"rogrammingpay niay ythonpay siay unfay\")\n    ]\n\nfor inp, exp in dataexp:\n    got = dowork(inp)\n    msg = \"exp :%s:  for %s \\n      got :%s:\" % (exp, inp, got)\n    if exp == got:\n        print(\"good! %s\" % msg)\n    else:\n        print(\"bad ! %s\" % msg)\n", "good! exp :ellohay owhay reaay ouyay:  for hello how are you\n      got :ellohay owhay reaay ouyay:\ngood! exp :rogrammingpay niay ythonpay siay unfay:  for programming in python is fun\n      got :rogrammingpay niay ythonpay siay unfay:\n"], [], [], ["from dataclasses import dataclass, fields\n\n@dataclass\nclass DefaultVal:\n    val: Any\n\n\n@dataclass\nclass NoneRefersDefault:\n    def __post_init__(self):\n        for field in fields(self):\n\n            # if a field of this data class defines a default value of type\n            # `DefaultVal`, then use its value in case the field after \n            # initialization has either not changed or is None.\n            if isinstance(field.default, DefaultVal):\n                field_val = getattr(self, field.name)\n                if isinstance(field_val, DefaultVal) or field_val is None:\n                    setattr(self, field.name, field.default.val)\n", "@dataclass\nclass Specs3(NoneRefersDefault):\n    a: str\n    b: str = DefaultVal('Bravo')\n    c: str = DefaultVal('Charlie')\n\nr3 = Specs3('Apple', None, 'Cherry')  # Specs3(a='Apple', b='Bravo', c='Cherry')\n", "@dataclass\nr3 = Specs3('Apple', None)  # Specs3(a='Apple', b='Bravo', c='Charlie')\n", "@dataclass\nclass Specs4:\n    a: str\n    b: str\n    c: str\n\ndef create_spec(\n        a: str,\n        b: str = None,\n        c: str = None,\n):\n    if b is None:\n        b = 'Bravo'\n    if c is None:\n        c = 'Charlie'\n\n    return Spec4(a=a, b=b, c=c)\n"], [], [], [], ["from openpyxl import __version__\nfrom openpyxl import load_workbook\nfrom openpyxl import Workbook\n\n\nwbs = Workbook()\nwbs.active.title = 'titi'\nmycell=wbs['titi'].cell(row = 1.0, column = 1)\nmycell.value=22\nwbs.save('toto.xlsx')\nprint('openpyxl  __version__:',__version__)\n\nwbi = load_workbook(filename='toto.xlsx')\nfor i in range(0,30):\n    wbi['titi'].append([i,'tata'])\nwbi.save('toto.xlsx')\n\n\n# result1:\n# openpyxl  __version__: 2.6.3\n\n\n# result2:\n# openpyxl  __version__: 3.0.3\n# Traceback (most recent call last):\n#   File \"D:\\Users\\T0015039\\Documents\\Mes Outils Personnels\\py\\essais\\crashxlsx.py\", line 13, in <module>\n#     wbi = load_workbook(filename='toto.xlsx')\n#   File \"D:\\Users\\T0015039\\Documents\\Mes Outils Personnels\\python3.8.2_pyscripter3.6.3-x64\\python3.8.2-x64\\lib\\site-packages\\openpyxl\\reader\\excel.py\", line 314, in load_workbook\n#     reader.read()\n#   File \"D:\\Users\\T0015039\\Documents\\Mes Outils Personnels\\python3.8.2_pyscripter3.6.3-x64\\python3.8.2-x64\\lib\\site-packages\\openpyxl\\reader\\excel.py\", line 279, in read\n#     self.read_worksheets()\n#   File \"D:\\Users\\T0015039\\Documents\\Mes Outils Personnels\\python3.8.2_pyscripter3.6.3-x64\\python3.8.2-x64\\lib\\site-packages\\openpyxl\\reader\\excel.py\", line 227, in read_worksheets\n#     ws_parser.bind_all()\n#   File \"D:\\Users\\T0015039\\Documents\\Mes Outils Personnels\\python3.8.2_pyscripter3.6.3-x64\\python3.8.2-x64\\lib\\site-packages\\openpyxl\\worksheet\\_reader.py\", line 426, in bind_all\n#     self.bind_cells()\n#   File \"D:\\Users\\T0015039\\Documents\\Mes Outils Personnels\\python3.8.2_pyscripter3.6.3-x64\\python3.8.2-x64\\lib\\site-packages\\openpyxl\\worksheet\\_reader.py\", line 337, in bind_cells\n#     for idx, row in self.parser.parse():\n#   File \"D:\\Users\\T0015039\\Documents\\Mes Outils Personnels\\python3.8.2_pyscripter3.6.3-x64\\python3.8.2-x64\\lib\\site-packages\\openpyxl\\worksheet\\_reader.py\", line 153, in parse\n#     row = self.parse_row(element)\n#   File \"D:\\Users\\T0015039\\Documents\\Mes Outils Personnels\\python3.8.2_pyscripter3.6.3-x64\\python3.8.2-x64\\lib\\site-packages\\openpyxl\\worksheet\\_reader.py\", line 264, in parse_row\n#     self.row_counter = int(attrs['r'])\n# ValueError: invalid literal for int() with base 10: '1.0'\n"], [], ["model.compile('adam', loss='binary_crossentropy', \n    metrics=[tf.keras.metrics.Recall()])\n"], ["from __future__ import absolute_import, division, print_function, unicode_literals\nimport tensorflow as tf\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom tensorflow.keras.callbacks import TensorBoard\nimport time\nimport os \n\n#load mnist dataset\nmnist = tf.keras.datasets.mnist\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\n\n#create and compile the model\nmodel = tf.keras.models.Sequential([\n  tf.keras.layers.Flatten(input_shape=(28, 28)), \n  tf.keras.layers.Dense(128, activation='relu'), \n  tf.keras.layers.Dropout(0.2), \n  tf.keras.layers.Dense(10, activation='softmax') \n])\nmodel.summary()\n\n# This will work because it makes sense\nmodel.compile(optimizer='adam',\n              loss='sparse_categorical_crossentropy',\n              metrics=[tf.keras.metrics.SparseCategoricalAccuracy(),\n                       tf.keras.metrics.CategoricalCrossentropy()])\n\n# This will not work because it isn't designed for the multiclass classification problem\nmodel.compile(optimizer='adam',\n              loss='sparse_categorical_crossentropy',\n              metrics=[tf.keras.metrics.SparseCategoricalAccuracy(),\n                       tf.keras.metrics.TruePositives()])\n\n#model checkpoint (only if there is an improvement)\n\ncheckpoint_path = \"logs/weights-improvement-{epoch:02d}-{accuracy:.2f}.hdf5\"\n\ncp_callback = ModelCheckpoint(checkpoint_path,\n                              monitor='accuracy',\n                              save_best_only=True,\n                              verbose=1,\n                              mode='max')\n\n#Tensorboard\nNAME = \"tensorboard_{}\".format(int(time.time())) # name of the model with timestamp\ntensorboard = TensorBoard(log_dir=\"logs/{}\".format(NAME))\n\n#train the model\nmodel.fit(x_train, y_train, epochs=5)\n\n#evaluate the model\nmodel.evaluate(x_test,  y_test, verbose=2)\n"], ["model.compile(optimizer='adam',\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy',tf.keras.metrics.Precision(),tf.keras.metrics.Recall()])\n"], ["def fizz_buzz(self):\n"], ["def fizz_buzz(self):\n", "def fizz_buzz():\n"], ["def fizz_buzz(self):\n    if number_value % 3 == 0 and number_value % 5 == 0:\n        print(\"FizzBuzz\")\n    elif number_value % 3 == 0:\n        print(\"Fizz\")\n    elif number_value % 5 == 0:\n        print(\"Buzz\")\n    else:\n        return f\"{number_value} can't be multiplied by either 3 or 5\"\n"], ["`def fizz_buzz(self):`\n"], [], ["/usr/local/Cellar/openssl/1.0.2t/lib/\n", "/usr/local/opt/openssl/lib\n"], ["LR [0.73958333 0.74736842]\nNB [0.60416667 0.71578947]\nRF [0.80208333 0.82105263]\nSVC [0.79166667 0.77894737]\nDtree [0.82291667 0.83157895]\nXGB [0.85416667 0.85263158]\nKNN [0.79166667 0.75789474]\n"], [], ["python3 -m pip install oscrypto\n"], ["pip uninstall cryptography\npip install cryptography\n"], [], ["@commands.command()\nasync def avatar(self, ctx, *,  avamember : discord.Member=None):\n    userAvatarUrl = avamember.avatar_url\n    await ctx.send(userAvatarUrl)\n", "@bot.command()\nasync def avatar(ctx, *,  avamember : discord.Member=None):\n    userAvatarUrl = avamember.avatar_url\n    await ctx.send(userAvatarUrl)\n"], [], ["python -m PyInstaller myscript.py\n"], ["python -m weasyprint http://weasyprint.org weasyprint.pdf\n"], [], ["pip show pytest attrs\n", "pip install -U pytest\n"], ["pip uninstall openpyxl\npip install openpyxl==3.0.1\n"], ["from openpyxl import load_workbook\nwriter = pd.ExcelWriter(filename, engine='openpyxl')\n\ntry:\n    # try to open an existing workbook\n    writer.book = load_workbook(filename)\n\n    # get the last row in the existing Excel sheet\n    # if it was not specified explicitly\n    if startrow is None and sheet_name in writer.book.sheetnames:\n        startrow = writer.book[sheet_name].max_row\n\n    # truncate sheet\n    if truncate_sheet and sheet_name in writer.book.sheetnames:\n        # index of [sheet_name] sheet\n        idx = writer.book.sheetnames.index(sheet_name)\n        # remove [sheet_name]\n        writer.book.remove(writer.book.worksheets[idx])\n        # create an empty sheet [sheet_name] using old index\n        writer.book.create_sheet(sheet_name, idx)\n\n    # copy existing sheets\n    writer.sheets = {ws.title: ws for ws in writer.book.worksheets}\nexcept FileNotFoundError:\n    # file does not exist yet, we will create it\n    pass\n\nif startrow is None:\n    startrow = 0\n\n# write out the new sheet\ndf.to_excel(writer, sheet_name, startrow=startrow, **to_excel_kwargs)\n\n# save the workbook\nwriter.save()\n"], ["python -m pip install bootstrap4\n"], [], [], ["  Found existing installation: asn1crypto 0.24.0\n    Uninstalling asn1crypto-0.24.0:\n      Successfully uninstalled asn1crypto-0.24.0\nSuccessfully installed asn1crypto-1.2.0\n", "# /usr/local/lib/python2.7/site-packages/asn1crypto/_perf/_big_num_ctypes.pyc matches /usr/local/lib/python2.7/site-packages/asn1crypto/_perf/_big_num_ctypes.py\nimport asn1crypto._perf._big_num_ctypes # precompiled from /usr/local/lib/python2.7/site-packages/asn1crypto/_perf/_big_num_ctypes.pyc\n[1]    59247 abort      python -v $(which ansible)\n"], ["(dt.replace(day=1) + datetime.timedelta(days=32)).replace(day=1)\n", ">>> dt = datetime.datetime(2016, 2, 29)\n>>> print((dt.replace(day=1) + datetime.timedelta(days=32)).replace(day=1))\n2016-03-01 00:00:00\n\n>>> dt = datetime.datetime(2019, 12, 31)\n>>> print((dt.replace(day=1) + datetime.timedelta(days=32)).replace(day=1))\n2020-01-01 00:00:00\n\n>>> dt = datetime.datetime(2019, 12, 1)\n>>> print((dt.replace(day=1) + datetime.timedelta(days=32)).replace(day=1))\n2020-01-01 00:00:00\n"], [], [], [], ["MAX_KEY_SIZE = 26\n\n\ndef getMode():\n    while True:\n        print('Do you wish to encrypt or decrypt a message?')\n        mode = input().lower()\n        if mode in 'encrypt e decrypt d'.split():\n            return mode\n        else:\n            print('Enter either \"encrypt\" or \"e\" or \"decrypt\" or \"d\".')\n\n\ndef getMessage():\n    print('Enter your message:')\n    return input()\n\n\ndef getKey():\n    key = 0\n    while True:\n        print('Enter the key number (1-%s)' % (MAX_KEY_SIZE))\n        key = int(input())\n        if (key >= 1 and key <= MAX_KEY_SIZE):\n            return key\n\n\ndef getTranslatedMessage(mode, message, key):\n    if mode[0] == 'd':\n        key = -key\n        translated = ''\n\n    for symbol in message:\n        if symbol.isalpha():\n            num = ord(symbol)\n            num += key\n\n    if symbol.isupper():\n        if num > ord('Z'):\n            num -= 26\n    elif num < ord('A'):\n        num += 26\n    elif symbol.islower():\n        if num > ord('z'):\n            num -= 26\n    elif num < ord('a'):\n        num += 26\n\n        translated += chr(num)\n    else:\n        translated += symbol\n        return translated\n\nmode = getMode()\nmessage = getMessage()\nkey = getKey()\nprint('Your translated text is:')\nprint(getTranslatedMessage(mode, message, key))\n\n"], [], [], [], [], ["def solution(N, A):\n    counters = [0] * N\n    max_c = 0\n    last_was_max = False\n    for el in A:\n        if el <= N:\n            counters[el - 1] += 1\n            max_c = max(counters[el - 1], max_c)\n            last_was_max = False\n        elif not last_was_max:\n            counters = [max_c] * N\n            last_was_max = True\n    return counters\n\n\ndef solution2_1(N, A):\n    counters = [0] * N\n    last_was_max = False\n    for el in A:\n        if el <= N:\n            counters[el - 1] += 1\n            last_was_max = False\n        elif not last_was_max:\n            counters = [max(counters)] * N\n            last_was_max = True\n    return counters\n", "def solution2(N, A):\n    counters = [0] * N\n    for el in A:\n        if el <= N:\n            counters[el - 1] += 1\n        else:\n            counters = [max(counters)] * N\n    return counters\n"], ["pip install \"numpy<1.17\"\n"], ["brew install openssl\ncd /usr/local/lib\nsudo ln -s /usr/local/opt/openssl/lib/libssl.dylib libssl.dylib\nsudo ln -s /usr/local/opt/openssl/lib/libcrypto.dylib libcrypto.dylib\n"], ["C:\\Users\\PC\\Anaconda3\\envs\\tut\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py\n", "_np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n_np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n_np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n_np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n_np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n\n\n# _np_bfloat16 is defined by a module import.\n\n# Custom struct dtype for directly-fed ResourceHandles of supported type(s).\nnp_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n", "_np_qint8 = np.dtype([(\"qint8\", np.int8, (1,))])\n_np_quint8 = np.dtype([(\"quint8\", np.uint8, (1,))])\n_np_qint16 = np.dtype([(\"qint16\", np.int16, (1,))])\n_np_quint16 = np.dtype([(\"quint16\", np.uint16, (1,))])\n_np_qint32 = np.dtype([(\"qint32\", np.int32, (1,))])\n\n# _np_bfloat16 is defined by a module import.\n\n# Custom struct dtype for directly-fed ResourceHandles of supported type(s).\nnp_resource = np.dtype([(\"resource\", np.ubyte, (1,))])\n", "C:\\Users\\PC\\Anaconda3\\envs\\tut\\lib\\site-packages\\tensorboard/compat/tensorflow_stub/dtypes.py\n"], ["# models.py\n\nclass De(models.Model):\n\n    fr = models.BooleanField(\"[...]\")\n    de = models.SmallIntegerField(\"[...]\")\n    gd = models.SmallIntegerField(\"[...]\")\n    na = models.SmallIntegerField(\"[...]\")\n    s_d = models.SmallIntegerField(\"[...]\", blank=True)\n\n    # [several_attributes, Meta, __str__() removed for readability]\n\n    def save(self, *args, **kwargs):\n        if self.fr:\n            self.s_d = self.de\n        else:\n            self.s_d = self.gd + self.na\n        super().save(*args, **kwargs)\n\n# admin.py\n\nclass DeAdmin(admin.ModelAdmin):\n    list_display = (\"[...]\", \"s_d\", \"gd\", \"na\", \"de\", \"fr\" )\n"], ["class De(models.Model):\n\n    fr = models.BooleanField(\"[...]\")\n    de = models.SmallIntegerField(\"[...]\")\n    gd = models.SmallIntegerField(\"[...]\")\n    na = models.SmallIntegerField(\"[...]\")\n    # [several_attributes, Meta, __str__() removed for readability]\n\n    def s_d(self):\n        if self.fr:\n            return self.de\n        else:\n            return self.gd + self.na\n    s_d.admin_order_field = '_s_d'\n    s_d = property(s_d)\n", "def decorate(**kwargs):\n    def wrap(function):\n        for name, value in kwargs.iteritems():\n            setattr(function, name, value)\n\n        return function\n    return wrap\n\nclass De(models.Model):\n\n    fr = models.BooleanField(\"[...]\")\n    de = models.SmallIntegerField(\"[...]\")\n    gd = models.SmallIntegerField(\"[...]\")\n    na = models.SmallIntegerField(\"[...]\")\n    # [several_attributes, Meta, __str__() removed for readability]\n\n    @property\n    @decorate(admin_order_field='_s_d')\n    def s_d(self):\n        if self.fr:\n            return self.de\n        else:\n            return self.gd + self.na\n"], ["pip install mysqlclient-1.4.4-cp38-cp38-win_amd64.whl\n", " pip install mysqlclient-1.4.4-cp38-cp38-win32.whl\n"], ["class DeManager(models.Manager):\n    def get_queryset(self):\n        return super().get_queryset().annotate(\n            s_d=Case(\n                When(fr=True, then='s_d'),\n                When(fr=False, then=F('gd') + F('na')),\n                default=Value(0),\n                output_field=IntegerField(),\n            )\n        )\n\n\nclass De(models.Model):\n    fr = models.BooleanField(\"[...]\")\n    de = models.SmallIntegerField(\"[...]\")\n    gd = models.SmallIntegerField(\"[...]\")\n    na = models.SmallIntegerField(\"[...]\")\n    objects = DeManager()\n\n\nclass DeAdmin(admin.ModelAdmin):\n    list_display = (\"[...]\", \"s_d\", \"gd\", \"na\", \"de\", \"fr\" )\n"], ["from django.db.models import Value\nfrom django.db.models.functions import Concat\n\nclass Person(models.Model):\n    first_name = models.CharField(max_length=50)\n    last_name = models.CharField(max_length=50)\n\n    def full_name(self):\n        return self.first_name + ' ' + self.last_name\n    full_name.admin_order_field = Concat('first_name', Value(' '), 'last_name')\n", "class De(models.Model):\n    ...\n    def calculate_s_d(self):\n        if self.fr:\n            return self.de\n        else:\n            return self.gd + self.na\n\n    calculate_s_d.admin_order_field = Case(\n        When(fr=True, then='s_d'),\n        When(fr=False, then=F('gd') + F('na')),\n        default=Value(0),\n        output_field=IntegerField(),\n    )\n\n    s_d = property(calculate_s_d)\n", "class DeAdmin(admin.ModelAdmin):\n    list_display = (\"[...]\", \"s_d\")\n"], [], [], ["# Install openssl via homebrew.\n# Note: According to homebrew, \"openssl is keg-only, which means it was\n# not symlinked into /usr/local, because Apple has deprecated use of\n# OpenSSL in favor of its own TLS and crypto libraries.\"\nbrew install openssl\n# Symlink those versions into /usr/local/lib, which gets Python to dynamically\n# link against those instead of the version in /usr/lib/.\n# Got the idea from https://forums.developer.apple.com/thread/119429\ncd /usr/local/lib\nsudo ln -s /usr/local/Cellar/openssl/1.0.2t/lib/libssl.1.0.0.dylib libssl.dylib\nsudo ln -s /usr/local/Cellar/openssl/1.0.2t/lib/libcrypto.1.0.0.dylib libcrypto.dylib\n", "Process:               Python [52429]\nPath:                  /usr/local/Cellar/python/3.7.4_1/Frameworks/Python.framework/Versions/3.7/Resources/Python.app/Contents/MacOS/Python\nIdentifier:            Python\nVersion:               3.7.4 (3.7.4)\nCode Type:             X86-64 (Native)\nParent Process:        zsh [43309]\nResponsible:           iTerm2 [2316]\nUser ID:               501\n\nDate/Time:             2019-10-09 09:52:18.148 -0700\nOS Version:            Mac OS X 10.15 (19A583)\nReport Version:        12\nBridge OS Version:     4.0 (17P572)\nAnonymous UUID:        \n\nSleep/Wake UUID:       \n\nTime Awake Since Boot: 9900 seconds\nTime Since Wake:       7300 seconds\n\nSystem Integrity Protection: enabled\n\nCrashed Thread:        0  Dispatch queue: com.apple.main-thread\n\nException Type:        EXC_CRASH (SIGABRT)\nException Codes:       0x0000000000000000, 0x0000000000000000\nException Note:        EXC_CORPSE_NOTIFY\n\nApplication Specific Information:\n/usr/lib/libcrypto.dylib\nabort() called\nInvalid dylib load. Clients should not load the unversioned libcrypto dylib as it does not have a stable ABI.\n"], ["cd your-site-packages-path/\nvim ./asn1crypto/_int.py\n", "# from ._perf._big_num_ctypes import libcrypto\n", "Process:               Python [85179]\nPath:                  /usr/local/Cellar/python/3.7.4_1/Frameworks/Python.framework/Versions/3.7/Resources/Python.app/Contents/MacOS/Python\nIdentifier:            Python\nVersion:               3.7.4 (3.7.4)\nCode Type:             X86-64 (Native)\nParent Process:        ??? [85161]\nResponsible:           iTerm2 [11711]\nUser ID:               501\n\nDate/Time:             2019-10-07 23:00:25.143 +0800\nOS Version:            Mac OS X 10.15 (19A582a)\nReport Version:        12\nBridge OS Version:     3.0 (14Y906)\nAnonymous UUID:        32C73ADD-1291-FA0E-DC02-48D539674325\n\n\nTime Awake Since Boot: 42000 seconds\n\nSystem Integrity Protection: enabled\n\nCrashed Thread:        0  Dispatch queue: com.apple.main-thread\n\nException Type:        EXC_CRASH (SIGABRT)\nException Codes:       0x0000000000000000, 0x0000000000000000\nException Note:        EXC_CORPSE_NOTIFY\n\nApplication Specific Information:\n/usr/lib/libcrypto.dylib\nabort() called\nInvalid dylib load. Clients should not load the unversioned libcrypto dylib as it does not have a stable ABI.\n"], ["original_str = \"The quick brown rhino jumped over the extremely lazy fox.\"\nsplit_str = original_str.split()\nnum_words_list=[]\nfor words in split_str:\n    num_words_list.append(len(words))\n\n"], [], ["import numpy as np\n\narr1 = np.array([5,10,15,20,30])\narr2 = np.array([55,16,1,280,60, 70])  # Longer than arr1.\n\nmin_len = min(len(arr1), len(arr2))\nlonger_array = arr1 if len(arr1) > len(arr2) else arr2\npartial_result = arr1[:min_len] + arr2[:min_len]\n>>> np.concatenate((partial_result, longer_array[min_len:]))\narray([ 60,  26,  16, 300,  90,  70])\n"], ["import numpy as np\narr1 = np.array([5,10,15,20,30])\narr2 = np.array([55,16,1,280,60])\narr1+arr2\n", "new_list = []\nfor i in range(min(len(arr1), len(arr2))):\n    new_list.append(arr1[i]+arr2[i])\nnew_list\n"], [], ["selenium.common.exceptions.ElementClickInterceptedException: Message: element click intercepted: Element is not clickable at point (203, 530). Other element would receive the click: ... (Session info: chrome=76.0.3809.132)\n", "WebDriverWait(driver, 20).until(EC.element_to_be_clickable((By.CSS_SELECTOR, \"input.button#PersonalDetailsButton[data-controltovalidate='PersonalDetails']\"))).click()\n", "WebDriverWait(driver, 20).until(EC.element_to_be_clickable((By.XPATH, \"//input[@class='button' and @id='PersonalDetailsButton'][@data-controltovalidate='PersonalDetails']\"))).click()\n", "from selenium.webdriver.support.ui import WebDriverWait\nfrom selenium.webdriver.common.by import By\nfrom selenium.webdriver.support import expected_conditions as EC\n"], ["Next = driver.find_element_by_xpath(\"//input[@id='PersonalDetailsButton']\");\nNext.Click();\n", "Next = driver.find_element_by_xpath(//input[@value='Next' and @id='PersonalDetailsButton']);\nNext.Click();\n"], ["1. pip uninstall numpy \n2. pip install numpy==1.16.4\n"], ["def make_collection_from_data(data, collection_maker):\n    return collection_maker(data)\n\ndata = [1, 2, 3, 4]\n\nmake_collection_from_data(data, set) # Returns a list\nmake_collection_from_data(data, list) # Returns a set\n"], ["my_list = ['a', 'b', 'c']\n", "my_tuple = ('a', 'b', 'c')  # literal notation to create a new tuple\nmy_list = list(my_tuple)    # this is what you actually did in your first example\n"], [], [">>> list({1:2})\n[1]\n>>> [{1:2}]\n[{1: 2}]\n"], [], ["mylist = list(myset)\n"], [], ["In [123]: np.dtype([(\"qint8\", np.int8, 1)])                                                                  \n/usr/local/bin/ipython3:1: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  #!/usr/bin/python3\nOut[123]: dtype([('qint8', 'i1')])\n\nIn [124]: np.dtype([(\"qint8\", np.int8, (1,))])                                                               \nOut[124]: dtype([('qint8', 'i1', (1,))])\n\nIn [125]: np.dtype([(\"qint8\", np.int8)])                                                                     \nOut[125]: dtype([('qint8', 'i1')])\n\nIn [126]: np.dtype([(\"qint8\", np.int8, 2)])                                                                  \nOut[126]: dtype([('qint8', 'i1', (2,))])\n\nIn [127]: np.__version__                                                                                     \nOut[127]: '1.17.0'\n"], ["import datetime\nfrom dateutil import relativedelta\ntoday = datetime.date.today()\n\nnext_month = today + relativedelta.relativedelta(months=1, day=1)\n", "next_month = (today.replace(day=1) + datetime.timedelta(days=32)).replace(day=1)\n"], [], ["import datetime\nfrom dateutil import relativedelta\n\ndt = datetime.datetime(year=1998,\n                             month=12,\n                             day=12)\n\nnextmonth = dt + relativedelta.relativedelta(months=1)\nnextmonth.replace(day=1)\nprint(nextmonth)\n"], [], ["original_str = \"The quick brown rhino jumped over the extremely lazy fox\"\n\n\noriginal_list = list(original_str.split())\nnum_words = len(original_list)\nnum_words_list = []\nfor i in original_list:\n    num_words_list.append((len(i)))\n\nprint(num_words_list)\n"], ["def printMessage(name, msg = \"My name is \"):  \n    print(\"Hello! \",msg + name)\n\nprintMessage(\"Jack\")\n"], ["class Specs():\n    def __init__(self, a=None,b=None,c=None):\n        self.a = a if a is not None else 'Apple'\n        sefl.b = b if b is not None else 'Bravo'\n        self.c = c if c is not None else 'Cherry'\nexample = Specs('Apple', None, 'Cherry')\n", "class Specs():\n    def __init__(self, a = 'Apple', b = 'Bravo', c = 'Cherry'):\n        self.a = a\n        self.b = b\n        self.c = c\nexample = Specs('Apple', c = 'Cherry')\n"], ["Specs1(a='Apple', b='Bravo', c='Cherry')\n"], [], ["pip install name-of-whl-file.whl\n"], [], ["app_login_url = 'https://app:8000/accounts/login/'\n"], ["'goog:chromeOptions': {'args': ['--allow-insecure-localhost'],\n            'extensions': []}\n", "{'acceptInsecureCerts': True,\n'browserName': 'chrome',\n'goog:chromeOptions': {'args': ['--ignore-certificate-errors'],\n            'extensions': []},\n'platform': 'ANY',\n'version': ''}\n"], ["import pandas as pd\nimport seaborn as sns\n\ncolumns = ['category1', 'category2', 'category3', 'time', 'value']\n\ndata = [['content1', 'other1', 'critera1', 0, 0.1], ['content1', 'other1', 'critera1', 1, 0.4], ['content1', 'other1', 'critera1', 2, 0.7], ['content2', 'other1', 'critera1', 0, 0.2], ['content2', 'other1', 'critera1', 1, 0.6], ['content2', 'other1', 'critera1', 2, 0.8], ['content1', 'other2', 'critera1', 0, 0.0], ['content1', 'other2', 'critera1', 1, 0.2], ['content1', 'other2', 'critera1', 2, 0.8], ['content2', 'other2', 'critera1', 0, 0.3], ['content2', 'other2', 'critera1', 1, 0.6], ['content2', 'other2', 'critera1', 2, 0.5], [\n    'content1', 'other1', 'critera2', 0, 0.1], ['content1', 'other1', 'critera2', 1, 0.4], ['content1', 'other1', 'critera2', 2, 0.7], ['content2', 'other1', 'critera2', 0, 0.2], ['content2', 'other1', 'critera2', 1, 0.6], ['content2', 'other1', 'critera2', 2, 0.8], ['content1', 'other2', 'critera2', 0, 0.0], ['content1', 'other2', 'critera2', 1, 0.2], ['content1', 'other2', 'critera2', 2, 0.8], ['content2', 'other2', 'critera2', 0, 0.3], ['content2', 'other2', 'critera2', 1, 0.6], ['content2', 'other2', 'critera2', 2, 0.5], ]\n\ndf = pd.DataFrame(data, columns=columns)\n\nplot = sns.relplot(x='time', y='value', col='category3', hue='category1', style='category2', kind=\"line\",\n                   col_wrap=2, data=df)\n\nhandles, labels = plot.axes[0].get_legend_handles_labels()\nplot._legend.remove()\nplot.fig.legend(handles, labels, ncol=2, loc='upper center', \n                bbox_to_anchor=(0.5, 1.15), frameon=False)\n"], ["plot = sns.relplot(x='time', y='value', col='category3', hue='category1', style='category2', kind=\"line\", col_wrap=2, data=df, facet_kws=dict(legend_out=False))\nh,l = plot.axes[0].get_legend_handles_labels()\nplot.axes[0].legend_.remove()\nplot.fig.legend(h,l, ncol=2) # you can specify any location parameter you want here\n"], [], [">>> np.random.randint(2)\n"], [">>> np.random.randint(0,2,10)\narray([0, 1, 1, 0, 1, 1, 0, 0, 1, 0])\n>>> np.random.randint(2)\n0\n>>> np.random.randint(2)\n1\n"], ["In [1]: import numpy as np                                                                                                                                                                                                 \n\nIn [2]: np.random.choice([0,1])                                                                                                                                                                                            \nOut[2]: 0\n\nIn [5]: np.random.choice([0,1])                                                                                                                                                                                            \nOut[5]: 1\n\nIn [8]: np.random.randint(2)                                                                                                                                                                                             \nOut[8]: 0\n\nIn [9]: np.random.randint(2)                                                                                                                                                                                             \nOut[9]: 1\n\n"], ["random_int= np.random.random_integers(0,1)\nprint (random_int)\n"], ["class Dog:\n    SOUND = 'woof'\n    def __init__(self, name):\n        \"\"\"Creates a new instance of the Dog class.\n\n        This is the constructor in Python.\n        The underscores are pronounced dunder so this function is called\n        dunder init.\n        \"\"\" \n        # this is an instance variable.\n        # every time you instantiate an object (call the constructor)\n        # you must provide a name for the dog\n        self._name = name\n\n    def name(self):\n        \"\"\"Gets the name of the dog.\"\"\"\n        return self._name\n\n    @classmethod\n    def bork(cls):\n        \"\"\"Makes the noise Dogs do.\n\n        Look past the @classmethod as this is a more advanced feature of Python.\n        Just know that this is how you would create a class method in Python.\n        This is a little hairy.\n        \"\"\"\n        print(cls.SOUND)\n"], ["def some_method():\n    return 'hello world'\n\nsome_dictionary = {\n    \"a_data_key\": \"a value\",\n    \"a_method_key\": some_method,\n}\n"], [], ["df = pd.DataFrame(columns=['pre_A', 'pre_B', 'pre_predmet'])\ndf.columns = df.columns.str.replace('^pre_', '')\nprint (df)\nEmpty DataFrame\nColumns: [A, B, predmet]\nIndex: []\n", "import re\n\ndf.columns = [re.sub('^pre_',\"\", x) for x in df.columns]\n"], ["# Example dataframe\ndf = pd.DataFrame(columns=['pre_A', 'pre_B', 'C'])\ndf.columns = df.columns.str.lstrip('pre_')\n", "print(df.columns)\n# Index(['A', 'B', 'C'], dtype='object')\n"], ["pandas.read_csv(filepath_or_buffer=filename, header=None, sep=',')  \n"], ["df.columns = [i.replace(prefix,\"\") for i in df.columns]\n"], ["a = [i for i in range(1,10)]\na2 = filter(lambda x: x % 2 != 0, a)\na3 = map(lambda x: x**2, a2)        # This is a generator object\nfinal_list = list(a3)               # This is a list\n"], ["arr = []\nN = 10\nfor i in range(1, N):\n    arr.append(i)\n\narr2 = []\nf = lambda x: x ** 2\narr2 = filter(lambda x: x % 2 != 0, arr)\nfor i in list(arr2):\n    print(f(i))\n", "N = 10\narr = range(1, N)\n\nsquare = lambda x: x ** 2\nkeep_odd = lambda x: x % 2 != 0\narr2 = list(filter(keep_odd, arr))\nfor i in arr2:\n    print(square(i))\n\nprint(arr2)\n", "1\n9\n25\n49\n81\n[1, 3, 5, 7, 9]\n"], ["N = 10\nfor i in range(1, 10):\n    arr.append(i)\n\nresult = []\nf = lambda x: x ** 2\narr2 = filter(lambda x: x % 2 != 0, arr)\nfor i in arr2:\n    result.append(f(i))    \nprint(result)\n"], ["result = []\nfor i in arr2:\n    result.append(f(i))\n", "arr2 = list(map(lambda x: x ** 2, filter(lambda x: x % 2 != 0, arr)))\n"], [], ["original_str = \"The quick brown rhino jumped over the extremely lazy fox\".split()\noriginal_list = list(original_str)\nnum_words = len(original_list)\nnum_words_list = []\nfor i in original_list:\n    num_words_list.append((len(i)))\n\nprint(num_words_list)\n"], [], [], ["import nltk    \nnltk.download('all')\n"], [], [], [], [], ["[int(digit) for digit in str(arr[0])]\n", "list(map(int, str(arr[0])))\n", "import math\n\n[arr[0] // 10 ** n % 10 for n in reversed(range(int(math.log10(arr[0])) + 1))]\n"], ["def split_int(i):\n    while True:\n        i, r = divmod(i, 10)\n        yield r\n        if not i:\n            break\n", "[1, 0]\n"], [">>> [int(x) if x.isdigit() else x for y in arr for x in str(y)]\n[1, 0]\n>>> \n"], [">>> arr = [10]\n>>> num = arr[0]\n>>> string = str(num)\n>>> string_arr = list(string)\n>>> arr = list(map(int, string_arr))\n>>> arr\n[1,0]\n", ">>> arr = [10]\n>>> arr = list(map(int, str(arr[0])))\n>>> arr\n[1,0]\n"], ["import os\nimport requests\nfrom urllib.parse import urljoin\nfrom bs4 import BeautifulSoup\n\nurl = \"http://www.gatsby.ucl.ac.uk/teaching/courses/ml1-2016.html\"\n\n#If there is no such folder, the script will create one automatically\nfolder_location = r'E:\\webscraping'\nif not os.path.exists(folder_location):os.mkdir(folder_location)\n\nresponse = requests.get(url)\nsoup= BeautifulSoup(response.text, \"html.parser\")     \nfor link in soup.select(\"a[href$='.pdf']\"):\n    #Name the pdf files using the last portion of each link which are unique in this case\n    filename = os.path.join(folder_location,link['href'].split('/')[-1])\n    with open(filename, 'wb') as f:\n        f.write(requests.get(urljoin(url,link['href'])).content)\n"], ["from urllib import request\nfrom bs4 import BeautifulSoup\nimport re\nimport os\nimport urllib\n\n# connect to website and get list of all pdfs\nurl=\"http://www.gatsby.ucl.ac.uk/teaching/courses/ml1-2016.html\"\nresponse = request.urlopen(url).read()\nsoup= BeautifulSoup(response, \"html.parser\")     \nlinks = soup.find_all('a', href=re.compile(r'(.pdf)'))\n\n\n# clean the pdf link names\nurl_list = []\nfor el in links:\nif(el['href'].startswith('http')):\n    url_list.append(el['href'])\nelse:\n    url_list.append(\"http://www.gatsby.ucl.ac.uk/teaching/courses/\" + el['href'])\n\nprint(url_list)\n\n\n# download the pdfs to a specified location\nfor url in url_list:\n    print(url)\n    fullfilename = os.path.join('E:\\webscraping', url.replace(\"http://www.gatsby.ucl.ac.uk/teaching/courses/ml1-2016/\", \"\"))\n    print(fullfilename)\n    request.urlretrieve(url, fullfilename)\n"], ["# python 3\n\nimport os\n\nsync_command = f\"aws s3 sync s3://source-bucket/ s3://destination-bucket/\"\nos.system(sync_command)\n"], ["import matplotlib.pyplot as plt\nimport pandas as pd\n\ndf = pd.DataFrame()\ndf['Animal'] = ['Cow', 'Bear']\ndf['Weight'] = [250, 450]\ndf['Favorite'] = ['Grass', 'Honey']\ndf['Least Favorite'] = ['Meat', 'Leaves']\n\nfig = plt.figure(figsize=(9,2))\nax=fig.gca()\nax.axis('off')\nr,c = df.shape\n\n# ensure consistent background color\nax.table(cellColours=[['lightgray']] + [['none']], bbox=[0,0,1,1])\n\n# plot the real table\ntable = ax.table(cellText=np.vstack([['', '', 'Food', ''], df.columns, df.values]), \n                 cellColours=[['none']*c]*(2 + r), bbox=[0, 0, 1, 1])\n\n# need to draw here so the text positions are calculated\nfig.canvas.draw()\n\n# do the 3 cell merges needed\nmergecells(table, (1,0), (0,0))\nmergecells(table, (1,1), (0,1))\nmergecells(table, (0,2), (0,3))\n", "import matplotlib as mpl\n\ndef mergecells(table, ix0, ix1):\n    ix0,ix1 = np.asarray(ix0), np.asarray(ix1)\n    d = ix1 - ix0\n    if not (0 in d and 1 in np.abs(d)):\n        raise ValueError(\"ix0 and ix1 should be the indices of adjacent cells. ix0: %s, ix1: %s\" % (ix0, ix1))\n\n    if d[0]==-1:\n        edges = ('BRL', 'TRL')\n    elif d[0]==1:\n        edges = ('TRL', 'BRL')\n    elif d[1]==-1:\n        edges = ('BTR', 'BTL')\n    else:\n        edges = ('BTL', 'BTR')\n\n    # hide the merged edges\n    for ix,e in zip((ix0, ix1), edges):\n        table[ix[0], ix[1]].visible_edges = e\n\n    txts = [table[ix[0], ix[1]].get_text() for ix in (ix0, ix1)]\n    tpos = [np.array(t.get_position()) for t in txts]\n\n    # center the text of the 0th cell between the two merged cells\n    trans = (tpos[1] - tpos[0])/2\n    if trans[0] > 0 and txts[0].get_ha() == 'right':\n        # reduce the transform distance in order to center the text\n        trans[0] /= 2\n    elif trans[0] < 0 and txts[0].get_ha() == 'right':\n        # increase the transform distance...\n        trans[0] *= 2\n\n    txts[0].set_transform(mpl.transforms.Affine2D().translate(*trans))\n\n    # hide the text in the 1st cell\n    txts[1].set_visible(False)\n"], ["def format_axes(fig):\n    for i, ax in enumerate(fig.axes):\n        ax.tick_params(labelbottom=False, labelleft=False, labelright=False)\n        ax.get_xaxis().set_ticks([])\n        ax.get_yaxis().set_ticks([])\n\n\ndf = pd.DataFrame()\ndf['Animal'] = ['Cow', 'Bear']\ndf['Weight'] = [250, 450]\ndf['Favorite'] = ['Grass', 'Honey']\ndf['Least Favorite'] = ['Meat', 'Leaves']\n\nfig = plt.figure(figsize=(9, 2))\n\n\ngs = GridSpec(3, 4, figure=fig, wspace=0.0, hspace=0.0,height_ratios=[1, 1, 4])\n# plot table header\nax1 = fig.add_subplot(gs[:-1, 0])\nax1.text(0.5, 0.5, df.columns[0], va=\"center\", ha=\"center\")\nax2 = fig.add_subplot(gs[:-1, 1])\nax2.text(0.5, 0.5, df.columns[1], va=\"center\", ha=\"center\")\nax3 = fig.add_subplot(gs[0, -2:])\nax3.text(0.5, 0.5, \"Food\", va=\"center\", ha=\"center\")\nax4 = fig.add_subplot(gs[1, -2])\nax4.text(0.5, 0.5, df.columns[2], va=\"center\", ha=\"center\")\nax5 = fig.add_subplot(gs[1, -1])\nax5.text(0.5, 0.5, df.columns[3], va=\"center\", ha=\"center\")\n# plot table data\nax6 = fig.add_subplot(gs[-1, :])\ntable = ax6.table(cellText=df.values, cellLoc='center', bbox=[0, 0, 1, 1])\n\nformat_axes(fig)\n\nplt.show()\n"], ["#!/usr/bin/env python\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndf = pd.DataFrame()\ndf['Animal'] = ['Cow', 'Bear']\ndf['Weight'] = [250, 450]\ndf['Favorite'] = ['Grass', 'Honey']\ndf['Least Favorite'] = ['Meat', 'Leaves']\ndf\n\nfig = plt.figure(figsize=(9,2))\nax=plt.subplot(111)\nax.axis('off') \n\nplt.table(cellText=[['Animal', 'Weight']],\n                     loc='bottom',\n                     bbox=[0, 0.6, 0.5, 0.3]\n                     )\n\nplt.table(cellText=[['Food']],\n                     loc='bottom',\n                     bbox=[0.5, 0.75, 0.5, 0.15]\n                     )\n\nplt.table(cellText=[['Favorite', 'Least favorite']],\n                     loc='bottom',\n                     bbox=[0.5, 0.6, 0.5, 0.15]\n                     )\n\nplt.table(cellText=df.values,\n                     loc='bottom',\n                     bbox=[0, 0, 1, 0.6]\n                     )\n\nplt.show()\n"], [">>> import readline\n>>> readline.clear_history()\n"], ["import subprocess\nsubprocess.call('reset')\n"], ["print(chr(27) + \"[2J\")\n", "import os\nos.system('cls' if os.name == 'nt' else 'clear')\n"], ["s3 = boto3.resource('s3')\nsource_bucket = s3.Bucket('source')\ndestination_bucket = s3.Bucket('destination')\ndestination_keys = [object.key for object in destination_bucket.objects.all()]\nfor object in source_bucket.objects.all():\n  if (object.key not in destination_keys):\n    # copy object.key to destination\n"], ["from selenium import webdriver\nfrom selenium.webdriver.support.ui import WebDriverWait\nfrom selenium.webdriver.support import expected_conditions as EC\nfrom selenium.webdriver.common.by import By\n\ndriver = webdriver.Firefox(executable_path=r'C:\\\\Utility\\\\BrowserDrivers\\\\geckodriver.exe')\ndriver.get(\"http://sugang.korea.ac.kr\")\nWebDriverWait(driver, 10).until(EC.frame_to_be_available_and_switch_to_it((By.NAME,\"firstF\")))\nWebDriverWait(driver, 20).until(EC.element_to_be_clickable((By.CSS_SELECTOR, \"input.input_login[name='id']\"))).send_keys('abc')\ndriver.find_element_by_css_selector(\"input.input_login[name='pw']\").send_keys(\"cdef\")\n"], ["from selenium import webdriver\nfrom selenium.webdriver.common.by import By\nfrom selenium.webdriver.support.ui import WebDriverWait\nfrom selenium.webdriver.support import expected_conditions as EC\n\nurl =\"http://sugang.korea.ac.kr\"\ndriver = webdriver.Chrome()\ndriver.get(url)\nWebDriverWait(driver,5).until(EC.visibility_of_element_located((By.CSS_SELECTOR,'[name=firstF]')))\ndriver.switch_to.frame(driver.find_element_by_css_selector('[name=firstF]'))\nWebDriverWait(driver,5).until(EC.visibility_of_element_located((By.ID,'id'))).send_keys('abc')\ndriver.find_element_by_id('pw').send_keys('def')\ndriver.find_element_by_id('loginButton').click()\n"], ["from selenium.webdriver.support import expected_conditions as EC\n\nuserNameElement= WebDriverWait(driver, 2).until(\nEC.presence_of_element_located((By.NAME, \"id\"))\nuserNameElement.send_keys('abc')\n\npwdElement= WebDriverWait(driver, 2).until(\nEC.presence_of_element_located((By.NAME, \"pwd\"))\npwdElement.send_keys('cdef')\n"]]