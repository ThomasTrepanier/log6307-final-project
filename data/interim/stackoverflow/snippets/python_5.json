[[], ["rasa actions\n", "rasa train\n", "rasa shell --endpoints endpoints.yml\n"], ["number1 = input(\"What is your first number? \")\nnumber2 = input(\"What is your second number? \")\n\nif number1.isnumeric() and number2.isnumeric():\n    number1 = float(number1)\n    number2 = float(number2)\n"], ["arr = np.random.normal(size=100)\n", "mask = arr >= 0\n", "result = np.empty(arr.shape)\nresult[mask] = np.sqrt(arr[mask])\nresult[~mask] = arr[~mask]\n", "result = arr.copy()\nnp.sqrt(arr, where=mask, out=result)\n", "result = np.where(mask, np.sqrt(arr), arr)\n", "result = arr >= 0\n", "result = (arr >= 0).astype(int)\n", "result = -np.clip(arr, -1, 0)\n", "mask = arr >= 0\narr[mask] = 1\narr[~mask] = 0\n"], [], ["strs = [\"WorldWorldWorld\", \"Hello World\"]\nsubstr = \"World\"\nlen_substr = len(substr)\n\nfor s in strs:\n    s_set = set(s[i:(i + len_substr)] for i in range(0, len(s), len_substr))\n    print(len(s_set) == 1 and substr in s_set)\n# True\n# False\n", "for s in strs:\n    only_substr = True\n    for i in range(0, len(s), len_substr):\n        cur_substr = s[i:(i + len_substr)]\n        if cur_substr != substr:\n            only_substr = False\n            break\n    print(only_substr)\n# True\n# False\n"], ["len(target) * data.count(target) == len(data)\n"], [], [], ["if re.match(\"(?:World)+\", s):\n"], [], ["def is_float(number):\n  if isinstance(number, float):\n     return True\n  else:\n     return False\n", "if is_float(number_1):\n  # do something\n"], [], ["    try:\n        number_1 = float(input(\"What is your first number? \"))\n        number_2 = float(input(\"What is your second number? \"))\n    except ValueError:\n        return calculate()\n", "possible_op = {\n    \"*\": float.__mul__,\n    \"+\": float.__add__,\n    \"-\": float.__sub__,\n    \"/\": float.__truediv__,\n}\n\nwhile True:\n    operator = input(\"What operator do you wanna use(*,/,+,-)? \")\n    if operator not in possible_op:\n        continue\n    try:\n        number_1 = float(input(\"What is your first number? \"))\n        number_2 = float(input(\"What is your second number? \"))\n    except ValueError:\n        continue\n\n    print(possible_op[operator](number_1, number_2))\n    break\n"], ["def calculate():\n    while True:\n        operator = input(\"What operator do you wanna use(*,/,+,-)? \")\n        possible_op = \"+-*/\"\n\n        if operator not in possible_op:\n            continue\n        try:\n            number_1 = float(input(\"What is your first number? \"))\n            number_2 = float(input(\"What is your second number? \"))\n        except ValueError:\n            continue\n    \n        if operator == \"+\":\n            print(number_1 + number_2) \n        elif operator == \"-\":\n            print(number_1 - number_2) \n        elif operator == \"*\":\n            print(number_1 *  number_2) \n        elif operator == \"/\":\n            print(number_1 / number_2) \n        break\n"], ["conda install pytorch torchvision torchaudio cudatoolkit=11.3 -c pytorch -c nvidia\n", "conda env update --name NAMEOFENVIRONMENT --file environment.yml     \n"], ["conda create --name test_env\nconda activate test_env\nconda install -c anaconda ipykernel\npython -m ipykernel install --user --name=test_env\n", "ipython kernel install --user --name=ENVNAME\n"], ["pip install pipwin\npipwin install pyaudio\n"], ["from datetime import datetime\nfrom itertools import groupby\nfrom operator import itemgetter\n\ndef consecutive_groups(iterable, ordering=lambda x: x):\n    for k, g in groupby(enumerate(iterable), key=lambda x: x[0] - ordering(x[1])):\n        yield map(itemgetter(1), g)\n", "for g in consecutive_groups(dates, lambda x: datetime.strptime(x, '%Y-%m-%d').toordinal()):\n    print(list(g))\n", "def to_date(date):\n    return datetime.strptime(date, '%Y-%m-%d').toordinal()\n\nfor g in consecutive_groups(dates, to_date):\n    print(list(g))\n", "['2020-01-01', '2020-01-02', '2020-01-03']\n['2020-01-06', '2020-01-07', '2020-01-08']\n"], ["text = 'Hello This is my dog'\nprint(text.replace('dog','simba'))\n"], ["xs = np.array([1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0], dtype=float)\n   \nys = np.array([1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.5, 5.0, 5.5,6.0, 6.5,7.0], dtype=float)\n"], [], ["x = torch.tensor([1.0],requires_grad=True)\nloss1 = criterion(40,x)\nloss2 = criterion(50,x)\nloss3 = criterion(60,x)\n", "loss1.backward()\nloss2.backward()\nloss3.backward()\n\nprint(x.grad)\n", "loss = loss1+loss2+loss3\nloss.backward()\nprint(x.grad)\n"], [], ["# if you have 2 to join:\na + b\nf\"{a}{b}\"\n# if you have 4 to join:\n\nf\"this is {a} and {b}, also {c} and {d}\"\n\"this is\" + a + \"and\" + b + \"also\" + c + \"and\" + d\n", "# example: it allows mult-line\nf\"\"\" \nthis{a}, this{b}\nand this{c}\n\"\"\"\n\n# example: don't need type convert\n\"this is: \" + str(a)\nf\"this is: {a}\"\n"], [], ["from flask import Flask, render_template\n\napp = FLASK(__name__)\n\n@app.route('/')\ndef index():\n    return render_template('home.html')\n\n@app.route('/')\ndef about():\n    return render_template('about.html')\n"], ["def Solve(A):\n    sumn = 0\n    for i in range(len(A)):\n        if A[i] in \"aeiouAEIOU\":\n            sumn += len(A[i:])\n    return sumn%10003\n"], ["from datetime import datetime\n\ndef parse_timestamp(datestring, formats):\n    results = {'datestring': datestring, 'matches': []}\n    for f in formats:\n        try:\n            d = datetime.strptime(datestring, f)\n        except:\n            continue\n        results['matches'].append({'datetime': d, 'format': f})\n    return results\n", "formats = ['%A, %B %d, %Y', '%A, %B %d, %Y %I:%M:%S %p %Z', '%A, %d %B %Y', '%B %d %Y', '%B %d, %Y', '%H:%M:%S', '%H:%M:%S,%f', '%H:%M:%S.%f', '%Y %b %d %H:%M:%S.%f', '%Y %b %d %H:%M:%S.%f %Z', '%Y %b %d %H:%M:%S.%f*%Z', '%Y%m%d %H:%M:%S.%f', '%Y-%m-%d %H:%M:%S %z', '%Y-%m-%d %H:%M:%S%z', '%Y-%m-%d %H:%M:%S,%f', '%Y-%m-%d %H:%M:%S,%f%z', '%Y-%m-%d %H:%M:%S.%f', '%Y-%m-%d %H:%M:%S.%f%z', '%Y-%m-%d %I:%M %p', '%Y-%m-%d %I:%M:%S %p', '%Y-%m-%d*%H:%M:%S', '%Y-%m-%d*%H:%M:%S:%f', '%Y-%m-%dT%H:%M:%S', '%Y-%m-%dT%H:%M:%S%Z', '%Y-%m-%dT%H:%M:%S%z', '%Y-%m-%dT%H:%M:%S*%f%z', '%Y-%m-%dT%H:%M:%S.%f', '%Y-%m-%dT%H:%M:%S.%f%z', '%Y/%m/%d', '%Y/%m/%d*%H:%M:%S', '%a %b %d %H:%M:%S %Z %Y', '%a, %d %b %Y %H:%M:%S %z', '%b %d %H:%M:%S', '%b %d %H:%M:%S %Y', '%b %d %H:%M:%S %z', '%b %d %H:%M:%S %z %Y', '%b %d %Y', '%b %d %Y %H:%M:%S', '%b %d, %Y', '%b %d, %Y %I:%M:%S %p', '%b.%d.%Y', '%d %B %Y', '%d %B %Y %H:%M:%S %Z', '%d %b %Y %H:%M:%S', '%d %b %Y %H:%M:%S %z', '%d %b %Y %H:%M:%S*%f', '%d%m_%H:%M:%S', '%d%m_%H:%M:%S.%f', '%d-%b-%Y', '%d-%b-%Y %H:%M:%S', '%d-%b-%Y %H:%M:%S.%f', '%d-%b-%Y %I:%M:%S %p', '%d-%m-%Y', '%d-%m-%Y %I:%M %p', '%d-%m-%Y %I:%M:%S %p', '%d-%m-%y', '%d-%m-%y %I:%M %p', '%d-%m-%y %I:%M:%S %p', '%d/%b %H:%M:%S,%f', '%d/%b/%Y %H:%M:%S', '%d/%b/%Y %I:%M %p', '%d/%b/%Y:%H:%M:%S', '%d/%b/%Y:%H:%M:%S %z', '%d/%m/%Y', '%d/%m/%Y %H:%M:%S %z', '%d/%m/%Y %I:%M %p', '%d/%m/%Y %I:%M:%S %p', '%d/%m/%Y %I:%M:%S %p:%f', '%d/%m/%Y*%H:%M:%S', '%d/%m/%Y*%H:%M:%S*%f', '%d/%m/%y', '%d/%m/%y %H:%M:%S', '%d/%m/%y %H:%M:%S %z', '%d/%m/%y %I:%M %p', '%d/%m/%y %I:%M:%S %p', '%d/%m/%y*%H:%M:%S', '%m%d_%H:%M:%S', '%m%d_%H:%M:%S.%f', '%m-%d-%Y', '%m-%d-%Y %I:%M %p', '%m-%d-%Y %I:%M:%S %p', '%m-%d-%y', '%m-%d-%y %I:%M %p', '%m-%d-%y %I:%M:%S %p', '%m/%d/%Y', '%m/%d/%Y %H:%M:%S %z', '%m/%d/%Y %I:%M %p', '%m/%d/%Y %I:%M:%S %p', '%m/%d/%Y %I:%M:%S %p:%f', '%m/%d/%Y*%H:%M:%S', '%m/%d/%Y*%H:%M:%S*%f', '%m/%d/%y', '%m/%d/%y %H:%M:%S', '%m/%d/%y %H:%M:%S %z', '%m/%d/%y %I:%M %p', '%m/%d/%y %I:%M:%S %p', '%m/%d/%y*%H:%M:%S', '%y%m%d %H:%M:%S', '%y-%m-%d %H:%M:%S', '%y-%m-%d %H:%M:%S,%f', '%y-%m-%d %H:%M:%S,%f %z', '%y/%m/%d %H:%M:%S']\n\ndatestrings = ['03-11-1999', '03-12-1999 5:06 AM', '03-12-1999 5:06:07 AM', '03-12-99 5:06 AM', '03-12-99 5:06:07 AM', '03/12/1999', '03/12/1999 5:06 AM', '03/12/1999 5:06:07 AM', '03/12/99 5:06 AM', '03/12/99 5:06:07', '03/12/99 5:06:07 AM', '04/23/17 04:34:22 +0000', '0423_11:42:35', '0423_11:42:35.883', '05/09/2017*08:22:14*612', '06/01/22 04:11:05', '08/10/11*13:33:56', '10-04-19 12:00:17', '10-06-26 02:31:29,573', '10/03/2017 07:29:46 -0700', '11-02-11 16:47:35,985 +0000', '11/22/2017*05:13:11', '11:42:35', '11:42:35,173', '11:42:35.173', '12/03/1999', '12/03/1999 5:06 AM', '12/03/99 5:06 AM', '12/3/1999', '12/3/1999 5:06 AM', '12/3/1999 5:06:07 AM', '150423 11:42:35', '19/Apr/2017:06:36:15 -0700', '1999-03-12 05:06:07.0', '1999-03-12 5:06 AM', '1999-03-12 5:06:07 AM', '1999-03-12+01:00', '1999-3-12 5:06 AM', '1999-3-12 5:06:07 AM', '1999/3/12', '20150423 11:42:35.173', '2017 Mar 03 05:12:41.211 PDT', '2017 Mar 10 01:44:20.392', '2017-02-11T18:31:44', '2017-03-10 14:30:12,655+0000', '2017-03-12 13:11:34.222-0700', '2017-03-12T17:56:22-0700', '2017-06-26 02:31:29,573', '2017-07-01T14:59:55.711+0000', '2017-07-04*13:23:55', '2017-07-22T16:28:55.444', '2017-08-19 12:17:55 -0400', '2017-08-19 12:17:55-0400', '2017-09-08T03:13:10', '2017-10-14T22:11:20+0000', '2017-10-30*02:47:33:899', '2017-11-22T10:10:15.455', '2017/04/12*19:37:50', '2018 Apr 13 22:08:13.211*PDT', '2018-02-27 15:35:20.311', '2018-08-20T13:20:10*633+0000', '22 Mar 1999 05:06:07 +0100', '22 March 1999', '22 March 1999 05:06:07 CET', '22-Mar-1999', '22-Mar-1999 05:06:07', '22-Mar-1999 5:06:07 AM', '22/03/1999 5:06:07 AM', '22/Mar/1999 5:06:07 +0100', '22/Mar/99 5:06 AM', '23 Apr 2017 10:32:35*311', '23 Apr 2017 11:42:35', '23-Apr-2017 11:42:35', '23-Apr-2017 11:42:35.883', '23/Apr 11:42:35,173', '23/Apr/2017 11:42:35', '23/Apr/2017:11:42:35', '3-11-1999', '3-12-1999 5:06 AM', '3-12-99 5:06 AM', '3-12-99 5:06:07 AM', '3-22-1999 5:06:07 AM', '3/12/1999', '3/12/1999 5:06 AM', '3/12/1999 5:06:07 AM', '3/12/99 5:06 AM', '3/12/99 5:06:07', '8/5/2011 3:31:18 AM:234', '9/28/2011 2:23:15 PM', 'Apr 20 00:00:35 2010', 'Dec 2, 2017 2:39:58 AM', 'Jan 21 18:20:11 +0000 2017', 'Jun 09 2018 15:28:14', 'Mar 16 08:12:04', 'Mar 22 1999', 'Mar 22, 1999', 'Mar 22, 1999 5:06:07 AM', 'Mar.22.1999', 'March 22 1999', 'March 22, 1999', 'Mon Mar 22 05:06:07 CET 1999', 'Mon, 22 Mar 1999 05:06:07 +0100', 'Monday, 22 March 1999', 'Monday, March 22, 1999', 'Monday, March 22, 1999 5:06:07 AM CET', 'Sep 28 19:00:00 +0000']\n", "print(parse_timestamp('2018-08-20T13:20:10*633+0000', formats))\n# OUTPUT\n# {'datestring': '2018-08-20T13:20:10*633+0000', 'matches': [{'datetime': datetime.datetime(2018, 8, 20, 13, 20, 10, 633000, tzinfo=datetime.timezone.utc), 'format': '%Y-%m-%dT%H:%M:%S*%f%z'}]}\n"], ["from itertools import chain, repeat\n\ndef zip_first(first, *rest, fillvalue=None):\n    return zip(first, *map(chain, rest, repeat(repeat(fillvalue))))\n", "def zip_first(first, *rest, fillvalue=None):\n    a, b = tee(first)\n    return compress(zip_longest(b, *rest, fillvalue=fillvalue), zip(a))\n", "def zip_first(first, second, third, fillvalue=None):\n    filler = repeat(fillvalue)\n    return zip(first,\n               chain(second, filler),\n               chain(third, filler))\n", "def limit_cheat(*iterables, fillvalue=None):\n    return islice(zip_longest(*iterables, fillvalue=fillvalue), cheat_length)\n\ndef Kelly_Bundy_chain(first, *rest, fillvalue=None):\n    return zip(first, *map(chain, rest, repeat(repeat(fillvalue))))\n\ndef Kelly_Bundy_compress(first, *rest, fillvalue=None):\n    a, b = tee(first)\n    return compress(zip_longest(b, *rest, fillvalue=fillvalue), zip(a))\n\ndef CrazyChucky(*iterables, fillvalue=None):\n    SENTINEL = object()\n    \n    for first, *others in zip_longest(*iterables, fillvalue=SENTINEL):\n        if first is SENTINEL:\n            return\n        others = [i if i is not SENTINEL else fillvalue for i in others]\n        yield (first, *others)\n\ndef Sven_Marnach(first, *rest, fillvalue=None):\n    rest = [iter(r) for r in rest]\n    for x in first:\n        yield x, *(next(r, fillvalue) for r in rest)\n\ndef Mad_Physicist(*args, fillvalue=None):\n    # zip_by_first('ABCD', 'xy', fillvalue='-') --> Ax By C- D-\n    # zip_by_first('ABC', 'xyzw', fillvalue='-') --> Ax By Cz\n    if not args:\n        return\n    iterators = [iter(it) for it in args]\n    while True:\n        values = []\n        for i, it in enumerate(iterators):\n            try:\n                value = next(it)\n            except StopIteration:\n                if i == 0:\n                    return\n                iterators[i] = repeat(fillvalue)\n                value = fillvalue\n            values.append(value)\n        yield tuple(values)\n\ndef Kelly_Bundy_3(first, *rest, fillvalue=None):\n    a, b = tee(first)\n    return map(itemgetter(1), zip(a, zip_longest(b, *rest, fillvalue=fillvalue)))\n\ndef Kelly_Bundy_4(first, *rest, fillvalue=None):\n    sentinel = object()\n    for z in zip_longest(chain(first, [sentinel]), *rest, fillvalue=fillvalue):\n        if z[0] is sentinel:\n            break\n        yield z\n\ndef Kelly_Bundy_5(first, *rest, fillvalue=None):\n    stopped = False\n    def stop():\n        nonlocal stopped\n        stopped = True\n        return\n        yield\n    for z in zip_longest(chain(first, stop()), *rest, fillvalue=fillvalue):\n        if stopped:\n            break\n        yield z\n\n\nimport timeit\nfrom itertools import chain, repeat, zip_longest, islice, tee, compress\nfrom operator import itemgetter\nfrom collections import deque\n\nfuncs = [\n    limit_cheat,\n    Kelly_Bundy_chain,\n    Kelly_Bundy_compress,\n    CrazyChucky,\n    Sven_Marnach,\n    Mad_Physicist,\n    Kelly_Bundy_3,\n    Kelly_Bundy_4,\n    Kelly_Bundy_5,\n]\n\ndef test(args_creator):\n\n    # Correctness\n    expect = list(funcs[0](*args_creator()))\n    for func in funcs:\n        result = list(func(*args_creator()))\n        print(result == expect, func.__name__)\n    \n    # Speed\n    tss = [[] for _ in funcs]\n    for _ in range(5):\n        print()\n        print(args_creator.__name__)\n        for func, ts in zip(funcs, tss):\n            t = min(timeit.repeat(lambda: deque(func(*args_creator()), 0), number=1))\n            ts.append(t)\n            print(*('%4.1f ms ' % (t * 1e3) for t in sorted(ts)[:3]), func.__name__)\n\ndef args_few_but_long_iterables():\n    global cheat_length\n    cheat_length = 50_000\n    first = repeat(0, 50_000)\n    rest = [repeat(i, 10_000 * i) for i in range(1, 10)]\n    return first, *rest\n\ndef args_many_but_short_iterables():\n    global cheat_length\n    cheat_length = 50\n    first = repeat(0, 50)\n    rest = [repeat(i, i % 101) for i in range(1, 10_000)]\n    return first, *rest\n\ntest(args_few_but_long_iterables)\nfuncs[1:3] = funcs[1:3][::-1]\ntest(args_many_but_short_iterables)\n"], ["import pyautogui\n\nwindow = [ x for x in pyautogui.getAllWindows()]\n", "for i in window:\n    if 'Google Chrome' in i.title:\n        i.hide()\n"], ["res = []\n[res.append(x) for x in test_list if x not in res]\n\n# printing list after removal \nprint (\"The list after removing duplicates : \" + str(res))\n"], ["from pprint import pprint\n\nl = [{'name': 'jamie', 'age': 26, 'color': 'gold'},\n     {'name': 'tara', 'age': 43, 'hobby': 'archery'},\n     {'name': 'matt', 'age': 34, 'epic': 'louhi'}\n]\n\ndef compile(ls):\n    dx = dict()\n    for d in ls:\n        for k, v in d.items():\n            current = dx.get(k, [])  # Leverage get() default value option \n            current.append(v)\n            dx[k] = current\n    return dx\n\nresult = compile(l)\npprint(result)\n", "{'age': [26, 43, 34],\n 'color': ['gold'],\n 'epic': ['louhi'],\n 'hobby': ['archery'],\n 'name': ['jamie', 'tara', 'matt']}\n", "only_values = [v for _, v in result.items()]\n"], ["\nl = [{'name': 'jamie', 'age': 26},\n     {'name': 'tara', 'age': 43},\n     {'name': 'matt', 'age': 34}\n]\n\nnames = []\nages = []\n\nfor row in l:\n    names.append(row[\"name\"])\n    ages.append(row[\"age\"])\n    \noutput = [names, ages]\nprint(output)\n\n# Output: [['jamie', 'tara', 'matt'], [26, 43, 34]]\n", "l = [{'name': 'jamie', 'age': 26},\n     {'name': 'tara', 'age': 43},\n     {'name': 'matt', 'age': 34}\n]\n\nfrom collections import defaultdict\n\nvalue_lists = defaultdict(list)\n\nfor row in l:\n    for k, v in row.items():\n        value_lists[k].append(v)\n        \n# print(value_lists)\n\n# if it must be list of lists\noutput = list(value_lists.values())\n\nprint(output)\n\n# Output: [['jamie', 'tara', 'matt'], [26, 43, 34]]\n"], [], [], ["l = [{'name': 'jamie', 'age': 26},\n     {'name': 'tara', 'age': 43},\n     {'name': 'matt', 'age': 34}\n]\n", "names = []\nages = []\nfor d in l:\n    names.append(d['name'])\n    ages.append(d['age'])\nnames_ages  = [names,ages] \n"], ["class MyClass:\n    @classmethod\n    def action(cls, data):\n        print('first')\n\n        cls.next_action(data)\n\n    @classmethod\n    def next_action(cls, data):\n        print('second', data)\n\nMyClass.action('Hello World!')\n", "class MyClass:\n    def action(self, data):\n        print('first')\n\n        self.next_action(data)\n\n    def next_action(self, data):\n        print('second', data)\n\ninstance = MyClass()\ninstance.action('Hello World!')\n"], ["class MyClass:\n    def action(self):\n        print('first')\n\n        self.next_action()\n\n    def next_action(self):\n        print('second')\n\nmy = MyClass()\nmy.action()\n"], ["#!/usr/bin/env python3.10\n\nclass MyClass:\n    def action(self, data):\n        print('first')\n\n        self.next_action(data)\n\n    def next_action(self, data):\n        print('second')\n\nif __name__ == \"__main__\":\n    myclass = MyClass()\n    myclass.action('hmmm')\n", "#!/usr/bin/env python3.10\n\nclass MyClass:\n\n    @classmethod\n    def action(cls, data):\n        print('first')\n\n        MyClass.next_action(data)\n\n    @classmethod\n    def next_action(cls, data):\n        print('second')\n\nif __name__ == \"__main__\":\n    myclass = MyClass()\n    myclass.action('hmmm')\n"], ["def next_Action(self,data):\nself.next_action(data)\n"], ["class MyClass:\n    def action(self, data):\n        print('first')\n\n        self.next_action(data)\n\n    def next_action(self, data):\n        print('second')\n"], [], [], [], [], ["<your virtualenv path>/bin/python -m torch.utils.collect_env\n", "[pip3] numpy==1.21.5\n[pip3] torch==1.11.0\n[pip3] torchaudio==0.11.0\n[pip3] torchtuples==0.2.2\n[pip3] torchvision==0.12.0\n", "[pip3] numpy==1.21.5\n[pip3] torch==1.11.0+cu113  <---\n[pip3] torchaudio==0.11.0\n[pip3] torchtuples==0.2\n[pip3] torchvision==0.12.0\n"], ["import xgboost\nimport shap\n\nX, y = shap.datasets.adult()\nmodel = xgboost.XGBClassifier().fit(X, y)\n\nexplainer = shap.Explainer(model, X)\nshap_values = explainer(X)\n\nshap.plots.beeswarm(shap_values, show=False, color_bar=False)\nplt.colorbar()\nplt.show()\n"], [], ["web: uvicorn src.main:app --host=0.0.0.0 --port=${PORT:-5000}\n", "import socket\nimport sys\n\nfrom fastapi import FastAPI\n\napp = FastAPI()\n\nhostname = socket.gethostname()\n\nversion = f\"{sys.version_info.major}.{sys.version_info.minor}\"\n\n\n@app.get(\"/\")\nasync def read_root():\n    return {\n        \"name\": \"my-app\",\n        \"host\": hostname,\n        \"version\": f\"Hello world! From FastAPI running on Uvicorn. Using Python {version}\"\n    }\n"], [], [], [], [], ["number = int(input(\"Limit: \"))\nx = 1\ny = 1\nwhile y < number:\n    x +=1\n    y +=x\n    \nprint(y)\n"], ["from openpyxl import Workbook\n\nnew_list = [[\"first\", \"second\"], [\"third\", \"fourth\"]]\n\nwb = Workbook() # creates a workbook object.\nws = wb.active # creates a worksheet object.\n\nfor row in new_list:\n    ws.append(row) # adds values to cells, each list is a new row.\n\n    \nwb.save('File_Name.xlsx') # save to excel file.\n"], ["from file_read_backwards import FileReadBackwards\n\nwith FileReadBackwards(\"/tmp/file\", encoding=\"utf-8\") as frb:\n\n    # getting lines by lines starting from the last line up\n    for l in frb:\n        if l:\n            print(l)\n            break\n"], ["[1378, 191, 741]\n", "[1378, 191, 741]\n"], ["RUN apk add --update python make g++\\\n   && rm -rf /var/cache/apk/*\n"], ["[int(hh) * 60 + int(mm) for ts in timestamps for hh, mm = ts.split(\":\")]\n", "[int(hh) * 60 + int(mm) for ts in timestamps for hh, mm in [ts.split(':')]]\n"], ["timestamps = [\"22:58\", \"03:11\", \"12:21\"]\n\n#NOTE: Use () for generators, not [].\nhh_mms = (timestamp.split(':') for timestamp in timestamps)\nconverted = [int(hh) * 60 + int(mm) for (hh, mm) in hh_mms]\n\nprint(converted)\n# [1378, 191, 741]\n"], ["from datetime import datetime as dt\nimport typing\n\ndef timestamps_to_minutes(timestamps: typing.List[str]) -> typing.List[any]:\n    \"\"\"Uses datetime.strptime to parse a datetime string and return\n    minutes spent in this day.\"\"\"\n    return [int(((p := dt.strptime(t,\"%H:%M\")) - dt(p.year,p.month, p.day)\n                 ).total_seconds()//60) for t in timestamps]\n\ntimestamps = [\"22:58\", \"03:11\", \"12:21\"]\n\nprint(timestamps_to_minutes(timestamps))\n", "[1378, 191, 741]\n"], ["from operator import methodcaller\nout = [int(h) * 60 + int(m) for h, m in map(methodcaller(\"split\", \":\"), timestamps)]\n", "[1378, 191, 741]\n"], ["[int(hh)*60 + int(mm) for hh, mm in (ts.split(':') for ts in timestamps)]\n", "def timestamp_to_minutes(timestamp: str) -> int:\n    hh, mm = timestamp.split(\":\")\n    return int(hh)*60 + int(mm)\n\n[timestamp_to_minutes(ts) for ts in timestamps]\n\n# Alternative\nlist(map(timestamp_to_minutes, timestamps))\n"], ["name = 'robert lewandowski'\nprint(name.title())\n", "Robert Lewandowski\n"], ["letters=input() #letters already in the crossword\nguess=input() #word to check for fit\nl1 = list(letters)\nl2 = list(guess)\nall_match = 0\nfor c in l1:\n    for i in range(0, len(l2)):\n        if c == l2[i]:\n            l2 = l2[i+1:]\n            all_match = all_match + 1\n            break\n        \nif all_match == len(l1):\n    print('yes')\nelse:\n    print('no')\n"], ["https://{token}@raw.githubusercontent.com/username/repo/master/file.csv\n", "https://{username}:{token}@raw.githubusercontent.com/username/repo/master/file.csv\n", "from requests import get as rget\n\nres = rget(\"https://<username>:<token>@raw.githubusercontent.com/<username>/repo/<repo>/file.csv\")\nwith open('file.csv', 'wb+') as f:\n        f.write(res.content)\n"], [], ["{\n    httpRequest: {\n    status: 401\n    }\n    insertId: \"1xxol5ifezru6m\"\n    jsonPayload: {\n    @type: \"type.googleapis.com/google.cloud.scheduler.logging.AttemptFinished\"\n    jobName: \"projects/<PROJECT_ID>/locations/us-central1/jobs/test\"\n    status: \"UNAUTHENTICATED\"\n    targetType: \"HTTP\"\n    url: \"<MY_URL>\"\n    }\n    logName: \"projects/<PROJECT_ID>/logs/cloudscheduler.googleapis.com%2Fexecutions\"\n    receiveTimestamp: \"2022-04-19T02:09:54.932289922Z\"\n    resource: {\n    labels: {\n    job_id: \"test\"\n    location: \"us-central1\"\n    project_id: \"<PROJECT_ID>\"\n    }\n    type: \"cloud_scheduler_job\"\n    }\n    severity: \"ERROR\"\n    timestamp: \"2022-04-19T02:09:54.932289922Z\"\n}\n", "gcloud scheduler jobs create http senses-test-run \\\n  --oidc-service-account-email=\"senses-cloud-scheduler@<PROJECT_ID>.iam.gserviceaccount.com\" \\\n  --oidc-token-audience=\"https://my-custom-domain-that-maps-to-cloud-run\" \\\n  --location=\"us-central1\" \\\n  --schedule=\"5 4 * * mon\" \\\n  --uri=\"https://my-custom-domain-that-maps-to-cloud-run\" \\\n  --http-method=\"post\" \\\n  --headers=\"Content-Type=application/json\" \\\n  --message-body=\"{\\\"foo\\\":\\\"bar\\\",\\\"beep\\\":\\\"boop\\\"}\"\n"], [], [], [], ["import numpy as np\nimport math\n\nnb_steps = 3\nmin_val = 0\nmax_val = 100\n\nstep_size = math.floor((max_val-min_val)/nb_steps)\narr = np.arange(min_val,max_val,step_size)\n\n# update last value to match max_val\n# this step is needed if (max_val-min_val)/nb_steps is a decimal number\narr[-1] = max_val\n", "numpy.linspace(start, stop, num=50, endpoint=True, retstep=False, dtype=None, axis=0)\n"], ["def listWithNumberOfStep(startNumber, endNumber, nbSteps):\n   listNumber = []\n   delta = endNumber - startNumber\n   for i in range(nbSteps + 1):\n      listNumber.append(startNumber + (delta/nbSteps * i))\n   return listNumber\n"], ["sudo update-alternatives --config python3                                                                                                                                                                  \nThere are 2 choices for the alternative python3 (providing /usr/bin/python3).\n\n  Selection    Path                Priority   Status\n------------------------------------------------------------\n* 0            /usr/bin/python3.9   2         auto mode\n  1            /usr/bin/python3.6   1         manual mode\n  2            /usr/bin/python3.9   2         manual mode\n"], ["from collections import defaultdict\n\ndef heuristic(data, sort_data=False):\n    data = sorted(data) if sort_data else data[:]\n    out = [data.pop(0)]\n    indexes = defaultdict(set)\n    for i, triple in enumerate(data):\n        for mark in enumerate(triple):\n            indexes[mark].add(i)\n    remain = set(range(len(data)))\n    while remain:\n        a, b, c = out[-1]\n        best = 4, None\n        for mark in enumerate(out[-1]):\n            for i in indexes[mark]:\n                x, y, z = data[i]\n                candidate = (a != x) + (b != y) + (c != z), i\n                if candidate < best:\n                    best = candidate\n        i = best[1]\n        if i is None:\n            i = min(remain)\n        remain.remove(i)\n        t = data[i]\n        for pattern in enumerate(t):\n            indexes[pattern].remove(i)\n        out.append(t)\n    return out\n", "        for i in indexes[0, a]:\n            _, y, z = data[i]\n            candidate = (b != y) + (c != z), i\n            if candidate < best:\n                best = candidate\n        for i in indexes[1, b]:\n            x, _, z = data[i]\n            candidate = (a != x) + (c != z), i\n            if candidate < best:\n                best = candidate\n        for i in indexes[2, c]:\n            x, y, _ = data[i]\n            candidate = (a != x) + (b != y), i\n            if candidate < best:\n                best = candidate\n"], ["from selenium import webdriver\nfrom selenium.webdriver.firefox.service import Service\nfrom selenium.webdriver.firefox.options import Options\nfrom webdriver_manager.firefox import GeckoDriverManager\n\noptions = Options()\noptions.add_argument('--headless')\n\ndriver = webdriver.Firefox(service=Service(GeckoDriverManager().install()),options=options)\ndriver.get(\"https://www.google.com\")\nprint('Done')\ndriver.quit()\n"], ["old_date = '20200505'\n\nnew_date = old_date[:4]+'-'+old_date[4:6]+'-'+old_date[6:8]\n\nprint(new_date)\n"], [], [], [" conda install tensorflow-gpu=2.3 tensorflow=2.3=mkl_py38h1fcfbd6_0 cudatoolkit cudnn keras matplotlib\n"], ["!pip install tensorflow==2.3.0\n"], [], ["NOTE: Similarity figures are better when higher.\n\nRandom generation of 10000 items has similarity of  = 70\n  Same data random sorts gives similarity values: 70, 57, 65, 57, 51, 61, 64, 56, 63, 50\n\n(Column_index, Standard_deviation) of each column of numbers: [(0, 96.5443987139596), (1, 145.326873357098), (2, 288.69842362782305)]\n\nSimilarity when sorting by all column orders:\n  SIMILARITY  SORT_COLUMN_ORDER\n       9_978  [0, 1, 2]  (by INcreasing std-dev)\n       9_829  [0, 2, 1]\n       9_802  [1, 0, 2]\n       9_638  [1, 2, 0]\n       9_160  [2, 0, 1]\n       9_142  [2, 1, 0]  (by DEcreasing std-dev)\n\nNeighbourly swaps:\n  Neighbour swaps = 12 New similarity = 9990\n"], [], [], ["NOTE: Similarity figures are better when higher.\n\nRandom generation of 10000 items has similarity of  = 55\nfield_stddev = [(0, 96.04927579341764), (1, 145.8145251033312), (2, 288.84656085582884)]\n\nField indices by INcreasing stddev of tuple field values = [0, 1, 2]\nsimilarity(sort_by_field_of_inc_dev) = 9,949\n\nField indices by DEcreasing stddev of tuple field values = [2, 1, 0]\nsimilarity(sort_by_field_of_dec_dev) = 9,135\n\n Same data, random sorts, gives these similarity values:\n  Random similarity(0) = 55\n  Random similarity(1) = 61\n  Random similarity(2) = 54\n  Random similarity(3) = 60\n  Random similarity(4) = 68\n  Random similarity(5) = 55\n  Random similarity(6) = 56\n  Random similarity(7) = 58\n  Random similarity(8) = 56\n  Random similarity(9) = 63\n"], [], ["import random\n\ndef get_data(n=1000):\n    f = lambda n: random.randint(0, n)\n    return [(f(n // 30), f(n // 20), f(n // 10)) for _ in range(n)]\n\ndef dissimilar(t1, t2):\n    a, b, c = t1\n    x, y, z = t2\n    return (a != x) + (b != y) + (c != z)\n\ndef mst_score(data):\n    dist = dict.fromkeys(data, 3)\n    dist[data[0]] = 0\n    score = 0\n    while dist:\n        one = min(dist, key=dist.get)\n        score += dist.pop(one)\n        for other in dist:\n            dist[other] = min(dist[other], dissimilar(one, other))\n    return score\n\ntotal = 0\nfor i in range(100):\n    data = get_data()\n    score = mst_score(data)\n    total += score\n    print(score, total)\n"], ["import itertools\n\ndata = [\n    (1, 0, 5),\n    (2, 4, 2),\n    (3, 2, 1),\n    (4, 3, 4),\n    (3, 3, 1),\n    (1, 2, 2),\n    (4, 0, 3),\n    (0, 3, 5),\n    (1, 5, 1),\n    (1, 5, 2),\n]\n\ndef dissimilar(t1, t2):\n    if t1 and t2:\n        a, b, c = t1\n        x, y, z = t2\n        return (a != x) + (b != y) + (c != z)\n    return 0\n\ndef score(data):\n    return sum(dissimilar(t1, t2) for t1, t2 in zip(data, data[1:]))\n\ndef solve(data):\n    def solve(head, data, tail):\n        if len(data) <= 3:\n           perm = min(itertools.permutations(data),\n                      key=lambda perm: score([head, *perm, tail]))\n           return list(perm), score([head, *perm, tail])\n        half = len(data) // 2\n        result = result_score = None\n        for center in list(data):\n            data.remove(center)\n            for left in itertools.combinations(data, half):\n                left = set(left)\n                right = data - left\n                left, score_left = solve(head, left, center)\n                right, score_right = solve(center, right, tail)\n                if result_score is None or score_left + score_right < result_score:\n                    result = [*left, center, *right]\n                    result_score = score_left + score_right\n            data.add(center)\n        return result, result_score\n    return solve(None, set(data), None)\n\nresult, result_score = solve(data)\nprint(result, result_score, score(result), sorted(result) == sorted(data))\n"], ["for i in range(4):\n  funcs[i]()\n", "for x in range(4):\n   funcs[x]()\n"], ["def getfunc(i):\n    return lambda: i\n\nfuncs = []\nfor i in range(5):\n    funcs.append(getfunc(i))\n\nfor item in funcs:\n    print(item())\n"], [], ["def stop_at_four(lst):\ni = 0 \nnew_lst = []\nwhile i < len(lst):\n    if lst[i] != 4 :\n        new_lst.append(lst[i])\n    else :\n        break\n    i = i + 1\nreturn new_lst\n"], ["def stop_at_four(lst):\n    sublist = []\n    y = (num for num in lst)  \n    num = next(y, 4)  \n    while num != 4:\n        sublist.append(num)\n        num = next(y,4)  \nreturn sublist\n"], ["plt.legend(handles=[patch_1, patch_2], loc='upper right', handleheight=3, handlelength=4)\n"], ["import boto3\nimport threading\nimport time\nfrom queue import LifoQueue, Empty\nfrom tqdm.notebook import tqdm\n\nclass DDBTableCleaner(object):\n    def __init__(self, table_name, profile_name, threads_limit=32):\n        self._pbar = None\n        self._queue = LifoQueue()\n        self._threads = dict()\n        self._cnt = 0\n        self._done = False\n        self._threads_limit = threads_limit\n        self._table_name = table_name\n        self.session = boto3.Session(profile_name=profile_name)\n        dynamodb_client = self.session.resource('dynamodb')\n        self.table = dynamodb_client.Table(table_name)\n\n    def run(self):\n        if bool(self._pbar):\n            self._pbar.close()\n\n        self._pbar = tqdm(desc=self._table_name)\n        for i in range(self._threads_limit):\n            thread_name = f'worker_thread_{i}'\n            self._threads[thread_name] = threading.Thread(\n                target=self.worker_thread,\n                name=thread_name,\n            )\n            self._threads[thread_name].start()\n        self.queue_replenish()\n        while self._queue.qsize() > 0:\n            # print(f'items processed: ({self._cnt})')\n            time.sleep(1)\n        self._done = True\n        for thread in self._threads.values():\n            if thread.is_alive():\n                thread.join()\n        self._pbar.close()\n        print(f'items processed: ({self._cnt})')\n\n    def queue_replenish(self):\n        table_key_names = [key.get('AttributeName') for key in self.table.key_schema]\n        projection_expression = ', '.join('#' + key for key in table_key_names)\n        expression_attr_names = {'#' + key: key for key in table_key_names}\n        total_read = 0\n        page = self.table.scan(\n            ProjectionExpression=projection_expression,\n            ExpressionAttributeNames=expression_attr_names\n        )\n        while page['Count'] > 0:\n            total_read += page['Count']\n            for item in page['Items']:\n                self._queue.put(item)\n            # print(\"Still reading... Total read: %d\" % total_read)\n            self._pbar.total = total_read\n            if 'LastEvaluatedKey' in page:\n                page = self.table.scan(\n                    ProjectionExpression=projection_expression,\n                    ExpressionAttributeNames=expression_attr_names,\n                    ExclusiveStartKey=page['LastEvaluatedKey']\n                )\n            else:\n                break\n\n    def worker_thread(self):\n        thr_name = threading.current_thread().name\n        # print(f'[{thr_name}] thread started')\n        with self.table.batch_writer() as batch:\n            while not self._done:\n                try:\n                    item = self._queue.get_nowait()\n                except Empty:\n                    # print(\"Empty queue\")\n                    time.sleep(1)\n                else:\n                    try:\n                        batch.delete_item(Key=item)\n                        self._pbar.update(1)\n                        self._cnt += 1\n                    except Exception as e:\n                        print(e)\n        # print(f'[{thr_name}] thread completed')\n"], ["import datetime\nfrom threading import Thread, Event\nimport time\nfrom typing import Callable\n\n\nclass TimedCalls(Thread):\n    \"\"\"Call function again every `interval` time duration after it's first run.\"\"\"\n    def __init__(self, func: Callable, interval: datetime.timedelta) -> None:\n        super().__init__()\n        self.func = func\n        self.interval = interval\n        self.stopped = Event()\n\n    def cancel(self):\n        self.stopped.set()\n\n    def run(self):\n        next_call = time.time()\n        while not self.stopped.is_set():\n            self.func()  # Target activity.\n            next_call = next_call + self.interval\n            # Block until beginning of next interval (unless canceled).\n            self.stopped.wait(next_call - time.time())\n\n\ndef my_function():\n    print(f\"this is python: {time.strftime('%H:%M:%S', time.localtime())}\")\n\n# Start test a few secs from now.\nstart_time = datetime.datetime.now() + datetime.timedelta(seconds=5)\nrun_time = datetime.timedelta(minutes=2)  # How long to iterate function.\nend_time = start_time + run_time\n\nassert start_time > datetime.datetime.now(), 'Start time must be in future'\n\ntimed_calls = TimedCalls(my_function, 10)  # Thread to call function every 10 secs.\n\nprint(f'waiting until {start_time.strftime(\"%H:%M:%S\")} to begin...')\nwait_time = start_time - datetime.datetime.now()\ntime.sleep(wait_time.total_seconds())\n\nprint('starting')\ntimed_calls.start()  # Start thread.\nwhile datetime.datetime.now() < end_time:\n    time.sleep(1)  # Twiddle thumbs while waiting.\nprint('done')\ntimed_calls.cancel()\n\n"], [], ["import datetime\nimport time\n\n\ndef repeat_between(\n        start_dt,\n        stop_dt,\n        interval_td,\n        func,\n        func_args=None,\n        func_kws=None,\n        collect_results=True,\n        throttling_s=1):\n    # ensure valid `func_args` and `func_kws`\n    func_args = () if func_args is None else tuple(func_args)\n    func_kws = {} if func_kws is None else dict(func_kws)\n    # initialize current datetime and last run\n    curr_dt = datetime.datetime.now()\n    last_run = None\n    # ensure the start datetime is:\n    # - before the stop datetime\n    # - after the current datetime\n    if stop_dt < start_dt < curr_dt:\n        return\n    else:\n        # collect results here\n        result = []\n    # wait until reaching the start datetime\n    wait_td = (start_dt - curr_dt)\n    time.sleep(wait_td.total_seconds())\n    # loop until current datetime exceeds the stop datetime\n    while curr_dt <= stop_dt:\n        # if current time is\n        # - past the start datetime\n        # - near an interval timedelta\n        if curr_dt >= start_dt and \\\n                (not last_run or curr_dt >= last_run + interval_td):\n            curr_result = func(*func_args, **func_kws)\n            if collect_results:\n                result.append(curr.result)\n            last_run = curr_dt\n        # wait some time before checking again\n        if throttling_s > 0:\n            time.sleep(throttling_s)\n        # update current time\n        curr_dt = datetime.datetime.now()\n"], [], ["RUN apk add --no-cache python3 make g++\n"], [], ["tesla_revenue = pd.read_html(url, match = \"Tesla Quarterly Revenue\", flavor='bs4')[0]\nprint(\"Dataframe columns: \", tesla_revenue.columns)\ntesla_revenue = tesla_revenue.rename(columns = {\"Tesla Quarterly Revenue(Millions of US $)\":\"Date\"})\ntesla_revenue = tesla_revenue.rename(columns = {\"Tesla Quarterly Revenue(Millions of US $).1\":\"Revenue\"})  \ntesla_revenue.head()\n"], ["import collections\n\ns =\"outp4ut Thi1s 3an st5ring i2s\"\n\nd = collections.defaultdict()\n\nfor word in s.split():\n    for char in word:   # itertaing through the characters of the word\n        if char.isdigit():  \n            d[int(char)] = word  # adding char to the dictionary if the char is a digit\n            break\n       \nvalues_arr = []\n\nfor num in sorted(d.keys()): # sort the keys\n    values_arr.append(d[num])\n\noutput = \" \".join(values_arr)   \n\nprint(output)\n\n### output: Thi1s i2s 3an outp4ut st5ring\n"], ["\"python.languageServer\": \"Default\",\n"], ["!pip install --upgrade tensorflow\n!pip install keras_efficientnet_v2\n!pip install efficientnet\n"], ["plt.gcf().axes[-1].set_aspect('auto')\nplt.tight_layout()\n# As mentioned, smaller \"box_aspect\" value to make colorbar thicker\nplt.gcf().axes[-1].set_box_aspect(50) \n"], ["pip install --upgrade pip\npip uninstall pyopenssl cryptography\npip install pyopenssl cryptography\n"], ["import time\nimport datetime\n\nstart_time = datetime.datetime(year=2022, month=4, day=5, hour=1, minute=00, second=00)\nrelativedelta = datetime.timedelta(hours=1)\niteration_time = datetime.timedelta(minutes=5)\n\nend_time = start_time + relativedelta\nlast_run = None\n\n\ndef func():\n    print(\"this is python\")\n\n\nwhile True:\n    current_time = datetime.datetime.now()\n    if start_time <= current_time <= end_time:\n        if last_run:\n            if current_time >= last_run + iteration_time:\n                func()\n                last_run = current_time\n        else:\n            last_run = current_time\n    elif current_time > end_time:\n        break\n\n    time.sleep(1)\n"], [], ["def ListCheck():\n    number = 11\n    nums = [10, 15, 3, 7, 9, 6, 4, 8]\n    found = 0\n    while found == 0:\n        if len(nums) < 2: # check if array has at least 2 numbers\n            break\n        while len(nums) > 1:\n            comparenum = nums.pop() # removes comparable number from array to avoid false true if nums has item == number*2 \n            if (number - comparenum) in nums:\n                print(True)\n                found = 1\n                break\n\n    if found == 0:\n        print(False)\n        \n\nListCheck()\nexit\n"], [], ["import win32com.client\nimport comtypes.client\nimport pdfplumber\nword = win32com.client.Dispatch('Word.Application')\nwdFormatPDF = 17\nin_file = Filepath\nout_file = \"out.pdf\"\nword = comtypes.client.CreateObject('Word.Application')\ndoc = word.Documents.Open(in_file)\ndoc.SaveAs(out_file, FileFormat=wdFormatPDF)\ndoc.Close()\nword.Quit()\nwith pdfplumber.open(out_file) as pdf:       \n    for page in pdf.pages:\n        out=page.extract_text()            \n        print(out)\n\n    \n        \n"], ["Setter Called with Value  None\nNone\n", "$ pip install dataclass-wizard\n", "@dataclass\nclass Test(metaclass=field_property_support):\n    my_int: int\n    name: str\n    my_bool: bool = True\n\n    @property\n    def name(self):\n        return self._name\n\n    @name.setter\n    def name(self, val):\n        print(f'Setting name to: {val!r}')\n        self._name = val\n"], [], ["import dataclasses\nfrom typing import Optional\n\n\n@dataclasses.dataclass\nclass FileObject:\n    uploaded_by: Optional[str] = None\n\nclass FileObjectExpensive(FileObject):\n    @property\n    def uploaded_by(self):\n        return self._uploaded_by\n\n    @uploaded_by.setter\n    def uploaded_by(self, uploaded_by):\n        print('Setter Called with Value ', uploaded_by)\n        self._uploaded_by = uploaded_by\n\n    def save(self):\n        print(self.uploaded_by)\n\np = FileObjectExpensive()\np.save()\np2 = FileObjectExpensive(uploaded_by='Already Computed')\np2.save()\n", "Setter Called with Value  None\nNone\nSetter Called with Value  Already Computed\nAlready Computed\n"], [], [], ["    url = \"https://sharepoint.site.com/sites/MySite/MySheet.xlsx\"\n    sheet_name = 'Sheet X'\n    response = File.open_binary(ctx, relative_url)\n    bytes_file_obj = io.BytesIO()\n    bytes_file_obj.write(response.content)\n    bytes_file_obj.seek(0)\n    df = pd.read_excel(bytes_file_obj, sheet_name = sheet_name)  //call sheet name\n"], [], [], ["from itertools import combinations \n\nx = list(combinations(['A','B','C','D'],2))\n\nt = []\nfor i in (x):\n    t.append(i[0]+i[1]) # concatenating the strings and adding in a list\n\ng = []\nfor i in range(0,len(t),2):\n    for j in range(i+1,len(t)):\n        g.append([t[i],t[j]])\n        break\nprint(g)\n"], ["comb = [(a,b) for a in letters for b in letters if a != b]\n", "var = [tuple(sorted(sub)) for sub in comb]\nvar = list(set(var))\n"], ["def nrng_gen():\n    yield from range(10)\n\nnrng = nrng_gen()\n\nnrng_func = lambda: next(nrng)\n\nfor i in range(10):\n    print(nrng_func())\n", "class NRNG:\n    def __init__(self):\n        self.numbers = range(10)\n        self.state = -1\n    def __call__(self):\n        self.state += 1\n        return self.numbers[self.state]\n        \nnrng = NRNG()\n\n\nfor i in range(10):\n    print(nrng())\n"], ["# Get the first n numbers (10 in this case)\n\nfor i,j in enumerate(nrng()):  \n    if i > 9:\n        break\n    print('random number', rng())\n    print('non-random number', j)\n    \n# Or this if you want to get all numbers in nrng()\n\nfor j in nrng():\n    print('random number', rng())\n    print('non-random number', j)\n"], ["def foo():\n    foo = \"str\"\n    def inner():\n#(1)    foo = 1 # Commented this line\n        print(foo)\n    inner()\n    print(foo)\n\nfoo()\n# str\n# str\n\n# Uncommenting (1) gives output as\n\nfoo()\n# 1\n# str\n"], ["!pip install easyocr\n!pip install imutils\n", "import cv2\nfrom matplotlib import pyplot as plt\nimport numpy as np\nimport imutils\nimport easyocr\n"], [], ["print(f\"abcd_{cariable}\")\n", "s = \"abcd\"\nprint(f\"{s}_{cariable}\")\n"], [], ["that_function(nrng().__next__)\n", "that_function(partial(next, nrng()))\n", "that_function(iter(np.arange(1,10.5,0.5)).__next__)\n", "import numpy as np\nfrom functools import partial\n\n# a random number generator\nrng = lambda : np.random.randint(2,20)//2\n\n# a non-random number generator\ndef nrng():\n    numbers = np.arange(1,10.5,0.5)\n    for i in range(len(numbers)):\n        yield numbers[i]\n\ndef that_function(rng):\n    print(*(rng() for j in range(10)))\n\nthat_function(rng)\nthat_function(nrng().__next__)\nthat_function(iter(np.arange(1,10.5,0.5)).__next__)\nthat_function(partial(next, nrng()))\n", "4 6 1 3 8 7 3 6 2 1\n1.0 1.5 2.0 2.5 3.0 3.5 4.0 4.5 5.0 5.5\n1.0 1.5 2.0 2.5 3.0 3.5 4.0 4.5 5.0 5.5\n1.0 1.5 2.0 2.5 3.0 3.5 4.0 4.5 5.0 5.5\n"], [">>> def f():\n        yield 10\n        yield 20\n        yield 30\n    \n>>> g = f().__next__\n>>> g()\n10\n>>> g()\n20\n>>> g()\n30\n"], [], [], ["class NotRandom:\n\n    numbers = np.arange(1,10.5,0.5)\n    last_index = -1\n\n    @classmethod\n    def nrng(cls):\n        cls.last_index += 1\n        if cls.last_index < len(cls.numbers):\n            return cls.numbers[cls.last_index]\n        # else:\n        return None\n\n# Create an alias to the classmethod\nnrng = NotRandom.nrng      # Note this is OUTSIDE the class\n", "print(nrng())    # 1.0\nprint(nrng())    # 1.5\nprint(nrng())    # 2.0\n", "class NotRandom:\n    def __init__(self):\n        self.numbers = np.arange(1,10.5,0.5)\n        self.last_index = -1\n\n    def nrng(self):\n        self.last_index += 1\n        if self.last_index < len(self.numbers):\n            return self.numbers[self.last_index]\n        # else:\n        return None\n\n# Create an object. Then create an alias to its method\nnrng = NotRandom().nrng \n", "another_notrandom = NotRandom()\nnrng2 = another_notrandom.rng\n\nprint(nrng())    # 1.0\nprint(nrng())    # 1.5\n\nprint(nrng2())   # 1.0\n\nprint(nrng())    # 2.0\n\nprint(nrng2())   # 1.5\n\n"], ["# make it a generator\ndef _rng():\n    while True:\n        yield np.random.randint(2,20)//2\n\n# a non-random number generator\ndef _nrng():\n    numbers = np.arange(1,10.5,0.5)\n    for i in range(len(numbers)):\n        yield numbers[i]\n\nrng = _rng()\nnrng = _nrng()\nfor j in range(10):\n    print('random number', next(rng))\n    print('non-random number', next(nrng))\n"], ["for (root,dirs,files) in os.walk('Test', topdown=true):\n    for name in files:\n        fp = os.path.join(root, name)\n        if name.endswith(\".csv\"):\n            pass\n        else:\n             os.remove(fp)\n"], ["from datetime import datetime, timedelta\n\nnow = datetime.now()\nstart = now + timedelta(minutes = 15)\nfinish = start + timedelta(minutes = 30)\n\nelapsed = finish - start # This is a timedelta object\n\nreference_interval = 15*60 # interval in seconds\n\nnumber_of_intervals = elapsed.seconds/reference_interval\n", "number_of_intervals = (elapsed.days*86400+elapsed.seconds)/reference_interval\n# (86400 seconds in a day)\n"], [], ["import time\ninterval = 45*60\nstart = time.time()\nfinish = time.time() + interval\ndiff = finish - start\nprint(diff // (15*60))\n"], ["from datetime import datetime, timedelta\n\nDATE_TIME_STRING_FORMAT = '%Y-%m-%dT%H:%M:%S.%fZ'\n\nfrom_date_time = datetime.strptime('2016-06-06T05:00:00.000Z',\n                                   DATE_TIME_STRING_FORMAT)\nto_date_time = datetime.strptime('2016-06-06T06:00:00.000Z',\n                                 DATE_TIME_STRING_FORMAT)\n\ndate_times = [from_date_time.strftime(DATE_TIME_STRING_FORMAT)]\ndate_time = from_date_time\nwhile date_time < to_date_time:\n    date_time += timedelta(minutes=15)\n    date_times.append(date_time.strftime(DATE_TIME_STRING_FORMAT))\n\nprint(date_times)\n", "['2016-06-06T05:00:00.000000Z', '2016-06-06T05:15:00.000000Z', '2016-06-06T05:30:00.000000Z', '2016-06-06T05:45:00.000000Z', '2016-06-06T06:00:00.000000Z']\n", "DATE_TIME_STRING_FORMAT = '%Y-%m-%dT%H:%M:%S.%fZ'\n\nfrom_date_time = datetime.strptime('2016-06-06T05:00:00.000Z',\n                                   DATE_TIME_STRING_FORMAT)\nto_date_time = datetime.strptime('2016-06-06T06:00:00.000Z',\n                                 DATE_TIME_STRING_FORMAT)\n\nprint((to_date_time-from_date_time) / timedelta(minutes=15))\n"], ["now = datetime.now()\nstart = now + timedelta(minutes = 15)\nfinish = start + timedelta(minutes = 30)\ndifference = (finish - start).total_seconds()/60\nquarters = int(difference/15)\n"], ["    public static void main(String[] args) throws IOException {\n        System.out.println(\"Start scraping content...>> \" + new Timestamp(new Date().getTime()));\n        Set<Integer> allIds = new HashSet<>();\n        URL target = new URL(\"https://45bwzj1sgc-dsn.algolia.net/1/indexes/*/queries?x-algolia-agent=Algolia%20for%20JavaScript%20(3.35.1)%3B%20Browser%3B%20JS%20Helper%20(3.7.0)&x-algolia-application-id=45BWZJ1SGC&x-algolia-api-key=Zjk5ZmFjMzg2NmQxNTA0NGM5OGNiNWY4MzQ0NDUyNTg0MDZjMzdmMWY1NTU2YzZkZGVmYjg1ZGZjMGJlYjhkN3Jlc3RyaWN0SW5kaWNlcz1ZQ0NvbXBhbnlfcHJvZHVjdGlvbiZ0YWdGaWx0ZXJzPSU1QiUyMnljZGNfcHVibGljJTIyJTVEJmFuYWx5dGljc1RhZ3M9JTVCJTIyeWNkYyUyMiU1RA%3D%3D\");\n        String requestBody = \"{\\\"requests\\\":[{\\\"indexName\\\":\\\"YCCompany_production\\\",\\\"params\\\":\\\"hitsPerPage=1000&query&filters=objectID:24638\\\"}]}\";\n        int index = 1;\n        List<String> results = new ArrayList<>();\n        String bodyIndex = \"{\\\"indexName\\\":\\\"YCCompany_production\\\",\\\"params\\\":\\\"hitsPerPage=1000&query&filters=objectID:%d\\\"}\";\n        for (int i = 1; i <= 30; i++) {\n            StringBuilder body = new StringBuilder(\"{\\\"requests\\\":[\");\n            for (int j = 1; j <= 1000; j++) {\n                body.append(String.format(bodyIndex, index));\n                body.append(\",\");\n                index++;\n            }\n            body = new StringBuilder(body.substring(0, body.length() - 1));\n            body.append(\"]}\");\n            HttpURLConnection con = (HttpURLConnection) target.openConnection();\n            con.setDoOutput(true);\n            con.setRequestMethod(HttpMethod.POST.name());\n            con.setRequestProperty(HttpHeaders.CONTENT_TYPE, APPLICATION_JSON);\n            OutputStream os = con.getOutputStream();\n            os.write(body.toString().getBytes(StandardCharsets.UTF_8));\n            os.close();\n            con.connect();\n            String response = new String(con.getInputStream().readAllBytes(), StandardCharsets.UTF_8);\n            results.add(response);\n        }\n        results.forEach(result -> {\n            JsonArray array = JsonParser.parseString(result).getAsJsonObject().get(\"results\").getAsJsonArray();\n            array.forEach(data -> {\n                if (((JsonObject) data).get(\"nbHits\").getAsInt() == 0) {\n                    return;\n                } else {\n                    allIds.add(((JsonObject) data).get(\"hits\").getAsJsonArray().get(0).getAsJsonObject().get(\"id\").getAsInt());\n                }\n            });\n        });\n        System.out.println(\"Total scraped ids \" + allIds.size());\n        System.out.println(\"Finish scraping content...>>>> \" + new Timestamp(new Date().getTime()));\n    }\n"], ["def zip_first(first, *rest, fillvalue=None):\n    rest = [iter(r) for r in rest]\n    for x in first:\n        yield x, *(next(r, fillvalue) for r in rest)\n", "def zip_first(first, second, fillvalue=None):\n    second = iter(second)\n    for x in first:\n        yield x, next(second, fillvalue)\n"], [], ["import fs\nimport pyzipper\n\n# create in-memory file system\nmem_fs = fs.open_fs('mem://')\nmem_fs.makedir('hidden_dir')\n\n# generate data \ndata = b'ab' * 10\n\nsecret_password = b'super secret password'\n\n# Create encrypted password protected ZIP file in-memory\nwith pyzipper.AESZipFile(mem_fs.open('/hidden_dir/password_protected.zip', 'wb'),\n                         'w',\n                         compression=pyzipper.ZIP_LZMA,\n                         encryption=pyzipper.WZ_AES) as zf:\n    zf.setpassword(secret_password)\n    zf.writestr('data.txt', data)\n\n\n# Read encrypted password protected ZIP file from memory\nwith pyzipper.AESZipFile(mem_fs.open('/hidden_dir/password_protected.zip', 'rb')) as zf:\n    zf.setpassword(secret_password)\n    my_secrets = zf.read('data.txt')\n    print(my_secrets)\n    # output \n    b'abababababababababab'\n\n", "import os\nimport fs\nimport base64\n\nfrom cryptography.fernet import Fernet\nfrom cryptography.hazmat.primitives import hashes\nfrom cryptography.hazmat.primitives.kdf.pbkdf2 import PBKDF2HMAC\n\nmem_fs = fs.open_fs('mem://')\nmem_fs.makedir('hidden_dir')\n\npassword = b\"password\"\nsalt = os.urandom(16)\nkdf = PBKDF2HMAC(\n    algorithm=hashes.SHA256(),\n    length=32,\n    salt=salt,\n    iterations=390000,\n)\n\nkey = base64.urlsafe_b64encode(kdf.derive(password))\nf = Fernet(key)\n\ndata = b'ab' * 10\n\nencrypted_message = f.encrypt(data)\n\nwith mem_fs.open('hidden_dir/encrypted.text', 'wb') as in_file_in_memory:\n    in_file_in_memory.write(encrypted_message)\n    in_file_in_memory.close()\n\nwith mem_fs.open('hidden_dir/encrypted.text', 'rb') as out_file_in_memory:\n    raw_data = out_file_in_memory.read()\n    decrypted_data = f.decrypt(raw_data)\n    print(decrypted_data)\n    # output\n    b'abababababababababab'\n", "import os\nimport fs\nimport base64\nimport pyzipper\nfrom zipfile import ZipFile\nfrom cryptography.fernet import Fernet\n\nmem_fs = fs.open_fs('mem://')\nmem_fs.makedir('hidden_dir')\n\n# pregenerate key\nf = Fernet(b'-6_WO-GLrlXexdSbon_fKJoVOVBh66LdYrEM0Kvcwf0=')\n\ndata = b'ab' * 10\n\nencrypted_message = f.encrypt(data)\n\nwith mem_fs.open('hidden_dir/encrypted.text', 'wb') as in_file_in_memory:\n    in_file_in_memory.write(encrypted_message)\n    in_file_in_memory.close()\n\n# This uses standard ZIP with no password, but the data\n# is encrypted \nwith mem_fs.open('hidden_dir/encrypted.text', 'rb') as out_file_in_memory:\n    raw_data = out_file_in_memory.read()\n    with ZipFile('archive.zip', mode='w') as zip_file:\n        zip_file.writestr('file.txt', raw_data)\n\n# This uses pyzipper to create a password word protected \n# encrypted file, which stores the encrypted.text.\n# overkill, because the data is already encrypted prior\nwith mem_fs.open('hidden_dir/encrypted.text', 'rb') as out_file_in_memory:\n    raw_data = out_file_in_memory.read()\n    secret_password = b'super secret password'\n    # Create encrypted password protected ZIP file in-memory\n    with pyzipper.AESZipFile('password_protected.zip',\n                             'w',\n                             compression=pyzipper.ZIP_LZMA,\n                             encryption=pyzipper.WZ_AES) as zf:\n        zf.setpassword(secret_password)\n        zf.writestr('data.txt', raw_data)\n\n"], [], [], [], ["my_set = {1, 3, 4, 5, 6}\nprint(my_set)\n\n# discard an element\n# Output: {1, 3, 5, 6}\nmy_set.discard(4)\nprint(my_set)\n\n# remove an element\n# Output: {1, 3, 5}\nmy_set.remove(6)\nprint(my_set)\n\n# discard an element\n# not present in my_set\n# Output: {1, 3, 5}\nmy_set.discard(2)\nprint(my_set)\n\n# remove an element\n# not present in my_set\n# you will get an error.\n# Output: KeyError\n\nmy_set.remove(2)\n", "my_list = list(my_set)\n"], ["deduplicated = list(set(array))\n"], ["unique_values = np.unique(array)\n"], [], ["import filecmp   \n  \n# Path of first file \nfile1 = \"/home/geeks/Desktop/gfg/data.txt\"\n  \n# Path of second file \nfile2 = \"/home/geeks/Desktop/gfg/gfg.txt\"\n   \n# Compare the os.stat() \n# signature i.e the metadata \n# of both files  \ncomp = filecmp.cmp(file1, file2) \n  \n# Print the result of comparison \nprint(comp) \n  \n# Compare the \n# contents of both files \ncomp = filecmp.cmp(file1, file2, shallow = False) \n  \n# Print the result of comparison \nprint(comp)\n"], ["def run(self, cmd):\n    completed = subprocess.run([\"powershell\", \"-Command\", cmd], capture_output=True)\n    return completed\n", "# Note this code is not written by me, link is provide to the actual owner\nfunction Write-ZipUsing7Zip([string]$FilesToZip, [string]$ZipOutputFilePath, [string]$Password, [ValidateSet('7z','zip','gzip','bzip2','tar','iso','udf')][string]$CompressionType = 'zip', [switch]$HideWindow)\n{\n    # Look for the 7zip executable.\n    $pathTo32Bit7Zip = \"C:\\Program Files (x86)\\7-Zip\\7z.exe\"\n    $pathTo64Bit7Zip = \"C:\\Program Files\\7-Zip\\7z.exe\"\n    $THIS_SCRIPTS_DIRECTORY = Split-Path $script:MyInvocation.MyCommand.Path\n    $pathToStandAloneExe = Join-Path $THIS_SCRIPTS_DIRECTORY \"7za.exe\"\n    if (Test-Path $pathTo64Bit7Zip) { $pathTo7ZipExe = $pathTo64Bit7Zip }\n    elseif (Test-Path $pathTo32Bit7Zip) { $pathTo7ZipExe = $pathTo32Bit7Zip }\n    elseif (Test-Path $pathToStandAloneExe) { $pathTo7ZipExe = $pathToStandAloneExe }\n    else { throw \"Could not find the 7-zip executable.\" }\n\n    # Delete the destination zip file if it already exists (i.e. overwrite it).\n    if (Test-Path $ZipOutputFilePath) { Remove-Item $ZipOutputFilePath -Force }\n\n    $windowStyle = \"Normal\"\n    if ($HideWindow) { $windowStyle = \"Hidden\" }\n\n    # Create the arguments to use to zip up the files.\n    # Command-line argument syntax can be found at: http://www.dotnetperls.com/7-zip-examples\n    $arguments = \"a -t$CompressionType \"\"$ZipOutputFilePath\"\" \"\"$FilesToZip\"\" -mx9\"\n    if (!([string]::IsNullOrEmpty($Password))) { $arguments += \" -p$Password\" }\n\n    # Zip up the files.\n    $p = Start-Process $pathTo7ZipExe -ArgumentList $arguments -Wait -PassThru -WindowStyle $windowStyle\n\n    # If the files were not zipped successfully.\n    if (!(($p.HasExited -eq $true) -and ($p.ExitCode -eq 0)))\n    {\n        throw \"There was a problem creating the zip file '$ZipFilePath'.\"\n    }\n}\n"], ["vowels.add(char.lower())\n"], ["def count_vowels(args: str):\n    args = set(args.lower())\n    return sum([vowel in args for vowel in 'aeiou'])\n", "count_vowels = lambda args: sum([vowel in set(args.lower()) for vowel in 'aeiou'])\n"], ["def count_vowels(word):\n    # all letters you are interested in \n    allowed = frozenset(\"aeiou\")\n    # get the len of the intersection between allowed and lower cased word\n    return len(allowed.intersection( word.lower()))\n\ntests = [(\"swEet\",1), (\"Aaa aeeE\", 2),(\"eiOuayOI j_#Ra\", 5)]\n\nfor t in tests:\n    print(t[0], \"is\", count_vowels(t[0]), \"should be\", t[1])\n", "swEet is 1 should be 1\nAaa aeeE is 2 should be 2\neiOuayOI j_#Ra is 5 should be 5\n"], [], [], ["{f\"{row}_{k}\": v for row, data in df.iterrows() for k, v in data.items()}\n"], ["from itertools import zip_longest\n\ndef zip_left(*iterables, fillvalue=None):\n    SENTINEL = object()\n    \n    for first, *others in zip_longest(*iterables, fillvalue=SENTINEL):\n        if first is SENTINEL:\n            return\n        others = [i if i is not SENTINEL else fillvalue for i in others]\n        yield (first, *others)\n\n\nprint(list(zip_left(['a', 'b', 'c'], [1, 2])))\nprint(list(zip_left(['a', 'b'], [1, 2, 3])))\n", "[('a', 1), ('b', 2), ('c', None)]\n[('a', 1), ('b', 2)]\n"], ["class CArchiveUpdateCallback : public IArchiveUpdateCallback\n{\npublic:\n    STDMETHODIMP GetProperty(UInt32 Index, PROPID PropID, PROPVARIANT* PropValue)\n    {\n        const std::wstring& FilePath = m_FileList[Index].first;\n        const std::wstring& ItemPath = m_FileList[Index].second;\n        switch (PropID)\n        {\n        case kpidPath:\n            V_VT(PropValue) = VT_BSTR;\n            V_BSTR(PropValue) = SysAllocString(ItemPath.c_str());\n            break;\n        case kpidSize:\n            V_VT(PropValue) = VT_UI8;\n            PropValue->uhVal.QuadPart = Utils::GetSize(FilePath);\n            break;\n        }\n        return S_OK;\n    }\n    STDMETHODIMP GetStream(UInt32 ItemIndex, ISequentialInStream** InStream)\n    {\n        const std::wstring& FilePath = m_FileList[ItemIndex].first;\n        HRESULT hr = CInStream::Create(FilePath, IID_ISequentialInStream, (void**)InStream);\n        return hr;\n    }\nprotected:\n    std::vector<std::pair<std::wstring, std::wstring>> m_FileList;\n};\n"], [], ["from itertools import repeat\n\ndef zip_by_first(*args, fillvalue=None):\n    # zip_by_first('ABCD', 'xy', fillvalue='-') --> Ax By C- D-\n    # zip_by_first('ABC', 'xyzw', fillvalue='-') --> Ax By Cz\n    if not args:\n        return\n    iterators = [iter(it) for it in args]\n    while True:\n        values = []\n        for i, it in enumerate(iterators):\n            try:\n                value = next(it)\n            except StopIteration:\n                if i == 0:\n                    return\n                iterators[i] = repeat(fillvalue)\n                value = fillvalue\n            values.append(value)\n        yield tuple(values)\n"], ["docker run --network=\"host\" container_id_or_name\n"], ["from itertools import chain, repeat\n\na = ['a', 'b', 'c']\nb = [1, 2]\n\nb = chain(b, repeat(None))\n\nprint(*zip(a, b))\n"], ["first = ['a', 'b', 'c']\nlast = [1, 2, 3, 4]\nif len(first) < len(last):\n    b = list(zip(first, last))\nelse:\n    b = list(zip_longest(first, last))\nprint(b)\n"], ["from itertools import islice, zip_longest\n\ndef zip_first(a, b):\n    return islice(zip_longest(a, b), len(a))\n"], ["def zip_first(a, b):\n    ai, bi = iter(a), iter(b)\n    while True:\n        try:\n            aa = next(ai)\n        except StopIteration:\n            return           \n        try:\n            bb = next(bi)\n        except StopIteration:\n            bb = None\n        yield aa, bb\n"], ["import itertools\n\ninput1 = [['a', 'b', 'c'], [1, 2]]\ninput2 = [['a', 'b'], [1, 2, 3]]\n\nzip1 = itertools.zip_longest(input1[0], input1[1][:len(input1[0])])\nzip2 = itertools.zip_longest(input2[0], input2[1][:len(input2[0])])\n\nprint(list(zip1))\nprint(list(zip2))\n", "[('a', 1), ('b', 2), ('c', None)]\n[('a', 1), ('b', 2)]\n", "import itertools\n\ndef zip_first(lists):\n    equal_lists = [l[:len(lists[0])] for l in lists]\n    return itertools.zip_longest(*equal_lists)\n"], ["from itertools import zip_longest\n\ndef zip_first(a, b):\n    z = zip_longest(a, b)\n    for i, r in zip(range(len(a)), z):\n        yield r\n"], [], ["plt.gcf().axes[-1].set_aspect(100)\nplt.gcf().axes[-1].set_box_aspect(100)\n"], [], [], [], ["docker run -p 6379:6379 -d redis:latest\n", "version: \"3.9\"\nservices:\n  django:\n    build:\n      context: .\n    image: django-chatapp-image\n    container_name: django-chatapp\n    volumes:\n      - ./:/app\n      - /virtual-env\n    ports:\n      - 8000:8000\n    environment:\n      - SOME_KEY=SOME_VAL\n    depends_on:\n      - redis\n\n  redis:\n    image: redis:alpine\n    ports:\n      - \"6379:6379\"\n    volumes:\n      - ./redisdata:/data\n", "CHANNEL_LAYERS = {\n    'default': {\n        'BACKEND': 'channels_redis.core.RedisChannelLayer',\n        'CONFIG': {\n            \"hosts\": [('redis', 6379)],\n        },\n    },\n}\n"], ["# from original_question import pd,\\\n#                               username,\\\n#                               password,\\\n#                               UserCredential,\\\n#                               File,\\\n#                               BytesIO\n\nuser_credentials = UserCredential(user_name=username, \n                                  password=password)\n\nfile_url = ('https://sample.sharepoint.com'\n            '/sites/SAMPLE/{*recursive_folders}'\n            '/sample_worksheet.xlsx') \n    ## absolute path of excel file on SharePoint\n\nexcel_file = BytesIO() \n    ## initiating binary object\n\nexcel_file_online = File.from_url(abs_url=file_url)\n    ## requesting file from SharePoint\n\nexcel_file_online = excel_file_online.with_credentials(\n    credentials=user_credentials)\n        ## validating file with accessible credentials\n\nexcel_file_online.download(file_object=excel_file).execute_query()\n    ## writing binary response of the \n    ## file request into bytes object\n", "pd.read_excel(excel_file) # -> pd.DataFrame\n", "employee_list = pd.read_excel(excel_file,\n                              sheet_name='employee_list')\n    # -> pd.DataFrame\n", "data = pd.read_excel(excel_file,\n                     sheet_name=None) # -> dict\nemployee_list = data.get('employee_list') \n    # -> [pd.DataFrame, None]\n"], ["import time\nwhile true:\n    #program\n    time.sleep(300)\n", "from datetime import timedelta\nstart_date = date_utils.parse('2021-01-01')\nend_date = datetime.datetime.now()\nwhile start_date <= end_date:\n    one_hour = timedelta(hours=1)\n    one_minute = timedelta(minutes=1)\n    start_date = start_date + datetime.timedelta(days=1)\n"], [], ["a_dict = {\"level\": [1, 2, 3, 4, 5, 8], \"conf\": [-1, 1, -1, -2], \"text\": [\"-1\", \"hel\", \"llo\", \"ai\", 0, 9]}\n\n# iterate backwards over the list keeping the indexes\nfor index, item in reversed(list(enumerate(a_dict[\"conf\"]))):\n    if item <= 0:\n        for lists in a_dict.values():\n            del lists[index]\nprint(a_dict)\n", "{'level': [2, 5, 8], 'conf': [1], 'text': ['hel', 0, 9]}\n"], ["dct = {k: [x for i, x in enumerate(v) if d['conf'][i] > 0] for k, v in d.items()}\n", ">>> dct\n{'level': [2, 3], 'conf': [1, 2], 'text': ['hel', 'llo']}\n", "d = {\"level\":[1,2,3], \"conf\":[-1,1,2], \"text\":[\"here\",\"hel\",\"llo\"]\n"], [], ["from typing import Dict, List, Any, Set\n\nd = {\"level\":[1,2,3], \"conf\":[-1,1,2], \"text\":[\"-1\", \"hel\", \"llo\"]}\n\n# First, we create a set that stores the indices which should be kept.\n# I chose a set instead of a list because it has a O(1) lookup time.\n# We only want to keep the items on indices where the value in d[\"conf\"] is greater than 0\nfiltered_indexes = {i for i, value in enumerate(d.get('conf', [])) if value > 0}\n\ndef filter_dictionary(d: Dict[str, List[Any]], filtered_indexes: Set[int]) -> Dict[str, List[Any]]:\n    filtered_dictionary = d.copy()  # We'll return a modified copy of the original dictionary\n    for key, list_values in d.items():\n        # In the next line the actual filtering for each key/value pair takes place. \n        # The original lists get overwritten with the filtered lists.\n        filtered_dictionary[key] = [value for i, value in enumerate(list_values) if i in filtered_indexes]\n    return filtered_dictionary\n\nprint(filter_dictionary(d, filtered_indexes))\n", "{'level': [2, 3], 'conf': [1, 2], 'text': ['hel', 'llo']}\n"], ["a = {\"level\":[1,2,3,4], \"conf\": [-1,1,2,-1],\"text\": [\"-1\",\"hel\",\"llo\",\"test\"]}\n\n# inefficient solution\n# for k, v in a.items():\n#     if k == \"conf\":\n#         start_search = 0\n#         to_delete = [] #it will store the index numbers of the conf that you want to delete(conf<0)\n#         for element in v:\n#             if element < 0:\n#                 to_delete.append(v.index(element,start_search))\n#                 start_search = v.index(element) + 1\n\n#more efficient and elegant solution\nto_delete = [i for i, element in enumerate(a[\"conf\"]) if element < 0]\nfor position in list(reversed(to_delete)):\n    for k, v in a.items():\n        v.pop(position)\n", ">>> a\n{'level': [2, 3], 'conf': [1, 2], 'text': ['hel', 'llo']}\n"], ["mydict = {\"level\": [1, 2, 3], \"conf\": [-1, 1, 2], 'text': [\"-1\", \"hel\", \"llo\"]}\n\nfor i, v in enumerate(mydict['conf']):\n    if v <= 0:\n        for key in mydict.keys():\n            mydict[key][i] = None\n\nfor key in mydict.keys():\n    mydict[key] = [v for v in mydict[key] if v is not None]\n\nprint(mydict)\n", "{'level': [2, 3], 'conf': [1, 2], 'text': ['hel', 'llo']}\n"], [], [], ["dct = {\"level\":[1,2,3], \"conf\":[-1,1,2], \"text\":[\"here\",\"hel\",\"llo\"]}\ndct = {k: np.array(v) for k, v in d.items()}\ndct = {k: v[a['conf'] > 0].tolist() for k, v in a.items()}\n", ">>> dct\n{'level': [2, 3], 'conf': [1, 2], 'text': ['hel', 'llo']}\n"], [], ["kept_keys = [i for i in range(len(my_dict['conf'])) if my_dict['conf'][i] > 0]\n", "{k: list(map(lambda x: x[1], filter(lambda x: x[0] in kept_keys, enumerate(my_dict[k])))) for k in my_dict}\n", "{'level': [2, 3], 'conf': [1, 2], 'text': ['hel', 'llo']}\n"], [], ["pip list | grep opencv \n", "opencv-contrib-python    4.5.3.56\nopencv-python            4.5.5.62\n", "python -m pip install --upgrade opencv-contrib-python\n"], [], [">>> from pathlib import Path\n>>> p = Path('/path/to/directory/with/files')\n>>> # Get all file names\n>>> # https://stackoverflow.com/a/65025567/4865723\n>>> set_all_files = set(filter(Path.is_file, p.glob('**/*')))\n>>> # Get all csv filenames (BUT ONLY with lower case suffix!)\n>>> set_csv_files = set(filter(Path.is_file, p.glob('**/*.csv')))\n>>> # Create a file list without csv files\n>>> set_files_to_delete = set_all_files - set_csv_files\n>>> # Iteratore on that list and delete the file\n>>> for file_name in set_files_to_delete:\n...     Path(file_name).unlink()\n"], ["import os\n\ndir_path = 'output/'\n\n[os.remove(os.path.join(dir_path, item)) for item in os.listdir(dir_path) if not item.endswith('.csv')]\n"], ["import os\ndir_path = \"path/to/the/directory/containing/files\"\ndir_list = os.listdir(dir_path)\nfor item in dir_list:\n    if not item.endswith(\".csv\"):\n        os.remove(os.path.join(dir_path, item))\n"], [], ["pip uninstall opencv-python\npip install opencv-python\n"], ["conda update conda\npip install --upgrade pip\npip3 install --upgrade pip\n\nconda create -n meta_learning_a100 python=3.9\nconda activate meta_learning_a100\n\npip3 install torch==1.9.1+cu111 torchvision==0.10.1+cu111 torchaudio==0.9.1 -f https://download.pytorch.org/whl/torch_stable.html\n", "(meta_learning_a100) [miranda9@hal-dgx diversity-for-predictive-success-of-meta-learning]$ python -c \"import uutils; uutils.torch_uu.gpu_test()\"\ndevice name: A100-SXM4-40GB\nSuccess, no Cuda errors means it worked see:\nout=tensor([[ 0.5877],\n        [-3.0269]], device='cuda:0')\n", "def gpu_test():\n    \"\"\"\n    python -c \"import uutils; uutils.torch_uu.gpu_test()\"\n    \"\"\"\n    from torch import Tensor\n\n    print(f'device name: {device_name()}')\n    x: Tensor = torch.randn(2, 4).cuda()\n    y: Tensor = torch.randn(4, 1).cuda()\n    out: Tensor = (x @ y)\n    assert out.size() == torch.Size([2, 1])\n    print(f'Success, no Cuda errors means it worked see:\\n{out=}')\n"], ["C:\\Windows\\system32>pip list |findstr opencv\nopencv-python                 4.5.2.52\nopencv-python-headless        4.5.5.62\n"], ["docker inspect -f \"{{range.NetworkSettings.Networks}}{{.IPAddress}}{{end}}\" containerId\n\ndocker inspect -f \"{{ .NetworkSettings.IPAddress }}\" containerId\n\ndocker inspect containerId | grep IPAddress\n", "docker run --network=host --name myContainer -p 8080:8080 -d myImageName\n"], [], [], [], ["y = torch.tensor([loss1, loss2, loss3])\ny.backward(gradient=torch.tensor([1.0,1.0,1.0]))\n"], [], ["C:\\Windows\\system32>pip list |findstr opencv\nopencv-python                 4.5.2.52\nopencv-python-headless        4.5.5.62\n", "pip uninstall opencv-python-headless==4.5.5.62\n", "pip install opencv-python-headless==4.5.2.52\n"], [], ["sudo easy_install pip\n", "python get-pip.py\n"], ["import requests\nfrom requests.structures import CaseInsensitiveDict\n\n# Variables\nGH_PREFIX = \"https://raw.githubusercontent.com\"\nORG = \"my-user-name\"\nREPO = \"my-repo-name\"\nBRANCH = \"main\"\nFOLDER = \"some-folder\"\nFILE = \"some-file.csv\"\nURL = GH_PREFIX + \"/\" + ORG + \"/\" + REPO + \"/\" + BRANCH + \"/\" + FOLDER + \"/\" + FILE\n\n# Headers setup\nheaders = CaseInsensitiveDict()\nheaders[\"Authorization\"] = \"token \" + GITHUB_TOKEN\n\n# Execute and view status\nresp = requests.get(URL, headers=headers)\nif resp.status_code == 200:\n   print(resp.content)\nelse:\n   print(\"Request failed!\")\n"], ["for i in s.split():\n    s = s.replace(i,i.capitalize())\nreturn s\n"], [], ["def solve(s):\n    res=\"\"\n    for i in range(len(s)):\n        if i==0:\n           if s[i].isalpha():\n               res+=s[i].capitalize()\n           else:\n               res+=s[i]\n        else:\n            if s[i].isalpha() and s[i-1]==' ':\n                res+=s[i].capitalize()\n            else:\n                res+=s[i]\n    return res \n"], [], [], [], [], ["limit = int(input(\"Limit:\"))\n\nbase = 0\nnum = 1\n\n# Each time base is less than limit, add base by num (At the first iteration num is 1), and add num by 1\nwhile base < limit:\n    base += num \n    num += 1\nprint(base)\n", ">>> Limit: 18\n21\n", ">>> Limit: 10\n10\n"], ["limit = int(input(\"Limit:\"))\nbase = 0\nnumber = 1\nwhile base < limit:\n    base += number\n    number += 1\nprint(base)\n"], ["num = int(input(\"Limit:\"))\nfor n in range(1,num):\n    s = n * (n + 1) / 2\n    if s >= num:\n        break\nprint(int(s))\n"], ["num = int(input(\"Limit:\"))\nbase = 0\nwhile base < num:\n    base += base + 1\n    print(base)\n", "num = 21\nbase = 0\n", "num = 21\nbase = 1\n", "num = 21\nbase = 1\n\nnum = 21\nbase = 1 + 1 + 1 = 3\n\nnum = 21\nbase = 3 + 3 + 1 = 7\n\nnum = 21\nbase = 7 + 7 + 1 = 15\n\nnumber = 21\nbase = 15 + 15 + 1 = 31\n", "num = int(input(\"Limit:\"))\ncounter = 0\nsumNums = 0\nwhile counter < num:\n    sumNums += counter\n    count += 1\n    print(sumNums)\n", "print(sum(range(1, num)))\n"], ["sum(range(1, num + 1))\n"], ["def foo():\n  print(foo)\n", "def foo():\n  foo = 3\n  print(foo)\n", "def foo(): pass\nfoo = 3\n"], ["def fibo(n: int) -> int:\n    if n <= 1:\n        fibo = 1\n    else:\n        fibo = fibo(n - 1) + fibo(n - 2)\n    return fibo\n"], ["def foo():\n    foo = 5\n    print(foo + 5)\n", "def foo():\n    global foo\n    foo = 5\n    print(foo + 5)\n\nfoo()  # OK, prints 10\n", "def foo():\n    global foo\n    foo = 5\n    print(foo + 5)\n\nfoo()  # OK, prints 10 (and incidentally assigns a new value to foo)\nfoo()  # Raises TypeError: 'int' object is not callable\n"], [], [], ["    model_config = { \"class_name\": \"Model\",\n                     \"config\":model.get_config()\n                     }\n\n    with open(os.path.join(dump_model_dir, \"model_config.yaml\"), \"w\") as file:\n        file.write(model.to_yaml())\n\n    model.save_weights(os.path.join(dump_model_dir, \"model_weights.hdf5\"))\n", "*** model_config_tf22.yaml  2021-01-07 15:00:03.042791215 +0100\n--- model_config_tf23.yaml  2021-01-07 14:59:56.426791386 +0100\n***************\n*** 1,5 ****\n  backend: tensorflow\n! class_name: Model\n  config:\n    input_layers:\n    - - input_1\n--- 1,5 ----\n  backend: tensorflow\n! class_name: Functional\n  config:\n    input_layers:\n    - - input_1\n***************\n*** 34,39 ****\n--- 34,40 ----\n        - 1\n        dtype: float32\n        filters: 128\n+       groups: 1\n        kernel_constraint: null\n        kernel_initializer:\n          class_name: RandomUniform\n***************\n*** 343,346 ****\n    - - Conv2D_5_37\n      - 0\n      - 0\n! keras_version: 2.3.0-tf\n--- 351,354 ----\n    - - Conv2D_5_37\n      - 0\n      - 0\n! keras_version: 2.4.0\n"], [], [], ["cd /usr/lib/python3/dist-packages/gi/\nsudo ln -s _gi.so _gi.cpython-38-x86_64-linux-gnu.so\n"], ["...\n  redis:\n    image: redis:latest\n    ports:\n      - \"6379:6379\"\n    volumes:\n      - 'redisdata:/data'\n....    \n\n", "CHANNEL_LAYERS = {\n    'default': {\n        'BACKEND': 'channels_redis.core.RedisChannelLayer',\n        'CONFIG': {\n            \"hosts\": [('redis', 6379)],\n        },\n    },\n}\n"], ["4.565001290757209e-06\n"], ["```\nchessboard = {'1a': 'bking', '2a': 'bqueen', '3a': 'brook', '4a': 'brook',\n              '5a': 'bknight', '6a': 'bknight', '7a': 'bbishop', '8a': 'bbishop',\n              '1b': 'bpawn', '2b': 'bpawn', '3b': 'bpawn', '4b': 'bpawn',\n              '5b': 'bpawn', '6b': 'bpawn', '7b': 'bpawn', '8b': 'bpawn',\n              '1c': 'wking', '2c': 'wqueen', '3c': 'wrook', '4c': 'wrook',\n              '5c': 'wbishop', '6c': 'wbishop', '7c': 'wknight', '8c': 'wknight',\n              '1e': 'wpawn', '2e': 'wpawn', '3e': 'wpawn', '4e': 'wpawn',\n              '5e': 'wpawn', '6e': 'wpawn', '7e': 'wpawn', '8e': 'wpawn',\n              '1f': '', '2f': '', '3f': '', '4f': '', '5f': '', '6f': '', '7f': '', '8f': '',\n              '1g': '', '2g': '', '3g': '', '4g': '', '5g': '', '6g': '', '7g': '', '8g': '',\n              '1h': '', '2h': '', '3h': '', '4h': '', '5h': '', '6h': '', '7h': '', '8h': '', }\n\n\ndef check_location(board):\n    for location in board.keys():\n        row = int(location[:1])\n        column = location[1:]\n        if not ((1 <= row <= 8) and ('a' <= column <= \"h\")):\n            print(f\"Invalid to have {board[location]} at postion {location}\")\n            return False\n\n\ndef check_piece_count(board):\n    pieces = ['wpawn', 'bpawn', 'wknight', 'bknight', 'bbishop',\n              'wbishop', 'wrook', 'brook', 'wqueen', 'bqueen', 'wking', 'bking']\n    max_pieces = [8, 8, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1]\n\n    for piece in zip(pieces, max_pieces, board.keys()):\n        if sum(value == piece[0] for value in board.values()) > piece[1]:\n            return False\n    return True\n\n\nif check_location(chessboard) == None and check_piece_count(chessboard) == True:\n    print(True)\nelse:\n    print(False)\n"], [], ["timeit.timeit(\"12\") # works\ntimeit.timeit(3) # does not\n", "timeit.timeit(lambda: add(1,2))\n"], ["    import json, requests, urllib, io\n\n    user='my_github_username'\n    pao='my_pao'\n\n    github_session = requests.Session()\n    github_session.auth = (user, pao)\n\n    # providing raw url to download csv from github\n    csv_url = 'https://raw.githubusercontent.com/user/repo/master/csv_name.csv'\n\n    download = github_session.get(csv_url).content\n    downloaded_csv = pandas.read_csv(io.StringIO(download.decode('utf-8')), error_bad_lines=False)\n"], [], ["def lemma_conversion(sent):\n    carrier_str = str()\n    for token in sent:\n        carrier_str = carrier_str + token.lemma_ + ' '\n    return (carrier_str)\n", "# this function replaces the original form of the word in the original sentence with\n# the lemma form. This preserves the spacing with regard to punctuation.\n\ndef nice_lemma_sent(input_sent):\n    j = 0\n    lemma_sent = input_sent.text\n    offset_counter = 0\n    for token in input_sent:\n        j += 1\n        # the .idx value for the characters in the extracted sentences is based on the whole\n        # document. This first if statement determines the .idx for the first token in each \n        # sentence. this is used for adjusting the offset when doing the replacement of the \n        # original word with the lemma\n\n        if j == 1:\n            first_character_position = token.idx\n\n        # this identifies those tokens where the lemma is different. it then gets the values \n        # for the  words length and position so that slicing operations will cut them out \n        # and replace them with the lemma\n        if token.text != token.lemma_:\n            start_of_word = token.idx + offset_counter - first_character_position\n            len_word = len(token.text)\n            end_of_word = start_of_word + len_word\n            len_lemma = len(token.lemma_)\n\n            \n            # substitution of the first word in the sentence if the lemma form is \n            # different from the original form\n            if token.idx == first_character_position:\n                residual_sent_start_position = len_word \n                lemma_sent = token.lemma_ + lemma_sent[residual_sent_start_position:]\n\n            # substitution of subsequent words in the sentence if they are different\n            # from the original form\n            else:\n                front_sent_end = start_of_word\n                residual_sent_start = end_of_word\n                lemma_sent = lemma_sent[0:front_sent_end] + token.lemma_ + \\\n                             lemma_sent[residual_sent_start:]\n\n            offset_counter = len_lemma - len_word + offset_counter\n\n    return (lemma_sent) \n"], [], [], [], [], [], [">>> {f'{row}_{k}':v for row, col in df.iterrows() for k,v in list(col.items())[1:]}\n\n{'apple_T1': 5,\n 'apple_T2': 1.0,\n 'pear_T1': 2,\n 'pear_T2': 1.5,\n 'banana_T1': 10,\n 'banana_T2': 12.0}\n"], ["df = pd.DataFrame([[5, 1], [2, 1.5], [10, 12]], \n                  columns=['T1', 'T2'], \n                  index=['apple', 'pear', 'banana'])\nnew_dict = {}\nfor i in df.index:\n    for j in df.columns:\n        new_dict[i + '_' + j] = df.loc[i, j]\nprint(new_dict)\n", "{'apple_T1': 5,\n 'apple_T2': 1.0,\n 'pear_T1': 2,\n 'pear_T2': 1.5,\n 'banana_T1': 10,\n 'banana_T2': 12.0}\n"], ["df = pd.DataFrame(\n    columns=[\"T1\", \"T2\"], \n    data=[[5,1], [2, 1.5], [10, 12]], \n    index=[\"apple\", \"pear\", \"banana\"]\n)\n", "d = df.to_dict(orient='index')\nresult = {f\"{k1}_{k2}\": v for k1 in d for k2, v in d[k1].items()}\n", "{'apple_T1': 5,\n 'apple_T2': 1,\n 'banana_T1': 10,\n 'banana_T2': 12,\n 'pear_T1': 2,\n 'pear_T2': 1.5}\n"], ["import pandas as pd\n\ndata = [[5, 1], [2, 1.5], [10, 12]]\ndf = pd.DataFrame(data=data, columns=[\"T1\", \"T2\"], index=[\"apple\", \"pear\", \"banana\"])\n\nresult = { f\"{kout}_{kin}\" : value for kout, d in df.to_dict(\"index\").items() for kin, value in d.items()}\nprint(result)\n", "{'apple_T1': 5, 'apple_T2': 1.0, 'pear_T1': 2, 'pear_T2': 1.5, 'banana_T1': 10, 'banana_T2': 12.0}\n"], ["DEBUG=0\nSECRET_KEY=foo\nDJANGO_ALLOWED_HOSTS=\"localhost 127.0.0.1 192.168.2.253\"\nDJANGO_SETTINGS_MODULE=\"djdict.settings_prod\"\n\n\nSQL_ENGINE=\"django.db.backends.postgresql\"\n\n# ...\n"], [], ["arch -x86_64 /bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\"\n", "arch -x86_64 brew install openssl readline sqlite3 xz zlib\n", "arch -x86_64 brew install pyenv\n", "echo 'eval \"$(/usr/local/bin/brew shellenv)\"' >> ~/.zshrc\n", "export LDFLAGS=\"-L/usr/local/opt/zlib/lib\"\nexport CPPFLAGS=\"-I/usr/local/opt/zlib/include\"\nexport LDFLAGS=\"-L/usr/local/opt/openssl@3/lib\"\nexport CPPFLAGS=\"-I/usr/local/opt/openssl@3/include\"\n", "arch -x86_64 pyenv install --patch 3.6.15 <<(curl -sSL https://github.com/python/cpython/commit/8ea6353.patch\\?full_index\\=1)\n", "pyenv shell 3.6.15\n", "pyenv which python3\n"], ["> print(\"Num GPU: \", len(tf.config.list_physical_devices(\"GPU\")))\n> \n> print(tf.test.is_gpu_available()) print(tf.test.is_built_with_cuda())\n\n\n\n> OUTPUT \n> Num GPU:  1 \n> WARNING:tensorflow:From <ipython-input-2-8748de971110>:3:\n> is_gpu_available (from tensorflow.python.framework.test_util) is\n> deprecated and will be removed in a future version. Instructions for\n> updating: Use `tf.config.list_physical_devices('GPU')` instead. \n> True\n> True\n"], ["pip uninstall opencv-python\n", "pip install opencv-python\n"], [], [], ["sudo apt-get install portaudio19-dev\npip install pyaudio\n"], ["left = tuple(c[c[:, :, 0].argmin()][0])\nright = tuple(c[c[:, :, 0].argmax()][0])\ntop = tuple(c[c[:, :, 1].argmin()][0])\nbottom = tuple(c[c[:, :, 1].argmax()][0])\n", "import cv2\nimport numpy as np\n\n# Load image, grayscale, Gaussian blur, threshold\nimage = cv2.imread('1.png')\ngray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\nblur = cv2.GaussianBlur(gray, (3,3), 0)\nthresh = cv2.threshold(blur, 220, 255, cv2.THRESH_BINARY_INV)[1]\n\n# Find contours\ncnts = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\ncnts = cnts[0] if len(cnts) == 2 else cnts[1]\nc = max(cnts, key=cv2.contourArea)\n\n# Obtain outer coordinates\nleft = tuple(c[c[:, :, 0].argmin()][0])\nright = tuple(c[c[:, :, 0].argmax()][0])\ntop = tuple(c[c[:, :, 1].argmin()][0])\nbottom = tuple(c[c[:, :, 1].argmax()][0])\n\n# Draw dots onto image\ncv2.drawContours(image, [c], -1, (36, 255, 12), 2)\ncv2.circle(image, left, 8, (0, 50, 255), -1)\ncv2.circle(image, right, 8, (0, 255, 255), -1)\ncv2.circle(image, top, 8, (255, 50, 0), -1)\ncv2.circle(image, bottom, 8, (255, 255, 0), -1)\n\nprint('left: {}'.format(left))\nprint('right: {}'.format(right))\nprint('top: {}'.format(top))\nprint('bottom: {}'.format(bottom))\ncv2.imshow('thresh', thresh)\ncv2.imshow('image', image)\ncv2.waitKey()\n"], [], [], ["web: gunicorn -w 3 -k uvicorn.workers.UvicornWorker main:app\n"], [], [], [], ["import cv2\nimport numpy as np\n\ndef process(img):\n    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n    img_blur = cv2.GaussianBlur(img_gray, (1, 1), 1)\n    img_canny = cv2.Canny(img_blur, 350, 150)\n    kernel = np.ones((3, 3))\n    img_dilate = cv2.dilate(img_canny, kernel, iterations=2)\n    return cv2.erode(img_dilate, kernel, iterations=1)\n\ndef get_pts(img):\n    contours, _ = cv2.findContours(img, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n    cnt = max(contours, key=cv2.contourArea)\n    peri = cv2.arcLength(cnt, True)\n    return cv2.approxPolyDP(cv2.convexHull(cnt), 0.04 * peri, True)\n\nfiles = [\"1.jpg\", \"2.jpg\", \"3.jpg\"]\nwidth, height = 350, 450\npts2 = np.float32([[width, 0], [0, 0], [width, height], [0, height]])\n\nfor file in files:\n    img = cv2.imread(file)\n    pts1 = get_pts(process(img)).squeeze()\n    pts1 = np.float32(pts1[np.lexsort(pts1.T)])\n    matrix = cv2.getPerspectiveTransform(pts1, pts2)\n    out = cv2.warpPerspective(img, matrix, (width, height))[5:-5, 5:-5]\n    cv2.imshow(file, out)\n\ncv2.waitKey(0)\ncv2.destroyAllWindows()\n", "import cv2\nimport numpy as np\n", "def process(img):\n    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n    img_blur = cv2.GaussianBlur(img_gray, (1, 1), 1)\n    img_canny = cv2.Canny(img_blur, 350, 150)\n    kernel = np.ones((3, 3))\n    img_dilate = cv2.dilate(img_canny, kernel, iterations=2)\n    return cv2.erode(img_dilate, kernel, iterations=1)\n", "def get_pts(img):\n    contours, _ = cv2.findContours(img, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n    cnt = max(contours, key=cv2.contourArea)\n    peri = cv2.arcLength(cnt, True)\n    return cv2.approxPolyDP(cv2.convexHull(cnt), 0.04 * peri, True)\n", "files = [\"1.jpg\", \"2.jpg\", \"3.jpg\"]\nwidth, height = 350, 450\n", "pts2 = np.float32([[width, 0], [0, 0], [width, height], [0, height]])\n", "for file in files:\n    img = cv2.imread(file)\n    pts1 = get_pts(process(img)).squeeze()\n    pts1 = np.float32(pts1[np.lexsort(pts1.T)])\n    matrix = cv2.getPerspectiveTransform(pts1, pts2)\n    out = cv2.warpPerspective(img, matrix, (width, height))[5:-5, 5:-5]\n    cv2.imshow(file, out)\n", "cv2.waitKey(0)\ncv2.destroyAllWindows()\n"], [], ["# Current stable release for CPU-only\npip install tensorflow\n", "conda create --n <our_env_name> pip\nconda activate <your_env_name>\npip install tensorflow\n"], ["conda install tensorflow-gpu=2.1\npip install tensorflow-gpu==2.3.1\n"], ["conda create --name tftest python=3.7 -y  &&  conda activate tftest\nconda install ipython tensorflow-gpu==2.4.1 -y\n", "The following packages will be downloaded:\n\n    package                    |            build\n    ---------------------------|-----------------\n    _tflow_select-2.1.0        |              gpu           2 KB\n    absl-py-0.13.0             |   py37h06a4308_0         173 KB\n    aiohttp-3.7.4              |   py37h27cfd23_1         536 KB\n    astor-0.8.1                |   py37h06a4308_0          47 KB\n    astunparse-1.6.3           |             py_0          17 KB\n    async-timeout-3.0.1        |   py37h06a4308_0          13 KB\n    attrs-21.2.0               |     pyhd3eb1b0_0          46 KB\n    backcall-0.2.0             |     pyhd3eb1b0_0          13 KB\n    blas-1.0                   |              mkl           6 KB\n    blinker-1.4                |   py37h06a4308_0          23 KB\n    brotlipy-0.7.0             |py37h27cfd23_1003         320 KB\n    c-ares-1.17.1              |       h27cfd23_0         108 KB\n    cachetools-4.2.2           |     pyhd3eb1b0_0          13 KB\n    cffi-1.14.6                |   py37h400218f_0         223 KB\n    chardet-3.0.4              |py37h06a4308_1003         175 KB\n    charset-normalizer-2.0.4   |     pyhd3eb1b0_0          35 KB\n    click-8.0.1                |     pyhd3eb1b0_0          79 KB\n    coverage-5.5               |   py37h27cfd23_2         254 KB\n    cryptography-3.4.7         |   py37hd23ed53_0         904 KB\n    cudatoolkit-10.1.243       |       h6bb024c_0       347.4 MB\n    cudnn-7.6.5                |       cuda10.1_0       179.9 MB\n    cupti-10.1.168             |                0         1.4 MB\n    cython-0.29.24             |   py37h295c915_0         1.9 MB\n    decorator-5.0.9            |     pyhd3eb1b0_0          12 KB\n    gast-0.4.0                 |     pyhd3eb1b0_0          13 KB\n    google-auth-1.33.0         |     pyhd3eb1b0_0          80 KB\n    google-auth-oauthlib-0.4.4 |     pyhd3eb1b0_0          18 KB\n    google-pasta-0.2.0         |             py_0          46 KB\n    grpcio-1.36.1              |   py37h2157cd5_1         1.9 MB\n    h5py-2.10.0                |   py37hd6299e0_1         902 KB\n    hdf5-1.10.6                |       hb1b8bf9_0         3.7 MB\n    idna-3.2                   |     pyhd3eb1b0_0          48 KB\n    importlib-metadata-3.10.0  |   py37h06a4308_0          33 KB\n    intel-openmp-2021.3.0      |    h06a4308_3350         1.4 MB\n    ipython-7.26.0             |   py37hb070fc8_0        1005 KB\n    ipython_genutils-0.2.0     |     pyhd3eb1b0_1          27 KB\n    jedi-0.18.0                |   py37h06a4308_1         911 KB\n    keras-preprocessing-1.1.2  |     pyhd3eb1b0_0          35 KB\n    libgfortran-ng-7.5.0       |      ha8ba4b0_17          22 KB\n    libgfortran4-7.5.0         |      ha8ba4b0_17         995 KB\n    libprotobuf-3.17.2         |       h4ff587b_1         2.0 MB\n    markdown-3.3.4             |   py37h06a4308_0         127 KB\n    matplotlib-inline-0.1.2    |     pyhd3eb1b0_2          12 KB\n    mkl-2021.3.0               |     h06a4308_520       141.2 MB\n    mkl-service-2.4.0          |   py37h7f8727e_0          56 KB\n    mkl_fft-1.3.0              |   py37h42c9631_2         170 KB\n    mkl_random-1.2.2           |   py37h51133e4_0         287 KB\n    multidict-5.1.0            |   py37h27cfd23_2          66 KB\n    numpy-1.20.3               |   py37hf144106_0          23 KB\n    numpy-base-1.20.3          |   py37h74d4b33_0         4.5 MB\n    oauthlib-3.1.1             |     pyhd3eb1b0_0          90 KB\n    opt_einsum-3.3.0           |     pyhd3eb1b0_1          57 KB\n    parso-0.8.2                |     pyhd3eb1b0_0          69 KB\n    pexpect-4.8.0              |     pyhd3eb1b0_3          53 KB\n    pickleshare-0.7.5          |  pyhd3eb1b0_1003          13 KB\n    prompt-toolkit-3.0.17      |     pyh06a4308_0         256 KB\n    protobuf-3.17.2            |   py37h295c915_0         319 KB\n    ptyprocess-0.7.0           |     pyhd3eb1b0_2          17 KB\n    pyasn1-0.4.8               |             py_0          57 KB\n    pyasn1-modules-0.2.8       |             py_0          72 KB\n    pygments-2.10.0            |     pyhd3eb1b0_0         725 KB\n    pyjwt-2.1.0                |   py37h06a4308_0          32 KB\n    pyopenssl-20.0.1           |     pyhd3eb1b0_1          49 KB\n    pysocks-1.7.1              |           py37_1          27 KB\n    python-flatbuffers-1.12    |     pyhd3eb1b0_0          24 KB\n    requests-2.26.0            |     pyhd3eb1b0_0          59 KB\n    requests-oauthlib-1.3.0    |             py_0          23 KB\n    rsa-4.7.2                  |     pyhd3eb1b0_1          28 KB\n    scipy-1.6.2                |   py37had2a1c9_1        15.5 MB\n    six-1.16.0                 |     pyhd3eb1b0_0          18 KB\n    tensorboard-2.4.0          |     pyhc547734_0         8.8 MB\n    tensorboard-plugin-wit-1.6.0|             py_0         630 KB\n    tensorflow-2.4.1           |gpu_py37ha2e99fa_0           4 KB\n    tensorflow-base-2.4.1      |gpu_py37h29c2da4_0       195.2 MB\n    tensorflow-estimator-2.5.0 |     pyh7b7c402_0         267 KB\n    tensorflow-gpu-2.4.1       |       h30adc30_0           3 KB\n    termcolor-1.1.0            |   py37h06a4308_1           9 KB\n    traitlets-5.0.5            |     pyhd3eb1b0_0          81 KB\n    typing-extensions-3.10.0.0 |       hd3eb1b0_0           8 KB\n    typing_extensions-3.10.0.0 |     pyh06a4308_0          27 KB\n    urllib3-1.26.6             |     pyhd3eb1b0_1         112 KB\n    wcwidth-0.2.5              |             py_0          29 KB\n    werkzeug-1.0.1             |     pyhd3eb1b0_0         239 KB\n    wrapt-1.12.1               |   py37h7b6447c_1          49 KB\n    yarl-1.6.3                 |   py37h27cfd23_0         133 KB\n    zipp-3.5.0                 |     pyhd3eb1b0_0          13 KB\n    ------------------------------------------------------------\n                                           Total:       915.9 MB\n", "In [1]: import tensorflow as tf\n2021-08-29 12:26:36.582384: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n\nIn [2]: tf.config.list_physical_devices('GPU')\n2021-08-29 12:26:48.676151: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n2021-08-29 12:26:48.679894: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n2021-08-29 12:26:48.975002: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \npciBusID: 0000:04:00.0 name: Tesla V100-PCIE-32GB computeCapability: 7.0\ncoreClock: 1.38GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s\n2021-08-29 12:26:48.979341: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: \npciBusID: 0000:08:00.0 name: Tesla V100-PCIE-32GB computeCapability: 7.0\ncoreClock: 1.38GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s\n2021-08-29 12:26:48.981747: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 2 with properties: \npciBusID: 0000:09:00.0 name: Tesla V100-PCIE-32GB computeCapability: 7.0\ncoreClock: 1.38GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s\n2021-08-29 12:26:48.990002: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 3 with properties: \npciBusID: 0000:85:00.0 name: Tesla V100-PCIE-32GB computeCapability: 7.0\ncoreClock: 1.38GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s\n2021-08-29 12:26:48.992488: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 4 with properties: \npciBusID: 0000:89:00.0 name: Tesla V100-PCIE-32GB computeCapability: 7.0\ncoreClock: 1.38GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s\n2021-08-29 12:26:48.992523: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n2021-08-29 12:26:49.312793: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n2021-08-29 12:26:49.312907: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n2021-08-29 12:26:49.388961: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n2021-08-29 12:26:49.413946: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n2021-08-29 12:26:49.535055: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n2021-08-29 12:26:49.563142: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n2021-08-29 12:26:50.009291: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n2021-08-29 12:26:50.051301: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1, 2, 3, 4\nOut[2]: \n[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'),\n PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU'),\n PhysicalDevice(name='/physical_device:GPU:2', device_type='GPU'),\n PhysicalDevice(name='/physical_device:GPU:3', device_type='GPU'),\n PhysicalDevice(name='/physical_device:GPU:4', device_type='GPU')]\n\nIn [3]: tf.test.is_built_with_cuda()\nOut[3]: True\n"], [], [" - Read the input\n - Pad the image with white so that the lines can be extended until intersection\n - Threshold on black to extract the lines\n - Apply morphology close to try to connect the lines somewhat\n - Get the contours and filter on area drawing the contours on a black background\n - Apply morphology close again to fill the line centers\n - Skeletonize to thin the lines\n - Get the Hough lines and draw them as white on a black background\n - Floodfill the center of the rectangle of lines to fill with mid-gray. Then convert that image to binary so that the gray becomes white and all else is black.\n - Get the coordinates of all non-black pixels and then from the coordinates get the rotated rectangle.\n - Use the angle and center of the rotated rectangle to unrotated both the padded image and this mask image via an Affine warp\n - (Alternately, get the four corners of the rotated rectangle from the mask and then project that to the padded input domain using the affine matrix)\n- Get the coordinates of all non-black pixels in the unrotated mask and compute its rotated rectangle.\n - Get the bounding box of the (un-)rotated rectangle \n - Use those bounds to crop the padded image\n - Save the results\n\nimport cv2\nimport numpy as np\nimport math\nfrom skimage.morphology import skeletonize\n\n# read image\nimg = cv2.imread('passport.jpg')\nht, wd = img.shape[:2]\n\n# pad image with white by 20% on all sides\npadpct = 20\nxpad = int(wd*padpct/100)\nypad = int(ht*padpct/100)\nimgpad = cv2.copyMakeBorder(img, ypad, ypad, xpad, xpad, borderType=cv2.BORDER_CONSTANT, value=(255,255,255))\nht2, wd2 = imgpad.shape[:2]\n\n# threshold on black\nlow = (0,0,0)\nhigh = (20,20,20)\n\n# threshold\nthresh = cv2.inRange(imgpad, low, high)\n\n# apply morphology to connect the white lines\nkernel = np.ones((5,5), np.uint8)\nmorph = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\n\n# get contours\ncontours = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\ncontours = contours[0] if len(contours) == 2 else contours[1]\n\n# filter on area\nmask = np.zeros((ht2,wd2), dtype=np.uint8)\nfor cntr in contours:\n    area = cv2.contourArea(cntr)\n    if area > 20:\n        cv2.drawContours(mask, [cntr], 0, 255, 1)\n\n# apply morphology to connect the white lines and divide by 255 to make image in range 0 to 1\nkernel = np.ones((5,5), np.uint8)\nbmask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)/255\n\n# apply thinning (skeletonizing)\nskeleton = skeletonize(bmask)\nskeleton = (255*skeleton).clip(0,255).astype(np.uint8)\n\n# get hough lines\nline_img = np.zeros_like(imgpad, dtype=np.uint8)\nlines= cv2.HoughLines(skeleton, 1, math.pi/180.0, 90, np.array([]), 0, 0)\na,b,c = lines.shape\nfor i in range(a):\n    rho = lines[i][0][0]\n    theta = lines[i][0][1]\n    a = math.cos(theta)\n    b = math.sin(theta)\n    x0, y0 = a*rho, b*rho\n    pt1 = ( int(x0+1000*(-b)), int(y0+1000*(a)) )\n    pt2 = ( int(x0-1000*(-b)), int(y0-1000*(a)) )\n    cv2.line(line_img, pt1, pt2, (255, 255, 255), 1)\n\n# floodfill with mid-gray (128)\nxcent = int(wd2/2)\nycent = int(ht2/2)\nffmask = np.zeros((ht2+2, wd2+2), np.uint8)\nmask2 = line_img.copy()\nmask2 = cv2.floodFill(mask2, ffmask, (xcent,ycent), (128,128,128))[1]\n\n# convert mask2 to binary\nmask2[mask2 != 128] = 0\nmask2[mask2 == 128] = 255\nmask2 = mask2[:,:,0]\n\n# get coordinates of all non-zero pixels\n# NOTE: must transpose since numpy coords are y,x and opencv uses x,y\ncoords = np.column_stack(np.where(mask2.transpose() > 0))\n\n# get rotated rectangle from coords\nrotrect = cv2.minAreaRect(coords)\n(center), (width,height), angle = rotrect\n# from https://www.pyimagesearch.com/2017/02/20/text-skew-correction-opencv-python/\n# the `cv2.minAreaRect` function returns values in the\n# range [-90, 0); as the rectangle rotates clockwise the\n# returned angle trends to 0 -- in this special case we\n# need to add 90 degrees to the angle\nif angle < -45:\n    angle = -(90 + angle)\n \n# otherwise, just take the inverse of the angle to make\n# it positive\nelse:\n    angle = -angle\n\n# compute correction rotation\nrotation = -angle - 90\n\n# compute rotation affine matrix\nM = cv2.getRotationMatrix2D(center, rotation, scale=1.0)\n    \n# unrotate imgpad and mask2 using affine warp\nrot_img = cv2.warpAffine(imgpad, M, (wd2, ht2), flags=cv2.INTER_CUBIC, borderValue=(0,0,0))\nrot_mask2= cv2.warpAffine(mask2, M, (wd2, ht2), flags=cv2.INTER_CUBIC, borderValue=(0,0,0))\n\n# get coordinates of all non-zero pixels\n# NOTE: must transpose since numpy coords are y,x and opencv uses x,y\ncoords2 = np.column_stack(np.where(rot_mask2.transpose() > 0))\n\n# get bounding box\nx,y,w,h = cv2.boundingRect(coords2)\nprint(x,y,w,h)\n\n# crop rot_img\nresult = rot_img[y:y+h, x:x+w]\n\n# save resulting images\ncv2.imwrite('passport_pad.jpg',imgpad)\ncv2.imwrite('passport_thresh.jpg',thresh)\ncv2.imwrite('passport_morph.jpg',morph)\ncv2.imwrite('passport_mask.jpg',mask)\ncv2.imwrite('passport_skeleton.jpg',skeleton)\ncv2.imwrite('passport_line_img.jpg',line_img)\ncv2.imwrite('passport_mask2.jpg',mask2)\ncv2.imwrite('passport_rot_img.jpg',rot_img)\ncv2.imwrite('passport_rot_mask2.jpg',rot_mask2)\ncv2.imwrite('passport_result.jpg',result)\n\n# show thresh and result    \ncv2.imshow(\"imgpad\", imgpad)\ncv2.imshow(\"thresh\", thresh)\ncv2.imshow(\"morph\", morph)\ncv2.imshow(\"mask\", mask)\ncv2.imshow(\"skeleton\", skeleton)\ncv2.imshow(\"line_img\", line_img)\ncv2.imshow(\"mask2\", mask2)\ncv2.imshow(\"rot_img\", rot_img)\ncv2.imshow(\"rot_mask2\", rot_mask2)\ncv2.imshow(\"result\", result)\ncv2.waitKey(0)\ncv2.destroyAllWindows()\n"], [], ["   prediction = house_model([7.0])\n   print(prediction*100)\n"], ["# imports \nimport numpy as np\nimport cv2\n\nwidth = height = 600 # normal passport photo size in pixels\n\n# global variable that will update the points when we clicked on the image\npt1 = []\npt2 = np.float32([[0, 0], [height, 0], [0, width], [height, width]])\ndef mouseEvent(event, x, y, flags, param):\n    if event == cv2.EVENT_LBUTTONDOWN:\n        global pt1\n        if len(pt1) == 4:\n            pt1 = []\n        else:\n            pt1.append([x, y])\n\nwhile 1:\n    image = cv2.imread(\"img.jpg\", cv2.IMREAD_UNCHANGED)\n    cv2.imshow(\"Original Image\", image)\n    cv2.setMouseCallback(\"Original Image\", mouseEvent)\n    if cv2.waitKey(1) & 0xFF == ord('q'):\n        break\n    if len(pt1) == 4:\n        break\n", "------------------\n| (a)          (b)|\n|                 |\n|                 |\n|                 |\n|                 |\n|                 |\n| (c)          (d)|\n-------------------\n"], ["from spacy.lang.en import English\nnlp = English() # you probably don't need to load whole lang model for this\ntokenizer = nlp.tokenizer\ntokens = tokenizer(\"Hi this is my dog.\")\n\nmodified = \"\"\nfor token in tokens:\n    if token.text != \"dog\":\n        modified += token.text_with_ws\n    else:\n        modified += \"Simba\"\n        modified += token.whitespace_\n"], ["import boto3\nimport threading\nimport time\nfrom queue import LifoQueue, Empty\n\n\nclass DDBTableCleaner(object):\n\n    def __init__(self, table_name, threads_limit=32):\n        self._queue = LifoQueue()\n        self._threads = dict()\n        self._cnt = 0\n        self._done = False\n        self._threads_limit = threads_limit\n        dynamodb_client = boto3.resource('dynamodb')\n        self.table = dynamodb_client.Table(table_name)\n\n    def run(self):\n        for i in range(self._threads_limit):\n            thread_name = f'worker_thread_{i}'\n            self._threads[thread_name] = threading.Thread(\n                target=self.worker_thread,\n                name=thread_name,\n            )\n            self._threads[thread_name].start()\n        self.queue_replenish()\n        while self._queue.qsize() > 0:\n            print(f'items processed: ({self._cnt})')\n            time.sleep(1)\n        self._done = True\n        for thread in self._threads.values():\n            if thread.is_alive():\n                thread.join()\n        print(f'items processed: ({self._cnt})')\n\n    def queue_replenish(self):\n        table_key_names = [key.get('AttributeName') for key in self.table.key_schema]\n        projection_expression = ', '.join('#' + key for key in table_key_names)\n        expression_attr_names = {'#' + key: key for key in table_key_names}\n        page = self.table.scan(\n            ProjectionExpression=projection_expression,\n            ExpressionAttributeNames=expression_attr_names\n        )\n        while page['Count'] > 0:\n            for item in page['Items']:\n                self._queue.put(item)\n            if 'LastEvaluatedKey' in page:\n                page = self.table.scan(\n                    ProjectionExpression=projection_expression,\n                    ExpressionAttributeNames=expression_attr_names,\n                    ExclusiveStartKey=page['LastEvaluatedKey']\n                )\n            else:\n                break\n\n    def worker_thread(self):\n        thr_name = threading.current_thread().name\n        print(f'[{thr_name}] thread started')\n        with self.table.batch_writer() as batch:\n            while not self._done:\n                try:\n                    item = self._queue.get_nowait()\n                except Empty:\n                    time.sleep(1)\n                else:\n                    try:\n                        batch.delete_item(Key=item)\n                        self._cnt += 1\n                    except Exception as e:\n                        print(e)\n        print(f'[{thr_name}] thread completed')\n\n\nif __name__ == '__main__':\n\n    table = '...'\n    cleaner = DDBTableCleaner(table, threads_limit=10)\n    cleaner.run()\n\n\n"], [], [], ["1a has a correct value of wrook\n7h has broken value of bpawn      \n7g has a correct value of bpawn     \n1b has broken value of wknight    \nFigure bpawn is in a bad position.  \nFigure wknight is in a bad position.\n"], ["pip3 install torch==1.9.0+cu111 torchvision==0.10.0+cu111 torchaudio==0.9.0 -f https://download.pytorch.org/whl/torch_stable.html\n"], [], [], [], ["brew reinstall zlib bzip2\n", "sudo rm -rf /Library/Developer/CommandLineTools\nxcode-select --install\n", "nano ~/.zshrc or nano ~/.bashrc\n", "export PATH=\"$HOME/.pyenv/bin:$PATH\"\nexport PATH=\"/usr/local/bin:$PATH\"\n\neval \"$(pyenv init -)\"\neval \"$(pyenv virtualenv-init -)\"\nexport LDFLAGS=\"-L/usr/local/opt/zlib/lib -L/usr/local/opt/bzip2/lib\"\nexport CPPFLAGS=\"-I/usr/local/opt/zlib/include -I/usr/local/opt/bzip2/include\"\n", ". ~/.zshrc or . ~/.bashrc\n", "CFLAGS=\"-I$(brew --prefix openssl)/include -I$(brew --prefix bzip2)/include -I$(brew --prefix readline)/include -I$(xcrun --show-sdk-path)/usr/include\" LDFLAGS=\"-L$(brew --prefix openssl)/lib -L$(brew --prefix readline)/lib -L$(brew --prefix zlib)/lib -L$(brew --prefix bzip2)/lib\" pyenv install --patch 3.6.0 < <(curl -sSL https://github.com/python/cpython/commit/8ea6353.patch\\?full_index\\=1)\n"], [], ["# Create cloud function\ngcloud functions deploy my_function \\\n  --entry-point=my_entrypoint \\\n  --runtime=python37 \\\n  --trigger-http \\\n  --region=europe-west1 \\\n  --project=${PROJECT_ID}\n\n# Set invoke permissions\ngcloud functions add-iam-policy-binding my_function \\\n  --region=europe-west1 \\\n  --member=serviceAccount:${PROJECT_ID}@appspot.gserviceaccount.com \\\n  --role=\"roles/cloudfunctions.invoker\" \\\n  --project=${PROJECT_ID}\n\n# Deploy scheduler\ngcloud scheduler jobs create http my_job \\\n  --schedule=\"every 60 minutes\" \\\n  --uri=\"https://europe-west1-${PROJECT_ID}.cloudfunctions.net/my_function/\" \\\n  --http-method=POST \\\n  --oidc-service-account-email=\"${PROJECT_ID}@appspot.gserviceaccount.com\" \\\n  --oidc-token-audience=\"https://europe-west1-${PROJECT_ID}.cloudfunctions.net/my_function\" \\\n  --project=${PROJECT_ID}\n"], [], [], ["def url_of(request: Request, name: str, **path_params: dict):\n    from fastapi.routing import APIRoute\n    from starlette.routing import NoMatchFound\n    tag, tid, fname = None, name.find('.'), name\n    if tid > 0:\n        tag = name[:tid]\n        fname = name[tid + 1:]\n    url_no_tag = None\n    for route in request.app.router.routes:\n        if not isinstance(route, APIRoute):\n            continue\n        if fname == route.name and (not tag or tag in route.tags):\n            try:\n                url_path = route.url_path_for(fname, **path_params)\n                url_no_tag = url_path.make_absolute_url(base_url=request.base_url)\n                if tag:\n                    return url_no_tag\n            except NoMatchFound:\n                pass\n    if url_no_tag:\n        return url_no_tag\n    return request.url_for(name, **path_params)\n"], ["conda install ipykernel --update-deps --force-reinstall\n"], ["CFLAGS=\"-I$(brew --prefix openssl)/include -I$(brew --prefix bzip2)/include -I$(brew --prefix readline)/include -I$(xcrun --show-sdk-path)/usr/include\" \n\nLDFLAGS=\"-L$(brew --prefix openssl)/lib -L$(brew --prefix readline)/lib -L$(brew --prefix zlib)/lib -L$(brew --prefix bzip2)/lib\"\n\npyenv install --patch 3.6.13 < <(curl -sSL https://github.com/python/cpython/commit/8ea6353.patch\\?full_index\\=1)\n\n"], [], ["Collecting bpy\n  Using cached https://files.pythonhosted.org/packages/4b/ed/ba6092b691acc5b157891421d9fde4a9dd5dcc8a8b93a4e8119fec261391/bpy-2.82.1.tar.gz\nInstalling collected packages: bpy\n  Running setup.py install for bpy ... error\n    ERROR: Command errored out with exit status 1:\n     command: /<path-to-venv>/venv/bin/python3 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/private/var/folders/4n/wsjhxhbn0pb11r7cyqcvtxcc0000gn/T/pip-install-m6rixhki/bpy/setup.py'\"'\"'; __file__='\"'\"'/private/var/folders/4n/wsjhxhbn0pb11r7cyqcvtxcc0000gn/T/pip-install-m6rixhki/bpy/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /private/var/folders/4n/wsjhxhbn0pb11r7cyqcvtxcc0000gn/T/pip-record-ti3q9j4a/install-record.txt --single-version-externally-managed --compile --install-headers /<path-to-venv>/venv/include/site/python3.7/bpy\n         cwd: /private/var/folders/4n/wsjhxhbn0pb11r7cyqcvtxcc0000gn/T/pip-install-m6rixhki/bpy/\n    Complete output (58 lines):\n    running install\n    running build\n    running build_py\n    creating build\n    creating build/lib.macosx-10.9-x86_64-3.7\n    creating build/lib.macosx-10.9-x86_64-3.7/blenderpy\n    copying blenderpy/__init__.py -> build/lib.macosx-10.9-x86_64-3.7/blenderpy\n    copying blenderpy/pre_uninstall.py -> build/lib.macosx-10.9-x86_64-3.7/blenderpy\n    copying blenderpy/post_install.py -> build/lib.macosx-10.9-x86_64-3.7/blenderpy\n    running build_ext\n    Preparing the build environment\n    Searching for compatible Blender online (this will take a while)\n    Found compatible Blender version 2.82\n    Cloning Blender source from git (this will take a while)\n    Cloning precompiled libs from svn (this will take a while)\n    cmake -DWITH_PYTHON_INSTALL=OFF -DWITH_PYTHON_MODULE=ON -DWITH_OPENMP=OFF -DWITH_AUDASPACE=OFF -S/private/var/folders/4n/wsjhxhbn0pb11r7cyqcvtxcc0000gn/T/pip-install-m6rixhki/bpy/build/temp.macosx-10.9-x86_64-3.7/blender -B/private/var/folders/4n/wsjhxhbn0pb11r7cyqcvtxcc0000gn/T/pip-install-m6rixhki/bpy/build/temp.macosx-10.9-x86_64-3.7/build\n    -- The C compiler identification is AppleClang 12.0.5.12050022\n    -- The CXX compiler identification is AppleClang 12.0.5.12050022\n    -- Detecting C compiler ABI info\n    -- Detecting C compiler ABI info - done\n    -- Check for working C compiler: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/cc - skipped\n    -- Detecting C compile features\n    -- Detecting C compile features - done\n    -- Detecting CXX compiler ABI info\n    -- Detecting CXX compiler ABI info - done\n    -- Check for working CXX compiler: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/c++ - skipped\n    -- Detecting CXX compile features\n    -- Detecting CXX compile features - done\n    -- Detected OS X 11.3 and Xcode 12. at /Applications/Xcode.app\n    -- OSX_SYSROOT_PREFIX: /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform\n    -- Setting deployment target to 10.11, lower versions are not supported\n    CMake Warning at CMakeLists.txt:580 (message):\n      WITH_OPENAL requires WITH_AUDASPACE which is disabled\n\n\n    CMake Warning at CMakeLists.txt:584 (message):\n      WITH_JACK requires WITH_AUDASPACE which is disabled\n\n\n    -- WITH_DRACO requires WITH_PYTHON_INSTALL to be ON, disabling WITH_DRACO for now\n    -- Performing Test SUPPORT_SSE_BUILD\n    -- Performing Test SUPPORT_SSE_BUILD - Success\n    -- SSE Support: detected.\n    -- Performing Test SUPPORT_SSE2_BUILD\n    -- Performing Test SUPPORT_SSE2_BUILD - Success\n    -- SSE2 Support: detected.\n    -- Found Git: /usr/bin/git (found version \"2.30.1 (Apple Git-130)\")\n    CMake Error at build_files/cmake/platform/platform_apple.cmake:38 (message):\n      Mac OSX requires pre-compiled libs at:\n      '/private/var/folders/4n/wsjhxhbn0pb11r7cyqcvtxcc0000gn/T/pip-install-m6rixhki/bpy/build/temp.macosx-10.9-x86_64-3.7/blender/../lib/darwin'\n    Call Stack (most recent call first):\n      CMakeLists.txt:808 (include)\n\n\n    -- Configuring incomplete, errors occurred!\n    See also \"/private/var/folders/4n/wsjhxhbn0pb11r7cyqcvtxcc0000gn/T/pip-install-m6rixhki/bpy/build/temp.macosx-10.9-x86_64-3.7/build/CMakeFiles/CMakeOutput.log\".\n    See also \"/private/var/folders/4n/wsjhxhbn0pb11r7cyqcvtxcc0000gn/T/pip-install-m6rixhki/bpy/build/temp.macosx-10.9-x86_64-3.7/build/CMakeFiles/CMakeError.log\".\n    error: command 'cmake' failed with exit status 1\n    ----------------------------------------\nERROR: Command errored out with exit status 1: /<path to venv>/venv/bin/python3 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/private/var/folders/4n/wsjhxhbn0pb11r7cyqcvtxcc0000gn/T/pip-install-m6rixhki/bpy/setup.py'\"'\"'; __file__='\"'\"'/private/var/folders/4n/wsjhxhbn0pb11r7cyqcvtxcc0000gn/T/pip-install-m6rixhki/bpy/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /private/var/folders/4n/wsjhxhbn0pb11r7cyqcvtxcc0000gn/T/pip-record-ti3q9j4a/install-record.txt --single-version-externally-managed --compile --install-headers /<path to venv>/venv/include/site/python3.7/bpy Check the logs for full command output.\n"], [], ["sudo rm -rf /Library/Developer/CommandLineTools \n"], [], [], ["$ sudo ln -s /usr/lib/python3/dist-packages/gi/_gi.cpython-35m-x86_64-linux-gnu.so /usr/lib/python3/dist-packages/gi/_gi.cpython-38-x86_64-linux-gnu.so\n$ sudo ln -s /usr/lib/python3/dist-packages/gi/_gi_cairo.cpython-35m-x86_64-linux-gnu.so /usr/lib/python3/dist-packages/gi/_gi_cairo.cpython-38-x86_64-linux-gnu.so\n"], ["CFLAGS=\"-I$(brew --prefix openssl)/include -I$(brew --prefix bzip2)/include -I$(brew --prefix readline)/include -I$(xcrun --show-sdk-path)/usr/include\" LDFLAGS=\"-L$(brew --prefix openssl)/lib -L$(brew --prefix readline)/lib -L$(brew --prefix zlib)/lib -L$(brew --prefix bzip2)/lib\" pyenv install --patch 3.6.13 < <(curl -sSL https://github.com/python/cpython/commit/8ea6353.patch\\?full_index\\=1)\n"], ["#validate chess board \ndict_chess ={'1a':'bking', '8f':'wking', '1b':'bqueen', '6d': 'wqueen', \\\n          '5c': 'wrook'}\n\n\nchessHeightLocation = ['a','b','c','d','e','f','g','h']\nchessWidthLocation = [1, 2, 3, 4, 5, 6, 7, 8]\ncolors = ['w', 'b']\npieces = ['pawn', 'knight', 'bishop', 'rook', 'queen', 'king']\ndef isValidChessBoard(dictChess):\n    playerCount = {'bpawn': 0, 'wpawn': 0, 'wking': 0, 'bking': 0, 'wpieceCount': 0, 'bpieceCount': 0}\n    for keysInChessBoard in dictChess:\n        #check for Space\n        #print(int(keysInChessBoard[0]) not in chessWidthLocation)\n        if (int(keysInChessBoard[0]) not in chessWidthLocation) or (keysInChessBoard[1] not in chessHeightLocation):\n            print('Not valid space: ' + keysInChessBoard)\n            return False\n        \n        #check for black and white\n        if dictChess[keysInChessBoard][0] not in colors:\n            print('Not valid color of piece should have b for black or w for white: ' + dictChess[keysInChessBoard])\n            return False\n        \n        #check for piece\n        if dictChess[keysInChessBoard][1:] not in pieces:\n            print('Not valid piece: ' + dictChess[keysInChessBoard])\n            return False\n        \n        #check for pawns\n        if dictChess[keysInChessBoard] == 'bpawn' or dictChess[keysInChessBoard] == 'wpawn':\n            playerCount[dictChess[keysInChessBoard]] += 1\n            if playerCount[dictChess[keysInChessBoard]] > 8:\n                print('More than 8 pawns in one player')\n                return False\n        \n        #check for king\n        if dictChess[keysInChessBoard] == 'bking' or dictChess[keysInChessBoard] == 'wking':\n            playerCount[dictChess[keysInChessBoard]] += 1\n            if playerCount[dictChess[keysInChessBoard]] > 1:\n                print('More than 1 king')\n                return False\n        #pieceCount\n        if dictChess[keysInChessBoard][0] in colors:\n            if dictChess[keysInChessBoard][0] == 'w':\n                playerCount[dictChess[keysInChessBoard][0]+'pieceCount'] += 1\n            elif dictChess[keysInChessBoard][0] == 'b':\n                playerCount[dictChess[keysInChessBoard][0]+'pieceCount'] += 1\n            if playerCount[dictChess[keysInChessBoard][0]+'pieceCount'] > 16:\n                print('More than 16 piece')\n                return False\n        #print(playerCount)\n   return True\nprint(isValidChessBoard(dict_chess))\n"], ["@client.command()\nasync def reminder(ctx, time: int, *, message: str):\n"], [], [], [], [], [], [], [], [], ["your_model = tf.keras.models.load_model(\n    path_to_h5,\n    custom_objects={'Functional':tf.keras.models.Model})\n"], [], [], ["def stop_at_four(lst):\n    if 4 not in lst:\n        return lst\n    idx = 0\n    accum_list = []\n    while lst[idx] != 4:\n        accum_list.append(lst[idx])\n        idx += 1\n    return accum_list\n"], ["s = '1 w 2 r 3gH'\nprint(' '.join([word.capitalize() for word in s.split()]))\n# 1 W 2 R 3gh\n"], ["from numpy import *\n\nanswer=input(\"give your input\").title()\nprint(answer)\n"], ["z=[]\ns = input()\nx=s.split(\" \")\nprint(x)\nfor i in x:\n    z.append(i.capitalize())\n\nv=\" \".join(z)\nprint(v)\n"], [], ["conda install pytorch torchvision torchaudio cudatoolkit=11.1 -c pytorch -c nvidia\n"], [], ["action_endpoint:\n  url: \"http://localhost:9000/webhook\"\n", "rasa run actions -p 9000 --debug\n"], ["        fullName = '/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX.sdk/System/Library/Frameworks/OpenGL.framework/OpenGL'\n"], [], [], ["gunicorn pm.wsgi --log-level=debug \\\n-k uvicorn.workers.UvicornWorker --log-file - --timeout 60\n", "import os\n\nfrom django.core.wsgi import get_wsgi_application\nfrom dj_static import Cling\nfrom uvicorn.middleware.wsgi import WSGIMiddleware\nos.environ.setdefault(\"DJANGO_SETTINGS_MODULE\", \"pm.settings\")\n\n# added the WSGIMiddleWare wrapper\napplication = WSGIMiddleware(Cling(get_wsgi_application()))\n"], [], ["PS > conda install tensorflow-gpu=2.3\n## Package Plan ##\n\n  environment location: C:\\Anaconda3\\envs\\test_cuda_38\n\n  added / updated specs:\n    - tensorflow-gpu=2.3\n\n\nThe following packages will be downloaded:\n\n    package                    |            build\n    ---------------------------|-----------------\n    absl-py-0.12.0             |   py38haa95532_0         176 KB\n    aiohttp-3.7.4              |   py38h2bbff1b_1         513 KB\n    astunparse-1.6.3           |             py_0          17 KB\n    async-timeout-3.0.1        |   py38haa95532_0          14 KB\n    blas-1.0                   |              mkl           6 KB\n    blinker-1.4                |   py38haa95532_0          23 KB\n    brotlipy-0.7.0             |py38h2bbff1b_1003         412 KB\n    cachetools-4.2.1           |     pyhd3eb1b0_0          13 KB\n    cffi-1.14.5                |   py38hcd4344a_0         224 KB\n    chardet-3.0.4              |py38haa95532_1003         194 KB\n    click-7.1.2                |     pyhd3eb1b0_0          64 KB\n    coverage-5.5               |   py38h2bbff1b_2         272 KB\n    cryptography-3.4.7         |   py38h71e12ea_0         643 KB\n    cython-0.29.23             |   py38hd77b12b_0         1.7 MB\n    gast-0.4.0                 |             py_0          15 KB\n    google-auth-1.29.0         |     pyhd3eb1b0_0          76 KB\n    google-auth-oauthlib-0.4.4 |     pyhd3eb1b0_0          18 KB\n    google-pasta-0.2.0         |             py_0          46 KB\n    grpcio-1.36.1              |   py38hc60d5dd_1         1.7 MB\n    h5py-2.10.0                |   py38h5e291fa_0         841 KB\n    hdf5-1.10.4                |       h7ebc959_0         7.9 MB\n    icc_rt-2019.0.0            |       h0cc432a_1         6.0 MB\n    idna-2.10                  |     pyhd3eb1b0_0          52 KB\n    importlib-metadata-3.10.0  |   py38haa95532_0          34 KB\n    intel-openmp-2021.2.0      |     haa95532_616         1.8 MB\n    keras-applications-1.0.8   |             py_1          29 KB\n    keras-preprocessing-1.1.2  |     pyhd3eb1b0_0          35 KB\n    libprotobuf-3.14.0         |       h23ce68f_0         1.9 MB\n    markdown-3.3.4             |   py38haa95532_0         144 KB\n    mkl-2021.2.0               |     haa95532_296       115.5 MB\n    mkl-service-2.3.0          |   py38h2bbff1b_1          49 KB\n    mkl_fft-1.3.0              |   py38h277e83a_2         137 KB\n    mkl_random-1.2.1           |   py38hf11a4ad_2         223 KB\n    multidict-5.1.0            |   py38h2bbff1b_2          61 KB\n    numpy-1.20.1               |   py38h34a8a5c_0          23 KB\n    numpy-base-1.20.1          |   py38haf7ebc8_0         4.2 MB\n    oauthlib-3.1.0             |             py_0          91 KB\n    opt_einsum-3.1.0           |             py_0          54 KB\n    protobuf-3.14.0            |   py38hd77b12b_1         242 KB\n    pyasn1-0.4.8               |             py_0          57 KB\n    pyasn1-modules-0.2.8       |             py_0          72 KB\n    pycparser-2.20             |             py_2          94 KB\n    pyjwt-1.7.1                |           py38_0          48 KB\n    pyopenssl-20.0.1           |     pyhd3eb1b0_1          49 KB\n    pyreadline-2.1             |           py38_1         145 KB\n    pysocks-1.7.1              |   py38haa95532_0          31 KB\n    requests-2.25.1            |     pyhd3eb1b0_0          52 KB\n    requests-oauthlib-1.3.0    |             py_0          23 KB\n    rsa-4.7.2                  |     pyhd3eb1b0_1          28 KB\n    scipy-1.6.2                |   py38h66253e8_1        13.0 MB\n    tensorboard-plugin-wit-1.6.0|             py_0         630 KB\n    tensorflow-2.3.0           |mkl_py38h8557ec7_0           6 KB\n    tensorflow-base-2.3.0      |eigen_py38h75a453f_0        49.5 MB\n    tensorflow-estimator-2.3.0 |     pyheb71bc4_0         271 KB\n    termcolor-1.1.0            |   py38haa95532_1           9 KB\n    typing-extensions-3.7.4.3  |       hd3eb1b0_0          12 KB\n    typing_extensions-3.7.4.3  |     pyh06a4308_0          28 KB\n    urllib3-1.26.4             |     pyhd3eb1b0_0         105 KB\n    werkzeug-1.0.1             |     pyhd3eb1b0_0         239 KB\n    win_inet_pton-1.1.0        |   py38haa95532_0          35 KB\n    wrapt-1.12.1               |   py38he774522_1          49 KB\n    yarl-1.6.3                 |   py38h2bbff1b_0         153 KB\n    ------------------------------------------------------------\n                                           Total:       210.0 MB\n", "PS > conda install tensorflow-gpu=2.1\n## Package Plan ##\n\n  environment location: C:\\Anaconda3\\envs\\test_cuda\n\n  added / updated specs:\n    - tensorflow-gpu=2.1\n\n\nThe following packages will be downloaded:\n\n    package                    |            build\n    ---------------------------|-----------------\n    _tflow_select-2.1.0        |              gpu           3 KB\n    absl-py-0.12.0             |   py37haa95532_0         175 KB\n    aiohttp-3.7.4              |   py37h2bbff1b_1         507 KB\n    astor-0.8.1                |   py37haa95532_0          47 KB\n    async-timeout-3.0.1        |   py37haa95532_0          14 KB\n    blas-1.0                   |              mkl           6 KB\n    blinker-1.4                |   py37haa95532_0          23 KB\n    brotlipy-0.7.0             |py37h2bbff1b_1003         337 KB\n    cachetools-4.2.1           |     pyhd3eb1b0_0          13 KB\n    cffi-1.14.5                |   py37hcd4344a_0         220 KB\n    chardet-3.0.4              |py37haa95532_1003         192 KB\n    click-7.1.2                |     pyhd3eb1b0_0          64 KB\n    coverage-5.5               |   py37h2bbff1b_2         273 KB\n    cryptography-3.4.7         |   py37h71e12ea_0         641 KB\n    cudatoolkit-10.1.243       |       h74a9793_0       300.3 MB\n    cudnn-7.6.5                |       cuda10.1_0       179.1 MB\n    cython-0.29.23             |   py37hd77b12b_0         1.7 MB\n    gast-0.2.2                 |           py37_0         155 KB\n    google-auth-1.29.0         |     pyhd3eb1b0_0          76 KB\n    google-auth-oauthlib-0.4.4 |     pyhd3eb1b0_0          18 KB\n    google-pasta-0.2.0         |             py_0          46 KB\n    grpcio-1.36.1              |   py37hc60d5dd_1         1.7 MB\n    h5py-2.10.0                |   py37h5e291fa_0         808 KB\n    hdf5-1.10.4                |       h7ebc959_0         7.9 MB\n    icc_rt-2019.0.0            |       h0cc432a_1         6.0 MB\n    idna-2.10                  |     pyhd3eb1b0_0          52 KB\n    importlib-metadata-3.10.0  |   py37haa95532_0          34 KB\n    intel-openmp-2021.2.0      |     haa95532_616         1.8 MB\n    keras-applications-1.0.8   |             py_1          29 KB\n    keras-preprocessing-1.1.2  |     pyhd3eb1b0_0          35 KB\n    libprotobuf-3.14.0         |       h23ce68f_0         1.9 MB\n    markdown-3.3.4             |   py37haa95532_0         144 KB\n    mkl-2021.2.0               |     haa95532_296       115.5 MB\n    mkl-service-2.3.0          |   py37h2bbff1b_1          48 KB\n    mkl_fft-1.3.0              |   py37h277e83a_2         133 KB\n    mkl_random-1.2.1           |   py37hf11a4ad_2         214 KB\n    multidict-5.1.0            |   py37h2bbff1b_2          85 KB\n    numpy-1.20.1               |   py37h34a8a5c_0          23 KB\n    numpy-base-1.20.1          |   py37haf7ebc8_0         4.1 MB\n    oauthlib-3.1.0             |             py_0          91 KB\n    opt_einsum-3.1.0           |             py_0          54 KB\n    protobuf-3.14.0            |   py37hd77b12b_1         240 KB\n    pyasn1-0.4.8               |             py_0          57 KB\n    pyasn1-modules-0.2.8       |             py_0          72 KB\n    pycparser-2.20             |             py_2          94 KB\n    pyjwt-1.7.1                |           py37_0          49 KB\n    pyopenssl-20.0.1           |     pyhd3eb1b0_1          49 KB\n    pyreadline-2.1             |           py37_1         143 KB\n    pysocks-1.7.1              |           py37_1          28 KB\n    requests-2.25.1            |     pyhd3eb1b0_0          52 KB\n    requests-oauthlib-1.3.0    |             py_0          23 KB\n    rsa-4.7.2                  |     pyhd3eb1b0_1          28 KB\n    scipy-1.6.2                |   py37h66253e8_1        12.8 MB\n    six-1.15.0                 |   py37haa95532_0          51 KB\n    tensorboard-plugin-wit-1.6.0|             py_0         630 KB\n    tensorflow-2.1.0           |gpu_py37h7db9008_0           4 KB\n    tensorflow-base-2.1.0      |gpu_py37h55f5790_0       105.3 MB\n    tensorflow-estimator-2.1.0 |     pyhd54b08b_0         251 KB\n    tensorflow-gpu-2.1.0       |       h0d30ee6_0           3 KB\n    termcolor-1.1.0            |   py37haa95532_1           9 KB\n    typing-extensions-3.7.4.3  |       hd3eb1b0_0          12 KB\n    typing_extensions-3.7.4.3  |     pyh06a4308_0          28 KB\n    urllib3-1.26.4             |     pyhd3eb1b0_0         105 KB\n    werkzeug-0.16.1            |             py_0         258 KB\n    win_inet_pton-1.1.0        |   py37haa95532_0          35 KB\n    wrapt-1.12.1               |   py37he774522_1          49 KB\n    yarl-1.6.3                 |   py37h2bbff1b_0         151 KB\n    ------------------------------------------------------------\n                                           Total:       745.0 MB\n"], ["from docx2python import docx2python\ndoc_result = docx2python('page-wise-file.docx')\ncount = 0\npara = 0\npages= []\nwhile para < len(doc_result.body[0][0][0]):\n    if doc_result.body[0][0][0][para] != \"\":\n        current_page = {}\n        current_page_paras = []\n        count+=1\n        while doc_result.body[0][0][0][para]!= \"\" and para<len(doc_result.body[0][0][0]):\n            current_page_paras.append(doc_result.body[0][0][0][para])\n            para+=1\n        current_page[\"page_text\"] = \"\\n\".join(current_page_paras)\n        current_page[\"page_no\"] = count\n        pages.append(current_page)\n    else:\n        para+=1\n", "from PyPDF2 import PdfFileReader\npdf = PdfFileReader(open(\"page-wise-file.pdf\", \"rb\"))\npage = pdf.getPage(0)\npage.extractText()\n"], ["df['output']=[df.loc[x,y] for x,y in enumerate(df['source'])]\n", "      A     B       source      output\n0   John    Fred        A       John\n1   Andrew  Simon       B       Simon\n2   Bob     Andrew      A       Bob\n3   Fred    Andrew      B       Andrew\n"], ["def blackjack(numbers):\n    if len(numbers) == 3 and max(numbers) <= 11 and min(numbers)>=1:\n        sum_n = sum(numbers)\n        res =[]\n        if (sum_n  <= 21):\n            res = sum_n \n        else:\n            if 11 in numbers:\n                res =sum_n-10\n            else:\n                res = \"BUST\"\n        return res\n    else:\n        return \"numbers length should be 3 and max is 11 and min 1\"\n"], [], [], ["def find_number(word): #returns the number present in the string\n    for i in range(len(word)):\n        if(word[i].isdigit()):\n            num=\"\"\n            while(i<len(word) and word[i].isdigit()):\n                num+=word[i]\n                i+=1\n            return int(num)\ndef order(sentence):\n    od={}\n    ct=\"a\"\n    for i in sentence.split():\n        #numbering the strings so that if there are duplicates they are not lost\n        od[ct+i]=find_number(i)\n        ct=chr(ord(ct)+1)\n    for i in sorted(od.values()):\n        for j in od: #we can use other way of printing but this is the simplest but way less efficient\n            if (od[j]==i):\n                print(j[1:])\n                break\ns=input()\norder(s)\n"], [], [], [">>> from timeit import timeit\n\n>>> timeit('a+b', setup='a,b = \"h\", \"e\"')\n0.05678774899979544\n>>> timeit('f\"{a}{b}\"', setup='a,b = \"h\", \"e\"')\n0.09656870200024059\n\n>>> timeit('a+b+c', setup='a,b,c = \"h\", \"e\", \"l\"')\n0.09475198700010878\n>>> timeit('f\"{a}{b}{c}\"', setup='a,b,c = \"h\", \"e\", \"l\"')\n0.08498188300018228\n\n>>> timeit('a+b+c+d', setup='a,b,c,d = \"h\", \"e\", \"l\", \"l\"')\n0.13406166100003247\n>>> timeit('f\"{a}{b}{c}{d}\"', setup='a,b,c,d = \"h\", \"e\", \"l\", \"l\"')\n0.09481844199990519\n\n>>> timeit('a+b+c+d+e', setup='a,b,c,d,e = \"h\", \"e\", \"l\", \"l\",\"o\"')\n0.21804361799991057\n>>> timeit('f\"{a}{b}{c}{d}{e}\"', setup='a,b,c,d,e = \"h\", \"e\", \"l\", \"l\",\"o\"')\n0.11850353900013033\n"], ["# for OS: Windows, package-manager: pip, Language: python3.6 (below command is valid for only mentioned python 3.6)\n\npip3 install https://download.pytorch.org/whl/cu90/torch-1.1.0-cp36-cp36m-win_amd64.whl\npip3 install https://download.pytorch.org/whl/cu90/torchvision-0.3.0-cp36-cp36m-win_amd64.whl\n"], [], ["print(\"abcd\", cariable, sep='_')\n"], [], ["print('abcd' + '_' + cariable)\n"], [], ["a = '_' + '2021'\n"], ["df['output'] = df.stack().loc[zip(df.index,df['source'])].droplevel(-1)\n", "df['output'] = (df.stack().loc[pd.MultiIndex.from_arrays((df.index,df['source']))]\n                .droplevel(1))\n", "df['output'] =  df.lookup(df.index,df['source'])\n", "        A       B source  output\n0    John    Fred      A    John\n1  Andrew   Simon      B   Simon\n2     Bob  Andrew      A     Bob\n3    Fred  Andrew      B  Andrew\n"], ["df['output'] = np.where(df.source == 'A', df.A, df.B)\n", "conditions = [df.source == 'A', df.source == 'B']\nvalues = [df.A, df.B]\ndf['output'] = np.select(conditions, values)\n"], ["df['output'] = df.apply(lambda x: x[x.source], axis=1)\n", "    A         B source  output\n0   John    Fred    A   John\n1   Andrew  Simon   B   Simon\n2   Bob     Andrew  A   Bob\n3   Fred    Andrew  B   Andrew\n"], ["df['new'] = df.values[df.index,df.columns.get_indexer(df.source)]\ndf\nOut[339]: \n        A       B source     new\n0    John    Fred      A    John\n1  Andrew   Simon      B   Simon\n2     Bob  Andrew      A     Bob\n3    Fred  Andrew      B  Andrew\n"], ["gcloud projects describe [project-id] --format='table(projectNumber)'\nReplacing [project-id] with your project ID.\n", "gcloud projects add-iam-policy-binding [project-id] --member serviceAccount:service-[project-number]@gcp-sa-cloudscheduler.iam.gserviceaccount.com --role roles/cloudscheduler.serviceAgent\n"], ["# 60.lastlinefromlargefile.py\n# juanfc 2021-03-17\n\nimport os\n\n\ndef get_last_lines(fileName, offset=500):\n    \"\"\" An efficient way to get the last lines of a file.\n\n    IMPORTANT:\n    1. Choose offset to be greater than\n    max_line_length * number of lines that you want to recover.\n    2. This will throw an os.OSError if the file is shorter than\n    the offset.\n    \"\"\"\n    with open(fileName, \"rb\") as f:\n        f.seek(-offset, os.SEEK_END)\n        return f.read().decode('utf-8').rstrip().split('\\n')[-1]\n\n\n\nprint(get_last_lines('60.lastlinefromlargefile.py'))\n"], [], ["@bot.command()\nasync def combinestring(ctx, arg: str):\n    #your code\n", "@bot.command()\nasync def combinestring(ctx, *, arg):\n    #your code\n"], ["with open(\"test.txt\") as f:\n    p = f.seek(0,2)-1              # ignore trailing end of line\n    while p>0 and f.read(1)!=\"\\n\": # detect end of line (or start of file)\n        p = f.seek(p-1,0)          # search backward\n    lastLine = f.read().strip()    # read from start of last line\nprint(lastLine)\n", "with open(\"test.txt\") as f:\n    p,lastLine = f.seek(0,2),\"\"    # start from end of file\n    while p and not lastLine:      # want last non-empty line\n        while p>0 and f.read(1)!=\"\\n\": # detect end of line (or start of file)\n            p = f.seek(p-1,0)          # search backward\n        lastLine = f.read().strip()    # read from start of last line\n"], ["import mmap\n\n\ndef iterate_lines_backwards(filename):\n    with open(filename, \"rb\") as f:\n        # memory-map the file, size 0 means whole file\n        with mmap.mmap(f.fileno(), 0, access=mmap.ACCESS_READ) as mm:\n            start = len(mm)\n\n            while start > 0:\n                start, prev = mm.rfind(b\"\\n\", 0, start), start\n                slice = mm[start + 1:prev + 1]\n                # if the last character in the file was a '\\n',\n                # technically the empty string after that is not a line.\n                if slice:\n                    yield slice.decode()\n\n\ndef get_last_nonempty_line(filename):\n    for line in iterate_lines_backwards(filename):\n        if stripped := line.rstrip(\"\\r\\n\"):\n            return stripped\n\n\nprint(get_last_nonempty_line(\"datafile.csv\"))\n", "print(\"Iterating the lines of datafile.csv backwards\")\nfor l in iterate_lines_backwards(\"datafile.csv\"):\n    print(l, end=\"\")\n"], ["def get_last_line(file, how_many_last_lines = 1):\n\n    # open your file using with: safety first, kids!\n    with open(file, 'r') as file:\n\n        # find the position of the end of the file: end of the file stream\n        end_of_file = file.seek(0,2)\n        \n        # set your stream at the end: seek the final position of the file\n        file.seek(end_of_file)             \n        \n        # trace back each character of your file in a loop\n        n = 0\n        for num in range(end_of_file+1):            \n            file.seek(end_of_file - num)    \n           \n            # save the last characters of your file as a string: last_line\n            last_line = file.read()\n           \n            # count how many '\\n' you have in your string: \n            # if you have 1, you are in the last line; if you have 2, you have the two last lines\n            if last_line.count('\\n') == how_many_last_lines: \n                return last_line\nget_last_line('lala.csv', 2)\n"], ["import subprocess\n\nsubprocess.run(['tail', '-n', '1', '/path/to/lala.csv'])\n"], ["from collections import deque\n\ndef return_last_line(filepath):\n    with open(filepath,'r') as f:\n        q = deque(f, 1)\n    return q[0]\n"], ["real_last_n_lines_non_binary = [x.decode() for x in real_last_n_lines]\n"], ["def isValidChessBoard(board: dict) -> bool:\n    \"\"\"Return True or False depending on if  a board is valid in chess.\"\"\"\n    board_pieces = list(board.values()) #initiate variable for repeated use\n    all_pieces = ['king', 'queen', 'bishop','knight','rook','pawn']\n    blacks, whites = 0, 0 #variable to keep count of black/white pieces\n    \n    def pCount(to_count: str) -> int:\n        \"\"\"Return count value of the piece\"\"\"\n        return board_pieces.count(to_count)\n        \n    #check if board has one king and at most one queen for each side\n    if (pCount('bking') != 1) or (pCount('wking') != 1) or \\\n       (pCount('bqueen') > 1) or (pCount('wqueen') > 1):\n        return False  \n    \n    #check if all pieces names are valid \n    for piece in board_pieces:\n        if piece[0] not in 'bw' or piece[1:] not in all_pieces:\n            return False\n                 \n    #check if the position is valid (between 1a and 8h)\n    for p in board.keys():\n        if p[0] not in '12345678' or p[1] not in 'abcdefgh':\n            return False\n               \n    #check if each side has a valid number of pieces\n    for i in board_pieces:\n        if i[0] == 'b':\n            blacks += 1\n        elif i[0] == 'w':\n            whites += 1\n    \n    if (blacks or whites) > 16:\n        return False\n    elif (pCount('bpawn') or pCount('wpawn')) > 8:\n        return False    \n    elif (pCount('bbishop') or pCount('bknight') or pCount('brook')) > 2 \\\n    or   (pCount('wbishop') or pCount('wknight') or pCount('wrook')) > 2:\n        return False\n            \n    return True\n", "#more than 2 kings\ntest_1  = {'1a':'bking', '8f':'wking', '2a': 'bking', '5d':'wking'}\n\n#more than 8 pawns for one side\ntest_2 = {'2a':'bpawn', '2b': 'bpawn', '2c':'bpawn', '2d': 'bpawn', '2e': 'bpawn',\\\n         '2f': 'bpawn', '2g': 'bpawn', '2h': 'bpawn',\\\n         '7a': 'bpawn', '7b': 'wpawn', '8e': 'wking', '1e': 'bking'}\n\n#more than 16 pieces for one player\ntest_3 = {'2a':'bpawn', '2b': 'bpawn', '2c':'bpawn', '2d': 'bpawn', '2e': 'bpawn',\\\n         '2f': 'bpawn', '2g': 'bpawn', '2h': 'bpawn',\\\n         '1a': 'brook', '1b': 'bknight', '1c': 'bbishop', '1d': 'bqueen', \\\n         '1e':'bking', '1f': 'brook', '1g': 'bknight', '1h': 'bbishop', \\\n         '3a': 'bpawn', '7b': 'wking', '7c': 'wqueen'}\n\n#invalid space 9d\ntest_4 = {'1a':'bking', '8f':'wking', '1b':'bqueen', '9d': 'wqueen'}\n\n#names don't begin with 'w' or 'b'\ntest_5 = {'1a':'bking', '8f':'wking', '1b':'zqueen', '6d': 'wqueen'}\n\n#pieces names \ntest_6 = {'1a':'bking', '8f':'wking', '1b':'bqueen', '6d': 'wqueen',\\\n          '7b':'wknightt'}\n\n#too many white rooks\ntest_7 = {'1a':'bking', '8f':'wking', '1b':'bqueen', '6d': 'wqueen', \\\n          '5c': 'wrook', '8c':'wrook', '7d': 'wrook'}\n\n#this board should be valid\ntest_8 = {'1a':'bking', '8f':'wking', '1b':'bqueen', '6d': 'wqueen', \\\n          '5c': 'wrook'}\n"], ["import spacy\nnlp = spacy.load(\"en_core_web_lg\")\nfrom spacy.tokens import Doc\n\ndoc1 = nlp(\"Hi this is my dog.\")\nnew_words = [token.text if token.text!=\"dog\" else \"Simba\" for token in doc1]\nspaces = [True]*len(doc1)\nspaces[-2:] = [False, False]\nDoc(doc1.vocab, words=new_words, spaces=spaces)\n"], ["#!/usr/bin/env python3\n\n\n# Using lists instead of sets for COLORS and PIECES should work.\n#\n#\n# However, because it is important to stress that those constant define\n# a *set* of permitted values, using sets sounds more acceptable.\n\n\n# Please, note that sets are not explained in the chapter this exercise\n# was taken from.\n\nCOLORS = {'b', 'w'}\n\nPIECES = {\n    'king',\n    'queen',\n    'rook',\n    'bishop',\n    'knight',\n    'pawn'\n    }\n\nVALID_QUANTITY = {\n    'king': (1, 1),\n    'queen': (0, 1),\n    'rook': (0, 2),\n    'bishop': (0, 2),\n    'knight': (0, 2),\n    'pawn': (0, 8),\n    }\n\n\n# The following constants can be easily made using set('12345678') and\n# set('abcdefgh').\n\nROWS = {'1', '2', '3', '4', '5', '6', '7', '8'}\nCOLUMNS = {'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h'}\n\n\n# This function verifies if black pieces or white pieces quantity\n# is correct, comparing the total pieces of each kind in the board, with\n# the acceptable values defined in VALID_QUANTITY.\n\ndef verify_quantity(pieces):\n    for piece, quantity in pieces.items():\n        low, high = VALID_QUANTITY[piece]\n        if low <= quantity <= high:\n            return True\n        else:\n            return False\n\n\n# This is the main function object of the exercise.\n\ndef is_valid_chess_board(board):\n    \n    black_pieces = {}\n    white_pieces = {}\n    \n    for position, player_piece in board.items():\n        \n        row, column = position\n        player = player_piece[0]\n        piece = player_piece[1:]\n\n\n        # First it is checked that the positions of the pieces, their\n        # kind and colors are the ones allowed.\n        \n        if (row not in ROWS) or (column not in COLUMNS):\n            return False\n        if player not in COLORS:\n            return False\n        if piece not in PIECES:\n            return False\n\n\n        # The pieces present in the board are counted for each color.\n        \n        if player == 'b':\n            black_pieces[piece] = black_pieces.get(piece, 0) + 1\n        else:\n            white_pieces[piece] = white_pieces.get(piece, 0) + 1\n\n\n        # The quantity is finally checked to see if it is the one\n        # allowed by the rules.\n        \n        if not(verify_quantity(black_pieces) or verify_quantity(white_pieces)):\n            return False\n\n    return True\n"], ["tesla_revenue = pd.DataFrame(columns=[\"Date\", \"Revenue\"])\ntable = soup.find_all('table', attrs={'class': 'historical_data_table table'})\n\nfor result in table:\n    if result.find('th').getText().startswith(\"Tesla Quarterly Revenue\"):\n        for row in result.find_all('tbody'):\n            for col in row.find_all('tr'):\n                #print(col)\n                items = col.text.split('$')\n                items1=[i.strip('\\n') for i in items]\n                #print(items1)\n                if len(items1) ==2:\n                    \n                    Date=items1[0]\n                    Revenue = '$'+items1[1]\n                    tesla_revenue = tesla_revenue.append({\"Date\":Date,  \"Revenue\":Revenue}, ignore_index=True)\n\n\n\npd.to_datetime(tesla_revenue['Date'])\npd.to_numeric(tesla_revenue['Revenue'],errors='coerce')\n\ntesla_revenue = tesla_revenue.dropna()\ntesla_revenue\n"], ["import requests\nfrom bs4 import BeautifulSoup\nimport pandas as pd\n\nhtml_data = requests.get('https://www.macrotrends.net/stocks/charts/TSLA/tesla/revenue')\nsoup = BeautifulSoup(html_data.text, 'lxml')#\n\ntesla_revenue = pd.DataFrame(columns=[\"Date\", \"Revenue\"])\ntable = soup.select('table.historical_data_table:contains(\"Quarterly\") tr td')\n\nfor idx in range(0, len(table), 2):\n  Date = table[idx].getText()\n  Revenue = table[idx+1].getText()[1:]\n  tesla_revenue = tesla_revenue.append({\"Date\":Date,  \"Revenue\":Revenue}, ignore_index=True)\n\ntesla_revenue['Date'] = pd.to_datetime(tesla_revenue['Date'])\ntesla_revenue['Revenue'] = pd.to_numeric(tesla_revenue['Revenue'])\n\nprint(tesla_revenue)\n"], ["import pandas as pd\n\ndf = pd.read_html('https://www.macrotrends.net/stocks/charts/TSLA/tesla/revenue')[1]\n", "print(df)\n   Tesla Quarterly Revenue(Millions of US $) Tesla Quarterly Revenue(Millions of US $).1\n0                                 2020-12-31                                     $10,744\n1                                 2020-09-30                                      $8,771\n2                                 2020-06-30                                      $6,036\n3                                 2020-03-31                                      $5,985\n4                                 2019-12-31                                      $7,384\n5                                 2019-09-30                                      $6,303\n6                                 2019-06-30                                      $6,350\n7                                 2019-03-31                                      $4,541\n8                                 2018-12-31                                      $7,226\n9                                 2018-09-30                                      $6,824\n10                                2018-06-30                                      $4,002\n11                                2018-03-31                                      $3,409\n12                                2017-12-31                                      $3,288\n13                                2017-09-30                                      $2,985\n14                                2017-06-30                                      $2,790\n15                                2017-03-31                                      $2,696\n16                                2016-12-31                                      $2,285\n17                                2016-09-30                                      $2,298\n18                                2016-06-30                                      $1,270\n19                                2016-03-31                                      $1,147\n20                                2015-12-31                                      $1,214\n21                                2015-09-30                                        $937\n22                                2015-06-30                                        $955\n23                                2015-03-31                                        $940\n24                                2014-12-31                                        $957\n25                                2014-09-30                                        $852\n26                                2014-06-30                                        $769\n27                                2014-03-31                                        $621\n28                                2013-12-31                                        $615\n29                                2013-09-30                                        $431\n30                                2013-06-30                                        $405\n31                                2013-03-31                                        $562\n32                                2012-12-31                                        $306\n33                                2012-09-30                                         $50\n34                                2012-06-30                                         $27\n35                                2012-03-31                                         $30\n36                                2011-12-31                                         $39\n37                                2011-09-30                                         $58\n38                                2011-06-30                                         $58\n39                                2011-03-31                                         $49\n40                                2010-12-31                                         $36\n41                                2010-09-30                                         $31\n42                                2010-06-30                                         $28\n43                                2010-03-31                                         $21\n44                                2009-12-31                                         NaN\n45                                2009-09-30                                         $46\n46                                2009-06-30                                         $27\n47                                2008-12-31         \n\n                            NaN\n"], ["import requests\nfrom bs4 import BeautifulSoup\nimport pandas as pd\n\nresponse = requests.get('https://www.macrotrends.net/stocks/charts/TSLA/tesla/revenue')\nsoup = BeautifulSoup(response.text, 'lxml')\n\nall_tables = soup.find_all('table', attrs={'class': 'historical_data_table table'})\n\ntesla_revenue = pd.DataFrame(columns=[\"Date\", \"Revenue\"])\n\nfor table in all_tables:\n    if table.find('th').getText().startswith(\"Tesla Quarterly Revenue\"):\n        for row in table.find_all(\"tr\"):\n            col = row.find_all(\"td\")  \n            if len(col) == 2: \n                date = col[0].text\n                revenue = col[1].text.replace('$', '').replace(',', '')\n                tesla_revenue = tesla_revenue.append({\"Date\": date, \"Revenue\": revenue}, ignore_index=True)\n\n#tesla_revenue = tesla_revenue.apply(pd.to_numeric, errors='coerce')\n#tesla_revenue = tesla_revenue.dropna()\n\nprint(tesla_revenue)\n"], [], ["test_set_raw, test_set_transformed, train_set_raw, train_set_transformed = None\n", "test_set_raw = None\ntest_set_transformed = None\ntrain_set_raw = None\ntrain_set_transformed = None\n"], ["print([\"yes\",\"no\"][not re.match(\".*\".join(\"^\"+letters+\"$\"),guess)])\n\nletters = \"cwd\"\n\nguess = \"crossword\"   --> yes\nguess = \"crowd\"       --> yes\nguess = \"crowded\"     --> yes\nguess = \"overcrowded\" --> yes\nguess = \"wicked\"      --> no\n", "with open(\"/usr/share/dict/words\") as wf:\n    words = [w.lower() for w in wf.read().split(\"\\n\") if len(w)>=2]\n\ncIndex = dict()  # { (length,position,letter): set of words }\nfor word in words:\n    for i,c in enumerate(word):\n        cIndex.setdefault((len(word),i,c),set()).add(word)\n\n\ndef findwords(placed):\n    result = None\n    s = len(placed)\n    for i,c in enumerate(placed):  #Run through known letters/positions\n        if c==\".\" : continue\n        if result is None:\n            result  = cIndex.get((s,i,c),set()).copy()\n        else:\n            result &= cIndex.get((s,i,c),set())  # combine word sets\n    return result or set()\n", "print(findwords(\".l.p..n.\"))\n\n# {'slapping', 'aleppine', 'clipping', 'slipband', 'oliphant', 'elephant', 'clupeine', 'slipping', 'flippant', 'elaphine', 'clepsine', 'clapping', 'flopwing', 'slopping'}\n", "from collections import Counter\ndef fitWord(placed,letters,maxLen=None):\n    if maxLen is None:\n        maxLen = len(placed)-placed.count(\".\")+len(letters)\n    result = findwords(placed)\n    if len(placed)<maxLen:\n        result |= fitWord(\".\"+placed,letters,maxLen)\n        result |= fitWord(placed+\".\",letters,maxLen)\n    letterCounts = Counter(letters)+Counter(placed.replace(\".\",\"\"))\n    return {w for w in result if not Counter(w)-letterCounts}\n        \n    \nprint(fitWord(\"l.p..n\",\"eehatoi\"))\n\n# {'elaphine', 'elephant', 'lophine', 'lepton', 'oliphant'}\n"], ["board = {'e3': 'wking', 'c6': 'wqueen',\n     'g2': 'bbishop', 'd2': 'bqueen', 'g3': 'bking',\n     'a1': 'bpawn', 'm1': 'bpawn', 'c1': 'bpawn', 'd1': 'bpawn', \n     'e1': 'bpawn', 'f1': 'bpawn', 'g1': 'bpawn', 'h1': 'bpawn', \n     'e2': 'bpawn', 'a2': 'bpawn'}\n\ndef isValidChessBoard(board):\n    wKing, bKing, wPieces, bPieces = 0, 0, 0, 0\n    wPawns, bPawns, spaces, check = 0, 0, [], True\n\n    for x in ('a', 'b', 'c', 'd', 'e', 'f', 'g', 'h'):\n        for y in range(1,9):\n            spaces.append(x + str(y))\n\n    for space, piece in board.items():\n\n        if space not in spaces:\n            print('Space is wrong: ' + space + ' ' + piece)\n            check = False\n        if piece == 'wking':\n            wKing += 1\n        if piece == 'bking':\n            bKing += 1\n        if piece == 'wpawn':\n            wPawns += 1\n        if piece == 'bpawn':\n            bPawns += 1\n        if piece.startswith('w'):\n            wPieces += 1\n        if piece.startswith('b'):\n            bPieces += 1\n    if wKing != 1:\n        print('White king != 1 : ' + str(wKing))\n        check = False\n    if bKing != 1:\n        print('Black king != 1 : ' + str(bKing))\n        check = False\n    if wPieces > 16:\n        print('Total white pieces on board > 16: ' + str(wPieces))\n        check = False\n    if bPieces > 16:\n        print('Total black pieces on board > 16: ' + str(bPieces))\n        check = False\n    if wPawns > 8:\n        print('White pawns on board > 8: ' + str(wPawns))\n        check = False\n    if bPawns > 8:\n        print('Black pawns on board > 8: ' + str(bPawns))\n        check = False\n  \n    if check:\n        return True\n    else:\n        return False    \n\nprint(isValidChessBoard(board))\n"], ["sentence = 'Hi this is my dog. dogdog this is mydog'\nreplacement = 'Simba'\nto_replace = 'dog'\nst = re.sub(f'(\\W|^)+({to_replace})(\\W|$)+', f'\\g<1>{replacement}\\g<3>', sentence)\n"], ["piece = {}\n\n\n# enter chess piece and position\ndef pieceSet():\n    while True:\n        print(\"Enter chess piece: (start with 'b' or 'w' + piece) or  enter 'q' to exit\")\n        pc = str(input())\n        if pc == 'q':\n            break\n        print(\"Place the piece on the chess board: \")\n        position = str(input())\n        piece[str(position)] = str(pc)\n\n\ndef isValidChessBoard():\n    # board position and coordinates\n    board = []\n    for row in range(1, 9):\n        for col in ('a', 'b', 'c', 'd', 'e', 'f', 'g', 'h'):\n            board.append(str(row)+str(col))\n\n    # check if both kings are still on the board\n    if 'wking' not in piece.values() or 'bking' not in piece.values():\n        print('---The Board is Invalid!---')\n        print(\"King is not on the board!\")\n        return False\n\n    # check the position of every piece on the board\n    for key in piece.keys():\n        if key not in board:\n            print('---The Board is Invalid!---')\n            print(\"Chess Board only has 8 boxes per row ('a' to 'h') and 8 boxes percolumn ('1 to 8')\")\n            return False\n\n    # check if the name starts with a \"w\" or \"b\"\n    for pieces in piece.values():\n        if pieces[0] != \"b\" and pieces[0] != \"w\":\n            print('---The Board is Invalid!---')\n            print(\"Chess pieces only have 2 colors: (b)lack and (w)hite\")\n            return False\n\n    # check the quantity of every chess pieces and see if every piece is valid\n    bpawn = 0\n    wpawn = 0\n    bking = 0\n    wking = 0\n    bqueen = 0\n    wqueen = 0\n    bbishop = 0\n    wbishop = 0\n    bknight = 0\n    wknight = 0\n    brook = 0\n    wrook = 0\n    for value in piece.values():\n        if value == 'bpawn':\n            bpawn += 1\n            if bpawn > 8:\n                print('---The Board is Invalid!---')\n                print(\"Exceeded the limit of bpawn!\")\n                return False\n            else:\n                continue\n        elif value == 'wpawn':\n            wpawn += 1\n            if wpawn > 8:\n                print('---The Board is Invalid!---')\n                print(\"Exceeded the limit of wpawn!\")\n                return False\n            else:\n                continue\n        elif value == 'bking':\n            bking += 1\n            if bking > 1:\n                print('---The Board is Invalid!---')\n                print(\"Exceeded the limit of bking!\")\n                return False\n            else:\n                continue\n        elif value == 'wking':\n            wking += 1\n            if wking > 1:\n                print('---The Board is Invalid!---')\n                print(\"Exceeded the limit of wking!\")\n                return False\n            else:\n                continue\n        elif value == 'bqueen':\n            bqueen += 1\n            if bqueen > 1:\n                print('---The Board is Invalid!---')\n                print(\"Exceeded the limit of bqueen!\")\n                return False\n            else:\n                continue\n        elif value == 'wqueen':\n            wqueen += 1\n            if wqueen > 1:\n                print('---The Board is Invalid!---')\n                print(\"Exceeded the limit of wqueen!\")\n                return False\n            else:\n                continue\n        elif value == 'bbishop':\n            bbishop += 1\n            if bbishop > 2:\n                print('---The Board is Invalid!---')\n                print(\"Exceeded the limit of bbishop!\")\n                return False\n            else:\n                continue\n        elif value == 'wbishop':\n            wbishop += 1\n            if wbishop > 2:\n                print('---The Board is Invalid!---')\n                print(\"Exceeded the limit of wbishop!\")\n                return False\n            else:\n                continue\n        elif value == 'bknight':\n            bknight += 1\n            if bknight > 2:\n                print('---The Board is Invalid!---')\n                print(\"Exceeded the limit of bknight!\")\n                return False\n            else:\n                continue\n        elif value == 'wknight':\n            wknight += 1\n            if wknight > 2:\n                print('---The Board is Invalid!---')\n                print(\"Exceeded the limit of wknight!\")\n                return False\n            else:\n                continue\n        elif value == 'brook':\n            brook += 1\n            if brook > 2:\n                print('---The Board is Invalid!---')\n                print(\"Exceeded the limit of brook!\")\n                return False\n            else:\n                continue\n        elif value == 'wrook':\n            wrook += 1\n            if wrook > 2:\n                print('---The Board is Invalid!---')\n                print(\"Exceeded the limit of wrook!\")\n                return False\n            else:\n                continue\n        else:\n            print('---The Board is Invalid!---')\n            print(str(value) + \" piece not included!\")\n            return False\n\n\ndef result():\n    if isValidChessBoard() == False:\n        return False\n    else:\n        print('---The Board is Valid!---')\n        return True\n\n\npieceSet()\nprint('piece =', piece)\nprint(result())\n"], ["### import Library for using re.compile() method\nimport re\n\n### letters already in the crossword\nletters=input() \n\n### word to check for fit\nguess=input() \n\n### modify letters to include .* between each character \nx=re.findall(\".*\".join(list(letters)),guess) \n\nif (x):\n    print(\"yes\")\nelse:\n    print(\"no\")\n        \n"], ["libcrypto-1_1-x64.dll\nlibssl-1_1-x64.dll\nsqlite3.dll\nsqlite3.exe\n"], ["count = {}\n\nfor v in board.values():\n    count.setdefault(v, 0)\n    count[v] = count[v] + 1\nprint(count)\n# Criteria 2 - Each player can have at most 16 pieces, at most 8 pawns\n\ndel count['']\n#print(count)\npieces = 0\nfor v in count.values():\n    pieces = pieces + v\n#print(pieces)\n\n# Criteria 3 and 4 - All pieces must be on a valid space '1a' to '8h', not '9z'. Names must start with w or b.\n\nvalidSpace = {'1a': 'brook', '1b': 'bknight', '1c': 'bbishop', '1d': 'bking', '1e': 'bqueen', '1f': 'bbishop',\n         '1g': 'bknight', '1h': 'brook',\n         '2a': 'bpawn', '2b': 'bpawn', '2c': 'bpawn', '2d': 'bpawn', '2e': 'bpawn', '2f': 'bpawn',\n         '2g': 'bpawn', '2h': 'bpawn',\n         '3a': '', '3b': '', '3c': '', '3d': '', '3e': '', '3f': '',\n         '3g': '', '3h': '',\n         '4a': '', '4b': '', '4c': '', '4d': '', '4e': '', '4f': '',\n         '4g': '', '4h': '',\n         '5a': '', '5b': '', '5c': '', '5d': '', '5e': '', '5f': '',\n         '5g': '', '5h': '',\n         '6a': '', '6b': '', '6c': '', '6d': '', '6e': '', '6f': '',\n         '6g': '', '6h': '',\n         '7a': 'wpawn', '7b': 'wpawn', '7c': 'wpawn', '7d': 'wpawn', '7e': 'wpawn', '7f': 'wpawn',\n         '7g': 'wpawn', '7h': 'wpawn',\n         '8a': 'wrook', '8b': 'wknight', '8c': 'wbishop', '8d': 'wking', '8e': 'wqueen', '8f': 'wbishop',\n         '8g': 'wknight', '8h': 'wrook'\n         }\nprint(count['bking'])\nprint(count['bpawn'])\nif count['bking'] == 1:\n    if count['wking'] == 1:\n        if pieces == 32:\n            if count['bpawn'] == 8:\n                if count['wpawn'] == 8:\n                    if board == validSpace:\n                        return True\n"], ["def isValidChessBoard(board):\n    board = {'1a': 'brook', '1b': 'bknight', '1c': 'bbishop', '1d': 'bking', '1e': 'bqueen', '1f': 'bbishop',\n             '1g': 'bknight', '1h': 'brook',\n             '2a': 'bpawn', '2b': 'bpawn', '2c': 'bpawn', '2d': 'bpawn', '2e': 'bpawn', '2f': 'bpawn',\n             '2g': 'bpawn', '2h': 'bpawn',\n             '3a': '', '3b': '', '3c': '', '3d': '', '3e': '', '3f': '',\n             '3g': '', '3h': '',\n             '4a': '', '4b': '', '4c': '', '4d': '', '4e': '', '4f': '',\n             '4g': '', '4h': '',\n             '5a': '', '5b': '', '5c': '', '5d': '', '5e': '', '5f': '',\n             '5g': '', '5h': '',\n             '6a': '', '6b': '', '6c': '', '6d': '', '6e': '', '6f': '',\n             '6g': '', '6h': '',\n             '7a': 'wpawn', '7b': 'wpawn', '7c': 'wpawn', '7d': 'wpawn', '7e': 'wpawn', '7f': 'wpawn',\n             '7g': 'wpawn', '7h': 'wpawn',\n             '8a': 'wrook', '8b': 'wknight', '8c': 'wbishop', '8d': 'wking', '8e': 'wqueen', '8f': 'wbishop',\n             '8g': 'wknight', '8h': 'wrook'\n             }\n    # Criteria 1 - 1 bbking and 1 wking\n\n    count = {}\n\n    for v in board.values():\n        count.setdefault(v, 0)\n        count[v] = count[v] + 1\n    # print(count)\n    # Criteria 2 - Each player can have at most 16 pieces, at most 8 pawns\n\n    del count['']\n    #print(count)\n    pieces = 0\n    for v in count.values():\n        pieces = pieces + v\n    #print(pieces)\n\n    # Criteria 3 - All pieces must be on a valid space '1a' to '8h', not '9z'\n\n    validSpace = {'1a': 'brook', '1b': 'bknight', '1c': 'bbishop', '1d': 'bking', '1e': 'bqueen', '1f': 'bbishop',\n             '1g': 'bknight', '1h': 'brook',\n             '2a': 'bpawn', '2b': 'bpawn', '2c': 'bpawn', '2d': 'bpawn', '2e': 'bpawn', '2f': 'bpawn',\n             '2g': 'bpawn', '2h': 'bpawn',\n             '3a': '', '3b': '', '3c': '', '3d': '', '3e': '', '3f': '',\n             '3g': '', '3h': '',\n             '4a': '', '4b': '', '4c': '', '4d': '', '4e': '', '4f': '',\n             '4g': '', '4h': '',\n             '5a': '', '5b': '', '5c': '', '5d': '', '5e': '', '5f': '',\n             '5g': '', '5h': '',\n             '6a': '', '6b': '', '6c': '', '6d': '', '6e': '', '6f': '',\n             '6g': '', '6h': '',\n             '7a': 'wpawn', '7b': 'wpawn', '7c': 'wpawn', '7d': 'wpawn', '7e': 'wpawn', '7f': 'wpawn',\n             '7g': 'wpawn', '7h': 'wpawn',\n             '8a': 'wrook', '8b': 'wknight', '8c': 'wbishop', '8d': 'wking', '8e': 'wqueen', '8f': 'wbishop',\n             '8g': 'wknight', '8h': 'wrook'\n             }\n\n    if count['bking'] == 1:\n        if count['wking'] == 1:\n            if pieces == 32:\n                if count['bpawn'] == 8:\n                    if count['wpawn'] == 8:\n                        if board == validSpace:\n                            #return 'True: This is a Vaild Chessboard'\n                            return True\n\n\n\nchessBoardOne = {'1a': 'wrook', '1b': 'wknight', '1c': 'wbishop', '1d': 'wqueen', '1e': 'wking', '1f': 'wbishop',\n'1g': 'wknight', '1h': 'wrook','2a': 'wpawn', '2b': 'wpawn', '2c': 'wpawn', '2d': 'wpawn', '2e': 'wpawn',\n'2f': 'wpawn', '2g': 'wpawn', '2h': 'wpawn', '3a': '', '3b': '', '3c': '', '3d': '', '3e': '', '3f': '',\n'3g': '', '3h': '', '4a': '', '4b': '', '4c': '', '4d': '', '4e': '', '4f': '', '4g': '', '4h': '',\n'5a': '', '5b': '', '5c': '', '5d': '', '5e': '', '5f': '', '5g': '', '5h': '',\n'6a': '', '6b': '', '6c': '', '6d': '', '6e': '', '6f': '', '6g': '', '6h': '',\n'7a': 'bpawn', '7b': 'bpawn', '7c': 'bpawn', '7d': 'bpawn', '7e': 'bpawn', '7f': 'bpawn', '7g': 'bpawn', '7h': 'bpawn',\n'8a': 'brook', '8b': 'bknight', '8c': 'bbishop' , '8d': 'bqueen', '8e': 'bking', '8f': 'bbishop',\n'8g': 'bknight','8h': 'brook'}\n\nprint(isValidChessBoard(chessBoardOne))\n#print(Answer)\n"], ["def isValid(board):\n    # PUT TOGETHER A LIST OF ALL POSSIBLE PIECES\n    pieces = ['king', 'queen', 'rook', 'knight', 'bishop', 'pawn']\n    colors = ['b', 'w']\n    all_pieces = {}\n    possible_pieces = ['']\n    color_count = {'b': 0, 'w': 0}\n    for piece in pieces:\n        for color in colors:\n            possible_pieces.append('{}{}'.format(color, piece))\n            all_pieces.setdefault('{}{}'.format(color, piece), 0)\n\n    # CHECKS IF PIECES HAVE VALID NAMES\n    for v in board.values():\n        if v not in possible_pieces:\n            print('Error: Invalid chess piece type')\n            return False\n\n    # ITERATE THROUGH BOARD, AND COUNT PIECES AND COLORS\n    for k in board:\n        if board.get(k) == '':\n            continue\n        all_pieces[board.get(k)] += 1      # INCREASE PIECE TYPE\n        color_count[board.get(k)[0]] += 1  # INCREASE COLOR COUNT\n\n    # CHECK TOTAL WHITE/BLACK PIECES\n    if color_count['w'] > 16 or color_count['b'] > 16:\n        print('Error: Invalid number of white or black pieces')\n        return False\n\n    # CHECKS IF VALID NUMBER OF PIECES\n    for i in possible_pieces:\n        num = all_pieces.get(i)\n        if i == 'bking' or i == 'wking':\n            if num != 1:\n                print('Error: Invalid number of Kings')\n                return False\n        elif i == 'bqueen' or i == 'wqueen':\n            if num > 1:\n                print('Error: Invalid number of Queens')\n                return False\n        elif i == 'brook' or i == 'wrook':\n            if num > 2:\n                print('Error: Invalid number of Rooks')\n                return False\n        elif i == 'bknight' or i == 'wknight':\n            if num > 2:\n                print('Error: Invalid number of Knights')\n                return False\n        elif i == 'bbishop' or i == 'wbishop':\n            if num > 2:\n                print('Error: Invalid number of Bishops')\n                return False\n        elif i == 'bpawn' or i == 'wpawn':\n            if num > 8:\n                print('Error: Invalid number of Pawns')\n                return False\n\n    # CHECK ALL VALID SPACES\n    for s in board:\n        if s[0] not in '12345678' or s[1] not in 'abcdefgh':\n            print('Error: Space is not valid!')\n            return False\n\n    # IF PASS ALL CHECKS, THE BOARD IS VALID \n    return True\n"], ["X_train, y_train, X_test, y_test = None\n"], ["conda create -n tfgpu python=3.7\nconda activate tfgpu\nconda install tensorflow-gpu=2.1\n\npip uninstall tensorflow\npip uninstall tensorflow-estimator\npip uninstall tensorboard \npip uninstall tensorboard-plugin-wit\npip install tensorflow==2.3\npip check\n"], [], ["import pandas as pd\n\nData = pd.DataFrame({'Date Created': [\"2016-02-20 09:26:45\", \"2016-02-19 19:30:25\", \"2016-02-19 18:13:39\"]})\n\nData['Date Created'] = pd.to_datetime(Data['Date Created'])\nData['Date'] = Data['Date Created'].dt.strftime(\"%Y-%m-%d\")\nData['Time'] = Data['Date Created'].dt.strftime(\"%H:%M:%S\")\n\nData\n         Date Created        Date      Time\n0 2016-02-20 09:26:45  2016-02-20  09:26:45\n1 2016-02-19 19:30:25  2016-02-19  19:30:25\n2 2016-02-19 18:13:39  2016-02-19  18:13:39\n"], [">>> Data.loc[:,'Date Created'] = pd.to_datetime(Data.loc[:,'Date Created'], format=\"%Y-%m-%d %H:%M:%S\")\n>>> Data['Date'] = Data['Date Created'].dt.date\n>>> Data['Time'] = Data['Date Created'].dt.time\n>>> Data\n         Date Created        Date      Time\n0 2016-02-20 09:26:45  2016-02-20  09:26:45\n1 2016-02-19 19:30:25  2016-02-19  19:30:25\n2 2016-02-19 18:13:39  2016-02-19  18:13:39\n3 2016-03-01 14:15:36  2016-03-01  14:15:36\n4 2016-03-04 14:47:57  2016-03-04  14:47:57\n", ">>> Data['Time'][0]\ndatetime.time(9, 26, 45)\n>>> Data['Date'][0]\ndatetime.date(2016, 2, 20)\n"], ["from datetime import datetime\n\nnow = datetime.now() # current date and time\n\nhour = now.strftime(\"%H\")# current hour \n"], [">>> df['TimeOnly']=df['Date Created'].dt.strftime('%H:%M:%S')\n\n>>> df\n         Date Created  TimeOnly\n0 2016-02-20 09:26:45  09:26:45\n1 2016-02-19 19:30:25  19:30:25\n2 2016-02-19 18:13:39  18:13:39\n3 2016-03-01 14:15:36  14:15:36\n4 2016-03-04 14:47:57  14:47:57\n"], ["import requests\nimport string\n\nparams = {\n    'x-algolia-agent': 'Algolia for JavaScript (3.35.1); Browser; JS Helper (3.1.0)',\n    'x-algolia-application-id': '45BWZJ1SGC',\n    'x-algolia-api-key': 'NDYzYmNmMTRjYzU4MDE0ZWY0MTVmMTNiYzcwYzMyODFlMjQxMWI5YmZkMjEwMDAxMzE0OTZhZGZkNDNkYWZjMHJl'\n                         'c3RyaWN0SW5kaWNlcz0lNUIlMjJZQ0NvbXBhbnlfcHJvZHVjdGlvbiUyMiU1RCZ0YWdGaWx0ZXJzPSU1QiUyMiUy'\n                         'MiU1RCZhbmFseXRpY3NUYWdzPSU1QiUyMnljZGMlMjIlNUQ='\n}\n\nurl = 'https://45bwzj1sgc-dsn.algolia.net/1/indexes/*/queries'\nresult = dict()\nfor letter in string.ascii_lowercase:\n    print(letter)\n\n    payload = {\n        \"requests\": [{\n            \"indexName\": \"YCCompany_production\",\n            \"params\": \"hitsPerPage=1000&query=\" + letter + \"&page=0&facets=%5B%22top100%22%2C%22isHiring%22%2C%22nonprofit%22%2C%22batch%22%2C%22industries%22%2C%22subindustry%22%2C%22status%22%2C%22regions%22%5D&tagFilters=\"\n        }]\n    }\n\n    r = requests.post(url, params=params, json=payload)\n    result.update({h['id']: h for h in r.json()['results'][0]['hits']})\n\nprint(len(result))\n"], ["try:\n    import OpenGL as ogl\n    try:\n        import OpenGL.GL   # this fails in <=2020 versions of Python on OS X 11.x\n    except ImportError:\n        print('Drat, patching for Big Sur')\n        from ctypes import util\n        orig_util_find_library = util.find_library\n        def new_util_find_library( name ):\n            res = orig_util_find_library( name )\n            if res: return res\n            return '/System/Library/Frameworks/'+name+'.framework/'+name\n        util.find_library = new_util_find_library\nexcept ImportError:\n    pass\n"], ["payload = {\"requests\":[{\"indexName\":\"YCCompany_production\",\n                        \"params\": \"query=&offset=1000&length=500&facets=%5B%22top100%22%2C%22isHiring%22%2C%22nonprofit\"\n                                 \"%22%2C%22batch%22%2C%22industries%22%2C%22subindustry%22%2C%22status%22%2C%22regions%22%5D&tagFilters=\"}]}\n", "\"hits\": [],\n    \"nbHits\": 2432,\n    \"offset\": 1000,\n    \"length\": 500,\n    \"message\": \"you can only fetch the 1000 hits for this query. You can extend the number of hits returned via the paginationLimitedTo index parameter or use the browse method. You can read our FAQ for more details about browsing: https://www.algolia.com/doc/faq/index-configuration/how-can-i-retrieve-all-the-records-in-my-index\",\n", "'paginationLimitedTo': number_of_records\n", "----------------------------------------\nMy system information\n----------------------------------------\nPlatform:    macOS\nPython:      3.8.0\nRequests:    2.25.1\n----------------------------------------\n"], ["lets=input()\n\nguess=input()\n\ni = 0\n\nfor x in guess:\n    if x == lets[i]: \n          i += 1\n          if i >= len(lets): break\n\nif (i == len(lets)):\n    print(\"Yes\")\nelse:\n    print(\"No\")\n"], ["%%writefile gpu_usage.sh\n#! /bin/bash\n#comment: run for 10 seconds, change it as per your use\nend=$((SECONDS+10))\n\nwhile [ $SECONDS -lt $end ]; do\n    nvidia-smi --format=csv --query-gpu=power.draw,utilization.gpu,memory.used,memory.free,fan.speed,temperature.gpu >> gpu.log\n    #comment: or use below command and comment above using #\n    #nvidia-smi dmon -i 0 -s mu -d 1 -o TD >> gpu.log\ndone\n", "%%bash --bg\n\nbash gpu_usage.sh\n"], ["   index.set_settings\n\n  'paginationLimitedTo': number_of_records\n", " index.set_settings({'customRanking': ['desc(followers)']})\n"], [], ["    def _github(url: str, mode: str = \"private\"):\n        url = url.replace(\"/blob/\", \"/\")\n        url = url.replace(\"/raw/\", \"/\")\n        url = url.replace(\"github.com/\", \"raw.githubusercontent.com/\")\n\n        if mode == \"public\":\n            return requests.get(url)\n        else:\n            token = os.getenv('GITHUB_TOKEN', '...')\n            headers = {\n                'Authorization': f'token {token}',\n                'Accept': 'application/vnd.github.v3.raw'}\n            return requests.get(url, headers=headers)\n"], ["fullName = \"/System/Library/Frameworks/{}.framework/{}\".format(name,name)\n"], [">>> import timeit\n>>> def add(x, y):\n...     return x + y\n...\n>>> a = '1'\n>>> b = '2'\n>>> add(a, b)\n'12'\n>>> timeit.timeit('12')\n0.009553937998134643\n>>> a = 1\n>>> b = 2\n>>> add(a, b)\n3\n>>> timeit.timeit(3)\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\n  File \"/.../lib/python3.7/timeit.py\", line 232, in timeit\n    return Timer(stmt, setup, timer, globals).timeit(number)\n  File \"/.../lib/python3.7/timeit.py\", line 128, in __init__\n    raise ValueError(\"stmt is neither a string nor callable\")\nValueError: stmt is neither a string nor callable\n", "timeit.timeit('add(a, b)', 'from __main__ import add, a, b')\n", ">>> import timeit\n>>> def add(x, y):\n...     return x + y\n...\n>>> a = '1'\n>>> b = '2'\n>>> timeit.timeit('add(a, b)', 'from __main__ import add, a, b')\n0.16069997000158764\n>>> a = 1\n>>> b = 2\n>>> timeit.timeit('add(a, b)', 'from __main__ import add, a, b')\n0.10841095799696632\n"], ["async def test(ctx, arg):\n    await ctx.send(arg)\n", "@bot.command()\nasync def test(ctx, *args)\n", "s = \"Foo\"\n#<User puts in a value for s>#\ns == \"Foo\" #Returns a boolean value (True if the string matches, False if it does not)\n"], [], [], ["# Create cloud function\ngcloud functions deploy my_function \\\n  --entry-point=my_entrypoint \\\n  --runtime=python37 \\\n  --trigger-http \\\n  --region=europe-west1 \\\n  --project=${PROJECT_ID}\n", "# Deploy scheduler\ngcloud scheduler jobs create http my_job \\\n  --schedule=\"every 60 minutes\" \\\n  --uri=\"https://europe-west1-${PROJECT_ID}.cloudfunctions.net/my_function/\" \\\n  --http-method=POST \\\n  --oidc-service-account-email=\"${SERVICE_ACCOUNT_EMAIL}\" \\\n  --oidc-token-audience=\"https://europe-west1-${PROJECT_ID}.cloudfunctions.net/my_function\" \\\n  --project=${PROJECT_ID}\n", "  --uri=\"https://europe-west1-${PROJECT_ID}.cloudfunctions.net/my_function?key=value\" \\\n  --oidc-token-audience=\"https://europe-west1-${PROJECT_ID}.cloudfunctions.net/my_function\" \\\n"], [], [], ["conda create --name tf_gpu tensorflow-gpu \n", "import tensorflow as tf\n"], [], [], ["resultArray = [] #list\n\ndef hailstone(n):\n    if n <= 0: # Base Condition\n        return\n    if n > 0:\n       resultArray.append(n)\n    if n > 1:\n       if n % 2 == 0:\n          hailstone(int(n/2))\n       else:\n          hailstone((n * 3) + 1)\n\n# function call\nhailstone(20)\nprint(len(resultArray), resultArray)\n", "8 [20, 10, 5, 16, 8, 4, 2, 1]\n"], ["count = 0\nlist_num = []\n\ndef input_check():\n    number = int(input(\"Enter a positive integer (1-1000). To quit, enter -1: \"))\n    if number >= 1 and number <= 1000:\n        hailstone_game(number)\n    elif number == -1:\n        return \n    else:\n        print(\"Please type in a number between 1-1000\")\n        input_check()\n\ndef hailstone_game(number):\n    global count\n    while number != 1:\n        count += 1\n        list_num.append(number)\n        if number % 2 == 0:\n            return hailstone_game(int(number/2))\n        else:\n            return hailstone_game(int(number*3+1))\n\n    list_num.append(1) # cheap uncreative way to add the one\n    print(*list_num, sep=\" \")\n    print(f\"The loop executed {count} times.\")\n    return\n\ninput_check()\n", "- Catching non-integer inputs using try / except \n"], ["import sys\n\nres = []\ndef hailstone(number):\n    global res\n    \n    if number > 1:\n        if number % 2 == 0:\n            res.append( number // 2 )\n            hailstone(res[len(res)-1])\n        else:\n            res.append(number * 3 + 1) \n            hailstone(res[len(res)-1])\n\n    return res\n\n\n\n\nnumber = int(input('Enter a positive integer. To quit, enter -1: '))\nif number <= 0 or number == 0:\n    print('Thank you for playing Hailstone.')\n    sys.exit()\n\nelse:\n    answers = hailstone(number)\n    for answer in answers:\n        print(answer)\n    print('The loop executed {} times.'.format(len(answers) + 1))\n"], ["from sys import exit\n\n\ndef check_number(number):\n    \n    if number % 2 ==0:\n        print(number // 2)\n        return(number // 2)\n    else:\n        print(number*3+1)\n        return number*3+1\n\ndef user_call(number):\n    count = 0\n    while number != 1:\n        count += 1\n        number = check_number(number)\n    return count\n\n\nif __name__ == \"__main__\":\n    \n    try:\n        number = int(input('Give a number \\n'))\n        count = user_call(number)\n        print('count ',count)\n\n    except Exception as e:\n        exit()\n"], [], ["CHANNEL_LAYERS = {\n    'default': {\n        'BACKEND': 'channels_redis.core.RedisChannelLayer',\n        'CONFIG': {\n            \"hosts\": [('172.20.0.1', 6379)],\n        },\n    },\n}\n"], ["pip install torch==1.7.0+cpu torchvision==0.8.1+cpu torchaudio===0.7.0 -f https://download.pytorch.org/whl/torch_stable.html\n", "pip install torch===1.7.0+cu110 torchvision===0.8.1+cu110 torchaudio===0.7.0 -f https://download.pytorch.org/whl/torch_stable.html\n"], [], [], ["pip install torch===1.7.0 torchvision===0.8.1 torchaudio===0.7.0 -f https://download.pytorch.org/whl/torch_stable.html\n"], ["import hashlib\n\ndef compare_common_files_by_hash(directory_one, directory_two):\n   d1_files = set(os.listdir(directory_one))\n   d2_files = set(os.listdir(directory_two))\n   common_files = list(d1_files &  d2_files)\n   if common_files:\n     for filename in common_files:\n        hash_01 = hashlib.sha256(open(f'{directory_one}/{filename}', 'rb').read()).hexdigest()\n        hash_02 = hashlib.sha256(open(f'{directory_two}/{filename}', 'rb').read()).hexdigest()\n        if hash_01 == hash_02:\n            print(f'The file - {filename} is identical in the directories {directory_one} and {directory_two}')\n        elif hash_01 != hash_02:\n            print(f'The file - {filename} is different in the directories {directory_one} and {directory_two}')\n", "import os \n\ndef compare_common_files_by_size(directory_one, directory_two):\n  d1_files = set(os.listdir(directory_one))\n  d2_files = set(os.listdir(directory_two))\n  common_files = list(d1_files &  d2_files)\n  if common_files:\n    for filename in common_files:\n       file_01 = os.stat(f'{directory_one}/{filename}')\n       file_02 = os.stat(f'{directory_two}/{filename}')\n       if file_01.st_size == file_02.st_size:\n            print(f'The file - {filename} is identical in the directories {directory_one} and {directory_two}')\n       elif file_01.st_size != file_02.st_size:\n            print(f'The file - {filename} is different in the directories {directory_one} and'\n                  f' {directory_two}')\n", "import os\n\n def compare_common_files_by_metadata(directory_one, directory_two):\n   d1_files = set(os.listdir(directory_one))\n   d2_files = set(os.listdir(directory_two))\n   common_files = list(d1_files & d2_files)\n   if common_files:\n     for filename in common_files:\n        file_01 = os.stat(f'{directory_one}/{filename}')\n        file_02 = os.stat(f'{directory_two}/{filename}')\n        if file_01.st_size == file_02.st_size and file_01.st_mtime == file_02.st_mtime:\n            print(f'The file - {filename} is identical in the directories {directory_one} and {directory_two}')\n        elif file_01.st_size != file_02.st_size or file_01.st_mtime != file_02.st_mtime:\n            print(f'The file - {filename} is different in the directories {directory_one} and'\n                  f' {directory_two}')\n", "import os\n\ndef compare_common_files_by_lines(directory_one, directory_two):\n   d1_files = set(os.listdir(directory_one))\n   d2_files = set(os.listdir(directory_two))\n   common_files = list(d1_files & d2_files)\n   if common_files:\n     for filename in common_files:\n        if fileName.endswith('.csv'):\n          file_01 = open(f'{directory_one}/{filename}', 'r', encoding='ISO-8859-1')\n          file_02 = open(f'{directory_two}/{filename}', 'r', encoding='ISO-8859-1')\n          csv_file_01 = set(map(tuple, csv.reader(file_01)))\n          csv_file_02 = set(map(tuple, csv.reader(file_02)))\n          different = csv_file_01 ^ csv_file_02\n            for row in sorted(different, key=lambda x: x, reverse=True):\n               if row:\n                  print(f'This row: \\n {row} \\n was different between the file {fileName} in the directories'\n                          f' {directory_one} and {directory_two}')\n", "import filecmp\n\ndef compare_common_files(directory_one, directory_two):\n  d1_files = set(os.listdir(directory_one))\n  d2_files = set(os.listdir(directory_two))\n  common_files = list(d1_files & d2_files)\n  if common_files:\n    for filename in common_files:\n        file_01 = f'{directory_one}/{filename}'\n        file_02 = f'{directory_two}/{filename}'\n        comparison = filecmp.cmp(file_01, file_02, shallow=False)\n        if comparison:\n            print(f'The file - {filename} is identical in the directories - {directory_one} and {directory_two}')\n        elif not comparison:\n            print(f'The file - {filename} is different in the directories - {directory_one} and {directory_two}')\n", "import filecmp\n\ndef directory_recursive(directory_one, directory_two):\n   files = filecmp.dircmp(directory_one, directory_two)\n   for filename in files.diff_files:\n      print(f'The file - {filename} is different in the directories - {files.left} and {files.right}')\n   for filename in files.left_only:\n      print(f'The file - {filename} - was only found in the directory {files.left}')\n   for filename in files.right_only:\n      print(f'The file - {filename} - was only found in the directory {files.right}')\n", "import csv\n\ndef get_csv_file_lines(file):\n   with open(file, 'r', encoding='utf-8') as csv_file:\n      rows = csv.reader(csv_file)\n      for row in rows:\n         yield row\n\ndef compare_csv_files_line_by_line(csv_file_one, csv_file_two):\n   csvfile_02 = get_csv_file_lines(csv_file_two)\n   for line_one in get_csv_file_lines(csv_file_one):\n      line_two = csvfile_02.__next__()\n      if line_two != line_one:\n        print('File names being compared:')\n        print(f'csv_file_one: {csv_file_one}')\n        print(f'csv_file_two: {csv_file_two}')\n        print(f'The following rows have difference in the files being compared.')\n        print('csv_file_one:', line_one)\n        print('csv_file_two:', line_two)\n        print('\\n')\n", "import fs\nimport os\nimport boto3\nimport hashlib\n\ndef create_temp_memory_filesystem():\n   mem_fs = fs.open_fs('mem://')\n   virtual_disk = mem_fs.makedir('hidden_dir')\n   return mem_fs, virtual_disk\n\ndef query_s3_file_by_name(filename, memory_filesystem, temp_directory):\n   s3 = boto3.resource('s3', aws_access_key_id='your_access_key_id',\n                    aws_secret_access_key='your_secret_access_key')\n   bucket = s3.Bucket('your_bucket_name')\n   for obj in bucket.objects.all():\n      if obj.key == filename:\n        body = obj.get()['Body'].read()\n        with memory_filesystem.open(f'{temp_directory}/s3_{filename}', 'w') as f:\n            f.write(str(body))\n            f.close()\n\n def compare_local_files_to_s3_files(local_csv_files):\n    virtual_disk = create_temp_memory_filesystem()\n    directory_name = str(virtual_disk[1]).split('/')[1]\n    files = set(os.listdir(local_csv_files))\n    for filename in files:\n       if filename.endswith('.csv'):\n         local_file_hash = hashlib.sha256(open(f'{local_csv_files}/{filename}', 'rb').read()).hexdigest()\n         query_s3_file_by_name(filename, virtual_disk[0], directory_name)\n         virtual_files = virtual_disk[0].opendir(directory_name)\n         for file_name in virtual_files.listdir('/'):\n            s3_file_hash = hashlib.sha256(open(file_name, 'rb').read()).hexdigest()\n            if local_file_hash == s3_file_hash:\n                print(f'The file - {filename} is identical in both the local file system and the S3 bucket.')\n            elif local_file_hash != s3_file_hash:\n                print(f'The file - {filename} is different between the local file system and the S3 bucket.')\n            virtual_files.remove(file_name)\n    virtual_disk[0].close()\n", "import fs\nimport os\nimport boto3\nimport filecmp\n\ndef create_temp_memory_filesystem():\n   mem_fs = fs.open_fs('mem://')\n   virtual_disk = mem_fs.makedir('hidden_dir')\n   return mem_fs, virtual_disk\n\ndef query_s3_file_by_name(filename, memory_filesystem, temp_directory):\n   s3 = boto3.resource('s3', aws_access_key_id='your_access_key_id',\n                    aws_secret_access_key='your_secret_access_key')\n   bucket = s3.Bucket('your_bucket_name')\n   for obj in bucket.objects.all():\n      if obj.key == filename:\n        body = obj.get()['Body'].read()\n        with memory_filesystem.open(f'{temp_directory}/s3_{filename}', 'w') as f:\n            f.write(str(body))\n            f.close()\n\ndef compare_local_files_to_s3_files(local_csv_files):\n   virtual_disk = create_temp_memory_filesystem()\n   directory_name = str(virtual_disk[1]).split('/')[1]\n   files = set(os.listdir(local_csv_files))\n   for filename in files:\n      if filename.endswith('.csv'):\n        local_file = f'{local_csv_files}/{filename}'\n        query_s3_file_by_name(filename, virtual_disk[0], directory_name)\n        virtual_files = virtual_disk[0].opendir(directory_name)\n        for file_name in virtual_files.listdir('/'):\n            comparison = filecmp.cmp(local_file, file_name, shallow=False)\n            if comparison:\n                print(f'The file - {filename} is identical in both the local file system and the S3 bucket.')\n            elif not comparison:\n                print(f'The file - {filename} is different between the local file system and the S3 bucket.')\n            virtual_files.remove(file_name)\n   virtual_disk[0].close()\n", "import fs\nimport os\nimport hashlib\nfrom google.cloud import storage\n\ndef create_temp_memory_filesystem():\n   mem_fs = fs.open_fs('mem://')\n   virtual_disk = mem_fs.makedir('hidden_dir')\n   return mem_fs, virtual_disk\n\ndef query_google_cloud_storage_file_by_name(filename, memory_filesystem, temp_directory):\n  client = storage.Client.from_service_account_json('path_to_your_credentials.json')\n  bucket = client.get_bucket('your_bucket_name')\n  blobs = bucket.list_blobs()\n  for blob in blobs:\n     if blob.name == filename:\n       with memory_filesystem.open(f'{temp_directory}/{filename}', 'w') as f:\n           f.write(str(blob.download_to_filename(blob.name)))\n           f.close()\n\ndef compare_local_files_to_google_storage_files(local_csv_files):\n   virtual_disk = create_temp_memory_filesystem()\n   directory_name = str(virtual_disk[1]).split('/')[1]\n   files = set(os.listdir(local_csv_files))\n   for filename in files:\n      if filename.endswith('.csv'):\n        local_file_hash = hashlib.sha256(open(f'{local_csv_files}/{filename}', 'rb').read()).hexdigest()\n        query_google_cloud_storage_file_by_name(filename, virtual_disk[0], directory_name)\n        virtual_files = virtual_disk[0].opendir(directory_name)\n        for file_name in virtual_files.listdir('/'):\n            gs_file_hash = hashlib.sha256(open(file_name, 'rb').read()).hexdigest()\n            if local_file_hash == gs_file_hash:\n                print(f'The file - {filename} is identical in both the local file system and the Google Cloud bucket.')\n            elif local_file_hash != gs_file_hash:\n                print(f'The file - {filename} is different between the local file system and the Google Cloud bucket.')\n            virtual_files.remove(file_name)\n    virtual_disk[0].close()\n", " import fs\n import os\n import filecmp\n from google.cloud import storage\n\n def create_temp_memory_filesystem():\n    mem_fs = fs.open_fs('mem://')\n    virtual_disk = mem_fs.makedir('hidden_dir')\n    return mem_fs, virtual_disk\n\n def query_google_cloud_storage_file_by_name(filename, memory_filesystem, temp_directory):\n   client = storage.Client.from_service_account_json('path_to_your_credentials.json')\n   bucket = client.get_bucket('your_bucket_name')\n   blobs = bucket.list_blobs()\n   for blob in blobs:\n      if blob.name == filename:\n        with memory_filesystem.open(f'{temp_directory}/{filename}', 'w') as f:\n            f.write(str(blob.download_to_filename(blob.name)))\n            f.close()\n\n def compare_local_files_to_google_storage_files(local_csv_files):\n   virtual_disk = create_temp_memory_filesystem()\n   directory_name = str(virtual_disk[1]).split('/')[1]\n   files = set(os.listdir(local_csv_files))\n   for filename in files:\n      if filename.endswith('.csv'):\n        local_file = f'{local_csv_files}/{filename}'\n        query_google_cloud_storage_file_by_name(filename, virtual_disk[0], directory_name)\n        virtual_files = virtual_disk[0].opendir(directory_name)\n        for file_name in virtual_files.listdir('/'):\n          comparison = filecmp.cmp(local_file, file_name, shallow=False)\n          if comparison:\n            print(f'The file - {filename} is identical in both the local file system and the Google Cloud bucket.')\n          elif not comparison:\n                print(f'The file - {filename} is different between the local file system and the Google Cloud bucket.')\n           virtual_files.remove(file_name)\n   virtual_disk[0].close()\n"], ["#!/usr/bin/env python3\n\nimport pysftp\nimport sys\nfrom pathlib import Path\nfrom io import BytesIO\nimport re\n\nLOCAL_DIR = 'C:\\\\My\\\\Directory\\\\' # with closing separator\nREMOTE_DIR = '/home/directory/' # absolute directory with closing separator\n\n\nclass Sftp:\n    def __init__(self, host, port, username, password, deploymentDirectory, verbose=True):\n        if deploymentDirectory[-1] != '/': deploymentDirectory += '/'\n        self.deployment_directory = deploymentDirectory\n        self.verbose = verbose\n        self.connection = None\n        try:\n            self.connection = pysftp.Connection(host, port=port, username=username, password=password)\n        except Exception:\n            print('Could not connect to remote sftp server with the specified arguments.', file=sys.stderr)\n            sys.exit(1)\n\n    def __del__(self):\n        self.close()\n\n    def close(self):\n        if self.connection:\n            self.connection.close()\n            self.connection = None\n\n    def read_text_file(self, remote_file_name):\n        full_remote_file_name = self.deployment_directory + remote_file_name\n        b = BytesIO()\n        self.connection.getfo(full_remote_file_name, b)\n        s = b.getvalue().decode('utf-8')\n        return s\n\n\n    def remote_file_exists(self, remote_file_name):\n        full_remote_file_name = self.deployment_directory + remote_file_name\n        return self.connection.isfile(full_remote_file_name)\n\n\ndef compare(local_text, remote_text):\n    \"\"\"\n    The files could be the same except for the way the hosts handle the line-termination sequence (Windows: \\r\\n, Unix/Linux: \\n, Mac: \\r).\n    So, let's normalize:\n    \"\"\"\n    rex = re.compile(r'\\r\\n?')\n    local_text = rex.sub('\\n', local_text)\n    remote_text = rex.sub('\\n', remote_text)\n    return local_text == local_text\n\n\ndef main():\n    sftp = Sftp(host='demo.com', port=22, username='xxxx', password='xxxx', deploymentDirectory=REMOTE_DIR)\n    l_local_dir = len(LOCAL_DIR)\n    for path in Path(LOCAL_DIR).rglob('*.csv'):\n        dir, file_name = path.parent, path.name\n        # compute relative remote path:\n        remote_file_name = str(dir)[l_local_dir:].replace('\\\\', '/') + '/' + file_name\n        if not sftp.remote_file_exists(remote_file_name):\n            print(f'{path}: This file does not exist in remote directory.')\n        else:\n            remote_text = sftp.read_text_file(remote_file_name)\n            with path.open(encoding='utf-8') as f:\n                local_text = f.read()\n                if compare(local_text, remote_text):\n                    print(f'{path} exits in the remote directory and matches.')\n                else:\n                    print(f'{path} exits in the remote directory but does not match.')\n    sftp.close()\n\n\nmain()\n"], ["board_width = ['1', '2', '3', '4', '5', '6', '7', '8']\nboard_height = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h']\nboard = []\nfor x in board_width:  #create a list of possible board positions\n    for y in board_height:\n        board.append(x + y)\n\n\n\npieces = ['king', 'queen', 'rook', 'rook',\n          'bishop', 'bishop', 'knight', 'knight',\n          'pawn', 'pawn', 'pawn', 'pawn', 'pawn',\n          'pawn', 'pawn', 'pawn']    #list of all pieces for each player\n\nwhite_pieces = pieces.copy()\nblack_pieces = pieces.copy()\n\ndef is_valid_chess_board(chess_dict):\n\n    if 'wking' and 'bking' in chess_dict.values():\n\n        for key, value in chess_dict.items(): #iterate each dict elements\n\n            if value == '':\n                board.remove(key)\n\n            elif value.startswith('w') and key in board:  \n                lis_val = list(value)\n                lis_val.remove('w')\n                val_str = \"\".join(lis_val)\n                if val_str in white_pieces:\n                    white_pieces.remove(val_str)\n                    board.remove(key)\n                    print(f\"The White {val_str} was placed at {key}\")\n                else:\n                    print(f\"This {val_str} is not a proper Chess piece\")\n\n            elif value.startswith('b') and key in board:\n                lis_val = list(value)\n                lis_val.remove('b')\n                val_str = \"\".join(lis_val)\n                if val_str in black_pieces:\n                    black_pieces.remove(val_str)\n                    board.remove(key)\n                    print(f\"The Black {val_str} was placed at {key}\")\n                else:\n                    print(f\"This {val_str} is not a proper Chess piece\")\n\n            else:\n                print(\"You have an incomplete Chess board\")\n                break\n    else:\n        print(\"You have an incomplete Chess board!\")\n\n    print(board)\n"], ["import hashlib\nfrom pathlib import Path\nfrom time import perf_counter\n\ndef sha256sum(filename):\n    ''' source:  https://stackoverflow.com/a/44873382/13608599 '''\n    h  = hashlib.sha256()\n    b  = bytearray(128 * 1024)\n    mv = memoryview(b)\n    with open(filename, 'rb', buffering=0) as f:\n        for n in iter(lambda : f.readinto(mv), 0):\n            h.update(mv[:n])\n    return h.hexdigest()\n\ndef csv_hashes(dir_name):\n    ''' Map CSV filenames to SHA hashes. '''\n    return { csv_file: sha256sum(csv_file)\n             for csv_file in dir_name.rglob('*.csv') }\n", "local_dir = Path('../../../projects')\n\nstart = perf_counter()\nlocal_hashes = csv_hashes(local_dir)\nelapsed = perf_counter() - start\n\nrate = len(local_hashes) / elapsed\nprint(f'indexed {rate:.3f} files/sec')\n\nindexed 53.342 files/sec  ## too slow for real-world use case?\n"], [], [], [], [], ["from git import Repo\n\nrepo = Repo('my_repo')\n\n# Check differences between current files and last commit\ndiff = repo.git.diff(repo.head.commit.tree)\nprint(diff)\n"], [], ["def isValidChessBoard(board):\n      \"\"\"Validate counts and location of pieces on board\"\"\"\n    \n      # Define pieces and colors\n      pieces = ['king','queen','rook', 'knight','bishop', 'pawn']\n      colors = ['b', 'w']\n      # Set of all chess pieces\n      all_pieces = set(color+piece for piece in pieces for color in colors)\n    \n      # Define valid range for count of chess pieces by type (low, high) tuples\n      valid_counts = {'king': (1, 1),\n                  'queen': (0, 1),\n                  'rook': (0, 2),\n                  'bishop': (0, 2),\n                  'knight': (0, 2),\n                  'pawn': (0, 8)}\n    \n      # Get count of pieces on the board\n      piece_cnt = {}\n      for v in board.values():\n        if v in all_pieces:\n          piece_cnt.setdefault(v, 0)\n          piece_cnt[v] += 1\n    \n      # Check if there are a valid number of pieces\n      for piece in all_pieces:\n        cnt = piece_cnt.get(piece, 0)\n        lo, hi = valid_counts[piece[1:]]\n        if not lo <= cnt <= hi:   # Count needs to be between lo and hi\n          if lo != hi:\n            print(f\"There should between {lo} and {hi} {piece} but there are {cnt}\")\n          else:\n            print(f\"There should be {lo} {piece} but there are {cnt})\")\n          return False\n    \n      # Check if locations are valid\n      for location in board.keys():\n        row = int(location[:1])\n        column = location[1:]\n        if not ((1 <= row <= 8) and ('a' <= column <= \"h\")):\n          print(f\"Invaid to have {board[location]} at postion {location}\")\n          return False\n\n      # Check if all pieces have valid names\n      for loc, piece in board.items():\n        if piece:\n          if not piece in all_pieces:\n            print(f\"{piece} is not a valid chess piece at postion {loc}\")\n            return False\n\n      return True\n"], ["pip install torch==1.5.0 torchvision==0.6.0 -f https://download.pytorch.org/whl/torch_stable.html\n"], ["from dataclasses import dataclass, asdict\nfrom enum import Enum\n\n\n@dataclass\nclass Foobar:\n  name: str\n  template: \"FoobarEnum\"\n\n\nclass FoobarEnum(Enum):\n  FIRST = \"foobar\"\n  SECOND = \"baz\"\n\n\ndef custom_asdict_factory(data):\n\n    def convert_value(obj):\n        if isinstance(obj, Enum):\n            return obj.value\n        return obj\n\n    return dict((k, convert_value(v)) for k, v in data)\n\n\nfoobar = Foobar(name=\"John\", template=FoobarEnum.FIRST)\n\nprint(asdict(foobar, dict_factory=custom_asdict_factory))\n# {'name': 'John', 'template': 'foobar'}\n"], [], ["import json\n\ndef dumps(object):\n    def default(o):\n        if isinstance(o, Enum):\n            # use enum value when JSON deserialize the enum\n            return o.__dict__['_value_'] \n        else:\n            return o.__dict__\n    return json.dumps(object, default=default)\n\nprint(json.dumps(YOUR_OBJECT_CONTAINS_ENUMS, default=default))\n"], ["from dataclasses import dataclass, asdict\nfrom enum import Enum\nfrom typing import Union\n\n\n@dataclass\nclass Foobar:\n    name:str\n    template: Union[\"FoobarEnum\", str]\n    def __post_init__(self):\n        self.template = self.template.value\n\nclass FoobarEnum(Enum):\n    FIRST = \"foobar\"\n    SECOND = \"baz\"\n\nfoobar = Foobar(name=\"John\", template=FoobarEnum.FIRST)\nprint(asdict(foobar))\n"], ["def stop_at_four(lis):\n    new_list = []\n    start = 0\n    while start < len(lis) and lis[start] != 4:\n        new_list.append(lis[start])\n        start += 1\n    return new_list    \n    \nlist1 = [1, 6, 2, 3, 9]     \nprint(stop_at_four(list1))\n"], [], [], ["class FoobarEnum(Enum):\n  FIRST = \"foobar\"\n  SECOND = \"baz\"\n\n  def __deepcopy__(self, memo):\n      return self.value\n"], ["curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py\npython3 get-pip.py\n"], ["\nboard = {'1a': 'wrook', '1b': 'wknight', '1c': 'wbishop', '1d': 'wqueen', '1e': 'wking', '1f': 'wbishop',\n'1g': 'wknight', '1h': 'wrook','2a': 'wpawn', '2b': 'wpawn', '2c': 'wpawn', '2d': 'wpawn', '2e': 'wpawn',\n'2f': 'wpawn', '2g': 'wpawn', '2h': 'wpawn', '3a': '', '3b': '', '3c': '', '3d': '', '3e': '', '3f': '',\n'3g': '', '3h': '', '4a': '', '4b': '', '4c': '', '4d': '', '4e': '', '4f': '', '4g': '', '4h': '',\n'5a': '', '5b': '', '5c': '', '5d': '', '5e': '', '5f': '', '5g': '', '5h': '',\n'6a': '', '6b': '', '6c': '', '6d': '', '6e': '', '6f': '', '6g': '', '6h': '',\n'7a': 'bpawn', '7b': 'bpawn', '7c': 'bpawn', '7d': 'bpawn', '7e': 'bpawn', '7f': 'bpawn', '7g': 'bpawn', '7h': 'bpawn',\n'8a': 'brook', '8b': 'bknight', '8c': 'bbishop' , '8d': 'bqueen', '8e': 'bking', '8f': 'bbishop',\n'8g': 'bknight','8h': 'brook'}\n\n\n\ndef isValidChessBoard(board_dict):\n    #check for 1 black king and 1 white king\n    bking=0\n    wking=0\n    for king in board_dict.values():\n        if king == 'bking':\n            bking += 1\n        if king == 'wking':\n           wking += 1\n    if bking != 1 or wking != 1:\n        return False\n\n    # check for 8 black pawns and 8 white pawns\n    bpawn = 0\n    wpawn = 0\n    for pawn in board_dict.values():\n        if pawn == 'bpawn':\n            bpawn += 1\n        if pawn == 'wpawn':\n            wpawn += 1\n    if wpawn != 8 or wpawn != 8:\n        return False\n\n\n    #check for valid spaces\n    valid_spaces = {'1a', '1b', '1c', '1d', '1e', '1f', '1g', '1h','2a', '2b', '2c', '2d', '2e', '2f', '2g', '2h',\n    '3a', '3b', '3c', '3d', '3e', '3f', '3g', '3h','4a', '4b', '4c', '4d', '4e', '4f', '4g', '4h',\n    '5a', '5b', '5c', '5d', '5e', '5f', '5g', '5h','6a', '6b', '6c', '6d', '6e', '6f', '6g', '6h',\n    '7a', '7b', '7c', '7d', '7e', '7f', '7g', '7h','8a', '8b', '8c', '8d', '8e', '8f', '8g', '8h'}\n\n    spaces = set()\n    for i in board_dict.keys():\n        spaces.add(i) # use set add method (like append for lists)\n    if spaces != valid_spaces:\n        return False\n\n\n    #check for 16 pieces per player\n    piece_count = 0\n    for piece in board_dict.values():\n        if piece != '': # don't count the empty spaces (no pieces)\n            piece_count += 1\n    if piece_count != 32: # 16 x 2 = 32 total pieces\n        return False\n\n    return 'This is a valid board'\n\n\nprint(isValidChessBoard(board))\n"], [], ["!pip install wandb\nimport wandb\nwandb.init()\n"], ["import boto3\ndynamo = boto3.resource('dynamodb')\n\ndef truncateTable(tableName):\n    table = dynamo.Table(tableName)\n    \n    #get the table keys\n    tableKeyNames = [key.get(\"AttributeName\") for key in table.key_schema]\n\n    #Only retrieve the keys for each item in the table (minimize data transfer)\n    projectionExpression = \", \".join('#' + key for key in tableKeyNames)\n    expressionAttrNames = {'#'+key: key for key in tableKeyNames}\n    \n    counter = 0\n    page = table.scan(ProjectionExpression=projectionExpression, ExpressionAttributeNames=expressionAttrNames)\n    with table.batch_writer() as batch:\n        while page[\"Count\"] > 0:\n            counter += page[\"Count\"]\n            # Delete items in batches\n            for itemKeys in page[\"Items\"]:\n                batch.delete_item(Key=itemKeys)\n            # Fetch the next page\n            if 'LastEvaluatedKey' in page:\n                page = table.scan(\n                    ProjectionExpression=projectionExpression, ExpressionAttributeNames=expressionAttrNames,\n                    ExclusiveStartKey=page['LastEvaluatedKey'])\n            else:\n                break\n    print(f\"Deleted {counter}\")\n            \ntruncateTable(\"YOUR_TABLE_NAME\")\n"], ["pip3 install --upgrade tensorflow\n"], [], ["def blackjack(x,y,z):\n    tot=int(x+y+z)\n    if tot < 21:\n        return tot\n    \n    elif tot > 21 and x == 11 or y == 11 or z == 11:\n        tot2=tot-10\n        return tot2\n    \n    else:\n        return \"BUST\"\n        \n    \n    \nprint(blackjack(5, 6, 7))\nprint(blackjack(9, 9, 9))\nprint(blackjack(9, 9, 11))\n"], ["import boto3\n\nTABLE = ...\nID    = ...\n\ntable = boto3.resource('dynamodb').Table(TABLE)\nscan = None\n\nwith table.batch_writer() as batch:\n    count = 0\n    while scan is None or 'LastEvaluatedKey' in scan:\n        if scan is not None and 'LastEvaluatedKey' in scan:\n            scan = table.scan(\n                ProjectionExpression=ID,\n                ExclusiveStartKey=scan['LastEvaluatedKey'],\n            )\n        else:\n            scan = table.scan(ProjectionExpression=ID)\n\n        for item in scan['Items']:\n            if count % 5000 == 0:\n                print(count)\n            batch.delete_item(Key={ID: item[ID]})\n            count = count + 1\n"], [], ["import pyarrow.plasma as pa\nimport numpy as np\nclient = pa.connect(\"/tmp/plasma\")\ntemp = np.random.rand(80,80)\n"], ["import io\nimport json\nimport pandas as pd\nfrom office365.runtime.auth.authentication_context import AuthenticationContext\nfrom office365.runtime.auth.user_credential import UserCredential\nfrom office365.runtime.http.request_options import RequestOptions\nfrom office365.sharepoint.client_context import ClientContext\nfrom office365.sharepoint.files.file import File\nfrom io import BytesIO\n\n\nusername = 'abc@a.com'\npassword = 'abcd'\nsite_url = 'https://sample.sharepoint.com/_vti_bin/ExcelRest.aspx/RootFolder/ExcelFileName.xlsx/Model/Ranges('employee_list!A1%7CA10')?$format=json'      \n# Replace RootFolder/ExcelFileName.xlsx with actual path of excel file from the root.\n# Replace A1 and A10 with actual start and end of cell range.\n\nctx = ClientContext(site_url).with_credentials(UserCredential(username, password))\nrequest = RequestOptions(site_url)\nresponse = ctx.execute_request_direct(request)\njson_data = json.loads(response.content) \n    \n\n"], ["pip3 install numpy\npip3 install --pre torch torchvision -f https://download.pytorch.org/whl/nightly/cpu/torch_nightly.html\n"], ["https://site/lib/workbook.xlsx#'Sheet1'!A1\n"], ["    fullName = util.find_library( name )\n", "    fullName = '/System/Library/Frameworks/OpenGL.framework/OpenGL'\n"], [], ["import xlrd\n  \nloc = (\"File location\") \n\nwb = xlrd.open_workbook(loc) \nsheet = wb.sheet_by_index(0) \n\n# For row 0 and column 0 \nprint(sheet.cell_value(1, 0))\n"], [], ["Requests per second:    8665.48 [#/sec] (mean)\nConcurrency Level:      500\nTime taken for tests:   0.577 seconds\nComplete requests:      5000\nTime per request:       57.700 [ms] (mean)\n", "Requests per second:    3200.62 [#/sec] (mean)\nConcurrency Level:      500\nTime taken for tests:   1.562 seconds\nComplete requests:      5000\nTime per request:       156.220 [ms] (mean)\n", "web: gunicorn -w 4 -k uvicorn.workers.UvicornWorker main:app\n", "web: uvicorn main:app --workers 4\n"], [], ["app = FastAPI()\n\n@app.get(\"/hello/{number}/\")\ndef hello_world_number(number: int):\n    return {\"msg\": \"Hello World Number\", \"number\": number}\n", "In:  app.url_path_for(\"hello_world_number\", number=3)\nIn:  app.url_path_for(\"hello_world_number\", number=50)\n\nOut: /hello/3/\nOut: /hello/50/\n", "router = APIRouter()\n\n@router.get(\"/hello\")\ndef hello_world():\n    return {\"msg\": \"Hello World\"}\n\nIn:  router.url_path_for(\"hello_world\")\nOut: /hello\n"], [], [], ["grep -n 'password_admin' /tmp/config.yml | cut -d ':' -f1\n", "sed -i '6s/.*/    password: \\'new_admin_pass\\'/' /tmp/config.yml\n"], ["$ awk -v new=\"'sumthin'\" 'prev==\"main:\"{sub(/\\047.*/,\"\"); $0=$0 new} {prev=$1} 1' file\ndb:\n  host: 'x.x.x.x.x'\n  main:\n    password: 'sumthin'\n  admin:\n    password: 'password_admin'\n", "new=\"'sumthin'\" awk 'prev==\"main:\"{sub(/\\047.*/,\"\"); $0=$0 ENVIRON[\"new\"]} {prev=$1} 1' file\n"], ["pw='new_&pass'\nawk -v pw=\"${pw//&/\\\\\\\\&}\" '/^[[:blank:]]*main:/ {\n   print\n   if (getline > 0 && $1 == \"password:\")\n      sub(/\\047[^\\047]*\\047/, \"\\047\" pw \"\\047\")\n} 1' file\n", "db:\n  host: 'x.x.x.x.x'\n  main:\n    password: 'new_&pass'\n  admin:\n    password: 'password_admin'\n"], ["awk -v s1=\"'\" -v new_pass=\"new_value_here\" '\n/main:/{\n  main_found=1\n  print\n  next\n}\nmain_found && /password/{\n  next\n}\n/admin:/ && main_found{\n  print \"    password: \" s1 new_pass s1 ORS $0\n  main_found=\"\"\n  next\n}\n1\n'  Input_file\n"], [], [], [], ["sudo easy_install pip  \n", "pip install beautifulsoup4\n", "python -m pip install beautifulsoup4\n"], ["def valid_chess_board(board):\n    bpieces, wpieces = 0, 0\n    pieces = (\"king\", \"queen\", \"rook\", \"bishop\", \"knight\", \"pawn\")\n    board_pieces = list(board.values())\n\n    # Checking the kings\n    if board_pieces.count(\"bking\") != 1 or board_pieces.count(\"wking\") != 1:\n        return False\n\n    # Checking the pawns\n    if board_pieces.count(\"bpawn\") > 8 or board_pieces.count(\"wpawn\") > 8:\n        return False\n\n    # Checking the colors\n    for p in board_pieces:\n        if p[0] == \"b\" and p[1:] in pieces:\n            bpieces += 1\n        elif p[0] == \"w\" and p[1:] in pieces:\n            wpieces += 1\n        else:\n            return False\n\n    # Checking the pieces\n    if bpieces > 16 or wpieces > 16:\n        return False\n\n    # Checking the spaces\n    for s in board:\n        if s[0] not in \"12345678\" or s[1] not in \"abcdefgh\":\n            return False\n\n    return True\n\nchess_board = {\n    \"1a\": \"wrook\",\n    \"2a\": \"wpawn\",\n    \"6a\": \"bpawn\",\n    \"8a\": \"brook\",\n    \"2b\": \"wpawn\",\n    \"5b\": \"bpawn\",\n    \"1c\": \"wbishop\",\n    \"2c\": \"wbishop\",\n    \"3c\": \"wpawn\",\n    \"6c\": \"bknight\",\n    \"7c\": \"bpawn\",\n    \"1d\": \"wqueen\",\n    \"2d\": \"wknight\",\n    \"5d\": \"bpawn\",\n    \"8d\": \"bqueen\",\n    \"6e\": \"bbishop\",\n    \"7e\": \"bbishop\",\n    \"1f\": \"wrook\",\n    \"2f\": \"wpawn\",\n    \"3f\": \"wknight\",\n    \"6f\": \"bknight\",\n    \"8f\": \"brook\",\n    \"1g\": \"wking\",\n    \"2g\": \"wpawn\",\n    \"7g\": \"bpawn\",\n    \"8g\": \"bking\",\n    \"2h\": \"wpawn\",\n    \"7h\": \"bpawn\",\n}\n\nprint(valid_chess_board(chess_board))\n"], [], ["#!/usr/bin/env python3\n\nimport struct\nimport redis\nimport numpy as np\n\ndef toRedis(r,a,n):\n   \"\"\"Store given Numpy array 'a' in Redis under key 'n'\"\"\"\n   h, w = a.shape\n   shape = struct.pack('>II',h,w)\n   encoded = shape + a.tobytes()\n\n   # Store encoded data in Redis\n   r.set(n,encoded)\n   return\n\ndef fromRedis(r,n):\n   \"\"\"Retrieve Numpy array from Redis key 'n'\"\"\"\n   encoded = r.get(n)\n   h, w = struct.unpack('>II',encoded[:8])\n   # Add slicing here, or else the array would differ from the original\n   a = np.frombuffer(encoded[8:]).reshape(h,w)\n   return a\n\n# Create 80x80 numpy array to store\na0 = np.arange(6400,dtype=np.uint16).reshape(80,80) \n\n# Redis connection\nr = redis.Redis(host='localhost', port=6379, db=0)\n\n# Store array a0 in Redis under name 'a0array'\ntoRedis(r,a0,'a0array')\n\n# Retrieve from Redis\na1 = fromRedis(r,'a0array')\n\nnp.testing.assert_array_equal(a0,a1)\n", "80x80 Numpy array of np.uint16   => 58 microseconds to write\n200x200 Numpy array of np.uint16 => 88 microseconds to write\n"], [], ["from selenium import webdriver\nfrom selenium.webdriver.firefox.options import Options\nfrom webdriver_manager.firefox import GeckoDriverManager\noptions = Options()\noptions.headless = True\ndriver = webdriver.Firefox(executable_path=GeckoDriverManager().install(),firefox_options=options)\ndriver.get(\"https://google.com\")\nprint('Done')\ndriver.quit()\n"], ["pip install torch==1.4.0+cpu torchvision==0.5.0+cpu -f https://download.pytorch.org/whl/torch_stable.html\n"], ["from selenium.webdriver.firefox.options import Options\n\noptions = Options()\noptions.add_argument('--headless')\ndriver = webdriver.Firefox(executable_path='path to the driver', options=options)\n"], ["pip install webdriver-manager \nfrom webdriver_manager.firefox import GeckoDriverManager\nself.browser = webdriver.Firefox(executable_path=GeckoDriverManager().install())\n"], ["python3 -m ensurepip --upgrade\n"], [], [], [], [], ["def stop_at_four(lst):\n    n = 0\n    new_lst = []\n    if len(lst) == 0:\n        return new_lst\n    else:\n        while lst[n] != 4 and n < len(lst):\n            new_lst.append(lst[n])\n            n += 1\n        return new_lst\nlst = [3, 5, 7, 9.5, 7, 1, 4]\nprint(stop_at_four(lst))`\n"], ["image_size = (212, 212)\nbatch_size = 32\n\ndata_augmentation = keras.Sequential(\n    [\n        layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n        layers.experimental.preprocessing.RandomRotation(0.8),\n    ]\n)\n\n\ndef make_model(input_shape, num_classes):\n    inputs = keras.Input(shape=input_shape)\n    # Image augmentation block\n    x = data_augmentation(inputs)\n\n    # Entry block\n    x = layers.experimental.preprocessing.Rescaling(1.0 / 255)(x)\n    x = layers.Conv2D(32, 3, strides=2, padding=\"same\")(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation(\"relu\")(x)\n\n    x = layers.Conv2D(64, 3, padding=\"same\")(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation(\"relu\")(x)\n\n    previous_block_activation = x  # Set aside residual\n\n    for size in [128, 256, 512, 728]:\n        x = layers.Activation(\"relu\")(x)\n        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n        x = layers.BatchNormalization()(x)\n\n        x = layers.Activation(\"relu\")(x)\n        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n        x = layers.BatchNormalization()(x)\n\n        x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n\n        # Project residual\n        residual = layers.Conv2D(size, 1, strides=2, padding=\"same\")(\n            previous_block_activation\n        )\n        x = layers.add([x, residual])  # Add back residual\n        previous_block_activation = x  # Set aside next residual\n\n    x = layers.SeparableConv2D(1024, 3, padding=\"same\")(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation(\"relu\")(x)\n\n    x = layers.GlobalAveragePooling2D()(x)\n    if num_classes == 2:\n        activation = \"sigmoid\"\n        units = 1\n    else:\n        activation = \"softmax\"\n        units = num_classes\n\n    x = layers.Dropout(0.5)(x)\n    outputs = layers.Dense(units, activation=activation)(x)\n    return keras.Model(inputs, outputs)\n\n\nmodel = make_model(input_shape=image_size + (3,), num_classes=2)\nkeras.utils.plot_model(model, show_shapes=False)\n", "model.load_weights('save_at_47.h5')\n", "# Running inference on new data\nimg = keras.preprocessing.image.load_img(\n    \"le_image.jpg\", target_size=image_size\n)\nimg_array = keras.preprocessing.image.img_to_array(img)\nimg_array = tf.expand_dims(img_array, 0)  # Create batch axis\n\npredictions = model.predict(img_array)\nscore = predictions[0]\nprint(\n    \"This image is %.2f percent negative and %.2f percent positive.\"\n    % (100 * (1 - score), 100 * score)\n)\n"], [], ["docker run -p 6379:6379 -d redis:5\n"], [], ["import pandas as pd\n\nnew_list =['whatever']\npd.Series(new_list)\nnew_list.to_excel('aFileName.xlsx')\n"], ["cd /usr/bin/\nrm python3\nln -s python3.6 python3\n"], [], ["from spacy.matcher import Matcher\n\nmatcher = Matcher(nlp.vocab)\nmatcher.add(\"dog\", on_match, [{\"LOWER\": \"dog\"}])\n\ndef replace_word(doc, replacement):\n    doc = nlp(doc)\n    match_id, start, end = matcher(doc)[0] #assuming only one match replacement\n\n    return nlp.make_doc(doc[:start].text + f\" {replacement}\" + doc[-1].text)\n\n>>> replace_word(\"Hi this is my dog.\", \"Simba\")\nHi this is my Simba.\n", "import re\ndef replace_word_re(text, word, replacement):\n    return re.sub(word, replacement, text)\n\n>>> replace_word_re(\"Hi this is my dog.\", \"dog\", \"Simba\")\nHi this is my Simba.\n"], ["string = \"Hi this is my dog.\"\nstring = string.replace(\"dog\",\"Simba\")\n"], ["pip37 install torch-1.5.1+cpu-cp37-cp37m-win_amd64.whl\npip37 install torchvision-0.6.1+cpu-cp37-cp37m-win_amd64.whl\n"], [], ["!pip install wandb\nimport wandb\nwandb.init()\n"], [], [], [], [], ["replacers = {',':'','.':'','-':'','ltd':'limited'} #etc....\ndf1['CompanyA'] = df1['CompanyA'].replace(replacers)\n"], ["def remover(row, replaces):\n    for k,v in replacers.items():\n        if k in row:\n            row = row.replace(k, v)\n    return row      \n\n\nreplacers = {',' : \"\",\n         '.':'',\n         '-':'',\n         'ltd':'limited'\n        }\n\nfor column in df.columns:\n    df[column] = df[column].apply(lambda row: remover(row, replacers))\n"], ["to_replace = {'.': '',\n              ',': '',\n              'foo': 'bar'\n             }\n\nfor k, v in to_replace.items():\n    df1['CompanyA'] = df1['CompanyA'].str.replace(k, v)\n"], ["df1.replace({'CompanyA' : { '&' : 'and', '.': '' , '-': ''}},regex=True)\n"], ["df1['CompanyA'] = df1['CompanyA'].str.replace('.','').replace('-','').replace(',','').replace('ltd','limited').replace('&','and')\n...\n"], ["X_train, y_train, X_test, y_test = None\n"], ["def stop_at_four(lst):\n    n = 0\n    new_lst = []\n    while lst[n] != 4:\n        new_lst.append(lst[n])\n        n += 1\n    return new_lst\nlst = [1,2,4,6,12]\nprint(stop_at_four(lst))\n"], ["from github import Github\nmy_reviewers = ['usernames', 'of_reviewers']\ngh = Github(\"<token string>\")\nrepo_name = '<my_org>/<my_repo>'\nrepo = gh.get_repo(repo_name)\ndefault_branch_name = repo.default_branch\nbase = repo.get_branch(default_branch_name)\nnew_branch_name = \"my_new_branchname\"\nnew_branch = repo.create_git_ref(ref=f'refs/heads/{new_branch_name}',sha=base.commit.sha)\ncontents = repo.get_contents(\"some_script_in_repo.sh\", ref=new_branch_name)\nrepo.delete_file(contents.path, \"commit message\", contents.sha, branch=new_branch_name)\npr = repo.create_pull(\n    title=\"PR to Remove some_script_in_repo.sh\",\n    body=\"This is the text in the main body of your pull request\",\n    head=new_branch_name,\n    base=default_branch_name,\n)\npr.create_review_request(reviewers=my_reviewers)\n"], [], [], ["def encode_vector(ar):\n    return base64.encodestring(ar.tobytes()).decode('ascii')\n\ndef decode_vector(ar):\n    return np.fromstring(base64.decodestring(bytes(ar.decode('ascii'), 'ascii')), dtype='uint16')\n"], [], ["timeit.timeit('%s'%(add(1,2)))\nor\ntimeit.timeit(f'{add(1,2)}')\n"], ["print(func(9,9,9)) # bust\n\nprint(func(11,11,11)) # 13\n\nprint(func(11,10,9,9)) # bust\n"], ["s=\"YYYYMMDD\"\ns=s[:4]+\"-\"+ s[4:6]+\"-\"+s[6:]\n"], ["before = '20190501'\nprint('before:', before)\nafter = ''.join((before[:4],'-',before[4:6],'-',before[6:]))\nprint('after:', after)\n"], ["d = '20190501'\nprint(d[0:4] + '-' + d[4:6] + '-' + d[6:8])\n"], [">>> date = '20190501'\n>>> newdate = \"{}-{}-{}\".format(date[:4],date[4:6],date[6:])\n>>> newdate\n'2019-05-01'\n"], [], ["my_array = np.array([-1.2, 3.0, -10.11, 5.2])\nsol = np.asarray([0 if val < 0 else 1 for val in my_array])\n"], ["np.where(arr < 0, 0, 1)\n"], ["model = tensorflow.keras.Sequential()\n"], ["import numpy as np\n\ndef unit(elem):\n    if elem < 0:\n        elem = 0\n    else:\n        elem = 1\na = np.array([[1, 2, -0.5], [0.5, 2, 3]])\nvfunc = np.vectorize(unit)\nvfunc(a)\n\n# array([[1, 1, 0], [1, 1, 1]])\n"], ["arr = (arr >= 0).astype(int)\n"], ["import numpy as np\n\na=np.array([-2,-1,0,1,2])\n\na[a>=0]=1\na[a<0]=0\n\n>>> a\narray([0, 0, 1, 1, 1])\n"], ["import dataclasses\n\n\n@dataclasses.dataclass\nclass FileObject:\n    uploaded_by: str = None\n\n    def save(self):\n        print(self.uploaded_by)\n\n    @property\n    def _uploaded_by(self):\n        return self._uploaded_by_attr\n\n    @_uploaded_by.setter\n    def _uploaded_by(self, uploaded_by):\n        # print('Setter Called with Value ', uploaded_by)\n        self._uploaded_by_attr = uploaded_by\n\n\n# --- has to be called at module level ---\nFileObject.uploaded_by = FileObject._uploaded_by\n\n\ndef main():\n    p = FileObject()\n    p.save()                            # displays 'None'\n\n    p = FileObject()\n    p.uploaded_by = 'foo'\n    p.save()                            # displays 'foo'\n\n    p = FileObject(uploaded_by='bar')\n    p.save()                            # displays 'bar'\n\n\nif __name__ == '__main__':\n    main()\n"], ["def blackjack(a,b,c):  \n    total = a+b+c\n    if total <= 21:     \n        return total\n    elif 11 in [a,b,c] and total > 21:   \n        new_total = total-10     \n        if new_total > 21:    \n            return 'Bust' \n        else:         \n            return new_total   \n    else: \n        return 'Bust'\n"], ["rasa run actions\n", "rasa x\n"], [], ["brew install portaudio\n", "brew link portaudio\n\npip install pyAudio\n"], [], [], [], ["import cv2\nimport numpy as np\nimg = cv2.imread('statue.png')\ngray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\nthresh = cv2.threshold(gray, 220, 255, cv2.THRESH_BINARY_INV)[1]\nsz=thresh.shape\ntop=divmod(np.flatnonzero(thresh)[0], sz[0])[::-1]\nbotton=divmod(np.flatnonzero(thresh)[-1], sz[0])[::-1]\nthresh=thresh.T\nleft=divmod(np.flatnonzero(thresh)[0], sz[1])\nright=divmod(np.flatnonzero(thresh)[-1], sz[1])\nprint(left, right, top, botton, sep='\\n')\n"], [], [], [], [], ["import tensorflow as tf\nimport tensorflow.keras as keras\n#import keras\nimport keras.backend as K\nfrom keras.models import Model, Sequential, load_model\nfrom keras.layers import Dense, Embedding, Dropout, Input, Concatenate\n\nprint(\"Python: \"+str(sys.version))\nprint(\"Tensorflow version: \"+tf.__version__)\nprint(\"Keras version: \"+keras.__version__)\n", "Python: 3.6.9 (default, Nov  7 2019, 10:44:02) \n[GCC 8.3.0]\nTensorflow version: 2.1.0\nKeras version: 2.2.4-tf\n"], [], ["from selenium import webdriver\n\noptions = webdriver.ChromeOptions()\noptions.add_argument(\"--start-maximized\")\noptions.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\noptions.add_experimental_option('useAutomationExtension', False)\ndriver = webdriver.Chrome(chrome_options=options, executable_path=r'C:\\Utility\\BrowserDrivers\\chromedriver.exe')\ndriver.get('https://www.google.co.in')\ndriver.minimize_window()\n"], ["from selenium import webdriver\nfrom selenium.webdriver.chrome.options import Options\n\ndriver_exe = 'chromedriver'\noptions = Options()\noptions.add_argument(\"--headless\")\ndriver = webdriver.Chrome(driver_exe, options=options)\n"], ["pip install torch===1.4.0 torchvision===0.5.0 -f https://download.pytorch.org/whl/torch_stable.html\n"], ["from selenium import webdriver\nfrom xvfbwrapper import Xvfb\n\ndisplay = Xvfb()\ndisplay.start()\n\ndriver = webdriver.Chrome()\ndriver.get('http://www.stackoverflow.com')\n\nprint(driver.title)\ndriver.quit()\n\ndisplay.stop()\n"], [], [], [], ["-   libcrypto-1_1-x64.dll\n-   libssl-1_1-x64.dll \n"], [], ["import pgi\npgi.install_as_gi()\nfrom gi.repository import GLib, Gio\n"], ["import pandas as pd\nimport keras\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import *\n\ntraining_data_df = pd.read_csv(\"sales_data_training_scaled.csv\")\n\nX = training_data_df.drop('total_earnings', axis=1).values\nY = training_data_df[['total_earnings']].values\n\n# Define the model\nmodel = Sequential()\nmodel.add(Dense(50, input_dim=9, activation='relu', name='layer_1'))\nmodel.add(Dense(100, activation='relu', name='layer_2'))\nmodel.add(Dense(50, activation='relu', name='layer_3'))\nmodel.add(Dense(1, activation='linear', name='output_layer'))\nmodel.compile(loss='mean_squared_error', optimizer='adam')\n\n# Create a TensorBoard logger\nlogger = tf.keras.callbacks.TensorBoard(\n    log_dir='logs',\n    write_graph=True,\n    histogram_freq=5\n)\n\n# Train the model\nmodel.fit(\n    X,\n    Y,\n    epochs=50,\n    shuffle=True,\n    verbose=2,\n    callbacks=[logger]\n)\n\n# Load the separate test data set\ntest_data_df = pd.read_csv(\"sales_data_test_scaled.csv\")\n\nX_test = test_data_df.drop('total_earnings', axis=1).values\nY_test = test_data_df[['total_earnings']].values\n\ntest_error_rate = model.evaluate(X_test, Y_test, verbose=0)\nprint(\"The mean squared error (MSE) for the test data set is: {}\".format(test_error_rate))\n"], ["from keras.models import Sequential\n", "from tensorflow.keras.models import Sequential\n"], [], [], [], [], [], ["cd /tmp; python -c 'from gocd import Server'\necho $?\n0\n", "cp gocd.py /tmp\ncd /tmp; python -c 'from gocd import Server'\nTraceback (most recent call last):\n  File \"<string>\", line 1, in <module>\n  File \"/tmp/gocd.py\", line 3, in <module>\n    from gocd import Server\nImportError: cannot import name 'Server' from partially initialized module 'gocd' (most likely due to a circular import) (/tmp/gocd.py)\n"], ["dates = [datetime.strptime(d, \"%Y-%m-%d\") for d in dates] # new datetime parsed from a string\ndate_ints = [d.toordinal() for d in dates]  # toordinal() returns the day count from the date 01/01/01 in integers\nranges = {}; arange = []; prev=0; index=0; j=1\nfor i in date_ints: # iterate through date integers\n    if i+1 == date_ints[index] + 1 and i - 1 == prev: # check and compare if integers are in sequence\n        arange.append(dates[index].strftime(\"%Y-%m-%d\"))\n    elif prev == 0: # append first date to 'arange' list since 'prev' has not been updated\n        arange.append(dates[index].strftime(\"%Y-%m-%d\"))\n    else:\n        ranges.update({f'Range{j}': tuple(arange)}) # integer are no longer in sequence, update dictionary with new range  \n        arange = []; j += 1                                   # clear 'arange' and start appending to new range  \n        arange.append(dates[index].strftime(\"%Y-%m-%d\"))\n    index += 1; prev = i\nranges.update({f'Range{j}': tuple(arange)})\nprint(ranges)  \nprint(ranges['Range1'])  # access a range based on the associated key\nprint(ranges['Range2']) \n", "{'Range1': ('2020-01-01', '2020-01-02', '2020-01-03'), 'Range2': ('2020-01-06', '2020-01-07', '2020-01-08')}\n('2020-01-01', '2020-01-02', '2020-01-03')\n('2020-01-06', '2020-01-07', '2020-01-08')\n"], ["pto = [\n    '2020-01-03',\n    '2020-01-08',\n    '2020-01-02',\n    '2020-01-07',\n    '2020-01-01',\n    '2020-01-06'\n]\n\nordinal_dates = [datetime.datetime.strptime(i, '%Y-%m-%d').toordinal() for i in pto]\n", "def ranges(nums):\n    nums = sorted(set(nums))\n    gaps = [[s, e] for s, e in zip(nums, nums[1:]) if s+1 < e]\n    edges = iter(nums[:1] + sum(gaps, []) + nums[-1:])\n    return list(zip(edges, edges))\n", "def get_date_ranges(pto_list: list) -> list:\n    pto_dates = [datetime.datetime.strptime(i, '%Y-%m-%d').toordinal() for i in pto_list]\n    nums = sorted(set(pto_dates))\n    gaps = [[s, e] for s, e in zip(nums, nums[1:]) if s + 1 < e]\n    edges = iter(nums[:1] + sum(gaps, []) + nums[-1:])\n    ordinal_ranges = list(zip(edges, edges))\n    date_bounds = []\n    for start, end in ordinal_ranges:\n        date_bounds.append((\n            datetime.datetime.fromordinal(start).strftime('%Y-%m-%d'),\n            datetime.datetime.fromordinal(end).strftime('%Y-%m-%d')\n        ))\n    return date_bounds\n"], ["ranges = []\n\ndates = [datetime.strptime(date, '%Y-%m-%d') for date in dates]\nstart = dates[0]\n\nfor i in range(1, len(dates)):\n    if (dates[i] - dates[i-1]).days == 1 and i==len(dates)-1:\n        end = dates[i]\n        ranges.append(f'{start} to {end}')\n        start = dates[i]\n    elif (dates[i] - dates[i - 1]).days > 1:\n        end = dates[i - 1]\n        ranges.append(f'{start} to {end}')\n        start = dates[i]\n    else:\n        continue\n"], ["def makedate(s):\n    return datetime.strptime( s, \"%Y-%m-%d\" )\ndef splitIntoRanges( dates ):\n    ranges = []\n    start_s = last_s = dates[0]\n    last = makedate(start_s)\n    for curr_s in dates[1:]:\n        curr = makedate(curr_s)\n        if (curr - last).days > 1:\n            ranges.append((start_s,last_s))\n            start_s = curr_s\n        last_s = curr_s\n        last = curr\n    return ranges + [(start_s,last_s)]\n"], ["In [11]: import dataclasses\n    ...:\n    ...: @dataclasses.dataclass\n    ...: class FileObject:\n    ...:     uploaded_by: str\n    ...:     _uploaded_by: str = dataclasses.field(repr=False, init=False)\n    ...:     def save(self):\n    ...:         print(self.uploaded_by)\n    ...:\n    ...:     def _get_uploaded_by(self):\n    ...:         return self._uploaded_by\n    ...:\n    ...:     def _set_uploaded_by(self, uploaded_by):\n    ...:         print('Setter Called with Value ', uploaded_by)\n    ...:         self._uploaded_by = uploaded_by\n    ...:     uploaded_by = property(_get_uploaded_by, _set_uploaded_by)\n    ...: p = FileObject()\n    ...: p.save()\nSetter Called with Value  <property object at 0x10761e7d0>\n<property object at 0x10761e7d0>\n", "In [13]: @dataclasses.dataclass\n    ...: class Foo:\n    ...:     bar:int = 1\n    ...:     bar = 2\n    ...:\n\nIn [14]: Foo()\nOut[14]: Foo(bar=2)\n", "In [22]: import dataclasses\n    ...:\n    ...: @dataclasses.dataclass\n    ...: class FileObject:\n    ...:     uploaded_by: str\n    ...:     _uploaded_by: str = dataclasses.field(repr=False, init=False)\n    ...:     @property\n    ...:     def uploaded_by(self):\n    ...:         return self._uploaded_by\n    ...:     @uploaded_by.setter\n    ...:     def uploaded_by(self, uploaded_by):\n    ...:         print('Setter Called with Value ', uploaded_by)\n    ...:         self._uploaded_by = uploaded_by\n    ...:\n    ...: p = FileObject(None)\n    ...: print(p.uploaded_by)\nSetter Called with Value  None\nNone\n\nIn [23]: FileObject()\nSetter Called with Value  <property object at 0x1086debf0>\nOut[23]: FileObject(uploaded_by=<property object at 0x1086debf0>)\n", "import dataclasses\nimport typing\n@dataclasses.dataclass\nclass FileObject:\n    uploaded_by:typing.Optional[str]=None\n\n    def _uploaded_by_getter(self):\n        return self._uploaded_by\n\n    def _uploaded_by_setter(self, uploaded_by):\n        print('Setter Called with Value ', uploaded_by)\n        self._uploaded_by = uploaded_by\n\nFileObject.uploaded_by = property(\n    FileObject._uploaded_by_getter,\n    FileObject._uploaded_by_setter\n)\np = FileObject()\nprint(p)\nprint(p.uploaded_by)\n"], ["raw_xml = parser.from_file(file, xmlContent=True)\nbody = raw_xml['content'].split('<body>')[1].split('</body>')[0]\nbody_without_tag = body.replace(\"<p>\", \"\").replace(\"</p>\", \"\").replace(\"<div>\", \"\").replace(\"</div>\",\"\").replace(\"<p />\",\"\")\ntext_pages = body_without_tag.split(\"\"\"<div class=\"page\">\"\"\")[1:]\nnum_pages = len(text_pages)\nif num_pages==int(raw_xml['metadata']['xmpTPg:NPages']) : #check if it worked correctly\n     return text_pages\n"], ["def stop_at_four():  \n    list_=[3,6,4,1,3]\n    accum_lst=[]\n    accum_var=0\n\n    while list_[accum_var] !=4:\n        accum_lst.append(list_[accum_var])\n        accum_var+=1\n    return accum_lst\n"], ["def stop_at_four():\n    list_=[3,6,4,1,3]\n    accum_lst=[]\n    accum_var=0\n\n    while list_[accum_var] != 4 :\n        accum_lst.append(list_[accum_var])\n        accum_var += 1\n    return accum_lst\n\nprint(stop_at_four())\n"], ["def stop_at_four(my_list):\n    accum_lst=[]\n    accum_var=0\n\n    while (accum_var < len(my_list)) and (my_list[accum_var] != 4):\n        accum_lst.append(my_list[accum_var])\n        accum_var+=1\n    return accum_lst\n\nprint(stop_at_four([3,6,4,1,3]))\n"], [], ["C:\\Users\\winuser\\AppData\\Local\\Packages\\CanonicalGroupLimited.Ubuntu18.04onWindows_79rhkp1fndgsc\\LocalState\\rootfs\\home\\wslusr\\anaconda3\\envs\\myenv\\bin \n"], ["pip3 install https://download.pytorch.org/whl/cu90/torch-1.1.0-cp37-cp37m-win_amd64.whl\npip3 install https://download.pytorch.org/whl/cu90/torchvision-0.3.0-cp37-cp37m-win_amd64.whl\n", "pip3 install torch===1.3.1 torchvision===0.4.2 -f https://download.pytorch.org/whl/torch_stable.html\n"], ["FROM node:10\nWORKDIR /usr/app\nCOPY ./src .\nRUN npm install\nEXPOSE 3000 # Use here the port you want to expose\n"], [], ["\nfrom docx import Document\n\ndocument = Document('anydoccumnet.docx')\nfor para in document.paragraphs:\n    print(para.text)\n"], [], [], ["For two strings of length      10, concatenation is 1.06938 times faster than f-strings\nFor two strings of length     100, concatenation is 1.14887 times faster than f-strings\nFor two strings of length    1000, concatenation is 1.13994 times faster than f-strings\nFor two strings of length   10000, concatenation is 1.26934 times faster than f-strings\nFor two strings of length  100000, concatenation is 1.21585 times faster than f-strings\nFor two strings of length 1000000, concatenation is 1.01816 times faster than f-strings\n", "For three strings of length      10, concatenation is 0.77931 times faster than f-strings\nFor three strings of length     100, concatenation is 0.67699 times faster than f-strings\nFor three strings of length    1000, concatenation is 0.60220 times faster than f-strings\nFor three strings of length   10000, concatenation is 1.27484 times faster than f-strings\nFor three strings of length  100000, concatenation is 0.98911 times faster than f-strings\nFor three strings of length 1000000, concatenation is 0.60201 times faster than f-strings\n"], [], [], ["rasa run actions\n", "rasa x\n", "rasa shell\n"], ["action_endpoint:\n  url: \"http://localhost:5055/webhook\"\n"], [">>> myspearman = stats.pearsonr(sequence_1,sequence_2)\n/Users/rlucas/scipy-dev/scipy/scipy/stats/stats.py:3508: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n  warnings.warn(PearsonRConstantInputWarning())\n"], ["from scipy import stats\nsequence_1 = [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0]\nsequence_2 = [0, 0.009783728115345005, 0, 0, 0.0019759230121848587, 0.0007535430349118562, 0.0002661781514710257, 0, 0, 0.0007835762419683435]\nmyspearman = stats.spearmanr(sequence_1,sequence_2)\nprint(myspearman)\n", "SpearmanrResult(correlation=0.30949223029508643, pvalue=0.3841919479937841)\n"], [], [], [], ["conda install pytorch torchvision cudatoolkit=10.1 -c pytorch\n"], ["$ conda install tensorflow=2.0 python=3.7\n", "$ conda install tensorflow-gpu=2.0 python=3.7\n"], [], ["x=re.findall(\".*\".join(list(letters)),guess)\n\nif (x):\n    print(\"yes\")\nelse:\n    print(\"no\")\n"], ["def blackjack(a,b,c):\n\n    Ace_count = [a,b,c].count(11)\n\n    total = sum([a,b,c])\n\n    if total <= 21:\n        return (\"Not busted\", total)\n\n    while total > 21:\n        if Ace_count > 0:\n            Ace_count -= 1\n            total -= 10\n        else:\n            return \"Bust\"\n\n    return (\"Not busted\", total)\n\nprint(blackjack(11,11,11))\n", "('Not busted', 13)\n"], ["from os.path import join, abspath, dirname\nbase_path = dirname(dirname(abspath(__file__)))\nos.environ['PATH'] = '%s%s' % (\n    os.environ['PATH'],\n    join(base_path, 'Library', 'bin'),\n)\n"], ["pattern = \"xyz\"                     # can be replaced to have the desired pattern\nlst =[\"crossword\", \"crowd\"]         # this can be replaced to contain the words of your choice\npattern = '.*'.join(list(pattern))  # modifies the pattern to include .* between each of the characters of the pattern\nobj = re.compile(pattern)          # create compiled regex object to use it again and again\nfor word in lst:\n    if obj.search(word):\n        print \"Yes\"\n    else:\n        print \"No\"\n"], ["c.*w.*d\n"], ["pip3 install https://download.pytorch.org/whl/cu90/torch-1.0.1-cp37-cp37m-win_amd64.whl\n"], ["@app.route('/login',methods=[\"POST\",\"GET\"])\ndef login():\n    if request.method==\"POST\":\n        user=request.form[\"nm\"]\n    else:\n        user=request.args.get(\"nm\")\n    if user:\n        return redirect(url_for('success', name = str(user)))\n    else:\n        return \"go to the form\"\n"], [], ["def order(sentence):\n    words = sentence.split()\n    ordered_words = sorted(words, key=int_from_word)\n    return \" \".join(ordered_words)\n\ndef int_from_word(word):\n    for character in word:\n        if character.isdigit():\n            return int(character)\n    return None\n\nprint(order(\"is2 Thi1s T4est 3a\"))\n", "Thi1s is2 3a T4est\n"], ["import re\n\ns = \"is2 Thi1s T4est 3a\"\nwords = s.split()\n\nmyre = re.compile(r'\\d+')\nwords.sort(key=lambda x: myre.findall(x))\n\nprint(' '.join(words))\n", "import re\n\ns = \"is2 Thi1s T4est 3a\"\nnew = ' '.join(sorted(s.split(), key=lambda x: re.findall(r'\\d+', x)))\nprint(new)\n"], ["sentence = \"is2 Thi1s T4est 3a\"\n\ndef order(sentence):\n    # creates a tuple of (int, word) for each word in the sentence\n    # we need a nested listed comprehension to iterate each letter in the word\n    # [... for w in sentence.split() ...] -> for each word in the sentence\n    # [... for l in w ...] -> for each letter in each word\n    # [... if l.isdigit()] -> if the letter is a digit\n    # [(int(l), w) ...] -> add a tuple of (int(letter), word) to the final list\n    words = [(int(l), w) for w in sentence.split() for l in w if l.isdigit()]\n    words.sort(key=lambda t: t[0])\n    return \" \".join(t[1] for t in words)\n\nprint(order(sentence))\n\n>>> Thi1s is2 3a T4est\n", "sentence = \"is2 Thi1s T4est 3a\"\nnew = \" \".join(t[1] for t in sorted([(int(l), w) for w in sentence.split() for l in w if l.isdigit()], key=lambda t: t[0]))\nprint(new)\n\n>>> Thi1s is2 3a T4est\n"], [], ["import numpy as np\n\n# Total up all the elements in each column\ncolsums = np.sum(gray, axis=0)\n", "array([153000, 153000, 153000, 153000, 153000, 153000, 153000, 153000,\n       153000, 153000, 153000, 153000, 153000, 153000, 153000, 153000,\n       153000, 153000, 153000, 153000, 153000, 153000, 153000, 153000,\n       153000, 153000, 153000, 153000, 153000, 153000, 153000, 153000,\n       153000, 153000, 153000, 153000, 153000, 153000, 153000, 153000,\n       153000, 153000, 153000, 153000, 153000, 153000, 153000, 153000,\n       153000, 153000, 153000, 153000, 153000, 153000, 153000, 153000,\n       153000, 153000, 153000, 153000, 153000, 153000, 153000, 153000,\n       153000, 153000, 153000, 153000, 153000, 153000, 153000, 153000,\n       153000, 153000, 153000, 153000, 153000, 153000, 153000, 153000,\n       153000, 153000, 153000, 153000, 153000, 153000, 153000, 153000,\n       153000, 153000, 153000, 153000, 153000, 153000, 153000, 153000,\n       153000, 153000, 153000, 153000, 153000, 153000, 153000, 153000,\n       153000, 153000, 153000, 153000, 153000, 153000, 153000, 153000,\n       153000, 153000, 153000, 153000, 153000, 153000, 153000, 153000,\n       153000, 153000, 153000, 153000, 153000, 153000, 153000, 153000,\n       153000, 153000, 153000, 153000, 153000, 153000, 153000, 153000,\n       153000, 153000, 153000, 153000, 153000, 153000, 153000, 153000,\n       153000, 153000, 153000, 153000, 153000, 153000, 153000, 153000,\n       153000, 153000, 153000, 153000, 152991, 153000, 152976, 152920,\n       152931, 152885, 151600, 148818, 147448, 146802, 146568, 146367,\n       146179, 145888, 145685, 145366, 145224, 145066, 144745, 144627,\n       144511, 144698, 144410, 144329, 144162, 143970, 143742, 143381,\n       141860, 139357, 135358, 133171, 131138, 129246, 128410, 127866,\n       127563, 127223, 126475, 125614, 125137, 124848, 122906, 121653,\n       119278, 115548, 114473, 113800, 113486, 112655, 112505, 112670,\n       111845, 111124, 110378, 110315, 109996, 109693, 109649, 109411,\n       110626, 110628, 112247, 112348, 111865, 111571, 110601, 108308,\n       107213, 106768, 105546, 103971, 103209, 101866, 100215,  98964,\n        98559,  97008,  94981,  94513,  92490,  91555,  91491,  90072,\n        88642,  87210,  86960,  86834,  85759,  84496,  83237,  81911,\n        80249,  78942,  77715,  76918,  75746,  75826,  75443,  75087,\n        75156,  75432,  75730,  75699,  77028,  77825,  76813,  76718,\n        75958,  75207,  74216,  73042,  72527,  72043,  71819,  71384,\n        70693,  69922,  69537,  69685,  69688,  69876,  69552,  68937,\n        68496,  67942,  67820,  67626,  67627,  68113,  68426,  67894,\n        67868,  67365,  66191,  65334,  65752,  66438,  66285,  66565,\n        67616,  69090,  69386,  69928,  70470,  70318,  70228,  71028,\n        71197,  71827,  71712,  71312,  72013,  72878,  73398,  74038,\n        75017,  76270,  76087,  75317,  75210,  75497,  75099,  75620,\n        75059,  75008,  74146,  73531,  73556,  73927,  75395,  77235,\n        77094,  77229,  77463,  77808,  77538,  77104,  76816,  76500,\n        76310,  76331,  76889,  76293,  75626,  74966,  74871,  74950,\n        74931,  74852,  74885,  75077,  75576,  76104,  76208,  75387,\n        74971,  75878,  76311,  76566,  77014,  77205,  77231,  77456,\n        77983,  78379,  78793,  78963,  79154,  79710,  80777,  82547,\n        85164,  88944,  91269,  92438,  93646,  94836,  96071,  97918,\n       100244, 102011, 103553, 104624, 104961, 105354, 105646, 105866,\n       106367, 106361, 106461, 106659, 106933, 107055, 106903, 107028,\n       107080, 107404, 107631, 108022, 108194, 108261, 108519, 109023,\n       109349, 109873, 110373, 110919, 111796, 112587, 113219, 114143,\n       115161, 115733, 116531, 117615, 118338, 119414, 120492, 121332,\n       122387, 123824, 124938, 126113, 127465, 128857, 130411, 131869,\n       133016, 133585, 134442, 135772, 136440, 136828, 137200, 137418,\n       137705, 137976, 138167, 138481, 138788, 138937, 139194, 139357,\n       139375, 139583, 139924, 140201, 140716, 140971, 141285, 141680,\n       141837, 141975, 142260, 142567, 142774, 143154, 143533, 143853,\n       144521, 145182, 145832, 147978, 149006, 150026, 151535, 152753,\n       152922, 152960, 152990, 152991, 153000, 152995, 153000, 153000,\n       153000, 153000, 153000, 153000, 153000, 153000, 153000, 153000,\n       153000, 153000, 153000, 153000, 153000, 153000, 153000, 153000,\n       153000, 153000, 153000, 153000, 153000, 153000, 153000, 153000,\n       153000, 153000, 153000, 153000, 153000, 153000, 153000, 153000,\n       153000, 153000, 153000, 153000, 153000, 153000, 153000, 153000,\n       153000, 153000, 153000, 153000, 153000, 153000, 153000, 153000,\n       153000, 153000, 153000, 153000, 153000, 153000, 153000, 153000,\n       153000, 153000, 153000, 153000, 153000, 153000, 153000, 153000,\n       153000, 153000, 153000, 153000, 153000, 153000, 153000, 153000,\n       153000, 153000, 153000, 153000, 153000, 153000, 153000, 153000,\n       153000, 153000, 153000, 153000, 153000, 153000, 153000, 153000,\n       153000, 153000, 153000, 153000, 153000, 153000, 153000, 153000,\n       153000, 153000, 153000, 153000, 153000, 153000, 153000, 153000,\n       153000, 153000, 153000, 153000, 153000, 153000, 153000, 153000,\n       153000, 153000, 153000, 153000, 153000, 153000, 153000, 153000,\n       153000, 153000, 153000, 153000, 153000, 153000, 153000, 153000],\n      dtype=uint64)\n", "np.nonzero(153000-colsums)                                                                 \n", "(array([156, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182,\n        183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n        209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221,\n        222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234,\n        235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n        248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260,\n        261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273,\n        274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286,\n        287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299,\n        300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312,\n        313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325,\n        326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338,\n        339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351,\n        352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364,\n        365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377,\n        378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390,\n        391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403,\n        404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416,\n        417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429,\n        430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442,\n        443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455,\n        456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 469]),)\n"], [], [], [], ["a^(a&1==a)\n", "a = np.arange(-3, 4)\na^(a&1==a)\n# array([-3, -2, -1,  1,  0,  2,  3])\n"], ["import numpy as np\narr = np.array([1, 0, 2, 3, 6, 1, 0])\nindices_one = arr == 1\nindices_zero = arr == 0\narr[indices_one] = 0 # replacing 1s with 0s\narr[indices_zero] = 1 # replacing 0s with 1s\n\nOutput: array([0, 1, 2, 3, 6, 0, 1])\n"], ["np.where((a==0)|(a==1), a^1, a)\n", "a = np.array([[0,1,2,1], [1,2,0,3]])\nprint(a)\narray([[0, 1, 2, 1],\n       [1, 2, 0, 3]])\n\nnp.where((a==0)|(a==1), a^1, a)\n\narray([[1, 0, 2, 0],\n       [0, 2, 1, 3]])\n"], ["where_0 = np.where(arr == 0)\nwhere_1 = np.where(arr == 1)\n\narr[where_0] = 1\narr[where_1] = 0\n"], [], ["import xlsxwriter\n\nnew_list = [['first', 'second'], ['third', 'four'], [1, 2, 3, 4, 5, 6]]\n\nwith xlsxwriter.Workbook('test.xlsx') as workbook:\n    worksheet = workbook.add_worksheet()\n\n    for row_num, data in enumerate(new_list):\n        worksheet.write_row(row_num, 0, data)\n"], ["import pyexcel\n\n# Get the data\nnew_list = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n\n# Save the array to a file\npyexcel.save_as(array=new_list, dest_file_name=\"array_data.xls\")\n\n\n# Retrieve the records of the file\n# records = pyexcel.get_records(file_name=\"test.xls\")\n\n# Get an array from the data\n# my_array = pyexcel.get_array(file_name=\"test.xls\")\n\n# Get your data in a dictionary of 2D arrays\n# 2d_array_dictionary = pyexcel.get_book_dict(file_name=\"test.xls\")\n\n# The data\n# 2d_array_dictionary = {'Sheet 1': [\n                               ['ID', 'AGE', 'SCORE']\n                               [1, 22, 5],\n                               [2, 15, 6],\n                               [3, 28, 9]\n                              ],\n                   'Sheet 2': [\n                                ['X', 'Y', 'Z'],\n                                [1, 2, 3],\n                                [4, 5, 6]\n                                [7, 8, 9]\n                              ],\n                   'Sheet 3': [\n                                ['M', 'N', 'O', 'P'],\n                                [10, 11, 12, 13],\n                                [14, 15, 16, 17]\n                                [18, 19, 20, 21]\n                               ]}\n\n  # Save the data to a file                        \n  # pyexcel.save_book_as(bookdict=2d_array_dictionary, dest_file_name=\"2d_array_data.xls\")\n"], [], ["scan = table.scan()\nwith table.batch_writer() as batch:\n    for each in scan['Items']:\n        batch.delete_item(\n            Key={\n                'uId': each['uId'],\n                'compId': each['compId']\n            }\n        )\n"], ["pip install tensorflow==2.0.0-alpha0 \n"], [], [], ["conda create --name opencv-env python=3.6\n", "activate opencv-env\n", "pip install numpy scipy matplotlib scikit-learn jupyter\npip install opencv-contrib-python\npip install dlib\n", "import cv2\ncv2.__version__\n"], ["A = \"pGpEusuCSWEaPOJmamlFAnIBgAJGtcJaMPFTLfUfkQKXeymydQsdWCTyEFjFgbSmknAmKYFHopWceEyCSumTyAFwhrLqQXbWnXSn\"\n\nlenA = len(A)\nvowel = \"aeiouAEIOU\"\ncount = 0\n\nfor idx, char in enumerate(A):\n    if char in vowel:\n       count += lenA - idx\n\nprint(count%10003)\n", "1244\n", "print( sum(len(A) - idx if char.lower() in \"aeiou\" else 0\n       for idx, char in enumerate(A)) )\n"], ["string = \"pGpEusuCSWEaPOJmamlFAnIBgAJGtcJaMPFTLfUfkQKXeymydQsdWCTyEFjFgbSmknAmKYFHopWceEyCSumTyAFwhrLqQXbWnXSn\"\n\namazing_substring_start = ['a','e','i','o','u','A','E','I','O','U']\n\namazing_substrings = []\n\nfor i in range(len(string)):\n    if string[i] in amazing_substring_start:\n        for j in range(len(string[i:])+1):\n            amazing_substring = string[i:i+j]\n            if amazing_substring!='':\n                amazing_substrings += [amazing_substring]\n\nprint amazing_substrings,len(amazing_substrings)%10003\n"], ["def solve(A):\n            x = ['a', 'e','i','o', 'u', 'A', 'E', 'I', 'O', 'U']\n            ans = 0\n\n            for i in range(len(A)):\n                if A[i] in x:\n                    ans = (ans + len(A)-i)%10003\n            return ans\n"], ["def solve(A):\n    x = ['a', 'e','i','o', 'u', 'A', 'E', 'I', 'O', 'U']\n    y = []\n    z = len(A)\n    for n,i in enumerate(A):\n        if i in x:\n            m = z\n            while m > n:\n                y.append(A[n:m])\n                m -= 1\n    if y:\n        return len(y)%10003\n    else:\n        return 0\n"], [], [], ["from flask import Flask, request, render_template, redirect, url_for\napp = Flask(__name__)\n\n@app.route('/success/<name>')\ndef success(name):\n    return 'welcome %s' % name\n\n@app.route('/login',methods = ['POST', 'GET'])\ndef login():\n    if request.method == 'POST':\n        user = request.form['nm']\n        return redirect(url_for('success',name = user))\n    else:\n        return render_template('login.html')\n\nif __name__ == '__main__':\n    app.run(debug = True)\n"], [], [], [], ["@app.route('/success/<name>')\ndef success(name):\n    return 'welcome %s' % name\n\n@app.route('/login', methods=['POST', 'GET'])\ndef login():\n    if request.method == 'POST':\n        user = request.form['nm']\n        return redirect(url_for('success', name = user))\n\n    return render_template(login.html)\n\nif __name__ == \"__main__\":\n    app.run(debug=True)\n"], ["funcs = []\nfor i in range(4):\n  def f():\n    print(i)\n  funcs.append(f)\n", ">>> for f in funcs:\n      f()\n", "for i in range(4):\n  funcs[i]()\n\n\n0\n1\n2\n3\n", ">>> i = 2\n>>> funcs[i]()\n\n2\n", "funcs = []\nfor i in range(4):\n  def f(num=i):\n    print(num)\n  funcs.append(f)\n"], ["def f():\n    print(i)\n", "for i in range(4):\n    funcs[i]()\n", "for f in funcs:\n    f()\n"], [], ["timeit.timeit(add(a,b))\n"], ["from dateutil.parser import parse\nfrom functools import wraps\n\ndef parse_wrapper(function):\n    @wraps(function)\n    def wrapper(*args):\n        return {'datetime': function(*args), 'args': args}\n    return wrapper\n\nwrapped_parse = parse_wrapper(parse)\nx = wrapped_parse(\"2014-01-01 00:12:12\")\n# {'datetime': datetime.datetime(2014, 1, 1, 0, 12, 12),\n#  'args': ('2014-01-01 00:12:12',)}\n"], ["pip install ipykernel\n"], [], ["import re\nfrom itertools import product\nfrom dateutil.parser import parse\nfrom collections import defaultdict, Counter\n\nCOMMON_SPECIFIERS = [\n    '%a', '%A', '%d', '%b', '%B', '%m',\n    '%Y', '%H', '%p', '%M', '%S', '%Z',\n]\n\n\nclass FormatFinder:\n    def __init__(self,\n                 valid_specifiers=COMMON_SPECIFIERS,\n                 date_element=r'([\\w]+)',\n                 delimiter_element=r'([\\W]+)',\n                 ignore_case=False):\n        self.specifiers = valid_specifiers\n        joined = (r'' + date_element + r\"|\" + delimiter_element)\n        self.pattern = re.compile(joined)\n        self.ignore_case = ignore_case\n\n    def find_candidate_patterns(self, date_string):\n        date = parse(date_string)\n        tokens = self.pattern.findall(date_string)\n\n        candidate_specifiers = defaultdict(list)\n\n        for specifier in self.specifiers:\n            token = date.strftime(specifier)\n            candidate_specifiers[token].append(specifier)\n            if self.ignore_case:\n                candidate_specifiers[token.\n                                     upper()] = candidate_specifiers[token]\n                candidate_specifiers[token.\n                                     lower()] = candidate_specifiers[token]\n\n        options_for_each_element = []\n        for (token, delimiter) in tokens:\n            if token:\n                if token not in candidate_specifiers:\n                    options_for_each_element.append(\n                        [token])  # just use this verbatim?\n                else:\n                    options_for_each_element.append(\n                        candidate_specifiers[token])\n            else:\n                options_for_each_element.append([delimiter])\n\n        for parts in product(*options_for_each_element):\n            counts = Counter(parts)\n            max_count = max(counts[specifier] for specifier in self.specifiers)\n            if max_count > 1:\n                # this is a candidate with the same item used more than once\n                continue\n            yield \"\".join(parts)\n", "def test_it_returns_value_from_question_1():\n    s = \"2014-01-01 00:12:12\"\n    candidates = FormatFinder().find_candidate_patterns(s)\n    sut = FormatFinder()\n    candidates = sut.find_candidate_patterns(s)\n    assert \"%Y-%m-%d %H:%M:%S\" in candidates\n\n\ndef test_it_returns_value_from_question_2():\n    s = 'Jan. 04, 2017'\n    sut = FormatFinder()\n    candidates = sut.find_candidate_patterns(s)\n    candidates = list(candidates)\n    assert \"%b. %d, %Y\" in candidates\n    assert len(candidates) == 1\n\n\ndef test_it_can_ignore_case():\n    # NB: apparently the 'AM/PM' is meant to be capitalised in my locale! \n    # News to me!\n    s = \"JANUARY 12, 2018 02:12 am\"\n    sut = FormatFinder(ignore_case=True)\n    candidates = sut.find_candidate_patterns(s)\n    assert \"%B %d, %Y %H:%M %p\" in candidates\n\n\ndef test_it_returns_parts_that_have_no_date_component_verbatim():\n    # In this string, the 'at' is considered as a 'date' element, \n    # but there is no specifier that produces a candidate for it\n    s = \"January 12, 2018 at 02:12 AM\"\n    sut = FormatFinder()\n    candidates = sut.find_candidate_patterns(s)\n    assert \"%B %d, %Y at %H:%M %p\" in candidates\n", "In [2]: ff = FormatFinder()\n\nIn [3]: list(ff.find_candidate_patterns(\"2014-01-01 00:12:12\"))\nOut[3]:\n['%Y-%d-%m %H:%M:%S',\n '%Y-%d-%m %H:%S:%M',\n '%Y-%m-%d %H:%M:%S',\n '%Y-%m-%d %H:%S:%M']\n\nIn [4]: list(ff.find_candidate_patterns(\"Jan. 04, 2017\"))\nOut[4]: ['%b. %d, %Y']\n\nIn [5]: list(ff.find_candidate_patterns(\"January 12, 2018 at 02:12 AM\"))\nOut[5]: ['%B %d, %Y at %H:%M %p', '%B %M, %Y at %H:%d %p']\n\nIn [6]: ff_without_case = FormatFinder(ignore_case=True)\n\nIn [7]: list(ff_without_case.find_candidate_patterns(\"JANUARY 12, 2018 02:12 am\"))\nOut[7]: ['%B %d, %Y %H:%M %p', '%B %M, %Y %H:%d %p']\n"], ["from itertools import combinations \n\ndef is_sum_of_n_numbers(data ,target_value, num_elem):\n    \"\"\"Returns 'True' if any combinatin of 'num_elem'ents \n    from 'data' sums to 'target_value'\"\"\"\n    return any(sum(x)==target_value for x in combinations(data, num_elem))\n\ndef find_sum_in_combination(data, target_value, num_elem):\n    \"\"\"Returns all combinations of 'num_elem'ent-tuples from 'data' \n    that sums to 'target_value'\"\"\"\n    return [x for x in combinations(data,num_elem) if sum(x) == target_value]\n", "d = [1,2,3,4,5]\nfor numbers in range(1,6):\n    for s in range(1,sum(d)+1):\n        result = find_sum_in_combination(d,s,numbers)\n        if result:\n            print(f\"Sum {s} from {d} with {numbers} numbers: \", result)\n", "Sum 1 from [1, 2, 3, 4, 5] with 1 numbers:  [(1,)]\nSum 2 from [1, 2, 3, 4, 5] with 1 numbers:  [(2,)]\nSum 3 from [1, 2, 3, 4, 5] with 1 numbers:  [(3,)]\nSum 4 from [1, 2, 3, 4, 5] with 1 numbers:  [(4,)]\nSum 5 from [1, 2, 3, 4, 5] with 1 numbers:  [(5,)]\nSum 3 from [1, 2, 3, 4, 5] with 2 numbers:  [(1, 2)]\nSum 4 from [1, 2, 3, 4, 5] with 2 numbers:  [(1, 3)]\nSum 5 from [1, 2, 3, 4, 5] with 2 numbers:  [(1, 4), (2, 3)]\nSum 6 from [1, 2, 3, 4, 5] with 2 numbers:  [(1, 5), (2, 4)]\nSum 7 from [1, 2, 3, 4, 5] with 2 numbers:  [(2, 5), (3, 4)]\nSum 8 from [1, 2, 3, 4, 5] with 2 numbers:  [(3, 5)]\nSum 9 from [1, 2, 3, 4, 5] with 2 numbers:  [(4, 5)]\nSum 6 from [1, 2, 3, 4, 5] with 3 numbers:  [(1, 2, 3)]\nSum 7 from [1, 2, 3, 4, 5] with 3 numbers:  [(1, 2, 4)]\nSum 8 from [1, 2, 3, 4, 5] with 3 numbers:  [(1, 2, 5), (1, 3, 4)]\nSum 9 from [1, 2, 3, 4, 5] with 3 numbers:  [(1, 3, 5), (2, 3, 4)]\nSum 10 from [1, 2, 3, 4, 5] with 3 numbers:  [(1, 4, 5), (2, 3, 5)]\nSum 11 from [1, 2, 3, 4, 5] with 3 numbers:  [(2, 4, 5)]\nSum 12 from [1, 2, 3, 4, 5] with 3 numbers:  [(3, 4, 5)]\nSum 10 from [1, 2, 3, 4, 5] with 4 numbers:  [(1, 2, 3, 4)]\nSum 11 from [1, 2, 3, 4, 5] with 4 numbers:  [(1, 2, 3, 5)]\nSum 12 from [1, 2, 3, 4, 5] with 4 numbers:  [(1, 2, 4, 5)]\nSum 13 from [1, 2, 3, 4, 5] with 4 numbers:  [(1, 3, 4, 5)]\nSum 14 from [1, 2, 3, 4, 5] with 4 numbers:  [(2, 3, 4, 5)]\nSum 15 from [1, 2, 3, 4, 5] with 5 numbers:  [(1, 2, 3, 4, 5)]\n"], ["import itertools\ndef f(lst,num):\n    for x,y in itertools.combinations(lst,2):\n        if x+y==num:\n            return True\n    return False\nlst=[1,2,3]\nnum=int(input(\"Give me a number: \"))\nprint(f(lst,num))\n"], ["def issumoftwo(lst,num):\n    for x in lst:\n        for y in lst:\n            if x+y==num and lst.index(x)!=lst.index(y):\n                return True\n    return False\nlst=[1,2,3]\nnum=int(input(\"Give me a Number: \"))\nprint(issumoftwo(lst,num))\n", "Give me a number: 5\nTrue\n"], ["n=[3,2,1]\nnumber=int(input(\"Please enter nubmer\"))\nfor i in n:\n    num=number - i\n    if num in n:\n        print(num,i)\n        break\n"], [], ["from datetime import datetime\nimport itertools\nimport re\n\nFORMAT_CODES = (\n    r'%a', r'%A', r'%w', r'%d', r'%b', r'%B', r'%m', r'%y', r'%Y',\n    r'%H', r'%I', r'%p', r'%M', r'%S', r'%f', r'%z', r'%Z', r'%j',\n    r'%U', r'%W',\n)\n\nTWO_LETTERS_FORMATS = (\n    r'%p',\n)\n\nTHREE_LETTERS_FORMATS = (\n    r'%a', r'%b'\n)\n\nLONG_LETTERS_FORMATS = (\n    r'%A', r'%B', r'%z', r'%Z',\n)\n\nSINGLE_DIGITS_FORMATS = (\n    r'w',\n)\n\nTWO_DIGITS_FORMATS = (\n    r'%d', r'%m', r'%y', r'%H', r'%I', r'%M', r'%S', r'%U', r'%W',\n)\n\nTHREE_DIGITS_FORMATS = (\n    r'%j',\n)\n\nFOUR_DIGITS_FORMATS = (\n    r'%Y',\n)\n\nLONG_DIGITS_FORMATS = (\n    r'%f',\n)\n\n# Non format code symbols\nSYMBOLS = (\n    '-',\n    ':',\n    '+',\n    'Z',\n    ',',\n    ' ',\n)\n\n\nif __name__ == '__main__':\n    date_str = input('Please input a date: ')\n\n    # Split with non format code symbols\n    pattern = r'[^{}]+'.format(''.join(SYMBOLS))\n    components = re.findall(pattern, date_str)\n\n    # Create a format placeholder, eg. '{}-{}-{} {}:{}:{}+{}'\n    placeholder = re.sub(pattern, '{}', date_str)\n\n    formats = []\n    for comp in components:\n        if re.match(r'^\\d{1}$', comp):\n            formats.append(SINGLE_DIGITS_FORMATS)\n        elif re.match(r'^\\d{2}$', comp):\n            formats.append(TWO_DIGITS_FORMATS)\n        elif re.match(r'^\\d{3}$', comp):\n            formats.append(THREE_DIGITS_FORMATS)\n        elif re.match(r'^\\d{4}$', comp):\n            formats.append(FOUR_DIGITS_FORMATS)\n        elif re.match(r'^\\d{5,}$', comp):\n            formats.append(LONG_DIGITS_FORMATS)\n        elif re.match(r'^[a-zA-Z]{2}$', comp):\n            formats.append(TWO_LETTERS_FORMATS)\n        elif re.match(r'^[a-zA-Z]{3}$', comp):\n            formats.append(THREE_LETTERS_FORMATS)\n        elif re.match(r'^[a-zA-Z]{4,}$', comp):\n            formats.append(LONG_LETTERS_FORMATS)\n        else:\n            formats.append(FORMAT_CODES)\n\n    # Create a possible format set\n    possible_set = itertools.product(*formats)\n\n    found = 0\n    for possible_format in possible_set:\n        # Create a format with possible format combination\n        dt_format = placeholder.format(*possible_format)\n        try:\n            dt = datetime.strptime(date_str, dt_format)\n            # Use the format to parse the date, and format the \n            # date back to string and compare with the origin one\n            if dt.strftime(dt_format) == date_str:\n                print('Possible result: {}'.format(dt_format))\n                found += 1\n        except Exception:\n            continue\n\n    if found == 0:\n        print('No pattern found')\n", "$ python3 reverse.py\nPlease input a date: 2018-12-31 10:26 PM\nPossible result: %Y-%d-%M %I:%S %p\nPossible result: %Y-%d-%S %I:%M %p\nPossible result: %Y-%m-%d %I:%M %p\nPossible result: %Y-%m-%d %I:%S %p\nPossible result: %Y-%m-%M %I:%d %p\nPossible result: %Y-%m-%M %I:%S %p\nPossible result: %Y-%m-%S %I:%d %p\nPossible result: %Y-%m-%S %I:%M %p\nPossible result: %Y-%H-%d %m:%M %p\nPossible result: %Y-%H-%d %m:%S %p\nPossible result: %Y-%H-%d %M:%S %p\nPossible result: %Y-%H-%d %S:%M %p\nPossible result: %Y-%H-%M %d:%S %p\nPossible result: %Y-%H-%M %m:%d %p\nPossible result: %Y-%H-%M %m:%S %p\nPossible result: %Y-%H-%M %S:%d %p\nPossible result: %Y-%H-%S %d:%M %p\nPossible result: %Y-%H-%S %m:%d %p\nPossible result: %Y-%H-%S %m:%M %p\nPossible result: %Y-%H-%S %M:%d %p\nPossible result: %Y-%I-%d %m:%M %p\nPossible result: %Y-%I-%d %m:%S %p\nPossible result: %Y-%I-%d %M:%S %p\nPossible result: %Y-%I-%d %S:%M %p\nPossible result: %Y-%I-%M %d:%S %p\nPossible result: %Y-%I-%M %m:%d %p\nPossible result: %Y-%I-%M %m:%S %p\nPossible result: %Y-%I-%M %S:%d %p\nPossible result: %Y-%I-%S %d:%M %p\nPossible result: %Y-%I-%S %m:%d %p\nPossible result: %Y-%I-%S %m:%M %p\nPossible result: %Y-%I-%S %M:%d %p\nPossible result: %Y-%M-%d %I:%S %p\nPossible result: %Y-%M-%S %I:%d %p\nPossible result: %Y-%S-%d %I:%M %p\nPossible result: %Y-%S-%M %I:%d %p\n"], ["from datetime import datetime\nimport re\nclass DateTime(object):\n    dateFormat = {\"%d\": \"dd\", \"%Y\": \"YYYY\", \"%a\": \"Day\", \"%A\": \"DAY\", \"%w\": \"ww\", \"%b\": \"Mon\", \"%B\": \"MON\", \"%m\": \"mm\",\n                  \"%H\": \"HH\", \"%I\": \"II\", \"%p\": \"pp\", \"%M\": \"MM\", \"%S\": \"SS\"}  # wil contain all format equivalent\n\n    def __init__(self, date_str, format):\n        self.dateobj = datetime.strptime(date_str, format)\n        self.format = format\n\n    def parse_format(self):\n        output=None\n        reg = re.compile(\"%[A-Z a-z]\")\n        fmts = None\n        if self.format is not None:\n            fmts = re.findall(reg, self.format)\n        if fmts is not None:\n            output = self.format\n            for f in fmts:\n                output = output.replace(f, DateTime.dateFormat[f])\n        return output\n\n\nnDate = DateTime(\"12 January, 2018\", \"%d %B, %Y\")\nprint(nDate.parse_format())\n"], [], ["import matplotlib\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.patches import Patch\n\nn = 5\nhatch_1 = 'o'\nhatch_2 = '.'\nopacity = 0.4\nbar_width = 0.4\n\ny = np.random.randint(low=0, high=10, size=n)\nx = np.arange(n)\n\nbars = plt.bar(x, y, bar_width, align='center',  alpha=opacity, fill=False)\nfor bar in bars:\n    bar.set_hatch(hatch_1)\n\ny = np.random.randint(low=0, high=10, size=n)\nbars = plt.bar(x + bar_width, y, bar_width,\n               align='center',  alpha=opacity, fill=False)\nfor bar in bars:\n    bar.set_hatch(hatch_2)\n\npatch_1 = Patch(fill=False, label='\\nHatch 1', hatch=hatch_1, alpha=opacity)\npatch_2 = Patch(fill=False, label='\\nHatch 2', hatch=hatch_2, alpha=opacity)\n\n# add legends\nleg = plt.legend(handles=[patch_1, patch_2], loc='upper right', labelspacing=1.5, handlelength=4)\n\nfor patch in leg.get_patches():\n    patch.set_height(22)\n    patch.set_y(-6)\n\nplt.show()\n"], ["plt.legend(handles=[patch_1, patch_2], loc='best', prop={'size': 24})\n"], ["n = 5\nhatch_1 = 'O'\nhatch_2 = '.'\nopacity = 0.4\nbar_width = 0.4\n\ny = np.random.randint(low=0, high=10, size=n)\nx = np.arange(n)\n\nbars = plt.bar(x, y, bar_width, align='center',  alpha=opacity, fill=False)\nfor bar in bars:\n    bar.set_hatch(hatch_1)\n\ny = np.random.randint(low=0, high=10, size=n)\nbars = plt.bar(x + bar_width, y, bar_width,\n               align='center',  alpha=opacity, fill=False)\nfor bar in bars:\n    bar.set_hatch(hatch_2)\n\npatch_1 = Patch(fill=False, label='Hatch 1', hatch=hatch_1, alpha=opacity)\npatch_2 = Patch(fill=False, label='Hatch 2', hatch=hatch_2, alpha=opacity)\nplt.rcParams['figure.figsize'] = (25,15)\n# add legends\nplt.legend(handles=[patch_1, patch_2], loc='upper right')\n\nplt.show()\n"], []]