[["newfilename = re.sub('IMG_', '', filename)\nnewfilename = newfilename[0:4] + '-' + newfilename[4:6] + '-' + newfilename[6:11] + '_' + newfilename[11:13] + '_' + newfilename[13:]\n"], [], [], ["import re\npattern = r\"IMG_(\\d{4})(\\d{2})(\\d{2})_(\\d{2})(\\d{2})(\\d{2})\"\ntest_str = \"IMG_20190401_235959.jpg\"\nsubst = \"\\\\1-\\\\2-\\\\3_\\\\4_\\\\5_\\\\6\"\nresult = re.sub(pattern, subst, test_str, 0, re.MULTILINE)\nif result:\n    print (result)\n\n# 2019-04-01_23_59_59.jpg\n"], ["original = 'IMG_20190401_235959.jpg'\nol = original.split('_')\ndate = f'{ol[1][:4]}-{ol[1][4:6]}-{ol[1][6:8]}'\ntime = f'{ol[2][:2]}_{ol[2][2:4]}_{ol[2][4:6]}'\nnew = f'{date}_{time}.jpg'\nprint(new)\n"], ["import re\ndef new_path(s):\n  _, a, b, f_type = re.findall('[a-zA-Z0-9]+', s)\n  new_b = '_'.join(b[i:i+2] for i in range(0, len(b), 2))\n  return f'{a[:4]}-{a[4:6]}-{a[6:]}_{new_b}.{f_type}'\n\nprint(new_path('IMG_20190401_235959.jpg'))\n", "'2019-04-01_23_59_59.jpg'\n", "import os, glob, sys, re    \nos.chdir(sys.argv[1])\nfor filename in glob.glob(\"IMG_*.jpg\"):\n  try:\n    os.rename(filename, new_path(filename))\n  except OSError,e:\n    print(e)\n"], [], ["from functools import reduce\ndata=[(1, 'a'), (2, 'b'), (2, 'b'), (2, 'c'), (3, 'd'), (2, 'e')]                                                    \nreduce(lambda rslt,t: rslt if rslt[-1][0]==t[0] else rslt+[t], data, [data[0]])                                      \n[(1, 'a'), (2, 'b'), (3, 'd'), (2, 'e')]\n"], ["# if you are reading data from a file...\nimport json\n\npath = \"/path/to/json\"\nd = json.load(open(path, \"r\"))\n\n# ...else\nd = {\n    \"data\": [\n        {\n            \"date\": \"2017-07-28_15-54-10\", \n            \"name\": \"name1\", \n            \"state\": \"true\",\n        }, \n        {\n            \"date\": \"2017-07-29_15-54-10\", \n            \"name\": \"name2\", \n            \"state\": \"true\",\n        }\n        ]\n    }\n\nrecords = [{x[\"name\"]: [{\"date\": x[\"date\"]}, {\"state\": x[\"state\"]}]} for x in d[\"data\"]]\nrecords\n\n>>> [{'name1': [{'date': '2017-07-28_15-54-10'}, {'state': 'true'}]},\n {'name2': [{'date': '2017-07-29_15-54-10'}, {'state': 'true'}]}]\n", "records = [\n    {x[\"name\"]: [{k: v} for k, v in x.items() if k != \"name\"]} \n    for x in d[\"data\"]\n]\n"], ["r = {\n  \"data\": [\n    {\n      \"date\": \"2017-07-28_15-54-10\",\n      \"name\": \"name1\",\n      \"state\": \"true\",\n    },\n     {\n      \"date\": \"2017-07-29_15-54-10\",\n      \"name\": \"name2\",\n      \"state\": \"true\",\n    }\n   ]\n  }\n\ndata = r['data']\nresult = []\nmkdic = lambda x: [{k: v} for k, v in x.items() if k != \"name\"]\nfor i in data:\n    result.append( {i.get(\"name\"): mkdic(i) })\nimport pprint\npprint.pprint(result, indent = 2)\n"], ["my_final_array = []\nfor jn in data:\n    name = jn.get(\"name\")\n    my_dict = {}\n    my_dict1 = {}\n    my_list = []\n    my_dict[\"date\"] = jn.get(\"date\")\n    my_dict1[\"state\"] = jn.get(\"state\")\n    my_list.append(my_dict)   # dict for date\n    my_list.append(my_dict1)   # dict for state\n    my_name_dict = {}\n    my_name_dict[name] = my_list   # add the small dicts to  the \"name\" dict\n    my_final_array.append(my_name_dict)\n    print(my_final_array)\n"], ["json_data = {\n    \"data\": [\n        {\n            \"date\": \"2017-07-28_15-54-10\",\n            \"name\": \"name1\",\n            \"state\": \"true\",\n        },\n        {\n            \"date\": \"2017-07-29_15-54-10\",\n            \"name\": \"name2\",\n            \"state\": \"true\",\n        }\n    ]\n}\nmain_list = []\nfor val in json_data['data']:\n    temp_dict = {}\n    temp_key = val.pop('name')\n    temp_dict[temp_key] = [val]\n    main_list.append(temp_dict)\nprint(main_list)\n", "[  \n    {  \n        'name1':[  \n            {  \n                'date':'2017-07-28_15-54-10',\n                'state':'true'\n            }\n        ]\n    },\n    {  \n        'name2':[  \n            {  \n                'date':'2017-07-29_15-54-10',\n                'state':'true'\n            }\n        ]\n    }\n]\n"], ["import re\nnum = re.findall(\"(\\d+(?:\\.\\d+)?)\", \"8,191.55 MB\")\nprint(float(''.join(num)))\n", "8191.55\n"], [], ["RAM = ' 8,191.55 MB '\nram_in_MB = float(RAM.replace(',','').split()[0])\nprint(ram_in_MB)\n# 8191.55\n"], ["TotalRAM = dfHandler['Total Physical Memory'].values[0]    \nTotalRAM = float(TotalRAM.replace(',', '').replace(' MB', ''))\nTotalRAMGb = TotalRam / 1024\n"], ["TotalRAM = dfHandler['Total Physical Memory'].values[0]\nTotalRAM = float(''.join(i for i in TotalRAM if (i.isdigit() or i == \".\")))\n"], ["def strip(group):\n    non_overlapping=[]\n    overlapping = [list(group.itertuples())[0]]\n    end = list(group.itertuples())[0].to\n    for row in list(group.itertuples())[1:]:\n        if row[3]<=end:\n            overlapping.append(row)\n            if row.to > end:\n                end = row.to\n        else:\n            non_overlapping.append(reduce_overlap(overlapping))\n            overlapping=[row]\n    non_overlapping.append(reduce_overlap(overlapping))\n    return non_overlapping\n", "def reduce_overlap(overlapping):\n    overlapping= sorted(overlapping,key=lambda x: x.value)\n    if len(overlapping)==1 or overlapping[0].value != overlapping[1].value:\n        return overlapping[0]\n    else:\n        return []\n", "def nonoverlapping(df):\n  return df.Dataframe.from_records([strip(group) for name,group in df.sort_values(['from', \"value\"]).groupby('id')])\n"], ["df = pd.DataFrame({'id': ['A', 'B', 'B', 'C', 'D', 'D' ,'D', 'D', 'D', 'D', 'D'],\n                  'hit': ['hit1', 'hit2', 'hit3','hit4', 'hit5','hit6', 'hit7','hit8', 'hit9','hit10', 'hit11'],\n                  'from': [56,89,240,332,291,287,381,287,373,514, 599],\n                  'to':[102,275,349,480,512,313,426,316,422,600, 602],\n                  'value': [0.00085,0.00034,0.00034,3.40E-15,3.80E-24,0.00098,0.00098,0.0029,0.0029,0.0021, 0.002]})\n\noverlapMask =  df.sort_values(by = 'from')\\\n                 .groupby('id')\\\n                 .apply(lambda x: np.where(x['from'] < x['to'].shift(), 0 , 1).cumsum())\\\n                 .reset_index()\n\ndf['Mask'] = np.concatenate((overlapMask[0].values))\n\n\ndf.drop_duplicates(subset = ['id','value'], keep = False, inplace = True)\n\n\ndf.sort_values(by = 'value')\\\n  .groupby(['id', 'Mask'])\\\n  .head(1)\\\n  .reset_index()\\\n  .drop(['Mask', 'index'],axis = 1)\\\n  .sort_values(by = 'id')\n\n\n    id  hit    from  to    value\n2   A   hit1    56  102 8.500000e-04\n1   C   hit4    332 480 3.400000e-15\n0   D   hit5    291 512 3.800000e-24\n3   D   hit11   599 602 2.000000e-03\n"], ["df['ID'] = range(df.shape[0])\ndf['Interval'] = df.apply(lambda x: pd.Interval(x['from'], x['to'], closed='both'), axis=1)\n", "columns = ['id', 'Interval', 'ID']\nconnected = df[columns].merge(df[columns], on='id')\nconnected['Overlap'] = connected.apply(lambda x: x['Interval_x'].overlaps(x['Interval_y']), axis=1) \nconnected = connected.loc[connected['Overlap'] == True, ['id', 'ID_x', 'ID_y']]\n", "def connections(graph, id):\n    def dict_to_df(d):\n        df = pd.DataFrame(data=[d.keys(), d.values()], index=['ID', 'Subgraph']).T\n        df['id'] = id\n        return df[['id', 'Subgraph', 'ID']]\n\n    def dfs(node, num):\n        visited[node] = num\n        for _node in graph.loc[node].iloc[0]:\n            if _node not in visited:\n                dfs(_node, num)\n\n    visited = {}\n    graph = graph.loc[id]\n    for (num, node) in enumerate(graph.index):\n        if node not in visited:\n            dfs(node, num)\n\n    return dict_to_df(visited)\n\ndfs = []\nfor id in graph.index.get_level_values(0).unique():\n    dfs.append(connections(graph, id))\n\nconns = pd.concat(dfs)\n", "def select_min(x):\n    m = x['value'].min()\n    if len(x) > 1 and (x['value'] == m).all():\n        return -1\n    else:\n        return x['value'].idxmin()\n\nselected = data.groupby(['id', 'Subgraph'])['value', 'ID'].apply(select_min)\nselected = selected[selected >= 0]\n", "print(df.loc[df.ID.isin(selected), :].drop(columns=['ID', 'Interval']))\n  id    hit  from   to         value\n0  A   hit1    56  102  8.500000e-04\n3  C   hit4   332  480  3.400000e-15\n4  D   hit5   291  512  3.800000e-24\n9  D  hit10   514  600  2.100000e-03\n"], ["df[\"t\"] = df[\"x\"].apply(lambda x: [i for i in finds if i in x][0])\n"], ["0    [m500_0]\n1    [m500_0]\n2     [0_500]\n3    [m150_0]\n"], ["def subset_df_test():\n  df = pandas.DataFrame({'x': [\"var_m500_0_somevartext\", \"var_m500_0_vartextagain\",\n                         \"varwithsomeothertext_0_500\", \"varwithsomext_m150_0_text\"], 'x1': [4, 5, 6, 8]})\n\n  finds = [\"m500_0\", \"0_500\", \"m150_0\"]\n  df['t'] = df['x'].map(lambda x: compare(x, finds))\n  print df\n\ndef compare(x, finds):\n  for f in finds:\n    if f in x:\n        return f\n"], ["df['t'] = df['x'].apply(lambda x: ''.join([i for i in finds if i in x]))\n", "print(df)\n", "                            x  x1       t\n0      var_m500_0_somevartext   4  m500_0\n1     var_m500_0_vartextagain   5  m500_0\n2  varwithsomeothertext_0_500   6   0_500\n3   varwithsomext_m150_0_text   8  m150_0\n", "df[\"t\"] = df[\"x\"].str.extract(\"(%s)\" % '|'.join(finds))\n", "df[\"t\"] = df[\"x\"].str.extract(\"({})\".format('|'.join(finds)))\n", "df[\"t\"] = df[\"x\"].str.extract(\"(\" + '|'.join(finds) + \")\")\n"], ["finds = [\"m500_0\", \"0_500\", \"m150_0\"]\ndf[\"t\"] = df[\"x\"].str.extract(f\"({'|'.join(finds)})\")\n"], ["file_name = file_name.split('.CSV')[0] + '.CSV'\n"], [">>> data = [(1, 'a'), (2, 'b'), (2, 'b'), (2, 'c'), (3, 'd'), (2, 'e')]\n>>> [v for ix, v in enumerate(data) if not ix or v[0] != data[ix-1][0]]\n[(1, 'a'), (2, 'b'), (3, 'd'), (2, 'e')]\n"], [">>> li = [(1, 'a'), (2, 'a'), (2, 'a'), (3, 'a'), (2, 'a')]\n>>> [li[i] for i in range(len(li)) if not i or li[i] != li[i-1]]\n[(1, 'a'), (2, 'a'), (3, 'a'), (2, 'a')]\n"], ["class SalesTable:\n\n    def __init__(self, banner, start_year, start_month, end_year, end_month):\n        ...\n\n    def sales_periods(self):\n        # ...\n        return some_dict\n\n\ndef find_sales_period_csv(dct):\n    return some_list\n\ndef csv_to_df(lst):\n    return some_list\n\ndef combine_dfs(lst):\n    return some_df\n\ndef check_data(df):\n    pass\n", "x = SalesTable(...)\ncheck_data(combine_dfs(csv_to_df(find_sales_period_csv(x.sales_periods()))))\n", "def sales_periods(banner, start_year, start_month, end_year, end_month):\n    ...\n    return some_dict\n\ncheck_data(combine_dfs(csv_to_df(find_sales_period_csv(sales_periods(...)))))\n"], [], [], [">>> L = [(1, 'a'), (2, 'b'), (2, 'b'), (2, 'c'), (3, 'd'), (2, 'e')]\n>>> list(zip(L[1:], L))\n[((2, 'b'), (1, 'a')), ((2, 'b'), (2, 'b')), ((2, 'c'), (2, 'b')), ((3, 'd'), (2, 'c')), ((2, 'e'), (3, 'd'))]\n", ">>> [L[0]]+[e for e, f in zip(L[1:], L) if e[0]!=f[0]]\n[(1, 'a'), (2, 'b'), (3, 'd'), (2, 'e')]\n"], [], [], ["def mkd(*args):\n    if len(args) == 1:\n        print(\"Making\", *args)\n    else:\n        print(\"mdk only takes 1 argument.\")\n\ndef pwd(*args):\n    if len(args) == 0:\n        print(\"You're here!\")\n    else:\n        print(\"pwd doesn't take any arguments.\")\n\ndef add(*args):\n    if len(args) == 2:\n        if args[0].isdigit() and args[1].isdigit(): \n            print(\"Result:\", int(args[0]) + int(args[1]))\n        else:\n            print(\"Can only add two numbers!\")\n    else:\n        print(\"add takes exactly 2 arguments.\")\n\ndef exit(*args):\n    quit()\n\n\nfunctions = {'mkd': mkd, 'pwd': pwd, 'add': add, 'exit': exit}  # The available functions.  \n\nwhile True:\n    command, *arguments = input(\"> \").strip().split(' ')  # Take the user's input and split on spaces.\n    if command not in functions:\n        print(\"Couldn't find command\", command)\n    else:\n        functions[command](*arguments)\n"], [], ["df.sort_values(['from', \"value\"]).groupby('id')\ndf.drop_duplicates(subset=['id', 'value'], keep=False, inplace=True)\n", "  id    hit from   to     value\n0  A   hit1   56  102   0.00085\n3  C   hit4  332  480  3.40E-15\n4  D   hit5  291  512  3.80E-24\n9  D  hit10  514  600    0.0021\n", "df.reset_index(drop=True, inplace=True)\n", "  id    hit from   to     value\n0  A   hit1   56  102   0.00085\n1  C   hit4  332  480  3.40E-15\n2  D   hit5  291  512  3.80E-24\n3  D  hit10  514  600    0.0021\n"], [">>> def foo():\n...     print(\"Hi from foo!\")\n... \n>>> locals()[\"foo\"]()\nHi from foo!\n", "commands = {\n    \"add\" : lambda x, y: x + y,\n    \"mul\" : lambda x, y: x * y,\n}\n\nif __name__ == __main__:\n    import sys\n    _, command, arg1, arg2, *_ = sys.args\n    f = commands.get(command, lambda *_: \"Invalid command\")\n    res = f(int(arg1), int(arg2))\n    print(res)\n"], ["f 1 2\n", "f << 1, 2\n"], [], ["from itertools import groupby\nfrom operator import itemgetter\n\ndata = [(1, 'a'), (2, 'a'), (2, 'b'), (3, 'a'), (4, 'a'), (2, 'a'), (2, 'a'), (3, 'a'), (3, 'a')]\n\n[next(group) for key, group in groupby(data, key=itemgetter(0))]\n", "[(1, 'a'), (2, 'a'), (3, 'a'), (4, 'a'), (2, 'a'), (3, 'a')]\n", "result = []\n\nfor first, second in zip(data, data[1:]):\n    if first[0] != second[0]:\n        result.append(first)\n\nresult\n", "[(1, 'a'), (2, 'b'), (3, 'a'), (4, 'a'), (2, 'a')]\n"], ["test = [(1, 'a'), (2, 'a'), (2, 'a'), (3, 'a'), (4, 'a'),(3, 'a'),(4,\"a\"),(4,\"a\")]\n\nresult = []\n\nfor i in test:\n    if result and i[0] == result[-1][0]: #edited since OP considers (1,\"a\") and (1,\"b\") as duplicate\n    #if result and i == result[-1]:\n        continue\n    else:\n        result.append(i)\n\nprint (result)\n", "[(1, 'a'), (2, 'a'), (3, 'a'), (4, 'a'), (3, 'a'), (4, 'a')]\n"], ["inputList = [(1, 'a'), (2, 'a'), (2, 'a'), (3, 'a'), (2, 'a')]\noutputList = []\nlastItem = None\n\nfor item in inputList:\n    if not item == lastItem:\n        outputList.append(item)\n        lastItem = item\nprint(outputList)\n"], ["l = [(1, 'a'), (2, 'a'), (2, 'a'), (3, 'a'), (4, 'a')]\nfrom itertools import groupby\n[tuple(k) for k, _ in groupby(l)]\n# [(1, 'a'), (2, 'a'), (3, 'a'), (4, 'a')]\n"], [">>> s = df.groupby(['Country', 'Industry', 'Field'])['Value'].sum()\n>>> s.xs('Import', axis=0, level='Field') - s.xs('Export', axis=0, level='Field')\nCountry  Industry\nCanada   Retail      20\nUSA      Energy      15\n         Finance     50\n         Retail      70\nName: Value, dtype: int64\n"], ["(df.groupby(['Country', 'Industry', 'Field'], sort=False)['Value']\n   .sum()\n   .unstack('Field')\n   .eval('Import - Export')\n   .reset_index(name='Value'))\n\n  Country Industry  Value\n0     USA  Finance     50\n1     USA   Retail     70\n2     USA   Energy     15\n3  Canada   Retail     20\n"], ["df=df.set_index(['Country','Industry'])\n\nNewdf=(df.loc[df.Field=='Export','Value']-df.loc[df.Field=='Import','Value']).reset_index().assign(Field='Net')\nNewdf\n  Country Industry  Value Field\n0     USA  Finance    -50   Net\n1     USA   Retail    -70   Net\n2     USA   Energy    -15   Net\n3  Canada   Retail    -20   Net\n", "df.pivot_table(index=['Country','Industry'],columns='Field',values='Value',aggfunc='sum').\\\n  diff(axis=1).\\\n     dropna(1).\\\n        rename(columns={'Import':'Value'}).\\\n          reset_index()\nOut[112]: \nField Country Industry  Value\n0      Canada   Retail   20.0\n1         USA   Energy   15.0\n2         USA  Finance   50.0\n3         USA   Retail   70.0\n"], ["df.set_index(['Country','Industry','Field'])\\\n  .unstack()['Value']\\\n  .eval('Net = Import - Export')\\\n  .stack().rename('Value').reset_index()\n", "   Country Industry   Field  Value\n0   Canada   Retail  Export     10\n1   Canada   Retail  Import     30\n2   Canada   Retail     Net     20\n3      USA   Energy  Export      5\n4      USA   Energy  Import     20\n5      USA   Energy     Net     15\n6      USA  Finance  Export     50\n7      USA  Finance  Import    100\n8      USA  Finance     Net     50\n9      USA   Retail  Export     10\n10     USA   Retail  Import     80\n11     USA   Retail     Net     70\n"], ["df['Value'] = df.groupby(['Country', 'Industry'])['Value'].diff().abs()\ndf['Field'] = 'Net'\ndf.dropna(inplace=True)\ndf.reset_index(drop=True, inplace=True)\n\nprint(df)\n  Country Industry Field  Value\n0     USA  Finance   Net   50.0\n1     USA   Retail   Net   70.0\n2     USA   Energy   Net   15.0\n3  Canada   Retail   Net   20.0\n"], ["r = ratio\ngeom_prog = []\nx = 1\nwhile x <= n:\n    geom_prog.append(x)\n    x *= r\n"], [">>> def geom(ratio, n):\n...     series = [1]\n...     while series[-1] < n:\n...         series.append( series[-1] * ratio )\n...     return series\n...\n>>>\n>>> geom(2, 8)\n[1, 2, 4, 8]\n"], ["r = 2 # set here the factor\ngeom_prog = []\nx = 1 # first element and var to update\nn = 8 # last element\nfor i in range(x, n+1):\n    geom_prog.append(x)\n    x *= r\n"], ["import math\n\nn=8\nratio = 2\nr= ratio\ngeom_prog = [1]\nfor i in range(1, int(math.log(n)/math.log(ratio))+1):\n    geom_prog.append(geom_prog[-1] * r)\n\nprint(geom_prog)\n"], ["import math\nr= 2\ngeom_prog = []\nn = 8\nn = int(math.log(n, r))\nfor i in range(0, n+1):\n    k = math.pow(r,i)\n    geom_prog.append(k)\n"], [">>> r = 2\n>>> n = 8\n>>> e = 1\n>>> geom_prog = []\n>>> while e <= n:\n...     geom_prog.append(e)\n...     e *= r\n... \n>>> geom_prog\n[1, 2, 4, 8]\n"], ["for i in range(1, n+1): \n", "n = 8\nr = 2\ngeom_prog = []\n\ni = 1 ;\nwhile(i*r <= n):\n    geom_prog.append(i*r)\n    i+=1 ;\n\n#print(geom_prog) #returns [2, 4, 6, 8]\n"], [], ["import re\nkeywords=['bimbo', 'qualified', 'tornadoes', 'alteryx', 'excel', 'manchester']\n# Compiling regext pattern from keyword list\npattern = re.compile('|'.join(keywords))\n\nwith open(\"recognition_log.txt\", \"r\", encoding=\"utf8\") as f:\n    searchInLines = f.readlines()\n\nfor line in searchInLines:\n    # if we get a match\n    if re.search(pattern, line.lower()):\n        print(line)\n"], [], ["keywords = ['bimbo', 'qualified', 'tornadoes', 'alteryx', 'excel', 'manchester']\n\nwith open(\"test.txt\", \"r\", encoding=\"utf8\") as f:\n    searchInLines = f.readlines()\n    f.close()\n\nfor words in keywords:\n    for i, line in enumerate(searchInLines):\n        if words.upper() in line.upper():\n            print(searchInLines[i])\n"], ["import re\n\nkeywords=['bimbo', 'qualified', 'tornadoes', 'alteryx', 'excel', 'manchester']\n\n\nwith open(\"recognition_log.txt\", \"r\", encoding=\"utf8\") as f:\n    searchInLines = f.readlines()\n\n#pattern = re.compile(\"(\" + \"|\".join(keywords) + \")\", flags=re.IGNORECASE)\npattern = re.compile(\"(\" + \"|\".join(r\"\\b{}\\b\".format(i) for i in keywords) + \")\", flags=re.IGNORECASE)\nfor line in searchInLines:\n    if pattern.search(line):\n        print(line)\n"], [], [], [], ["It is a common practice to keep a version number in the source code, there is nothing wrong in that.\n"], ["s = 'ABCDEF'\nins = '$'\nbefore = 'DE'\nnew_s = s.replace(before, ins + before, 1)\n\nprint(new_s)\n# ABC$DEF\n"], ["   x='high speed'\n    z='new text' \n    y = x.index('speed')\n    x =x[:y] + z +x[y:]\nprint(x) \n>>> high new textspeed\n"], ["In [1]: import re\n\n        pattern = r'(?=\\()'\n        string = '__int64 __fastcall(IOService *__hidden this);'\n        re.sub(pattern, 'pizza', string)\n\nOut[1]: '__int64 __fastcallpizza(IOService *__hidden this);'\n"], ["s = \"__int64__fastcall(IOService *__hidden this);\"\nt = s.split(\"__fastcall\",1)[0]+\"anystring\"+s.split(\"__fastcall\",1)[1]\n", "__int64__fastcallanystring(IOService *__hidden this);\n"], ["    string = 'abcdefg'\n    string_to_insert = '123'\n    insert_before_char = 'c'\n    for i in range(len(string)):\n        if string[i] == insert_before_char:\n            string = string[:i] + string_to_insert + string[i:]\n            break\n"], ["def printEvenfor(x,y):\n    return list(range(((x+1) // 2) * 2,y+1, 2))\n\nprintEvenfor(9,16)\n"], [">>> low, high = int(input()), int(input())\n5\n13\n>>> for n in range(low, high + 1):\n...     print('{}\\n'.format(n)*(not n%2), end='')\n... \n6\n8\n10\n12\n"], ["for each in range(int(input()),int(input())):\n    while each%2 == 0:\n       print (each)\n       break; \n"], ["def print_event_for(min_, max_):\n    reminder = min_ % 2\n    for i in range(min_+reminder, max_+reminder, 2):\n        print(i)\n\nprint_event_for(5, 12)\n", "6\n8\n10\n12\n"], ["x = (x // 2) * 2\n", "x = ((x + 1) // 2) * 2\n", "x = (x >> 1) << 1         #Alternative 1\nx = ((x + 1) >> 1) << 1   #Alternative 2\n", "#Alternative 1\nx = 9\nx = (x >> 1) << 1\n#x is now 8\n\n#Alternative 2\nx = 9\nx = ((x + 1) >> 1) << 1\n#x is now 10\n"], ["def print_even_between(x, y):\n    x = round(x / 2) * 2\n    y = round(y / 2) * 2\n\n    for i in range(x, y, 2):\n        print(i)  \n    print(y)\n"], [">>> for n in range((x + 1) // 2 * 2, y+1, 2):\n        print(n)\n"], [], [], ["X = X.append([state], ignore_index=True)\n"], ["import os\n\ndef up_n(path, n):\n    components = os.path.normpath(path).split(os.sep)\n    return os.sep.join(components[:-n])\n\nif __name__ == '__main__':\n    path = '/data/python_env/lib/python3.6/site-packages/matplotlib/mpl-data'\n    result = up_n(path, 2)\n    print(result)  # -> \\data\\python_env\\lib\\python3.6\\site-packages\n"], ["from pathlib import Path\nup_n = lambda orig, n: Path(orig).joinpath('/'.join(['..']*n))\n"], [">>> p = '/data/python_env/lib/python3.6/site-packages/matplotlib/mpl-data'\n>>> os.path.normpath(os.path.join(p, \"..\", \"..\"))\n'/data/python_env/lib/python3.6/site-packages'\n", "os.path.normpath(os.path.join(*([p]+[\"..\"]*n)))\n"], ["from pathlib import Path\n\npath = Path('/data/python_env/lib/python3.6/site-packages/matplotlib/mpl-data')\n\nlevels_up = 2\nprint(path.parents[levels_up-1])\n# /data/python_env/lib/python3.6/site-packages\n"], ["import os\n\ns = \"/data/python_env/lib/python3.6/site-packages/matplotlib/mpl-data\"\nfor _ in range(2):\n    s = os.path.dirname(s)\n\nprint(s)\n", "/data/python_env/lib/python3.6/site-packages\n"], [], [">>> import numpy as np\n>>> list_a = [\"a\", \"b\", \"c\", \"d\"]\n>>> _ = [list_a.remove(i) for i in np.random.choice(list_a, 2) if i in list_a]\n>>> list_a\n['b', 'd']\n"], ["import numpy as np\nlist_a = [\"a\", \"b\", \"c\", \"d\"]\nnp.random.shuffle(list_a)\nlist_b, list_a = list_a[:2], list_a[2:]\n"], ["import numpy as np\nlist_a = [\"a\", \"b\", \"c\", \"d\"]\nlist_b = np.random.choice(list_a, 2)\n\nfor i in list_b:\n    list_a.remove(i)\n\nprint list_a\nprint list_b\n", "list_a = [a, c]\nlist_b = [b, d]\n"], ["list_a = [\"a\", \"b\", \"c\", \"d\"]\nlist_b = np.random.choice(list_a, 2)\n\nprint([x for x in list_a if x not in list_b])\nprint(list_b)\n", "['c', 'd']\n['b' 'a']\n"], [], ["state.name=0\nX = pd.DataFrame()\nX.append(state)\n"], ["X=pd.concat([X,state], axis=1)\n\n\n"], [], [], ["while True:\n    inp = input(\"Would you like to add a student name: \")\n    if len(inp) == 0 or inp ==\"\": #checking the if the the length of the input is equal to 0 or is an empty string \n        break\n    student_name = input(\"Student name: \")\n    student_id = input(\"Studend ID: \")\n    add_student = (student_name, student_id)\n\nprint (\"The file list-{}.csv is created!\".format(\"something\"))\n"], ["if inp == str(0): # or simply inp == \"0\"\n   ...\n", "if int(inp) == 0:\n    ...\n"], ["while True:\n    inp = int(input(\"Would you like to add a student name: \"))\n    if inp == 0:\n        break\n    student_name = input(\"Student name: \")\n    student_id = input(\"Studend ID: \")\n    add_student(student_name, student_id)\n"], ["inp = int(input(\"Would you like to add a student name: \"))\nif inp == 0:\n", "inp = input(\"Would you like to add a student name: \")\nif inp == '0':\n"], ["import threading\nimport requests, json\nimport time\nfrom urllib.parse import urlparse\n\nfinal_dict = {} # will hold final results\n\ndef parser(u):\n    try:\n        parsed_uri = urlparse(u) # parse url to get domain name that'l be used as key in final_dict\n        domain = \"{uri.netloc}\".format(uri=parsed_uri)\n        x = requests.get(u)\n        status_code = x.status_code\n        headers = x.headers\n        cookies = x.cookies\n        # OR cookies = \";\".join(f\"{k}:{v}\" for k,v in x.cookies.iteritems())\n        html = x.text\n        # do something with the parsed url, in this case, I created a dictionary containing info about the parsed url: timestamp, url, status_code, html, headers and cookies\n        if not domain in final_dict:\n            final_dict[domain] = []\n        final_dict[domain].append( {'ts': time.time(), 'url': u, 'status': status_code , 'headers': str(headers), 'cookies': str(cookies), 'html': html} )\n\n    except Exception as e:\n        pass\n        print(e)\n        return {}\n\nmax_threads = 10\nurls = ['https://google.com','https://www.facebook.com', 'https://google.com/search?q=hello+world', 'https://www.facebook.com/messages/', 'https://google.com/search?q=learn+python', 'https://www.facebook.com/me/photos', 'https://google.com/search?q=visit+lisboa', 'https://www.facebook.com/me/photos_albums']\n\nfor u in urls:\n    threading.Thread(target=parser, args=[u]).start()\n    tc = threading.active_count()\n    while tc == max_threads:\n        tc = threading.active_count()\n        time.sleep(0.2)\n\nwhile tc != 1: # wait for threads to finish, when tc == 1 no more threads are running apart from the main process.\n    tc = threading.active_count()\n    time.sleep(0.2)\n\nprint(json.dumps(final_dict))\n\n'''\n# save to file\nwith open(\"output.json\", \"w\") as f:\n    f.write(json.dumps(final_dict))\n\n# load from file\nwith open(\"output.json\") as f:\n    _json = json.loads(f.read())\n'''\n"], [], ["taken_asks -= bool(taken_asks)\n"], ["if not taken_asks == 0:\n    taken_asks -= 1\n", "if not taken_asks == 0: taken_asks -= 1\n"], ["taken_asks = 0    \ntaken_asks -= 1 if taken_asks else 0    \nprint(taken_asks)   # 0\n"], [], ["import asyncio\n\nasync def coroutine():\n    print('in coroutine')\n\ncoro = coroutine()\nevent_loop = asyncio.get_event_loop()\n\nevent_loop.run_until_complete(coro)\nevent_loop.close()\n"], [], ["import random\nfrom students.models import students\n\npars = students.objects.all()\n\ndef groupp (x, y):\n    res = random.sample(x, y)\n    while len(set([u.first_language for u in res])) < y:\n        res = random.sample(x, y)\n    return res\n", "def lession_group (request):\n    results=[]\n    parr = list(students.objects.all())\n    pick = []\n    picked = []\n    final = []\n    for i in range(4):\n        pick = groupp (parr, 2)\n        while pick in final or pick[::-1] in final or any(p in picked for p in pick):\n            pick = groupp (parr, 2)\n        final.append(pick)\n        picked.extend(pick)\n"], ["password = [4,9,8] # List of numbers \nwhile True:\n    typed_in = int(input(\"What is the passing code?\\n> \"))\n    if typed_in not in password: # Check if input is IN the list\n        print(\"Wrong, try again!\")\n    elif typed_in in password: # Check if input is NOT in the list\n        print(\"Well done! You have stopped falling.\")\n        return # Exit function\n    else:\n        print(\"Say what?\")\n"], ["while True:\n        typed_in = int(input(\"What is the passing code?\\n> \"))\n        if typed_in not in password:\n                print(\"Wrong, try again!\")\n        elif typed_in in password:\n                print(\"Well done! You have stopped falling.\")\n                break\n        else:\n                print(\"Say what?\")\n"], [], ["def hell_hole():\nprint(\"You have just fallen through the hell hole.\")\nprint(\"You must guess the right number to stop falling otherwise this program will keep repeating.\")\nprint(\"The right numbers are between 1 - 10 \")\npassword = [4,9,8]\n\nwhile True:\n    typed_in = int(input(\"What is the passing code?\\n> \"))\n    if typed_in in password:\n        print(\"Well done! You have stopped falling.\")\n        break\n    else:\n        print(\"Wrong, try again!\")\n"], [], ["from django.core.cache import cache\nfrom django.core.exceptions import PermissionDenied\nfrom django.http import HttpResponse\nfrom django.views.decorators.cache import never_cache\n\n@never_cache\ndef clear_cache(request):\n    if not request.user.is_superuser:\n        raise PermissionDenied\n    cache.clear()\n    return HttpResponse('Cache has been cleared')\n", "from django.urls import path\nfrom . import views\n\nurlpatterns = [\n    ...\n    path('clear_cache/', views.clear_cache),\n]\n", "http://HOST/clear_cache\n"], ["bool_df = df.isnull()\ndf[bool_df['A'] ^ bool_df['B']].shape[0]\n", "df[bool_df['A'] & bool_df['B']].shape[0]\n"], ["v = df.isna().mul([1, 2]).sum(1).value_counts() \nv.index = v.index.map({2: 'only B', 1: 'only A', 0: 'neither'})    \nv\n\nonly B     3\nonly A     2\nneither    1\ndtype: int64\n", "df.isna().pivot_table(index='A', columns='B', aggfunc='size').stack()\n\nA      B    \nFalse  False    1.0\n       True     3.0\nTrue   False    2.0\ndtype: float64\n"], ["df1 = df.isna()\ndf2 = pd.crosstab(df1.A, df1.B)\nprint (df2)\nB      False  True \nA                  \nFalse      1      3\nTrue       2      0\n", "print (df2.loc[False, False])\n1\n", "df2 = pd.crosstab(df1.A, df1.B).add_prefix('B_').rename(lambda x: 'A_' + str(x))\nprint (df2)\nB        B_False  B_True\nA                       \nA_False        1       3\nA_True         2       0\n", "print (df2.loc['A_False', 'B_False'])\n1\n", "df = pd.DataFrame({'A': [1, np.nan,2,3, np.nan,4, np.nan], \n                   'B': [np.nan, 1,np.nan,2, 3, np.nan, np.nan]})\n\ns = df.isna().dot(df.columns).replace({'':'no match'}).value_counts()\nprint (s)\n\nB           3\nA           2\nno match    1\nAB          1\ndtype: int64\n"], ["df.isnull().groupby(['A','B']).size()\nOut[541]: \nA      B    \nFalse  False    1\n       True     3\nTrue   False    2\ndtype: int64\n"], ["df = pd.DataFrame({'A': [1, np.nan,2,3, np.nan,4], 'B': [np.nan, 1,np.nan,2, 3, np.nan]})\n\ncount1 = len(df[(~df['A'].isnull()) & (df['B'].isnull())])\ncount2 = len(df[(~df['A'].isnull()) & (~df['B'].isnull())])\ncount3 = len(df[(df['A'].isnull()) & (~df['B'].isnull())])\n\nprint(count1, count2, count3)\n", "3 1 2\n"], ["from django.core.cache import cache\n\ndef PageView(request):\n    ...\n    if request.GET.get('clear') == 'cache':\n        if request.user.is_superuser:\n            title = request.GET.get('flag') + ' ' + title \n            cache.clear()\n    ...\n    return render(request, template, context)\n"], ["s=df.A.values\n(s[:,None]>s).sum(1)\nOut[649]: array([0, 2, 1, 4, 5, 2])\n\n#df['NewCol']=(s[:,None]>s).sum(1)\n"], ["df['NewCol'] = (df['A'].rank(method='min') - 1).astype(int)\n", "   A  NewCol\n0  1       0\n1  3       2\n2  2       1\n3  5       4\n4  8       5\n5  3       2\n"], ["df=pd.DataFrame({'A': [1,3,2,5,8,3]})\ncol=df['A']\ndf['new_col']=[ sum(col<i) for i in col ]\n\nprint(df)\n", "   A  new_col\n0  1        0\n1  3        2\n2  2        1\n3  5        4\n4  8        5\n5  3        2\n"], ["m=df.A.sort_values().reset_index(drop=True).reset_index()\nm.columns=['new','A']\nprint(m)\n\n   new  A\n0    0  1\n1    1  2\n2    2  3\n3    3  3\n4    4  5\n5    5  8\n"], ["import pandas as pd\n\ndf = pd.DataFrame({'A': [1,3,2,5,8,3]})\n\ndf['NewCol'] = 0\nfor idx, row in df.iterrows():\n    df.loc[idx, 'NewCol'] = (df.loc[:, 'A'] < row.A).sum()\n\nprint(df)\n", "   A  NewCol\n0  1       0\n1  3       2\n2  2       1\n3  5       4\n4  8       5\n5  3       2\n"], ["A = [Your numbers]\nless_than = []\n    for element in A:\n        counter = 0\n        for number in A:\n            if number < element:\n                counter += 1\n        less_than.append(counter)\n"], [], [], ["#!/usr/bin/env python3\nimport os\nimport time\nimport random\nfrom threading import Thread\nfrom multiprocessing import Process, JoinableQueue\n\n\nWORKERS = 4\nDOWNLOADS_PER_SECOND = 2\n\n\ndef download_resource(url, resource_queue):\n    pid = os.getpid()\n\n    t = time.strftime('%H:%M:%S')\n    print('Thread {p} is downloading from {u} ({t})'.format(p=pid, u=url, t=t),\n          flush=True)\n    time.sleep(random.randint(1, 10))\n\n    results = '[resource {}]'.format(url)\n    resource_queue.put(results)\n\n\ndef process_resource(resource_queue):\n    pid = os.getpid()\n\n    while True:\n        res = resource_queue.get()\n\n        print('Process {p} is processing {r}'.format(p=pid, r=res),\n              flush=True)\n        time.sleep(random.randint(1, 10))\n\n        resource_queue.task_done()\n\n\ndef main():\n    resource_queue = JoinableQueue()\n\n    # Start process workers:\n    for _ in range(WORKERS):\n        worker = Process(target=process_resource,\n                         args=(resource_queue,),\n                         daemon=True)\n        worker.start()\n\n    urls = ['https://link/to/resource/{i}'.format(i=i) for i in range(10)]\n\n    while urls:\n        target_urls = urls[:DOWNLOADS_PER_SECOND]\n        urls = urls[DOWNLOADS_PER_SECOND:]\n\n        # Start downloader threads:\n        for url in target_urls:\n            downloader = Thread(target=download_resource,\n                                args=(url, resource_queue),\n                                daemon=True)\n            downloader.start()\n\n        time.sleep(1)\n\n    resource_queue.join()\n\n\nif __name__ == '__main__':\n    main()\n", "$ ./limit_download_rate.py\nThread 32482 is downloading from https://link/to/resource/0 (10:14:08)\nThread 32482 is downloading from https://link/to/resource/1 (10:14:08)\nThread 32482 is downloading from https://link/to/resource/2 (10:14:09)\nThread 32482 is downloading from https://link/to/resource/3 (10:14:09)\nThread 32482 is downloading from https://link/to/resource/4 (10:14:10)\nThread 32482 is downloading from https://link/to/resource/5 (10:14:10)\nProcess 32483 is processing [resource https://link/to/resource/2]\nProcess 32484 is processing [resource https://link/to/resource/0]\nThread 32482 is downloading from https://link/to/resource/6 (10:14:11)\nThread 32482 is downloading from https://link/to/resource/7 (10:14:11)\nProcess 32485 is processing [resource https://link/to/resource/1]\nProcess 32486 is processing [resource https://link/to/resource/3]\nThread 32482 is downloading from https://link/to/resource/8 (10:14:12)\nThread 32482 is downloading from https://link/to/resource/9 (10:14:12)\nProcess 32484 is processing [resource https://link/to/resource/6]\nProcess 32485 is processing [resource https://link/to/resource/9]\nProcess 32483 is processing [resource https://link/to/resource/8]\nProcess 32486 is processing [resource https://link/to/resource/4]\nProcess 32485 is processing [resource https://link/to/resource/7]\nProcess 32483 is processing [resource https://link/to/resource/5]\n"], ["from django.http import HttpRequest\ndef get_user_ip(request):\n    client_address = request.META['HTTPS_X_FORWARDED_FOR']\n    if your_ip == client_address:\n        save_user_ip()\n"], [">>> import re\n>>> myString = 'He got 10/19 questions right.'\n>>> stringNumber = re.findall('([0-9]+)/', myString)\n>>> stringNumber\n['10']\n", ">>> intNumber = list(map(int, stringNumber))\n>>> intNumber\n[10]\n"], ["import re\nmyString = \"He got 10/19 questions right.\"\noldnumber = re.findall('[0-9]+/', myString)  #find one or more digits followed by a slash.\nnewNumber = oldnumber[0].replace(\"/\",\"\")  #get rid of the slash.\n\nprint(newNumber)\n>>>10\n"], ["t = \"He got 10/19 questions right.\"\nt2 = \"He/she got 10/19 questions right\"\n\n\nfor q in [t,t2]:\n\n\n    # split whole string at spaces\n    # split each part at / \n    # only keep parts that contain / but not at 1st position and only consists\n    # out of numbers elsewise\n    numbers = [x.split(\"/\") for x in q.split() \n               if \"/\" in x and all(c in \"0123456789/\" for c in x)\n              and not x.startswith(\"/\")]\n    if numbers:\n        print(numbers[0][0])\n", "10\n10\n"], ["res = re.search('(\\d+)/\\d+', r'He got 10/19 questions right.')\nres.groups()\n('10',)\n"], ["\\d+(?=/)\n"], [">>> test_dict = {\"value1\": 111.2, \"value2\": \"asd\", \"value3\": 13.232}\n>>> test_dict = {key: int(math.floor(value)) if isinstance(value, float) else value for key, value in test_dict.items()}\n>>> test_dict\n{'value1': 111, 'value2': 'asd', 'value3': 13}\n"], ["import math  \n\nprint({k: int(v) if k == 'age' or k == 'year' and not math.isnan(v) else v for k,v in d.items()})\n", "{\n\n 'artForm': 'Madur', 'artistName': 'Bharati Dolai', 'gender': 'F', \n 'district': 'Paschim Medinipur', 'phone': '', \n 'artisanCard': {'exists': 'N', 'cardNo': ''}, \n 'dob': '', 'age': 45, 'year': 1971, \n 'education': 'I', 'childrenGoToSchool': 'Y'\n\n}\n", "print({k: int(v) for k, v in d.items() if k == 'age' or k == 'year' and not math.isnan(v)})\n", "{'age': 45, 'year': 1971}\n"], ["num_of_nans = 0\n\nfor entry in d:\n    try:\n        entry['age'] = int(entry['age'])\n    except ValueError:\n        entry['age'] = 'Age not known'\n        num_of_nans += 1\n"], [], ["import math\nfor i in range(len(d)):\n    if not math.isnan(d[i]['age']):\n        d[i]['age'] = int(d[i]['age'])\n"], ["d = {'artForm': 'Madur',\n  'artistName': 'Bharati Dolai',\n  'gender': 'F',\n  'district': 'Paschim Medinipur',\n  'phone': '',\n  'artisanCard': {'exists': 'N', 'cardNo': ''},\n  'dob': '',\n  'age': 45.0,\n  'year': 1971.0,\n  'education': 'I',\n  'childrenGoToSchool': 'Y'\n}\n\n\nfor i in range(len(d)):\n    #convert age to int and replace age\n    d['age'] = int(d['age'])\n#if you want to convert all the floats to ints:\nfor k in list(d):#list d to get all the key\n    #test is float?\n    if isinstance(d[k], float):\n        #yes? convert it to int\n        d[k] = int(d[k])\n    #else pass\n    else:\n        pass\n\nprint(d)\n"], ["for i in range(len(d)):\n    try:\n        d[i]['age'] = int(d[i]['age'])\n    except Exception as e1:\n        pass\n"], ["#!/usr/bin/env python3\nimport os\nimport time\nimport random\nfrom functools import partial\nfrom multiprocessing import Pool, Manager\n\n\nCPU_NUM = 4\nCONCURRENT_DOWNLOADS = 2\n\n\ndef download(url, semaphore):\n    pid = os.getpid()\n\n    with semaphore:\n        print('Process {p} is downloading from {u}'.format(p=pid, u=url))\n        time.sleep(random.randint(1, 5))\n\n    # Process the obtained resource:\n    time.sleep(random.randint(1, 5))\n\n    return 'Successfully processed {}'.format(url)\n\n\ndef main():\n    manager = Manager()\n\n    semaphore = manager.Semaphore(CONCURRENT_DOWNLOADS)\n    target = partial(download, semaphore=semaphore)\n\n    urls = ['https://link/to/resource/{i}'.format(i=i) for i in range(10)]\n\n    with Pool(processes=CPU_NUM) as pool:\n        results = pool.map(target, urls)\n\n    print(results)\n\n\nif __name__ == '__main__':\n    main()\n"], [], ["import numpy as np\nimport matplotlib.pyplot as plt\n\n# sample\nsize = 10000\nR = 1\nphi = np.random.random(size=size) * np.pi\nr = np.sqrt(np.random.random(size=size)) * R\n\n# transform\nx = r * np.cos(phi)\ny = r * np.sin(phi)\n\n# plot\nf = plt.figure(figsize=(12,12))\na = f.add_subplot(111)\na.scatter(x, y, marker='.')\na.set_aspect('equal')\nplt.show()\n"], ["import multiprocessing\nfrom multiprocessing import Pool\nimport time\nimport typing\n\ndef work(doc: str) -> str:\n    # do some processing here....\n    return doc + \" processed\"\n\ndef download(url: str) -> str:\n    return url  # a hack for demo, use e.g. `requests.get()`\n\ndef run_pipeline(\n    urls: typing.List[str],\n    session_request_limit: int = 10,\n    session_length: int = 60,\n) -> None:\n    \"\"\"\n    Download and process each url in `urls` at a max. rate limit\n    given by `session_request_limit / session_length`\n    \"\"\"\n    workers = Pool(multiprocessing.cpu_count())\n    results = []\n\n    n_requests = 0\n    session_start = time.time()\n\n    for url in urls:\n        doc = download(url)\n        results.append(\n            workers.apply_async(work, (doc,))\n        )\n        n_requests += 1\n\n        if n_requests >= session_request_limit:\n            time_to_next_session = session_length - time.time() - session_start\n            time.sleep(time_to_next_session)\n\n        if time.time() - session_start >= session_length:\n            session_start = time.time()\n            n_requests = 0\n\n    # Collect results\n    for result in results:\n        print(result.get())\n\nif __name__ == \"__main__\":\n    urls = [\"www.google.com\", \"www.stackoverflow.com\"]\n    run_pipeline(urls)\n"], ["from ratelimit import limits\n\nimport requests\n\nFIFTEEN_MINUTES = 900\n\n@limits(calls=15, period=FIFTEEN_MINUTES)\ndef call_api(url):\n    response = requests.get(url)\n\n    if response.status_code != 200:\n        raise Exception('API response: {}'.format(response.status_code))\n    return response\n", "import logging\nimport threading\nimport time\n\nlogging.basicConfig(level=logging.DEBUG,\n                    format='(%(threadName)-10s) %(message)s',\n                    )\n\ndef wait_for_event(e):\n    \"\"\"Wait for the event to be set before doing anything\"\"\"\n    logging.debug('wait_for_event starting')\n    event_is_set = e.wait()\n    logging.debug('event set: %s', event_is_set)\n\ndef wait_for_event_timeout(e, t):\n    \"\"\"Wait t seconds and then timeout\"\"\"\n    while not e.isSet():\n        logging.debug('wait_for_event_timeout starting')\n        event_is_set = e.wait(t)\n        logging.debug('event set: %s', event_is_set)\n        if event_is_set:\n            logging.debug('processing event')\n        else:\n            logging.debug('doing other work')\n\n\ne = threading.Event()\nt1 = threading.Thread(name='block', \n                      target=wait_for_event,\n                      args=(e,))\nt1.start()\n\nt2 = threading.Thread(name='non-block', \n                      target=wait_for_event_timeout, \n                      args=(e, 2))\nt2.start()\n\nlogging.debug('Waiting before calling Event.set()')\ntime.sleep(3)\ne.set()\nlogging.debug('Event is set')\n"], ["from django.core.cache.backends.filebased import FileBasedCache\nfrom django.core.cache.backends.dummy import DummyCache\nfrom django.core.cache.backends.base import DEFAULT_TIMEOUT\nfrom constance import config\n\n\nclass MyCache(DummyCache):\n\n    def __init__(self, *args, **kwargs):\n        self.dummy_cache = DummyCache(*args, **kwargs)\n        self.file_cache = FileBasedCache(*args, **kwargs)\n\n    def _active_cache(self):\n        \"\"\"\n        Select either DummyCache or FileBasedCache based on configuration\n        \"\"\"\n        return self.file_cache if config.CACHING_ENABLED else self.dummy_cache\n\n    def add(self, key, value, timeout=DEFAULT_TIMEOUT, version=None):\n        return self._active_cache().add(key, value, timeout, version)\n\n    def get(self, key, default=None, version=None):\n        return self._active_cache().get(key, default, version)\n\n    def set(self, key, value, timeout=DEFAULT_TIMEOUT, version=None):\n        self._active_cache().set(key, value, timeout, version)\n\n    def touch(self, key, timeout=DEFAULT_TIMEOUT, version=None):\n        return self._active_cache().touch(key, timeout, version)\n\n    def delete(self, key, version=None):\n        self._active_cache().delete(key, version)\n\n    def has_key(self, key, version=None):\n        return self._active_cache().has_key(key, version)\n\n    def clear(self):\n        self._active_cache().clear()\n", "CACHES = {\n    'default': {\n        'BACKEND': 'project.mycache.MyCache',\n        'LOCATION': '/var/www/mysite.com/cache,\n    }\n}\n", "INSTALLED_APPS = [\n    ...\n    'constance',\n    'constance.backends.database',\n]\n\nCONSTANCE_BACKEND = 'constance.backends.database.DatabaseBackend'\nCONSTANCE_CONFIG = {\n    'CACHING_ENABLED': (True, 'Set to False to disable caching'),\n}\n", "pip install django-constance[database]\npython manage.py migrate\n"], ["ray.init(num_cpus=4, resources={'Network': 2})\n", "@ray.remote(resources={'Network': 1})\ndef f():\n    pass\n", "@ray.remote\ndef g():\n    pass\n", "import ray\nimport time\n\nmax_concurrent_downloads = 2\n\nray.init(num_cpus=4, resources={'Network': max_concurrent_downloads})\n\n@ray.remote(resources={'Network': 1})\ndef download_content(url):\n    # Download the file.\n    time.sleep(1)\n    return 'result from ' + url\n\n@ray.remote\ndef process_result(result):\n    # Process the result.\n    time.sleep(1)\n    return 'processed ' + result\n\nurls = ['url1', 'url2', 'url3', 'url4']\n\nresult_ids = [download_content.remote(url) for url in urls]\n\nprocessed_ids = [process_result.remote(result_id) for result_id in result_ids]\n\n# Wait until the tasks have finished and retrieve the results.\nprocessed_results = ray.get(processed_ids)\n"], ["runif_in_semicircle <- function(n, radius=1){\n  theta <- runif(n, 0, pi)\n  r <- radius * sqrt(runif(n))\n  cbind(r*cos(theta), r*sin(theta))\n}\n\nsims <- runif_in_semicircle(1000)\nplot(sims[,1], sims[,2], asp=1, pch=19)\n", "# integrand example\nf <- function(x) x[1]^2 + exp(x[2])\n\nset.seed(666)\nsims <- runif_in_semicircle(10000)\nfsims <- apply(sims, 1, f)\nmean(fsims)*pi/2 # approximates the integral of f over the half-disk\n# 2.890905\n", "library(SphericalCubature)\nadaptIntegrateBallPolar(f, n=2, lowerLimit = 0, upperLimit = pi)\n# $integral\n# [1] 2.880598\n"], ["import numpy as np\nimport matplotlib.pyplot as plt\n\nn = 10000\nr = 3  # radius\n\nuniform_square = np.random.uniform(-r,r,(int(2.65*n),2))\nradius = np.sqrt(uniform_square[:,0]**2 + uniform_square[:,1]**2)\n\nuniform_circle = uniform_square[radius<=r,:]\n\nuniform_half_circle = uniform_circle[uniform_circle[:,0]>=0,:]\n\nfinal_points = uniform_half_circle[0:n,:]\n\nfig, axs = plt.subplots(1, 1)\naxs.scatter(final_points[:,0], final_points[:,1], marker='.')\naxs.set_aspect('equal', 'box')\nplt.show()\n"], ["# generate about n points in a half-circle with\n# given center (x, y) and given radius, and y>0\n\npoints <- function(x, y, radius, n) {\n    n2 = n * 4 / pi # each point has pi/4 probability to survive\n\n    # make [-1, 1] * [-1, 1] square\n    xs = runif(n2, -1, 1)\n    ys = runif(n2, 0, 1)  # or just runif(n2)\n    points = cbind(xs, ys)\n\n    # keep only points in circle with center (0,0) and radius 1 with y>0\n    ind = (xs**2 + ys**2 <= 1) # the condition ys>=0 is obeyed already\n    points = points[ind,]\n\n    # move/stretch to given center and radius\n    points = points * radius\n    points[,1] = points[,1] + x\n    points[,2] = points[,2] + y\n}\n\n# generate about 1000 points with center(1,1) and radius 3\npoints = f(1, 1, 3, 1000)\n\n# plot them, making them smaller for better visibility\nplot(points, cex=0.3)\n"], ["size <- 1000\nmaxRad <- 1 #maximum radius of the half-circle\nr <- runif(1000,0,maxRad) #generate random radius\nphi <- runif(size,0,pi) #generate angle for polarcoordinates (between 0 and pi since you want a halfcircle)\nx <- r*cos(phi) #polarcoordinates\ny <- r*sin(phi)\nplot(x,y)\n", "halfCircle <- function(size, maxRad) {\n r <- runif(1000,0,maxRad)\n phi <- runif(size,0,1)*pi\n x <- r*cos(phi)\n y <- r*sin(phi)\n plot(x,y)\n}\n"], ["import numpy as np\nimport matplotlib.pyplot as plt\n\nx = np.random.random(size) * 2 - 1\ny = np.random.random(size)\nr = np.sqrt(x**2 + y**2)\nx[r > 1] = -3\ny[r > 1] = -3\nplt.plot(x, y, 'o')\nplt.show()\n"], ["from itertools import accumulate\nfrom more_itertools import pairwise\n\na = [0, 1, 2, 3, 4, 5, 6, 7]\nb = (3, 3, 2)\n\n[a[slice(*s)] for s in pairwise(accumulate((0,)+b))]\n"], ["import numpy as np\n\na = [0, 1, 2, 3, 4, 5, 6, 7]\nb = (3, 3, 2)\n\nc = np.split(a, np.cumsum(b)[:-1])\n\nfor r in c:\n    print(r)\n"], [">>> from itertools import islice\n>>> a = [0, 1, 2, 3, 4, 5, 6, 7]\n>>> b = (3, 3, 2)\n>>> i = iter(a)\n>>> [list(islice(i, x)) for x in b]\n[[0, 1, 2], [3, 4, 5], [6, 7]]\n"], ["result = [ex_array[sum(extuple[:iii]):sum(extuple[:iii])+extuple[iii]] for iii in range(len(extuple))]\n"], ["a = [0, 1, 2, 3, 4, 5, 6, 7]\nb = (3, 3, 2)\n\nfor ind in b:\n    print(a[:ind])\n    a = a[ind:]\n"], ["def GetNumbersInBetween(lst, l_Bound, u_Bound):\n    n_List = []\n\n    lowerBound = min(l_Bound, u_Bound)   # Get the lower val\n    upperBound = max(l_Bound, u_Bound)   # Get the higher val\n\n    for x in lst:\n        if x >= lowerBound and x <= upperBound:\n            n_List.append(x)\n    return n_List\n\nlst = [9, 10, 11, 15, 19, 20, 21]\n\nlowerBound = 20       # intentionally given the wrong value\nupperBound = 10       # intentionally given the wrong value\n\nprint(GetNumbersInBetween(lst, lowerBound, upperBound))\n", "print([x for x in lst if min(lowerBound,upperBound) <= x <= max(lowerBound,upperBound)])\n", "[10, 11, 15, 19, 20]\n"], [">>> nums\n[9, 10, 11, 15, 19, 20, 21]\n>>> sorted_list = sorted(nums) # easier to find min, max ?\n>>> min_, max_ = sorted_list[0], sorted_list[-1]\n>>> filter(lambda x: min_ < x < max_, nums)\n[10, 11, 15, 19, 20]\n", ">>> import itertools\n>>> list(itertools.ifilter(lambda x: 10 <= x <= 20, nums))\n[10, 11, 15, 19, 20]\n", ">>> list(itertools.filterfalse(lambda x: not (10 <= x <= 20), nums))\n[10, 11, 15, 19, 20]\n"], ["dat=np.random.randint(0,20,50)\nx=5\ny=10\nans=dat[(dat>=x) & (dat<y)]\nprint(ans)\n", "import numpy as np\ndat=np.random.randint(0,20,50)\nx=5\ny=10\nans=dat[np.where((dat>=x) & (dat<y))]\nprint(ans)\n"], ["lst = [9, 10, 11, 15, 19, 20, 21]\nprint([n for n in lst if 10 <= n <= 20])\n", "list(range(10, 20+1))\n", "def get_numbers_in_between(li, x, y):\n    mx, mn = sorted((x, y))\n    return [n for n in li if mx <= n <= mn]\n\nprint(get_numbers_in_between(li=[9, 10, 11, 15, 19, 20, 21], x=20, y=10))\n"], ["def get_numbers_in_between(l,x,y):\n    return [i for i in l if i in range(min(x,y), max(x,y)+1)]\n\nget_numbers_in_between([9, 10, 11, 15, 19, 20, 21], 20, 10)   # [10, 11, 15, 19, 20]\n"], ["small = 8\nbig = 16\nnums_in_between = [n for n in li if n in range(small, big)]\n"], ["In [18]: list\nOut[18]: [[1, 2, 3], [4, 5, 6], [3, 2, 4]]\n\nIn [19]: def contains(sublist):\n             if sublist in list:\n                  return True\n             else:\n                  return False\n   ....:             \n\nIn [20]: contains([1,2,3])\nTrue\n\nIn [21]: contains(2)\nFalse\n\nIn [22]: \n"], ["#!/usr/lib/python\nimport os\nimport datetime\nos.makedirs(\"/home/xxx/\" + datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S'))\n", "os.makedirs(path[, mode])\n"], ["sudo crontab -e \n0 22 * * *  /path/to/directory/python my_code.py\n", "# python code to search pattern in a string using regex\nimport re\n\nstr1 = 'this is {new} string with [special] words.'\n\nr = re.search(r'\\{(.*?)\\}', str1)\nif r:\n    found =r.group()\nelse:\n    \"No match found\"\n\nprint found\n"], ["import os\nimport datetime\n\npath = \"/home/xxx/\"\ncurrent_time = datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\ncommand = \"mkdir {0}\".format(current_time)\n\nos.chdir(path)\nos.system(command)\n"], ["import os\nimport datetime\nos.makedirs(\"C:\\\\Users\\\\PycharmProjects\\\\opencv-basics\" + datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S'))\n", "C:\\Users\\PycharmProjects\\opencv-basics2019-03-22_14-49-26\n"], [], ["import os\nimport datetime\n\nos.makedirs(\"/home/xxx/\" + datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S'))\n"], ["import collections\n\n# 'list_' is the list we are searching for in a bigger list 'list_of_lists'\nfor element in list_of_lists:\n    if collections.Counter(element) == collections.Counter(list_) :\n        return True\n"], [">>> list_of_lists = [[2,2,2,3],[2,3,4],[2,2,6,8]]\n>>> serialize = lambda x: ','.join(map(str,x))\n>>> any(serialize([2,2,6]) in serialize(item) for item in list_of_lists)\nTrue\n>>> any(serialize([2,2,7]) in serialize(item) for item in list_of_lists)\nFalse\n"], ["list_of_lists = [[2,2,2,3],[2,3,4],[2,2,6]]\n\nif [2,2,6] in list_of_lists:\n    print(\"found\")\nelse:\n    print(\"not found\")\n", "found\n", "list_of_lists = [[2,2,2,3],[2,3,4],[2,2,6,8]]\n\nif [2,2,6] in list_of_lists:\n    print(\"found\")\nelse:\n    print(\"not found\")\n", "not found\n", "def chkList(lst):\n    return True if lst in list_of_lists else False\n\nlist_of_lists = [[2,2,2,3],[2,3,4],[2,2,6]]\nprint(chkList([2,2,6]))\n", "True\n"], ["print([2,2,6] in list_of_lists)\n", "print(list_of_lists.__contains__([2,2,6]))\n"], ["if any(list == [2, 2, 6] for list in list_of_lists):\n    #execute whatever code you want for this case\n"], ["------------\nColumns probably not a normal dist:\n  Column  Not_Normal  p-value   Normality\n0      V        True      0.0  Not Normal\n0      W        True      0.0  Not Normal\n0      X        True      0.0  Not Normal\n0      Y        True      0.0  Not Normal\n0      Z        True      0.0  Not Normal\n", "import pandas as pd\nimport numpy as np\nimport scipy\nfrom scipy import stats\nimport seaborn as sb\nimport matplotlib.pyplot as plt\nimport sys\n\nprint('System: {}'.format(sys.version))\nfor module in [pd, np, scipy, sb]:\n    print('Module {:10s} - version {}'.format(module.__name__, module.__version__))\n\nnb_lines = 10000\nheaders_normal = 'ABCDE'\nheaders_pareto = 'VWXYZ'\nreapeat_factor = 1\nnb_cols = len(list(reapeat_factor * headers_normal))\n\ndf_normal = pd.DataFrame(np.random.randn(nb_lines, nb_cols), columns=list(reapeat_factor * headers_normal))\n\ndf_pareto = pd.DataFrame((np.random.pareto(12.0, size=(nb_lines,nb_cols )) + 15.) * 4., columns=list(reapeat_factor * headers_pareto))\n\ndf = df_normal.join(df_pareto)\n\nalpha = 0.01\ndf_list = list()\n\n# normality code taken from https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.normaltest.html\ncat_map = {True: 'Not Normal',\n           False: 'Maybe Normal'}\nfor col in df.columns:\n    k2, p = stats.normaltest(df[col])\n    is_not_normal = p < alpha\n    tmp_df = pd.DataFrame({'Column': [col],\n                           'Not_Normal': [is_not_normal],\n                           'p-value': [p],\n                           'Normality': cat_map[is_not_normal]\n                           })\n    df_list.append(tmp_df)\n\ndf_results = pd.concat(df_list)\ndf_results['Normality'] = df_results['Normality'].astype('category')\n\nprint('------------')\nprint('Columns names probably not a normal dist:')\n# full data\nprint(df_results[(df_results['Normality'] == 'Not Normal')])\n# only column names\n# print(df_results[(df_results['Normality'] == 'Not Normal')]['Column'])\nprint('------------')\nprint('Plotting countplot')\nsb.countplot(data=df_results, y='Normality', orient='v')\nplt.show()\n", "System: 3.7.2 (default, Feb 21 2019, 17:35:59) [MSC v.1915 64 bit (AMD64)]\nModule pandas     - version 0.24.1\nModule numpy      - version 1.16.2\nModule scipy      - version 1.2.1\nModule seaborn    - version 0.9.0\n------------\nColumns names probably not a normal dist:\n  Column  Not_Normal  p-value   Normality\n0      V        True      0.0  Not Normal\n0      W        True      0.0  Not Normal\n0      X        True      0.0  Not Normal\n0      Y        True      0.0  Not Normal\n0      Z        True      0.0  Not Normal\n------------\nPlotting countplot\n"], ["df[\"limit\"]=df['temperature'].rolling(2).apply(lambda x: int(x[0]>90)&int(x[-1]> 90))\n"], ["import multiprocessing as mp\nimport time\nimport datetime\nimport sys\nimport signal\nimport os\n\ndef process(hr, minute):\n    while True:\n        d = datetime.datetime.now()\n        if d.hour == hr and d.minute == minute:\n            os.kill(os.getppid(), signal.SIGTERM)\n            sys.exit()\n        else:\n            time.sleep(25)\n\n\np = mp.Process(target=process, args=(18, 0))\np.start()\n\n# your program here ...\n"], ["import datetime\n#create the alarm clock.\nalarm = datetime.time(15, 8, 24) #Hour, minute and second you want.\n", "while alarm < datetime.datetime.now().time():\n    do something\n", "datetime.datetime(2019, 3, 21, 22, 0, 0)  #Year, month, day, hour, minute and second you want.\n"], ["import datetime\n\ndef proc(h, m):\n    while True:\n        currentHour = datetime.datetime.now().hour\n        currentMinute = datetime.datetime.now().minute\n        if currentHour == h and currentMinute == m:\n            break\n        # Do stuff...\n\n# Function call.\nproc(18,0)\n"], ["import datetime\n\nwhile datetime.datetime.now().hour < 18:\n    do stuff...\n", "if datetime.datetime.now().hour >= 18:\n    return\n"], [], [], [">> threshold = 90\n>> df['Above limit?'] = 0\n>> df.loc[((df['temperature [F]'] > threshold) & (df['temperature [F]'].shift(1) > threshold)), 'Above limit?'] = 1\n>> df\n    day temperature [F] Above limit?\n0   0   89              0\n1   1   91              0\n2   2   93              1\n3   3   88              0\n4   4   90              0\n"], [], ["df['limit']=\"\"\ndf.iloc[0,2]=0\n\nfor i in range (1,len(df)):\n     if df.iloc[i,1]>90 and df.iloc[i-1,1]>90:\n          df.iloc[i,2]=1\n     else:\n          df.iloc[i,2]=0\n"], ["df = pd.DataFrame({'temperature': [89, 91, 93, 88, 90, 91, 91, 93]})\n\nlimit = 90\ndf['Above'] = ((df['temperature']>limit) & (df['temperature'].shift(1)>limit)).astype(int)\ndf\n"], ["import seaborn as sns\nfrom scipy.stats import norm\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ncols = 1000\ndf = pd.DataFrame(np.random.normal(0, 1, [50, cols]))\nfrom scipy.stats import norm\nfig, ax = plt.subplots(figsize = (16, 10))\nfor i, col in enumerate(df.columns):\n    ax=fig.add_subplot(25, 4, i+1)\n    sns.distplot(df[col],fit=norm, kde=False,ax=ax)\nplt.tight_layout()\n", "import seaborn as sns\nfrom scipy.stats import norm\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n df = pd.DataFrame(np.random.randn(50, 1000), columns=list('ABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDED'))\n\nfig, ax = plt.subplots(figsize = (12, 10))\nfor i, col in enumerate(df.columns):\n    plt.subplot(25, 40, i+1)\n    sns.distplot(df.iloc[:,i],fit=norm, kde=False,ax=plt.gca())\n    plt.axis('off')\nplt.tight_layout()\n"], ["a = 1\nb = 2\nc = 3\n\na,b,c = list(map(lambda x: x*2, [a,b,c]))\n\nprint(a,b,c)\n\n# prints: (2, 4, 6)\n"], ["[\n    {\n        \"origin\": \"137.221.143.66, 137.221.143.66\"\n    },\n    {\n        \"user-agent\": \"python-requests/2.21.0\"\n    },\n    {\n        \"headers\": {\n            \"Accept\": \"*/*\",\n            \"Accept-Encoding\": \"gzip, deflate\",\n            \"Host\": \"httpbin.org\",\n            \"User-Agent\": \"python-requests/2.21.0\"\n        }\n    }\n]\n"], ["a, b, c = 3, 4, 5\na, b, c = (2 * i for i in (a, b, c))\nprint(a, b, c)\n# 6 8 10\n"], ["import json\nimport requests\n\nURLs = ['http://httpbin.org/ip',\n'http://httpbin.org/user-agent',\n'http://httpbin.org/headers']\n\njson_list = []\nfor url in URLs:\n    data = requests.get(url)\n    resolvedwo = data.json()\n    json_list.append(resolvedwo)\n\nwith open('resolvedworesolution.json', 'w+') as f:\n    json.dump(json_list, f)\n"], ["import json\nimport requests\nURLs = ['http://httpbin.org/ip',\n'http://httpbin.org/user-agent',\n'http://httpbin.org/headers']\n\njson_list = []\nfor url in URLs:\n    data = requests.get(url)\n    resolvedwo = data.json()\n    with open('resolvedworesolution.json', 'a') as f:   # Using the append mode\n        json.dump(resolvedwo, f)\n        f.write(\"\\n\")                                   # new line for readability\n", "{\"origin\": \"159.122.207.241, 159.122.207.241\"}\n{\"user-agent\": \"python-requests/2.21.0\"}\n{\"headers\": {\"Accept\": \"*/*\", \"Accept-Encoding\": \"gzip, deflate\", \"Host\": \"httpbin.org\", \"User-Agent\": \"python-requests/2.21.0\"}}\n", "with open('resolvedworesolution.json', 'a') as f:\n    f.write(str(resolvedwo))\n    f.write(\"\\n\")\n", "for url in URLs:\n    data = requests.get(url)\n    with open('resolvedworesolution.json', 'a') as f:\n        f.write(data.text)\n        f.write(\"\\n\")\n"], ["def function_to_apply(element):\n    return element*2\n\n# Define variables and store them in a container\na,b,c = 1,2,3\ncontainer = (a,b,c)\n\n# Apply the function on every element with map\ncontainer = tuple(map(function_to_apply, container))\na,b,c = container\n", "# Define variables and store them in a container\na,b,c = 1,2,3\ncontainer = (a,b,c)\n\n# Apply the function on every element with map\ncontainer = tuple(map(lambda x: x*2, container))\na,b,c = container\n"], [], [">>> a = 3\n>>> b = 4\n>>> c = 5\n>>> d, e, f = map(lambda x: x * 2, [a, b, c])\n>>> d\n6\n>>> e\n8\n>>> f\n10\n"], [], [], ["resolvedwo = data.json()\n", "resolvedwo += data.json()\n"], [">>> import numpy as np\n>>> data=np.array([['apples', 'oranges', 'cherries', 'banana'],\n             ['Alice', 'Bob', 'Carol', 'David'],\n             ['dogs', 'cats', 'moose', 'goose']]).reshape(-1)\n>>> max(data,key=len)\n'cherries'\n>>> len(max(data,key=len))\n8\n"], ["new_list = []\nfor sub_list in tableData:\n    for item in sub_list:\n        new_list.append(item)\n\nmax_element = max(new_list, key=len)\n\nprint(max_element) # this actually prints the item\nprint(len(max_element)) # this will give you the length\n"], ["from itertools import chain\n\nchain.from_iterable(tableData)\n", "max(chain.from_iterable(tableData), key=len)\n", "max(map(len, chain.from_iterable(tableData)))\n"], ["tableData = [['apples', 'oranges', 'cherries', 'banana'],\n             ['Alice', 'Bob', 'Carol', 'David'],\n             ['dogs', 'cats', 'moose', 'goose']]\n\nmaxCount = 0\nfor lst in tableData:\n    for elem in lst:\n        maxCount = max(maxCount, len(elem))\n\nprint(maxCount)\n", "8\n"], ["maxLength = 0\nfor row in tableData:\n    maxRowElementLength = len(max(row, key=len))\n    if maxLength < maxRowElementLength:\n        maxLength = maxRowElementLength\n\nprint(maxLength)\n"], ["d=[1,1,1,2,2,3,4,5,5,5]\nfor i in range(len(d)-1):\n   if d[i] == d[i+1]:\n     print(d[i])\n   else:\n     print(d[i])\n     print('\\n')\nprint(d[i])\n", "1\n1\n1\n\n2\n2\n\n3\n\n4\n\n5\n5\n5\n"], ["l = 0 \nfor row in tableData: \n     for col in row: \n         l = len(col) if l < len(col) else l \n"], ["l = max(len(x) for sublist in tableData for x in sublist)\n", ">>> print(l)\n8\n"], ["import pandas as pd\nimport matplotlib.pyplot as plt\n\ncols = 1000\ndf = pd.DataFrame(np.random.normal(0, 1, [50, cols]))\n\n# Loop over all columns\nfig, ax = plt.subplots(figsize = (16, 10))\nfor n, col in enumerate(df.columns):\n    plt.subplot(25, 40, n+1)\n    df[col].hist(ax = plt.gca())\n    plt.axis('off')\nplt.tight_layout()\n\nplt.savefig('1000_histograms.png', bbox_inches='tight', pad_inches = 0, dpi = 200)\n", "import statsmodels.api as sm\n\ncols = 1000\ndf = pd.DataFrame(np.random.normal(0,1, [50, cols]))\n\nfig, axs = plt.subplots(figsize=(18, 12))\nfor n, col in enumerate(df.columns):\n    plt.subplot(25,40,n+1)\n    sm.qqplot(df[col], ax=plt.gca(), #line='45', \n              marker='.', markerfacecolor='C0', markeredgecolor='C0', \n              markersize=2)\n#    sm.qqline(ax=plt.gca(), line='45', fmt='lightgray')\n    plt.axis('off')\n\nplt.savefig('1000_QQ_plots13.png', bbox_inches='tight', pad_inches=0, dpi=200)\n"], ["d=[1,1,1,2,2,3,4,5,5,5]\ntemp = d[0]\nfor i in d:\n  if temp != i:\n     print('\\n')\n  print(i)\n  temp = i\n"], ["d=[1,1,1,2,2,3,4,5,5,5]\n\nfor i in range(len(d)):\n  if i > 0 and d[i] != d [i - 1]:\n      print('\\n')\n  print(d[i])\n"], ["from itertools import groupby\n\nd = [1,1,1,2,2,3,4,5,5,5]\n\nfor _, y in groupby(d):\n    print('\\n'.join(map(str, y)), end='\\n\\n')\n"], [], [" elif params[\"type\"] == 'product':\n      get_product_report(request)\n", " elif params[\"type\"] == 'product': \n      return get_product_report(params)\n"], ["def api_report(request):\n    params = request.GET\n    sql=''\n"], [], ["def api_report(request):\n    params = request.GET\n    if params[\"type\"] == 'revenue': # False so sql is not made, move to next elif\n        sql = get_revenue_query(params)\n\n    elif params[\"type\"] == 'order_count': # False so sql is not made, move to next elif\n        sql = get_order_created_count(params)\n\n    elif params[\"type\"] == 'product_count': # False so sql is not made, move to next elif\n        sql = get_product_count(params)\n\n    elif params[\"type\"] == 'order_card_created_count': # False so sql is not made, move to next elif\n        sql = get_order_card_created_count(params)\n\n    elif params[\"type\"] == 'product_count': # False so sql is not made, move to next elif\n        sql = get_product_count(params)\n\n    elif params[\"type\"] == 'card': # False so sql is not made, move to next elif\n        sql = get_card_query(params)\n\n    elif params[\"type\"] == 'order_not_card_created_count': # False so sql is not made, move to next elif\n        sql = get_order_not_card_created_count(params)\n\n    elif params[\"type\"] == 'product': # False so sql is not made, move to next elif\n        get_product_report(request) # P.S There is also a chance that if this is run then sql variable will also not be made!\n\n    elif params[\"type\"] == 'order_rate_by_district':  # This is also false so code leaves.\n        sql = get_order_rate_by_district(params)\n\n        with connection.cursor() as cursor:\n            cursor.execute(sql)\n            rows = cursor.fetchall()\n            data = []\n            for row in rows:\n                data.append(OrderRateDataEntry(row[0], row[1], row[2]))\n        serializer = OrderRateDataEntrySerializer(data, many=True)\n        return JsonResponse(serializer.data, safe=False)\n\n        pass\n    # When the code is here it still didn't made variable sql. Thus so will crashes when refere to variable sql as it wasn't yet created\n    with connection.cursor() as cursor:\n        cursor.execute(sql) # sql was never made here and thus doesn't exist. Code crashes here.\n        rows = cursor.fetchall()\n        data = []\n        for row in rows:\n            data.append(TimeSeriesDataEntry(row[0], row[1]))\n    serializer = TimeSeriesDataEntrySerializer(data, many=True)\n    return JsonResponse(serializer.data, safe=False)\n"], [], [], [">>> None or False or 5\n5\n>>> -5 or 2\n-5\n", ">>> 2 | 4\n6\n", ">>> -5 | 2\n-5\n", "(vals[1] or vals[0]) > 0\n", ">>> vals = [2, -5]\n>>> (vals[1] or vals[0]) > 0\nFalse\n", ">>> vals = [-5, 2]\n>>> vals[0] > 0 or vals[1] > 0\nTrue\n", ">>> any(x > 0 for x in vals)\nTrue\n"], ["00000000000000000000000000000101\n", "00000000000000000000000000000101\n", "11111111111111111111111111111011\n", "   5 -> 00000000000000000000000000000101\n| -2 -> 11111111111111111111111111111110\n----    --------------------------------\n        11111111111111111111111111111111 -> -1\n"], [">>> 5 or -2\n5\n>>> -2 or 5\n-2\n"], ["In [1]: 5 or -2\nOut[1]: 5\n\nIn [2]: 5 | -2\nOut[2]: -1\n", "In [3]: bin(5)\nOut[3]: '0b101'\n\nIn [4]: bin(-2)\nOut[4]: '-0b10'\n\nIn [5]: bin(5 | -2)\nOut[5]: '-0b1'\n"], [], [">>> any(x > 0 for x in vals)\n", "vals[0] > 0 or vals[1] > 0\n", "vals[0] > 0 or vals[1] > 0 or vals[2] > 0\n"], ["import pandas as pd, numpy as np\nimport matplotlib.pyplot as plt\ndf = pd.DataFrame(np.random.randn(1000, 3*30), columns=list('ABC'*30))\n\ndf.hist(figsize=(20,20))\nplt.tight_layout()\nplt.show()\n"], ["plt.figure(figsize=(26, 3 * len(df.columns))\nfor i, col in enumerate(df.columns):\n    plt.subplot(3, 4, i + 1)\n    plt.hist(df[col], color='blue', bins=100)\n    plt.title(col)\n", "plt.subplot(len(df.columns) / 4, 4, i + 1)\n"], [" searchResult = driver.find_element_by_class_name('searchResults__detail')\n  searchResult.click()\n", "link.click()\n", "paginate = driver.find_element_by_class_name('pagination-link-next')\nwhile paginate.is_displayed() == true:\n    for link in soup_results_overview.findAll(\"a\", class_=\"searchResults__detail\"):\n\n        #Selenium visits each Search Result Page\n        searchResult.click() #click Search Result\n\n        #Scrape the form with a function defined elsewhere\n        scrape()\n\n        #Ask Selenium to go back to the search results overview page\n        driver.back()\n\n    #Click pagination button after executing the for loop finishes on each page\n    paginate.click()\n"], ["import json\nimport requests\nfrom bs4 import BeautifulSoup\n\n# Get 1000 results\nparams = {\"$filter\": \"TemplateName eq 'Application Article'\", \"$orderby\": \"ArticleDate desc\", \"$top\": \"1000\",\n          \"$inlinecount\": \"allpages\", }\nresponse = requests.get(\"https://www.cst.com/odata/Articles\", params=params).json()\n\n# iterate 1000 results\narticles = response[\"value\"]\nfor article in articles:\n    article_json = {}\n    article_content = []\n\n    # title of article\n    article_title = article[\"Title\"]\n    # article url\n    article_url = str(article[\"Url\"]).split(\"|\")[1]\n    print(article_title)\n\n    # request article page and parse it\n    article_page = requests.get(article_url).text\n    page = BeautifulSoup(article_page, \"html.parser\")\n\n    # get header\n    header = page.select_one(\"h1.head--bordered\").text\n    article_json[\"Title\"] = str(header).strip()\n    # get body content with images links and descriptions\n    content = page.select(\"section.content p, section.content img, section.content span.imageDescription, \"\n                          \"section.content  em\")\n    # collect content to json format\n    for x in content:\n        if x.name == \"img\":\n            article_content.append(\"https://cst.com/solutions/article/\" + x.attrs[\"src\"])\n        else:\n            article_content.append(x.text)\n\n    article_json[\"Content\"] = article_content\n\n    # write to json file\n    with open(f\"{article_json['Title']}.json\", 'w') as to_json_file:\n         to_json_file.write(json.dumps(article_json))\n\n  print(\"the end\")\n"], ["from selenium import webdriver\nfrom selenium.webdriver.common.by import By\nfrom selenium.webdriver.support.ui import WebDriverWait\nfrom selenium.webdriver.support import expected_conditions as EC\nimport math\n\nstartUrl = 'https://www.cst.com/solutions#size=20&TemplateName=Application+Article'\nurl = 'https://www.cst.com/solutions#size=20&TemplateName=Application+Article&page={}'\ndriver = webdriver.Chrome()\ndriver.get(startUrl)\ndriver.find_element_by_id('acceptAllCookies').click()\nitems = WebDriverWait(driver,10).until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, \".searchResults__detail\")))\nresultCount = int(driver.find_element_by_css_selector('[data-bind=\"text: resultsCount()\"]').text.replace('items were found','').strip())\nresultsPerPage = 20\nnumPages = math.ceil(resultCount/resultsPerPage)\ncurrentCount = resultsPerPage\nheader = driver.find_element_by_css_selector('.searchResults__detail h3').text\ntest = header\n\nfor page in range(1, numPages + 1):\n    if page == 1:   \n        print([item.text for item in items])\n        #do something with first page\n    else:   \n        driver.find_element_by_css_selector('.pagination-link-next').click()\n        while header == test:\n            try:\n                header = driver.find_element_by_css_selector('.searchResults__detail h3').text\n            except:\n                continue\n\n        items = WebDriverWait(driver,10).until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, \".searchResults__detail\")))\n        test = header\n        #do something with next page\n        print([item.text for item in items])\n    if page == 4:  #delete later\n        break #delete later\n"], ["from bs4 import BeautifulSoup as soup\nimport requests, re\nfrom selenium import webdriver\ndef scrape_page(_d, _link):\n   _head, _paras = _d.find('h1', {'class':'head--bordered'}).text, [i.text for i in _d.find_all('p')]\n   images = [i.img['src'] for i in _d.find_all('a', {'class':'fancybox'})]\n   for img in images:\n      _result, _url = requests.get(f'{_link}{img}').content, re.findall(\"\\w+\\.ashx$\", img)\n      if _url:\n        with open('electroresults/{}.png'.format(_url[0][:-5]), 'wb') as f:\n          f.write(_result)    \n   return _head, _paras, images   \n\n\nd = webdriver.Chrome('/path/to/chromedriver')\nd.get('https://www.cst.com/solutions#size=5&TemplateName=Application+Article')\nresults, page, _previous = [], 1, None\nwhile True:\n  _articles = [i.get_attribute('href') for i in d.find_elements_by_class_name('searchResults__detail')]\n  page_results = []\n  previous = d.current_url\n  for article in _articles:\n    d.get(article)\n    try:\n      d.find_elements_by_class_name('interaction')[0].click()\n    except:\n      pass\n    page_results.append(dict(zip(['title', 'paragraphs', 'imgs'], scrape_page(soup(d.page_source, 'html.parser'), d.current_url))))\n    results.append(page_results)\n  d.get(previous)\n  _next = d.find_elements_by_class_name('pagination-link-next')\n  if _next:\n    _next[0].click()\n  else:\n    break\n"], ["for link in soup_results_overview.findAll(\"a\", class_=\"searchResults__detail\"):\n\n  #Selenium visits each Search Result Page\n  searchResult = driver.find_element_by_class_name('searchResults__detail')\n  searchResult.click() #click Search Result\n\n  #Ask Selenium to go back to the search results overview page\n  driver.back()\n", "for link in soup_results_overview.findAll(\"a\", class_=\"searchResults__detail\"):\n    print(link['href'])\n    driver.get(link['href'])\n    driver.back()\n", "https://cst.com/solutions/article/sar-spherical-phantom-model\n  https://cst.com/solutions/article/pin-fed-four-edges-gap-coupled-microstrip-antenna-magus\n  https://cst.com/solutions/article/printed-self-matched-normal-mode-helix-antenna-antenna-magus\n  https://cst.com/solutions/article/broadband-characterization-of-launchers\n  https://cst.com/solutions/article/modal-analysis-of-a-dielectric-2-port-filter\n"], ["for i in range(n):\n    a = list(map(int, input().rstrip().split()))\n", "a = []\nfor i in range(n):\n    a += list(map(int, input().rstrip().split()))\n", "a = []\nfor i in range(n):\n    a.append(int(input().rstrip()))\n", "a = [int(input().rstrip()) for _ in range(n)]\n"], ["a=[]\nn=int(input(\"Enter no. of variables:\"))\nfor i in range(n):\n    a += list(map(int, input().rstrip().split()))\n    print(a)\nfor x in a:\n    if(x%2==0):\n        print(\"Yes\")\n    elif(x==2 or x==0):\n        print(\"No\")\n    else:\n        print(\"No\")\n"], ["a = []\nfor i in range(n):\n    a.append(int(input()))\n", "a = [int(input()) for i in range(n)]\n"], ["    a = list(map(int, input().rstrip().split()))\n", "a = []\nfor i in range(n):\n    a.append(int(input()))\n"], ["for i in range(n):\n    a = list(map(int, input().rstrip().split()))\n"], [], ["class Pool:\n    def __init__(self, func: Callable, params: list, thread_max = 10):\n        self.func = func\n        self.params = params\n        self.running = 0\n        self.finished = []\n        self.thread_max = thread_max\n        self.threads = []\n\n    def start(self):\n        Thread(target=check, args=(0.2)).start()\n\n    def check(self, t_sleep=0.5):\n        done = False\n        while not done:\n            sleep(t_sleep)\n            # first check for finished threads\n            for t in threads:\n                if not t.isAlive():\n                    # do something with return value\n                    # ...\n                    self.threads.remove(t)\n\n            if not len(self.params): # mean there is no more task left to LAUNCH\n                done = len(self.threads) # gonna be 0 when every tasks is COMPLETE\n                continue # avoid the next part (launching thread)\n\n            # now start some threads if needed\n            while len(self.threads) < self.thread_max:\n                arg = self.params.pop()\n                thread = Thread(target=self.func, args=(arg, ))\n                threads.insert(thread)\n                thread.start()\n"], ["grams = ['blood', 'pressure', 'high blood', 'blood pressure', 'high blood pressure']\n\nunique_grams = [grams[i] for i in range(len(grams)) if not grams[i] in ' '.join(grams[i+1:])]\n"], [], ["df['sub']=df['sub'].mask(df['sub'].str.startswith('None ... '),'')\ndf\nOut[338]: \n   id            sub\n0   1               \n1   2               \n2   3  math None ...\n3   4    probability\n4   5      chemistry\n"], ["df['sub'] = df['sub'].str.replace('[\\w\\s]*?(None \\.\\.\\.)[\\s\\w]*?','',1)\n", "    sub\nid  \n1   \n2   test\n3   \n4   probability\n5   chemistry\n"], ["df.loc[df['sub'].str.startswith(\"None\"), 'sub'] = \"\"\n\ndf.head()\n\n   id            sub\n0   1\n1   2\n2   3  math None ...\n3   4    probability\n4   5      chemistry\n"], ["df['sub'] = df['sub'].str.replace(r'^None \\.\\.\\.*','',1)\n", "   id            sub\n0   1               \n1   2           test\n2   3  math None ...\n3   4    probability\n4   5      chemistry\n"], ["from suffix_trees import STree\n# https://pypi.org/project/suffix-trees/\n# pip install suffix-trees\n\nwords = ['blood', 'pressure', 'high blood', 'blood pressure', 'high blood pressure'] + ['sleep', 'anxiety', 'lack of sleep']\nst = STree.STree(words)\n\nst.find_all('blood')\n# [0, 20, 26, 46]\n\nst.find_all('high blood pressure')\n# [41]\n\n[word for word in words if len(st.find_all(word)) == 1]\n# ['high blood pressure', 'anxiety', 'lack of sleep']\n"], ["usernames = [\"u1\", \"u2\", \"u3\"]\n\nwhile True:\n    username = input(\"Enter username:\")\n\n    if username in usernames:\n        print(\"Username found in index:\", usernames.index(username))\n        break\n    else:\n        print(\"Sorry,username not found\")\n", "usernames = [\"u1\", \"u2\", \"u3\"]\nfound = False\n\nwhile found is False:\n    found = False\n    username = input(\"Enter username:\")\n\n    for i in range(len(usernames)):\n        if usernames[i] == username:\n            print(\"Username found in index:\", i)\n            found = True\n            break\n\n    if found is False:\n        print(\"Sorry,username not found\")\n"], ["usernames=[\"u1\",\"u2\",\"u3\"]\n\nwhile True:\n  user = input(\"Enter username: \")    \n  if user in usernames:\n    print(\"Username found at Index: {}\".format(usernames.index(user)))\n    break\n  else:\n    print(\"Sorry, username not found. Try again\")\n", "usernames = [\"u1\",\"u2\",\"u3\"]\nfound = False\n\nwhile found == False:\n  username = input(\"Enter username: \")\n  for i in range(len(usernames)):\n    if username == usernames[i]:\n        print(\"Username found at Index: {}\".format(i))\n        break\n  else: # not and indentation error\n        print(\"Sorry, username not found. Try again\")\n", "usernames = [\"u1\",\"u2\",\"u3\"]\n\nwhile True:\n  username = input(\"Enter username: \")\n  for i in range(len(usernames)):\n    if username == usernames[i]:\n        print(\"Username found at Index: {}\".format(i))\n        break\n  else: # not and indentation error\n        print(\"Sorry, username not found. Try again\")\n", "Enter username: 2334\nSorry, username not found. Try again\nEnter username: u2\nUsername found at Index: 1\n"], ["usernames=[\"u1\",\"u2\",\"u3\"]\nindex = 0\nfound = False\n\nusername = input(\"Enter username:\")\nfor i in range(len(usernames)):\n  if username == usernames[i]:\n    found = True\n    index = i\n    break\n\nif found:\n  print(\"Username found in index:\",index)\nelse:\n  print(\"Sorry,username not found\")\n"], ["username=input(\"Enter username:\")\ntry:\n    i = usernames.index(username)\nexcept ValueError:\n    print(\"Sorry,username not found\")\nelse:\n    print(\"Username found in index:\",i)\n"], [], ["words = ['blood', 'pressure', 'high blood', 'blood pressure', 'high blood pressure']\n\nsuperset_word = ''\n#print (words)\nfor word in words:\n    word_list_minus_word = [each for each in words if word != each]\n    counter = 0\n    for other_word in word_list_minus_word:\n        if (other_word not in word):\n            break\n        else:\n            counter += 1\n    if (counter == len(word_list_minus_word)):\n        superset_word = word\n        break\nprint(superset_word)\n"], ["symptoms = ['blood', 'pressure', 'high blood', 'blood pressure', 'high blood pressure']\n\n\ndef removeSubstring(data):\n    for symptom in data[:-1]:\n        if symptom in data[-1]:\n            print(\"Removing: \", symptom)\n            data.remove(symptom)\n    print(data)\n\n\nremoveSubstring(symptoms)\n"], ["b = ['blood', 'pressure', 'high blood', 'blood pressure', 'high blood pressure']\nresult = [ i for i in b if not any( [ i in a for a in b if a != i]   )]\n", "word_list =  ['blood', 'pressure', 'high blood', 'blood pressure', 'high blood pressure']\n\nresult = []\nfor this_word in word_list:\n    words_without_this_word = [ other_word  for other_word in word_list if other_word != this_word]  \n    found = False\n    for other_word in words_without_this_word:\n        if this_word in other_word:\n            found = True\n\n    if not found:\n        result.append(this_word)\n\nresult\n"], ["from dateutil.parser import parse\n\nd = ['2018-7-1','2018-08-01']\n\ndate_mapping = dict((parse(x), x) for x in d)\nearliest_date = date_mapping[min(date_mapping)]\nprint(earliest_date)\n\n>>>> '2018-7-1'\n"], ["d = ['2018-7-1','2018-08-01']\nprint(min(d)) #prints 2018-08-01 i.e. later date\nprint(min(d,key=lambda x:tuple(int(i) for i in x.split('-')))) #prints 2018-7-1\n"], ["comment_list = comment_container.findAll(\"div\", {\"class\" : \"comment-date\"})\nD = [datetime.strptime(commentDate, '%Y-%m-%d') for commentDate in comment_list]\n\nprint(min(D))\n", "min_date_str = min(D).strftime('%Y-%m-%d')\n"], ["from datetime import datetime \n\nD = ['2018-06-26', '2018-04-01', '2018-07-19', '2018-04-23', '2018-08-25', '2018-06-08',\n '2018-06-14', '2018-07-08', '2019-03-15', '2019-03-15', '2019-03-15', '2019-03-15', '2019-03-15']\nD.sort()\nprint(D[0])\n", "T = D[:]\nT.sort()\nprint(T[0])\n"], ["comment_list = comment_container.findAll(\"div\", {\"class\" : \"comment-date\"})\nD =[]\n\n  for commentDate in comment_list:\n    year, month, day = map(int, commentDate.split('-'))\n    date_object = datetime(year, month, day)  \n    D.append(date_object)\n\nprint(min(D))\n"], ["A = ['2018-06-26', '2018-04-01', '2018-07-19', '2018-04-23', '2018-08-25', '2018-06-08', '2018-06-14', '2018-07-08', '2019-03-15', '2019-03-15', '2019-03-15', '2019-03-15', '2019-03-15']\nprint(min(A))\n", "2018-04-01\n"], ["def listOfLists(n):\n   if n:\n     yield []\n     yield from listOfLists(n-1)\n\nprint(list(listOfLists(4)))\n", "[[], [], [], []]\n"], ["def listOfLists(n,lists=[]):\n    lists.append([])\n    if n == 1:   \n        return\n\n    listOfLists(n-1,lists)\n    return lists\n\nprint (listOfLists(4))\n"], ["lists += lists.append([])\n", "lists.append([])\n", "lists = lists+[[]]\n", "x = [1,2,3]\ny = x.append(4)\nprint(y) #None\nprint(x) #[1, 2, 3, 4]\n"], ["def listoflist_func(n, currentList=[]):\n    if n < 0:\n        return \"Error: n must be > 0\"\n    elif n==0:\n        return currentList\n    else:\n        currentList.append([])\n        return listoflist_func(n-1, currentList)\n\n\nprint listoflist_func(4)\n", "[[], [], [], []]\n"], ["def listOfLists(n):\n    if n <= 0:\n        return []\n    else:\n        return [ [] ] + listOfLists(n-1)\n\n>>> listOfLists(4)\n[[], [], [], []]\n"], ["def listOfLists(n, lists = []):\n    if n > 0:\n        lists.append([])\n        return listOfLists(n-1, lists)\n    else:\n        return lists\n\nprint(listOfLists(4))\n"], ["def listOfLists(n):\n    lists = [[]]\n    if n <= 1:\n        return lists\n    else:\n        return lists + listOfLists(n-1)\n", "Call - listOfLists(3)\n Call - listOfLists(2)\n  Call - listOfLists(1)\n  Return [[]] # From listOfLists(1)\n Return [[]] + [[]] # From listOfLists(2)\nReturn [[]] + [[],[]] # From listOfLists(3)\n"], ["def home(request):\ntoday = datetime.date.today()\nform = CalculatorForm(request.POST)\n# If this is a POST request then process the Form data\n\nif form.is_valid():\n    instance = form.save()\n    currentdate = datetime.date.today()\n    userinput = str(instance.deadline)\n    birthday = datetime.datetime.strptime(userinput, '%Y-%m-%d').date()\n    if birthday < datetime.date.today():\n        return HttpResponse('Invalid date - You entered a date in the past')# print(birthday)\n    days = birthday - currentdate\n    print(days)\n    # daysLeft = 'Days to your event is ' , days \n    # print(daysLeft)\n    return render(request, 'calculator/check.html', {'days':days})\n    ............\n    ............\n"], ["def home(request):\n   if request.method == 'GET':\n\n       form = DeadlineForm(request.GET)\n       if form.is_valid():\n           userinput = form.cleaned_data['date']\n\n           birthday = datetime.datetime.strptime(userinput, '%m/%d/%Y').date()\n"], ["if request.method == 'GET':\n  render_form\nif request.method == 'POST':\n  handle_form\n"], ["def home(request):\n   today = datetime.date.today()\n   # If this is a POST request then process the Form data\n   if request.method == 'POST':\n\n       form = DeadlineForm(request.POST)\n       # instance = form.save()\n       currentdate = datetime.date.today()\n\n       userinput = form.cleaned_data['date']\n       or\n       userinput = request.POST.get('date')\n\n       birthday = datetime.datetime.strptime(userinput,    '%m/%d/%Y').date()\n       # print(birthday)\n       .....\n"], ["time.strptime(string[, format])\n", "#!/usr/bin/python\nimport time\n\nstruct_time = time.strptime(\"30 Nov 00\", \"%d %b %y\")\nprint (\"returned tuple: %s \" % struct_time)\n"], [], [" pip uninstall numpy\n pip install numpy\n"], ["import numba\n\n@numba.njit\ndef fwd_numba(a,b,c):\n    for i in range(N):\n        c[a[i]]=b[i]\n\n@numba.njit\ndef inv_numba(a,b,c):\n    for i in range(N):\n        c[i]=b[a[i]]\n"], ["import re\nstring = 'aba is a cowa'\npat = r'^(.).*\\1$'\nre.findall(pat,string)\nif re.findall(pat,string):\n    print(string)\n"], ["import re\nstring = 'aba'\nstring2 = 'no match'\npattern = re.compile(r'^(.).*\\1$')\n\nif re.match(pattern, string):\n  print('ok')\nelse:\n  print('nok')\nif re.match(pattern, string2):\n  print('ok')\nelse:\n  print('nok')\n", "ok\nnok\n", "^(.).*\\1$\n", "string = 'aba'\nif string[0] == string[-1]:\n  print 'same'\n", "same\n"], ["import re\nstring = 'abbaaaa'\npattern = re.compile(r'^(.).*\\1$')\n\nmatches = pattern.finditer(string)\nfor match in matches:\n   print (match)\n", "<_sre.SRE_Match object; span=(0, 7), match='abbaaaa'> \n"], ["import re\nstring = 'aba'\npattern = re.compile(r'^(\\w).(\\1)$')\n\nmatches = pattern.finditer(string)\nfor match in matches:\n   print (match.group(0))\n", "aba\n"], ["string[0] is string[-1]\n"], ["import pandas as pd\nimport pyarrow\n\n\ndef round_trip(fspec='/tmp/locations.parquet'):\n    rows = [\n        dict(lat=42.313, lng=-71.116),\n        dict(lat=42.377, lng=-71.065),\n        dict(lat=None, lng=None),\n    ]\n\n    df = pd.DataFrame(rows)\n    df.to_parquet(fspec)\n    del(df)\n\n    df2 = pd.read_parquet(fspec)\n    print(df2)\n\n\nif __name__ == '__main__':\n    round_trip()\n", "      lat     lng\n0  42.313 -71.116\n1  42.377 -71.065\n2     NaN     NaN\n"], [">>> import csv\n>>> from io import StringIO\n>>> def test_csv_writing(rows, quoting):\n...     outfile = StringIO()\n...     csv_writer = csv.writer(outfile, delimiter=',', quoting=quoting)\n...     csv_writer.writerows(rows)\n...     return outfile.getvalue()\n...\n>>> rows = [\n...     [42.313270000, -71.116240000],\n...     [42.377010000, -71.064770000],\n...     [None, None],\n... ]\n>>> print(test_csv_writing(rows, csv.QUOTE_NONNUMERIC))\n42.31327,-71.11624\n42.37701,-71.06477\n\"\",\"\"\n\n>>> print(test_csv_writing(rows, csv.QUOTE_MINIMAL))\n42.31327,-71.11624\n42.37701,-71.06477\n,\n\n>>> print(test_csv_writing(rows, csv.QUOTE_NONE))\n42.31327,-71.11624\n42.37701,-71.06477\n,\n"], ["#sorting the checkouts list in date order.\nfor i in range(len(lst)-1):\n        l=lst[i].find(\"2019\")\n        for j in range(i+1,len(lst)):\n            if lst[i][l:] > lst[j][l:]:\n                (lst[i],lst[j])=(lst[j],lst[i])\n    return lst\n\n#sorting the names.\ndef sortn(lst):\n    for i in range(len(lst)-1):\n        for j in range(i+1,len(lst)):\n            if lst[i][8:] > lst[j][8:]:\n                (lst[i],lst[j])=(lst[j],lst[i])\n    return lst\n\n#sorting the duplicates in date according to the question.\ndef check_dup(lst1,lst2,lst3):\n    l=lst1[0].find(\"2019\")\n    for i in range(len(lst1)-1):\n        for j in range(i+1,len(lst1)):\n\n            #if dates are same then check names\n            if lst1[i][l:]==lst1[j][l:]:\n                for k in range(len(lst2)):\n                    if lst2[k][:7]==lst1[i][:7]:\n                        n1=k\n                    if lst2[k][:7]==lst1[j][:7]:\n                        n2=k\n\n                if n1>n2:\n                    (lst1[i],lst1[j])=(lst1[j],lst1[i])\n\n            #if the names are also same then check\n            if lst1[i][:8]==lst1[j][:8] and lst1[i][15:]==lst1[j][15:]:\n                for k in range(len(lst3)):\n                    if lst3[k][:7]==lst1[i][8:15]:\n                        m1=k\n                    elif lst3[k][:7]==lst1[j][8:15]:\n                        m2=k\n                if m1>m2:\n                    (lst1[i],lst1[j])=(lst1[j],lst1[i])\n    return lst1\n\ns=input()\ns=input()\nBooks=[]\nwhile ( s != 'Borrowers' ) :\n    Books.append( s )\ns=input()\n\nBooks.sort()                                   \n\nBorrowers=[]\ns=input()\nwhile ( s != 'Checkouts' ) :\nBorrowers.append( s )\ns=input()\n\nBorrowers=sortn(Borrowers)\ns=input()\ncheckouts=[]\nwhile(s != 'EndOfInput'):\n    checkouts.append(s)\n    s=input()\n\ncheckouts=sortl(checkouts)\n\ncheckouts=check_dup(checkouts,Borrowers,Books)\n\n#printing acc to question.\nfor i in checkouts:\n    l=checkouts[0].find(\"2019\")\n    print(i[l:],end=\"~\")\n    for j in Borrowers:\n        if i[:7]==j[:7]:\n            print(j[8:],end=\"~\")\n            break\n\n    for k in Books:\n        if i[8:15]==k[:7]:\n            print(k)\n            break\n"], ["#no need to import psycopg2\nimport pandas as pd\nfrom sqlalchemy import create_engine\n\n\n#create connection to postgres\nengine = create_engine('postgres://.....')\n\n#get column names from cursor.description\ncolumns = [col[0] for col in self.cursor.description]\n\n#convert data into dataframe\ndf = pd.DataFrame(cursor.fetchall(),columns=columns)\n\n#send dataframe to postgres\ndf.to_sql('name_of_table',engine,if_exists='append',index=False)\n\n#if you still need to write to csv\ndf.to_csv('your_file.csv')\n"], ["l=[]\n\ndue_date=[]\n\nfull_name=[]\n\nwhile True:\n\n    x=input()\n    l.append(x)\n    if x==\"EndOfInput\":\n            inde=l.index(\"Books\")\n            inde2=l.index(\"Borrowers\")\n            inde3=l.index(\"Checkouts\")\n            l1=l[inde:inde2:1]\n            l2=l[inde2:inde3:1]\n            l3=l[inde3:len(l)-1:1]\n            d1={l1[0]:l1[1::]}\n            d2={l2[0]:l2[1::]}\n            d3={l3[0]:l3[1::]}\n            break\n\n\nfor e in d3.values():\n\n    for j in e:\n        x=j.split(\"~\")\n        x1=x[0] \n        x2=x[2] \n        for e1 in d2.values():\n            for j1 in e1:\n                xx=j1.split(\"~\")\n                xx1=xx[1]  \n                if x1 in xx[0]:\n                    due_date.append(x2)\n                    full_name.append(xx1)\n\nasscnu_title=[]\n\nfor e in d3.values():\n\n    for j in e:\n        x2=j.split(\"~\")\n        x2=x2[1]  \n        for e1 in d1.values():\n            for j1 in e1:\n                if x2 in j1:\n                    asscnu_title.append(j1)   \n\nfull_names=[]\n\nfor e in full_name:\n\n    full_names.append(\"~{}\".format(e))\n\nasscnu_titles=[]\n\nfor e in asscnu_title:\n\n    asscnu_titles.append(\"~{}\".format(e))\n\nfinal=zip(due_date,full_names,asscnu_titles)\n\nfinal=list(final)\n\nfinal.sort()\n\nfor e in final:\n\n    print(\"\".join(e))\n"], ["D = {'a': [1, 2, 3], 'b': [0.1, 0.5], 'c': [10, 20]}\nE = []\n\nlist_of_keys = list(D.keys())\nlist_of_lengths = [len(D[key]) for key in list_of_keys]\n\nproduct_number = 1\nfor length in list_of_lengths:\n    product_number *= length\n\nfor n in range(product_number):\n    index = n\n    index_list = []\n    for length in reversed(list_of_lengths):\n        index_list.insert(0, index % length)\n        index = index // length\n    keys_with_values = {}\n    for j, key in enumerate(list_of_keys):\n        keys_with_values[key] = D[key][index_list[j]]\n    E.append(keys_with_values)\n\nfor e in E:\n    print(e)\n", "{'a': 1, 'b': 0.1, 'c': 10}\n{'a': 1, 'b': 0.1, 'c': 20}\n{'a': 1, 'b': 0.5, 'c': 10}\n{'a': 1, 'b': 0.5, 'c': 20}\n{'a': 2, 'b': 0.1, 'c': 10}\n{'a': 2, 'b': 0.1, 'c': 20}\n{'a': 2, 'b': 0.5, 'c': 10}\n{'a': 2, 'b': 0.5, 'c': 20}\n{'a': 3, 'b': 0.1, 'c': 10}\n{'a': 3, 'b': 0.1, 'c': 20}\n{'a': 3, 'b': 0.5, 'c': 10}\n{'a': 3, 'b': 0.5, 'c': 20}\n"], ["parameter_values_each = {'a':[1,2,3], 'b':[0.1,0.5], 'c':[10,20]}\n\nparam_possibilities = []\nfor name in parameter_values_each:\n    temp = []\n    for val in parameter_values_each[name]:\n        temp.append((name,val))\n    param_possibilities.append(temp)\n\n\nresult = list(itertools.product(*param_possibilities))\n\nprint result\n"], ["import itertools\n\nD = {'a':[1,2,3], 'b':[0.1,0.5], 'c':[10,20]}\n\nE = [dict(zip(D.keys(), a)) for a in itertools.product(*D.values())]\n", "E= [{'a': 1, 'b': 0.1, 'c': 10},\n {'a': 1, 'b': 0.1, 'c': 20},\n {'a': 1, 'b': 0.5, 'c': 10},\n {'a': 1, 'b': 0.5, 'c': 20},\n {'a': 2, 'b': 0.1, 'c': 10},\n {'a': 2, 'b': 0.1, 'c': 20},\n {'a': 2, 'b': 0.5, 'c': 10},\n {'a': 2, 'b': 0.5, 'c': 20},\n {'a': 3, 'b': 0.1, 'c': 10},\n {'a': 3, 'b': 0.1, 'c': 20},\n {'a': 3, 'b': 0.5, 'c': 10},\n {'a': 3, 'b': 0.5, 'c': 20}]\n"], ["from itertools import product\nD = {'a':[1,2,3], 'b':[0.1,0.5], 'c':[10,20]}\nprint([dict(zip(D.keys(),v)) for v in product(*D.values())])\n", "[{'a': 1, 'b': 0.1, 'c': 10}, {'a': 1, 'b': 0.1, 'c': 20}, {'a': 1, 'b': 0.5, 'c': 10}, {'a': 1, 'b': 0.5, 'c': 20}, {'a': 2, 'b': 0.1, 'c': 10}, {'a': 2, 'b': 0.1, 'c': 20}, {'a': 2, 'b': 0.5, 'c': 10}, {'a': 2, 'b': 0.5, 'c': 20}, {'a': 3, 'b': 0.1, 'c': 10}, {'a': 3, 'b': 0.1, 'c': 20}, {'a': 3, 'b': 0.5, 'c': 10}, {'a': 3, 'b': 0.5, 'c': 20}]\n"], [">>> origin = {\n    'a': [1, 2, 3],\n    'b': [0.1, 0.5],\n    'c': [10, 20],\n}\n>>> result = [\n    {\n        'a': a,\n        'b': b,\n        'c': c,\n    }\n    for a in origin['a']\n    for b in origin['b']\n    for c in origin['c']]\n>>> result\n[{'a': 1, 'b': 0.1, 'c': 10}, {'a': 1, 'b': 0.1, 'c': 20},\n {'a': 1, 'b': 0.5, 'c': 10}, {'a': 1, 'b': 0.5, 'c': 20},\n {'a': 2, 'b': 0.1, 'c': 10}, {'a': 2, 'b': 0.1, 'c': 20},\n {'a': 2, 'b': 0.5, 'c': 10}, {'a': 2, 'b': 0.5, 'c': 20},\n {'a': 3, 'b': 0.1, 'c': 10}, {'a': 3, 'b': 0.1, 'c': 20},\n {'a': 3, 'b': 0.5, 'c': 10}, {'a': 3, 'b': 0.5, 'c': 20}]\n"], ["import csv\n\ntest_data = (None, 0, '', 'data')\nfor name, quotes in (('test1.csv', csv.QUOTE_NONNUMERIC),\n                     ('test2.csv', csv.QUOTE_MINIMAL)):\n\n    with open(name, mode='w') as outfile:\n        csv_writer = csv.writer(outfile, delimiter=',', quoting=quotes)\n        csv_writer.writerow(test_data))\n", "\"\",0,\"\",\"data\"\n", ",0,,data\n"], ["x=0       #do check indentation(must!!)\nusers={}\nbooks={}\ncheckouts={}\nwhile(True):\n   s=input()\n   if(s==\"EndOfInput\"):\n      break\n   if(s==\"Books\"):\n\n        x=1\n        continue\n   if(s==\"Borrowers\"):\n\n        x=2\n        continue\n   l=s.split(\"~\")\n   if(s==\"Checkouts\"):\n        x=3\n        continue\n   if(x==1):\n\n        books.__setitem__(l[0],l[1])\n   if(x==2) :\n\n        users.__setitem__(l[0],l[1])\n   if(x==3):\n        if(l[2]  not in checkouts.keys()):\n            checkouts.__setitem__(l[2],[[users[l[0]],str(l[1]),books[l[1]]]])\n        else:\n            checkouts[l[2]].append([users[l[0]],str(l[1]),books[l[1]]])\nfor i in sorted(checkouts.keys()):\n      checkouts[i].sort()\n      for j in range(len(checkouts[i])):\n         print(i,(*checkouts[i][j]),sep=\"~\")\n"], [], ["numbers = []\n", "for y in range(5):\n  numbers = [random.randint(1, 10) for x in range(100)]\n  numbers.append(max(set(numbers), key=numbers.count))\n", "#Prints your desired numbers.\nvals = \"\"\nfor i in range(len(numbers)):\n  vals = vals + numbers[i] + \", \"\nprint(vals)\n"], [">>> x = [max(set(numbers), key=numbers.count) for numbers in [[random.randint(1, 10) for x in range(100)] for y in range(5)]]\n>>> ', '.join(str(_) for _ in x)\n>>> '2, 10, 7, 5, 8'\n"], ["new = list()\nfor y in range(5):\n    numbers = [random.randint(1, 10) for x in range(100)]  # generates 100 random numbers from 1-10\n    new.append(str(max(set(numbers), key=numbers.count)))  # prints out one of which appeared the most\nprint new  # Prints whole list\nprint \", \".join(new) # Prints comma separated values in one line\n", "['10', '8', '6', '8', '2']\n10, 8, 6, 8, 2\n"], ["for y in range(5):\nnumbers = [random.randint(1, 10) for x in range(100)]  # generates 100 random numbers from 1-10\nprint(max(set(numbers), key=numbers.count) , end =\", \")\n", "for y in range(5): numbers = [(max(set(random.randint(1, 10),key=numbers.count))) for x in range(100)]  \n"], ["results = []\nfor y in range(5):\n    numbers = [random.randint(1, 10) for x in range(100)]\n    results.append(str(max(set(numbers), key=numbers.count)))\nprint(', '.join(results))\n"], [" str1=input()                           #do check indentation(must!!)\n\n (lst1,lst2,lst3)=([],[],[])\n\nwhile str1!=\"EndOfInput\":\n\nif str1==\"Books\":\n    while True:\n        str1=input()\n        if str1!=\"Borrowers\":\n            lst1.append(str1.split('~'))\n        else:\n            break\nif str1==\"Borrowers\":\n    while True:\n        str1=input()\n        if str1!=\"Checkouts\":\n            lst2.append(str1.split('~'))\n        else:\n            break\n\nif str1==\"Checkouts\":\n    while True:\n        str1=input()\n        if str1!=\"EndOfInput\":\n            lst3.append(str1.split('~'))\n        else:\n            break\nl1=dict(lst1)\nl2=dict(lst2)\nl3=sorted(lst3,key=lambda t:t[0])\nll=[]\n\nfor i in range(len(l3)):\n  ll.append([((l3[i][2],l2.get(l3[i][0]),l3[i][1],l1.get(l3[i][1])))])\n\n  fl=sorted(ll, key=lambda t:t[0])\n  for j in range(len(fl)):\n     for k in fl[j]:\n        print(k[0],k[1],k[2],k[3],sep=\"~\")\n"], ["    id  hit from    to  value\n5   D   hit6    287 313 9.800000e-04\n7   D   hit8    287 316 2.900000e-03\n4   D   hit5    291 512 3.800000e-24\n8   D   hit9    373 422 2.900000e-03\n6   D   hit7    381 426 9.800000e-04\n9   D   hit10   514 600 2.100000e-03\n"], ["for x in range(len(j))\n"], ["j[np.absolute(j) > 1] = 1\n", "#made 3 a negitive value to prove absolute works.\nj = np.array([[1],[-3],[1],[0],[9]])\n\nj[np.absolute(j) > 1] = 1\n", "[[1]\n [1]\n [1]\n [0]\n [1]]\n"], ["import numpy as np\n\nj = np.array([1,3,1,0,9])\n\n# Keep track of index starting at 0\ni = 0\nfor x in j:\n    if abs(x) > 1 :\n        # change value at index i\n        j[i] = 1\n    # increment index\n    i += 1\n"], ["def borrowers_input(b):\n    x=input()\n    while x!='Checkouts':\n        x=x.split('~')\n        b.append(x)\n        x=input()\n\ndef checkouts_input(c):\n    x=input()\n    while x!='EndOfInput':\n        x=x.split('~')\n        c.append(x)\n        x=input()\n\ndef output():\n    global books,borrower,checkout\n    date=[]\n    uname=[]\n    name=[]\n    Anum=[]\n    title=[]\n    for i in range(0,len(checkout)):\n        date.append(checkout[i][2])\n\n    for i in range(0,len(checkout)):\n        uname.append(checkout[i][0])\n\n    for i in range(0,len(uname)):\n        for j in range(0,len(borrower)):\n            if(uname[i] == borrower[j][0]):\n                name.append(borrower[j][1])\n\n    for i in range(0,len(checkout)):\n        Anum.append(checkout[i][1])\n\n    for i in range(0,len(Anum)):\n        for j in range(0,len(books)):\n            if(Anum[i] == books[j][0]):\n                title.append(books[j][1])\n\n    final=[]\n    for i in range(0,len(checkout)):\n        final.append(date[i]+'~'+name[i]+'~'+Anum[i]+'~'+title[i])\n    final.sort()\n    for i in range(0,len(final)):\n        print(final[i])\n\n\nbooks=[]\nborrower=[]\ncheckout=[]\nx=input()\nx=input()\nwhile x!='Borrowers':\n    x=x.split('~')\n    books.append(x)\n    x=input()\nborrowers_input(borrower)\nborrower.sort()\ncheckouts_input(checkout)\noutput()\n"], ["for i,x in  enumerate(j):\n    if abs(x) > 1 :\n        j[i] = 1\n"], ["import numpy as np\n\nj = np.array([[1],[3],[1],[0],[9]])\n\nfor i,x in enumerate(j):\n    if abs(x) > 1 :\n        j[i] = 1\n"], ["import numpy as np\n\nj = np.array([[1],[3],[1],[0],[9]])\n\nfor i,x in enumerate(j):    # i is the index, x is the value\n    if abs(x) > 1 :\n        j[i] = 1\n"], [], ["for i in a:\n    c[i] = b[i]\n", "#1. (iteration 1) c[0] = b[0]\n1a. read memory at b[0] and store result in register c0\n1b. write register c0 at memory address c[0]\n#2. (iteration 2) c[1] = b[1]\n2a. read memory at b[1] and store result in register c1\n2b. write register c1 at memory address c[1]\n#1. (iteration 2) c[2] = b[2]\n3a. read memory at b[2] and store result in register c2\n3b. write register c2 at memory address c[2]\n# etc\n", "size    4000    6000    9000    13496   20240   30360   45536   68304   102456  153680  230520  345776  518664  777992  1166984\nrd-rand 1.86821 2.52813 2.90533 3.50055 4.69627 5.10521 5.07396 5.57629 6.13607 7.02747 7.80836 10.9471 15.2258 18.5524 21.3811\nwr-rand 7.07295 7.21101 7.92307 7.40394 8.92114 9.55323 9.14714 8.94196 8.94335 9.37448 9.60265 11.7665 15.8043 19.1617 22.6785\n"], ["result = [[(x[0,0], x[0,1]), (y[0,0], y[0,1])],\n         [(x[1,0], x[1,1]), (y[1,0], y[1,1])]]\n", "[[(1, 2), (3, 4)], [(5, 6), (7, 8)]]\n"], ["print([list(map(tuple, i)) for i in zip(x, y)])\n# [[(1, 2), (3, 4)], [(5, 6), (7, 8)]]\n", "[(array([1, 2]), array([3, 4])), (array([5, 6]), array([7, 8])]\n"], ["z=np.array([x,y])\n[list(map(tuple,z[:,x]))for x in range(len(x))]\nOut[223]: [[(1, 2), (3, 4)], [(5, 6), (7, 8)]]\n"], ["for (row1, row2) in zip(x,y):\n    yield [tuple(row1), tuple(row2)]\n       #  [ (1,2)     ,  (3,4)     ]\n", "[ [tuple(row1),tuple(row2)] for (row1, row2) in zip(x,y) ]\n"], ["x_z = map(tuple,x)\ny_z = map(tuple,y)\n[list(i) for i in zip(x_z, y_z)]\n", "[[(1, 2), (3, 4)], [(5, 6), (7, 8)]]\n"], ["x = list([[1,2],[5,6]])\ny = list([[3,4],[7,8]])\nx\n[[1, 2], [5, 6]]\ny\n[[3, 4], [7, 8]]\nz=list(zip(x,y))\nz\n[([1, 2], [3, 4]), ([5, 6], [7, 8])]\n"], ["from requests import Request, Session\nfrom requests.exceptions import ConnectionError, Timeout, TooManyRedirects\nimport json\n\nurl = 'https://pro-api.coinmarketcap.com/v1/cryptocurrency/listings/latest'\nparameters = {\n      'start': '1',\n      'limit': '5000',\n      'convert': 'USD',\n  }\nheaders = {\n      'Accepts': 'application/json',\n      'X-CMC_PRO_API_KEY': 'yourKey',\n  }\n\nsession = Session()\nsession.headers.update(headers)\n\ntry:\n    response = session.get(url, params=parameters)\n    # print(response.text)\n    data = json.loads(response.text)\n    print(data['data'][64]['quote']['USD']['price'])\nexcept (ConnectionError, Timeout, TooManyRedirects) as e:\n    print(e)\n", "interested = ['Electroneum','Ethereum']\nfor item in data['data']:\n    if item['name'] in interested:\n        print(item)\n", "import requests\nfrom bs4 import BeautifulSoup\n\nurl = 'https://coinmarketcap.com/currencies/electroneum/'\nresponse = requests.get(url)\nhtml = response.content\n\nsoup = BeautifulSoup(html, 'html.parser')\nsoup.select_one('[data-currency-value]').text\n"], ["import requests\nfrom bs4 import BeautifulSoup\n\nurl = 'https://coinmarketcap.com/currencies/electroneum/'\nresponse = requests.get(url)\nhtml = response.content\n\nsoup = BeautifulSoup(html, 'html.parser')\nprice = soup.find('span' ,attrs={\"class\" : \"h2 text-semi-bold details-panel-item--price__value\"})\nprint (price.text)\n", "0.006778\n"], ["import requests\nfrom bs4 import BeautifulSoup\n\nurl = 'https://coinmarketcap.com/currencies/electroneum/'\nresponse = requests.get(url)\nhtml = response.content\n\nsoup = BeautifulSoup(html, 'html.parser')\nx=soup(id=\"quote_price\").text\nprint (x)\n"], ["soup.find(id=\"link3\")\n", "soup.find(\"relevant tag name like div or a\")\n", "find_this = soup.find(\"a\", id=\"ID HERE\")\n"], ["import requests\nfrom bs4 import BeautifulSoup\n\nurl = 'https://coinmarketcap.com/currencies/electroneum/'\nresponse = requests.get(url)\nhtml = response.content\n\nsoup = BeautifulSoup(html, 'html.parser')\nprice = soup.find(\"span\", id=\"quote_price\").get('data-usd')\nprint (price)\n"], ["import numpy as np\n\n_, cts = np.unique(df.values, axis=0, return_counts=True)\nlen(np.where(cts == 1)[0])\n#2\n"], ["df = pd.DataFrame({'a': [1, 1, 2, 3], 'b': [1, 1, 2, 2]})\nduplicates_s = df.duplicated(keep=False)\n(~duplicates_s).sum()\n"], ["len(df.groupby(['a','b']).filter(lambda x: len(x) == 1).index)\n\n2\n"], ["In [33]: df.groupby(df.columns.tolist()).size()                                                                                                                                                                                                                                            \nOut[33]: \na  b\n1  1    2\n2  2    1\n3  2    1\ndtype: int64\n"], ["out = (~df.duplicated(keep=False)).sum()\nprint (out)\n2 \n", "print (df.duplicated(keep=False))\n0     True\n1     True\n2    False\n3    False\n\nprint (~df.duplicated(keep=False))\n0    False\n1    False\n2     True\n3     True\ndtype: bool\n"], [], [], ["def is_int(value):\n    try:\n        int(value)\n        return True\n    except ValueError:\n        return False\n\n\nwith open('54928944.txt', 'r') as f:\n    numbers_counter = 0\n    one_line_words = []\n    line = f.read()\n    words = line.split(' ')\n    for word in words:\n        if is_int(word):\n            numbers_counter += 1\n        else:\n            numbers_counter = 0\n        one_line_words.append(word)\n        if numbers_counter == 3:\n            print(' '.join(one_line_words))\n            one_line_words = []\n"], ["a='sees mouse . 1980 1 1 sheep erythrocytes mouse 1980 6 5 seen mouse 1980 8 8'\ncount=0\nfor i in re.finditer('(\\d \\d \\d)',a):\n    print(a[count:i.end()].strip())\n    count=i.end()\n"], ["import re\n\npattern = re.compile(r'[a-zA-Z\\.\\s]+\\d{4}\\s+?\\d{1,2}\\s+?\\d{1,2}')\nprint([(m.start(0), m.end(0)) for m in re.finditer(pattern, s)])\n"], ["import re\ns = \"sees mouse . 1980 1 1 sheep erythrocytes mouse 1980 6 5 seen mouse 1980 8 8\"\npattern = r\"(\\d{4}\\s\\d{1,2}\\s\\d{1,2})\"\nfor match in re.findall(pattern, s):\n    s = re.sub(match, f'{match}\\n', s)\n", "'sees mouse . 1980 1 1\\n sheep erythrocytes mouse 1980 6 5\\n seen mouse 1980 8 8\\n'\n"], ["df['seq'] = df.groupby('Type').cumcount() + 1\ndf\n", "  Type  seq\n0    A    1\n1    A    2\n2    B    1\n3    B    2\n4    B    3\n", "import pandas as pd\ndf['seq'] = pd.factorize(df['Type'])[0] + 1\ndf\n", "  Type  seq\n0    A    1\n1    A    1\n2    B    2\n3    B    2\n4    B    2\n"], ["$ cat /sys/devices/system/cpu/cpu0/cache/index0/coherency_line_size\n64\n$ cat /sys/devices/system/cpu/cpu0/cache/index0/size\n32K\n"], ["(df.Type!=df.Type.shift()).ne(0).cumsum()\nOut[58]: \n0    1\n1    1\n2    2\n3    2\n4    2\nName: Type, dtype: int32\n", "v=c('A','A','B','B','B','A')\ndata.table::rleid(v)\n[1] 1 1 2 2 2 3\n\n\ndf \n  Type\n0    A\n1    A\n2    B\n3    B\n4    B\n5    A# assign a new  number in R data.table rleid\n(df.Type!=df.Type.shift()).ne(0).cumsum()\nOut[60]: \n0    1\n1    1\n2    2\n3    2\n4    2\n5    3# check \n"], ["df['seq'] = df['Type'].rank(method = 'dense').astype(int)\n\n   Type seq\n0   A   1\n1   A   1\n2   B   2\n3   B   2\n4   B   2\n"], ["df['Seq'] = df['Type'].apply(lamba x: ord(x.lower())-96)\n", "df['Seq'] = df['Type'].astype('category').cat.codes\n"], ["df.loc[df['Type'] == A, 'Seq'] = 1\n", "df.loc[df['Type'] == B, 'Seq'] = 2\n"], ["s = 'Testfile_20190226114536.CSV.986466.1551204043175'\nsuffix = '.CSV'\n\ns[:s.rindex(suffix) + len(suffix)]\n=> 'Testfile_20190226114536.CSV'\n"], [">>> filename = 'Testfile_20190226114536.CSV.986466.1551204043175'\n\n# split the string into a list at '.'\n>>> l = filename.split('.')\n\n>>> print(l)\n['Testfile_20190226114536', 'CSV', '986466', '1551204043175']\n\n# index the list to get all the elements before and including 'CSV'\n>>> filtered_list = l[0:l.index('CSV')+1]\n\n>>> print(filtered_list)\n['Testfile_20190226114536', 'CSV']\n\n# join together the elements of the list with '.'\n>>> out_string = '.'.join(filtered_list)\n>>> print(out_string)\n\nTestfile_20190226114536.CSV\n", "def filter_filename(filename):\n    l = filename.split('.')\n    filtered_list = l[0:l.index('CSV')+1]\n    out_string = '.'.join(filtered_list)\n    return out_string\n\n>>> filter_filename('Testfile_20190226114536.CSV.986466.1551204043175')\n'Testfile_20190226114536.CSV'\n"], ["name = \"Testfile_20190226114536.CSV.986466.1551204043175\"\nprint \".\".join(name.split(\".\")[0:2])\n"], ["import re\nresult = re.sub('(?<=\\.CSV)[\\w\\W]+', '', 'Testfile_20190226114536.CSV.986466.1551204043175')\n", "'Testfile_20190226114536.CSV'\n"], ["myDict = {637.0: [139.0, 1.8, 36.0, 18.2], 872.0: [139.0, 1.8, 36.0, 18.2]}\ny = np.zeros(len(myDict))\nX = np.zeros((len(myDict), 4))\ni = 0\nfor key, values in myDict.items():\n    y[i] = key\n    X[i, :] = values\n    i += 1\n"], ["import numpy as np\nfor key, value in dictionary.items():\n    dictionary[key] = np.asarray(value)\n"], [], ["import numpy as np\n\ndef convert_to_array(dictionary):\n    '''Converts lists of values in a dictionary to numpy arrays'''\n    return {k:np.array(v) for k, v in dictionary.items()}\n\nd = {\n    'date-1': [1.23, 2.34, 3.45, 5.67],\n    'date-2': [54.47, 45.22, 22.33, 54.89],\n    'date-3': [0.33, 0.589, 12.654, 4.36]\n}\n\nprint(convert_to_array(d))\n# {'date-1': array([1.23, 2.34, 3.45, 5.67]), 'date-2': array([54.47, 45.22, 22.33, 54.89]), 'date-3': array([ 0.33 ,  0.589, 12.654,  4.36 ])}\n"], ["import numpy as np\n\nSamples = {5.207403005022627: 0.69973543384229719, \n        6.8970222167794759: 0.080782939731898179, \n        7.8338517407140973: 0.10308033284258854, \n        8.5301143255505334: 0.018640838362318335, \n        10.418899728838058: 0.14427355015329846, \n        5.3983946820220501: 0.51319796560976771}\n\nkeys = np.fromiter(Samples.keys(), dtype=float)\nvals = np.fromiter(Samples.values(), dtype=float)\n\nprint(keys)\nprint('-'*20)\nprint(vals)\n"], ["lst1=[4,2]\nlst2=[9, 3, 12]\nlst3=[3]\nno_item=4\nprint([lst1[i%len(lst1)] for i in range(no_item)])\nprint([lst2[i%len(lst2)] for i in range(no_item)])\nprint([lst3[i%len(lst3)] for i in range(no_item)])\n"], ["available_items = [3, 5, 9]\nrequired_items = 4\n\ntimes = 4 // len(available_items)\nremain = 4 % len(available_items)\n\nnew_items = (available_items * times ) + available_items[:remain]\nprint(available_items)\nprint(new_items)\n"], [">>> lst = [1]; list(islice(cycle(lst), 4)) == [1,1,1,1]\n>>> lst = [1,3]; list(islice(cycle(lst), 4)) == [1,3,1,3]\n>>> lst = [1,3,2]; list(islice(cycle(lst), 4)) == [1,3,2,1]\n>>> lst = [1,3,2,4]; list(islice(cycle(lst), 4)) == [1,3,2,4]\n"], ["def repeat_items(l, c):\n    return l * (c // len(l)) + l[:(c % len(l))]\n\n>>> repeat_items([1, 2, 3], 4)\n[1, 2, 3, 1]\n"], [">>> i = [4, 2]\n>>> (i * 4)[:4]\n[4, 2, 4, 2]\n"], ["from itertools import cycle\n\navailable_items = [3, 5]\nrequired_items = 4\n\n[item for item, idx in zip(cycle(available_items), range(required_items))]\n\n# [3, 5, 3, 5]\n"], [], ["from itertools import cycle\n\navailable_items_1 = cycle([4, 2])\navailable_items_2 = cycle([9, 3, 12])\navailable_items_3 = cycle([3])\n\nn = 4\n\nprint([next(available_items_1)for i in range(n)])\nprint([next(available_items_2)for i in range(n)])\nprint([next(available_items_3)for i in range(n)])\n", "[4, 2, 4, 2]\n[9, 3, 12, 9]\n[3, 3, 3, 3]\n"], ["result = (available_items * (int(required_items /len(available_items ))+1))[:required_items]\n"], ["def solve(arr):\n    res = []\n    req = 4-len(arr)\n\n    while req>0:\n      for i in range(len(arr)):\n        res.append(arr[i])\n        req = req-1\n        if req == 0:\n          break\n\n    return arr+res\n\nnum = [4, 2]\nres_num = solve(num)\nprint(res_num)\n\nnum = [9, 3, 12]\nres_num = solve(num)\nprint(res_num)\n\nnum = [3]\nres_num = solve(num)\nprint(res_num)\n", "[4, 2, 4, 2]\n[9, 3, 12, 9]\n[3, 3, 3, 3]\n"], [">> available_items = [4, 2]\n>> Result = available_items * 4\n>> Result = Result[0:4]\n>> Result\n[4, 2, 4, 2]\n", ">> available_items = [9, 3, 12]\n>> Result = available_items * 4\n>> Result = Result[0:4]\n>> Result\n[9, 3, 12, 9]\n", ">> available_items = [3]\n>> Result = available_items * 4\n>> Result = Result[0:4]\n>> Result\n[3, 3, 3, 3]\n"], ["userInput = input(\"Enter a line of text: \")\nvowels = \"aeiouAEIOU\"\nfor i, char in enumerate(userInput):\n    if char in vowels:\n        print(char, i)\n"], [" userInput = input(\"Enter a line of text: \")\n vowels = \"aeiouAEIOU\"\n\n for count in userInput:\n     x = 9 #there are 10 vowels, from 0 to 9\n     while x >= 0:\n         if count == vowels[x]:\n             print(\"\\n\",count)\n         x -= 1\n\n print(\"\\n Done\")\n"], [], ["string find(str,str, beg=0, end=len(string)) \n", "userInput = (input(\"Enter a line of text: \")\nvowels = (\"aeiouAEIOU\")\nposition = 0\nfor char in userInput :\n    if char in vowels :\n        position = userInput.find(char)\n        print(char, position)\n"], ["positions = [i for i, char in enumerate(userInput) if char in vowels]\n"], ["$ cat test.py \nimport numpy as np\nfrom timeit import timeit\nimport numba\n\ndef fwd(a,b,c):\n    c = b[a]\n\ndef inv(a,b,c):\n    c[a] = b\n\n@numba.njit\ndef fwd_numba(a,b,c):\n    for i,j in enumerate(a):\n        c[i] = b[j]\n\n@numba.njit\ndef inv_numba(a,b,c):\n    for i,j in enumerate(a):\n        c[j] = b[i]\n\n\nfor p in range(4, 8):\n    N = 10**p\n    n = 10**(9-p)\n    a = np.random.permutation(N)\n    b = np.random.random(N)\n    c = np.empty_like(b)\n    print('---- N = %d ----' % N)\n    for f in 'fwd', 'fwd_numba', 'inv', 'inv_numba':\n        print(f, timeit(f+'(a,b,c)', number=n, globals=globals()))\n\n$ python test.py \n---- N = 10000 ----\nfwd 1.1199337750003906\nfwd_numba 0.9052993479999714\ninv 1.929507338001713\ninv_numba 1.5510062070025015\n---- N = 100000 ----\nfwd 1.8672701190007501\nfwd_numba 1.5000483989970235\ninv 2.509873716000584\ninv_numba 2.0653326050014584\n---- N = 1000000 ----\nfwd 7.639554155000951\nfwd_numba 5.673054756000056\ninv 7.685382894000213\ninv_numba 5.439735023999674\n---- N = 10000000 ----\nfwd 15.065879136000149\nfwd_numba 12.68919651500255\ninv 15.433822674000112\ninv_numba 14.862108078999881\n"], ["import random\nn = 4\nv1, v2 = 1, 2\nres = dict(zip([ f\"key{n}\" for n in [x for x in range(1,n+1)] ], [ f\"value{n}\" for n in sorted([v1 for _ in range(n-1)] + [v2], key=lambda k: random.random()) ]))\n"], ["def function(n):\n    pick = randrange(n)\n    return {'key %d' % i: ('value1', 'value2')[i == pick] for i in range(n)}\n"], ["import random\n\ndef function(n):\n   mydict = dict.fromkeys((\"key \"+ str(i) for i in range(n)), 'value1')\n   mydict[\"key \"+ str(random.randrange(n))] = 'value2'  # Change one value.\n   return mydict\n\nprint(function(3))  # -> {'key 0': 'value1', 'key 1': 'value1', 'key 2': 'value2'}\nprint(function(5))  # -> {'key 0': 'value2', 'key 1': 'value1', 'key 2': 'value1', 'key 3': 'value1', 'key 4': 'value1'}\n"], ["def function(n):\n   from random import randrange\n   values = ['value1', 'value2']\n   mydict = {\"key \" + str(i): values[0] for i in range(n)}\n   mydict[\"key \" + str(random.randrange(n))] = values[1]\n\n   return mydict\n"], ["from random import randint, sample\n\ndef pseudo_rand_dict(n):\n    d = dict()\n    r = randint(n, n ** n)\n    for i in range(n):\n        d[f'key_{i}'] = r\n    to_change = sample(d.keys(), 1)[0]\n    d[to_change] = randint(n, n * r)\n    return d\n\nd = pseudo_rand_dict(5)\n\nprint(d)\n\n{'key_0': 2523, 'key_1': 2523, 'key_2': 2523, 'key_3': 9718, 'key_4': 2523}\n"], ["def randDict(n):\n    from random import randint\n\n    keys  = [\"key\"+str(i) for i in range(n)]\n    values = [\"value\"+str(i) for i in range(n)]\n    final_dict={}\n    for key in keys:\n        final_dict[key]=values.pop(randint(0,n))\n\n    return final_dict\n"], ["def function(n):\n    from random import randrange, randint\n    mydict = {'key'+str(i):'value1' for i in range(n)}\n    mydict['key'+str(randint(0,n-1))] = 'value2'\n    return mydict\n\nprint(function(5))\n"], ["import random\ndef my_function(n):\n    mydict = {}\n    value2_index = random.randint(0, n-1)\n    for i in range(n):\n        key = \"key \" + str(i)\n        if i == value2_index:\n            value = ['value2']\n        else:\n            value = ['value1']\n        mydict.update({key: value})\n    return mydict\nthing = my_function(5)\nprint(thing)\n"], [], ["   from random import randrange\n   mydict = {}\n   value = ['value1', 'value2', 'v3', 'v4', 'v5']\n\n   for i in range(5):\n         key = \"key \" + str(i)\n         mydict.update(key: value[i])\n"], [">>> def func(n):\n...   mydict = {}\n...   for i in range(n):\n...     mydict['key'+str(i)] = randrange(10)\n...   return mydict\n... \n>>> print(func(5))\n{'key0': 8, 'key1': 2, 'key2': 4, 'key3': 4, 'key4': 7}\n"], [], ["from sklearn.cluster import KMeans\n\narray = np.vstack(contours)\nall_points = array.reshape(array.shape[0], array.shape[2])\nkmeans = KMeans(n_clusters=2, random_state=0, n_init = 50).fit(all_points)\nnew_contours = [all_points[kmeans.labels_==i] for i in range(2)]*\n"], ["import json\nimport os\nimport glob\nimport pprint\nkeywordList = []\npath = '/Users/Me/Api/downloaded'\nfor filename in glob.glob(os.path.join(path, '*.json')): #only process .JSON files in folder.      \n    with open(filename, encoding='utf-8', mode='r') as currentFile:\n        data=currentFile.read().replace('\\n', '')\n        keyword = json.loads(data)[\"keytolookup\"]\n        if keyword not in keywordList:\n            keywordList.append(keyword)\npprint(keywordList)\n"], ["import os\nimport glob\nimport pandas as pd\n\n\ndef nested_files_to_df(path,ext): \n\n    paths = []\n    all_data = pd.DataFrame()\n\n    #--- Putting all files name  in one list ---#\n\n    for root, dirs, files in os.walk(path):\n        for file in files:\n            if file.endswith(tuple(ext)):\n                s = os.path.join(root, file)\n                paths.append(s)\n\n    #--- Reading and merging all the  existing  excel files  into one  dataframe  ---#\n\n    for f in paths:\n        df = pd.read_excel(f)     \n        all_data = all_data.append(df,ignore_index=True)\n\n    return all_data\n", "df= nested_files_to_df('Your main folder root',[\".xls\",\".XLS\",\".xlsx\"])\n"], ["for row in self.cursor:\n    csv_writer.writerow(row)\n", "for row in self.cursor:\n    csv_writer.writerow(\"null\" if x is None else x for x in row)\n"], ["import os\nimport json\n\nos.chdir('/Users/Me/Api/downloaded')\n\nfileList = []\nkeywordList = []\n\nfor filenames in os.walk('/Users/Me/Api/downloaded'):\n    fileList.append(filenames)\n\nfor file in filenames:\n    with open(file, encoding='utf-8', mode='r') as currentFile:\n        data = json.load(currentFile)  # Parses the file to json object\n        keywordList.append(data['keyword'])\n\nprint(keywordList)\n"], ["for file in filenames:\n    with open(file, encoding='utf-8', mode='r') as currentFile:\n        for line in currentFile:\n            if 'keyword' in line:\n                keywordList.append('keyword')\n"], [], ["os.chdir('/Users/Me/Api/downloaded')\n\nfileList = []\nkeywordList = []\n\nfor filenames in os.walk('/Users/Me/Api/downloaded'):\n    fileList.append(filenames)\n\nfor file in fileList:\n    with open(file, encoding='utf-8', mode='r') as currentFile:\n        keywordList.append(currentFile['keyword'])\n"], ["import dask.dataframe as dd\nimport pandas as pd\n\ndf = dd.read_csv(\"data/*/*.csv\")\n# convert to pandas via\ndf = df.compute()\n"], [], ["import os\nimport pandas as pd\noutdir = [YOUR_INITIAL_PATH]\ndf_final = pd.DataFrame(columns=['column1', 'column2', 'columnN']) # creates an empty df with the desired structure\nfor root, dirs, filenames in os.walk(outdir):\n    for f in filenames:\n        if f.endswith('.csv'):\n            df_temp = pd.read_csv(root + '\\\\' + f)\n            df_final = pd.concat([df_final, df_temp])\n"], ["import glob\nimport pandas as pd\n\ncsv_paths = glob.glob('*.csv')\ndfs = [pd.read_csv(path) for path in csv_paths]\ndf = pd.concat(dfs)\n"], [">>> import dis\n>>> def fwd():\n...     c = b[a]\n...\n>>> dis.dis(fwd)\n  2           0 LOAD_GLOBAL              0 (b)\n              3 LOAD_GLOBAL              1 (a)\n              6 BINARY_SUBSCR\n              7 STORE_FAST               0 (c)\n             10 LOAD_CONST               0 (None)\n             13 RETURN_VALUE\n", ">>> def fwd2():\n...     global c\n...     c = b[a]\n...\n>>> dis.dis(fwd2)\n  3           0 LOAD_GLOBAL              0 (b)\n              3 LOAD_GLOBAL              1 (a)\n              6 BINARY_SUBSCR\n              7 STORE_GLOBAL             2 (c)\n             10 LOAD_CONST               0 (None)\n             13 RETURN_VALUE\n"], [], ["contacts.split('Phone')[0].strip()\n"], ["import re\n\nadress = re.search(r'^(.+?)\\sPhone', s, flags=re.MULTILINE | re.DOTALL)\nprint(adress.group(1))\n\n# 1040 S. Vintage Ave.\n# Building A Ontario, CA 91761\n# United States\n"], ["import timeit\n\nA = np.arange(0, 20, 1)\n# print(A)\nx = 3\n\n\ndef fun():\n    return [x < i < 7 for i in A]\n\n\ndef fun2():\n    return (A < 7) & (A > 3)\n\n\ndef fun3():\n    return np.logical_and(x < A, A < 7)\n\ndef fun4():\n    return [i < 7 and i > x for i in A]\n\n\nprint('fun()', timeit.timeit('fun()', number=10000, globals=globals()))\nprint('fun2()', timeit.timeit('fun2()', number=10000, globals=globals()))\nprint('fun3()', timeit.timeit('fun3()', number=10000, globals=globals()))\nprint('fun4()', timeit.timeit('fun4()', number=10000, globals=globals()))\n", "fun() 0.055701432000205386\nfun2() 0.016561345997615717\nfun3() 0.016588653001235798\nfun4() 0.0446821750010713\n"], ["x = 3\nnp.logical_and(x<A, A<7)\n"], ["a = np.arange(0,20,1)\na\narray([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n       17, 18, 19])\n\n(a>3) & (a<7)\narray([False, False, False, False,  True,  True,  True, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False])\n", "(a<3) | (a>7) #Less than 3 or greater than 7\narray([ True,  True,  True, False, False, False, False, False,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True])\n"], ["import numpy as np\nA = np.arange(0,20,1)\nB = np.logical_and(3<A,A<7)\nprint(B)\n", "[False False False False  True  True  True False False False False False\n False False False False False False False False]\n"], ["x = 3\nbools = [i<7 and i> x for i in A]\n"], ["contacts = \"\"\"1040 S. Vintage Ave.\nBuilding A Ontario, CA 91761\nUnited States Phone: 9099725134 Fax: 9099065401\n\nWeb: http://www.aareninc.com\"\"\"\n"], ["contacts.partition('Phone')[0]\n"], ["import re\nre.split('(Phone)', strng)\n['1040 S. Vintage Ave. Building A Ontario, CA 91761 United States ',\n'Phone',\n': 9099725134 Fax: 9099065401 Web: http://www.aareninc.com']\n"], ["v = st.split(\"Phone\"))\nprint(v[0])\n"], ["import re\ntext = '''1040 S. Vintage Ave.\nBuilding A Ontario, CA 91761\nUnited States Phone: 9099725134 Fax: 9099065401 \n\nWeb: http://www.aareninc.com'''\nadress = re.findall('.*(?=Phone)',text,re.DOTALL)[0]\nprint(adress)\n", "1040 S. Vintage Ave.\nBuilding A Ontario, CA 91761\nUnited States\n"], ["class Similarity:\n    def __init__(self, centroid, nlp, n_threads: int, batch_size: int):\n        # In our case it will be medicine\n        self.centroid = centroid\n\n        # spaCy's Language model (english), which will be used to return similarity to\n        # centroid of each concept\n        self.nlp = nlp\n        self.n_threads: int = n_threads\n        self.batch_size: int = batch_size\n\n        self.missing: typing.List[int] = []\n\n    def __call__(self, concepts):\n        concepts_similarity = []\n        # nlp.pipe is faster for many documents and can work in parallel (not blocked by GIL)\n        for i, concept in enumerate(\n            self.nlp.pipe(\n                concepts, n_threads=self.n_threads, batch_size=self.batch_size\n            )\n        ):\n            if concept.has_vector:\n                concepts_similarity.append(self.centroid.similarity(concept))\n            else:\n                # If document has no vector, it's assumed to be totally dissimilar to centroid\n                concepts_similarity.append(-1)\n                self.missing.append(i)\n\n        return np.array(concepts_similarity)\n", "import json\nimport typing\n\nimport numpy as np\nimport spacy\n\nnlp = spacy.load(\"en_vectors_web_lg\")\n\ncentroid = nlp(\"medicine\")\n\nconcepts = json.load(open(\"concepts_new.txt\"))\nconcepts_similarity = Similarity(centroid, nlp, n_threads=-1, batch_size=4096)(\n    concepts\n)\n", "class ActiveLearner:\n    def __init__(\n        self,\n        concepts,\n        concepts_similarity,\n        max_steps: int,\n        samples: int,\n        step: float = 0.05,\n        change_multiplier: float = 0.7,\n    ):\n        sorting_indices = np.argsort(-concepts_similarity)\n        self.concepts = concepts[sorting_indices]\n        self.concepts_similarity = concepts_similarity[sorting_indices]\n\n        self.max_steps: int = max_steps\n        self.samples: int = samples\n        self.step: float = step\n        self.change_multiplier: float = change_multiplier\n\n        # We don't have to ask experts for the same concepts\n        self._checked_concepts: typing.Set[int] = set()\n        # Minimum similarity between vectors is -1\n        self._min_threshold: float = -1\n        # Maximum similarity between vectors is 1\n        self._max_threshold: float = 1\n\n        # Let's start from the highest similarity to ensure minimum amount of steps\n        self.threshold_: float = 1\n", "def _ask_expert(self, available_concepts_indices):\n    # Get random concepts (the ones above the threshold)\n    concepts_to_show = set(\n        np.random.choice(\n            available_concepts_indices, len(available_concepts_indices)\n        ).tolist()\n    )\n    # Remove those already presented to an expert\n    concepts_to_show = concepts_to_show - self._checked_concepts\n    self._checked_concepts.update(concepts_to_show)\n    # Print message for an expert and concepts to be classified\n    if concepts_to_show:\n        print(\"\\nAre those concepts related to medicine?\\n\")\n        print(\n            \"\\n\".join(\n                f\"{i}. {concept}\"\n                for i, concept in enumerate(\n                    self.concepts[list(concepts_to_show)[: self.samples]]\n                )\n            ),\n            \"\\n\",\n        )\n        return input(\"[y]es / [n]o / [any]quit \")\n    return \"y\"\n", "Are those concepts related to medicine?                                                      \n\n0. anesthetic drug                                                                                                                                                                         \n1. child and adolescent psychiatry                                                                                                                                                         \n2. tertiary care center                                                     \n3. sex therapy                           \n4. drug design                                                                                                                                                                             \n5. pain disorder                                                      \n6. psychiatric rehabilitation                                                                                                                                                              \n7. combined oral contraceptive                                \n8. family practitioner committee                           \n9. cancer family syndrome                          \n10. social psychology                                                                                                                                                                      \n11. drug sale                                                                                                           \n12. blood system                                                                        \n\n[y]es / [n]o / [any]quit y\n", "# True - keep asking, False - stop the algorithm\ndef _parse_expert_decision(self, decision) -> bool:\n    if decision.lower() == \"y\":\n        # You can't go higher as current threshold is related to medicine\n        self._max_threshold = self.threshold_\n        if self.threshold_ - self.step < self._min_threshold:\n            return False\n        # Lower the threshold\n        self.threshold_ -= self.step\n        return True\n    if decision.lower() == \"n\":\n        # You can't got lower than this, as current threshold is not related to medicine already\n        self._min_threshold = self.threshold_\n        # Multiply threshold to pinpoint exact spot\n        self.step *= self.change_multiplier\n        if self.threshold_ + self.step < self._max_threshold:\n            return False\n        # Lower the threshold\n        self.threshold_ += self.step\n        return True\n    return False\n", "class ActiveLearner:\n    def __init__(\n        self,\n        concepts,\n        concepts_similarity,\n        samples: int,\n        max_steps: int,\n        step: float = 0.05,\n        change_multiplier: float = 0.7,\n    ):\n        sorting_indices = np.argsort(-concepts_similarity)\n        self.concepts = concepts[sorting_indices]\n        self.concepts_similarity = concepts_similarity[sorting_indices]\n\n        self.samples: int = samples\n        self.max_steps: int = max_steps\n        self.step: float = step\n        self.change_multiplier: float = change_multiplier\n\n        # We don't have to ask experts for the same concepts\n        self._checked_concepts: typing.Set[int] = set()\n        # Minimum similarity between vectors is -1\n        self._min_threshold: float = -1\n        # Maximum similarity between vectors is 1\n        self._max_threshold: float = 1\n\n        # Let's start from the highest similarity to ensure minimum amount of steps\n        self.threshold_: float = 1\n\n    def _ask_expert(self, available_concepts_indices):\n        # Get random concepts (the ones above the threshold)\n        concepts_to_show = set(\n            np.random.choice(\n                available_concepts_indices, len(available_concepts_indices)\n            ).tolist()\n        )\n        # Remove those already presented to an expert\n        concepts_to_show = concepts_to_show - self._checked_concepts\n        self._checked_concepts.update(concepts_to_show)\n        # Print message for an expert and concepts to be classified\n        if concepts_to_show:\n            print(\"\\nAre those concepts related to medicine?\\n\")\n            print(\n                \"\\n\".join(\n                    f\"{i}. {concept}\"\n                    for i, concept in enumerate(\n                        self.concepts[list(concepts_to_show)[: self.samples]]\n                    )\n                ),\n                \"\\n\",\n            )\n            return input(\"[y]es / [n]o / [any]quit \")\n        return \"y\"\n\n    # True - keep asking, False - stop the algorithm\n    def _parse_expert_decision(self, decision) -> bool:\n        if decision.lower() == \"y\":\n            # You can't go higher as current threshold is related to medicine\n            self._max_threshold = self.threshold_\n            if self.threshold_ - self.step < self._min_threshold:\n                return False\n            # Lower the threshold\n            self.threshold_ -= self.step\n            return True\n        if decision.lower() == \"n\":\n            # You can't got lower than this, as current threshold is not related to medicine already\n            self._min_threshold = self.threshold_\n            # Multiply threshold to pinpoint exact spot\n            self.step *= self.change_multiplier\n            if self.threshold_ + self.step < self._max_threshold:\n                return False\n            # Lower the threshold\n            self.threshold_ += self.step\n            return True\n        return False\n\n    def fit(self):\n        for _ in range(self.max_steps):\n            available_concepts_indices = np.nonzero(\n                self.concepts_similarity >= self.threshold_\n            )[0]\n            if available_concepts_indices.size != 0:\n                decision = self._ask_expert(available_concepts_indices)\n                if not self._parse_expert_decision(decision):\n                    break\n            else:\n                self.threshold_ -= self.step\n        return self\n", "class Classifier:\n    def __init__(self, centroid, threshold: float):\n        self.centroid = centroid\n        self.threshold: float = threshold\n\n    def predict(self, concepts_pipe):\n        predictions = []\n        for concept in concepts_pipe:\n            predictions.append(self.centroid.similarity(concept) > self.threshold)\n        return predictions\n", "import json\nimport typing\n\nimport numpy as np\nimport spacy\n\n\nclass Similarity:\n    def __init__(self, centroid, nlp, n_threads: int, batch_size: int):\n        # In our case it will be medicine\n        self.centroid = centroid\n\n        # spaCy's Language model (english), which will be used to return similarity to\n        # centroid of each concept\n        self.nlp = nlp\n        self.n_threads: int = n_threads\n        self.batch_size: int = batch_size\n\n        self.missing: typing.List[int] = []\n\n    def __call__(self, concepts):\n        concepts_similarity = []\n        # nlp.pipe is faster for many documents and can work in parallel (not blocked by GIL)\n        for i, concept in enumerate(\n            self.nlp.pipe(\n                concepts, n_threads=self.n_threads, batch_size=self.batch_size\n            )\n        ):\n            if concept.has_vector:\n                concepts_similarity.append(self.centroid.similarity(concept))\n            else:\n                # If document has no vector, it's assumed to be totally dissimilar to centroid\n                concepts_similarity.append(-1)\n                self.missing.append(i)\n\n        return np.array(concepts_similarity)\n\n\nclass ActiveLearner:\n    def __init__(\n        self,\n        concepts,\n        concepts_similarity,\n        samples: int,\n        max_steps: int,\n        step: float = 0.05,\n        change_multiplier: float = 0.7,\n    ):\n        sorting_indices = np.argsort(-concepts_similarity)\n        self.concepts = concepts[sorting_indices]\n        self.concepts_similarity = concepts_similarity[sorting_indices]\n\n        self.samples: int = samples\n        self.max_steps: int = max_steps\n        self.step: float = step\n        self.change_multiplier: float = change_multiplier\n\n        # We don't have to ask experts for the same concepts\n        self._checked_concepts: typing.Set[int] = set()\n        # Minimum similarity between vectors is -1\n        self._min_threshold: float = -1\n        # Maximum similarity between vectors is 1\n        self._max_threshold: float = 1\n\n        # Let's start from the highest similarity to ensure minimum amount of steps\n        self.threshold_: float = 1\n\n    def _ask_expert(self, available_concepts_indices):\n        # Get random concepts (the ones above the threshold)\n        concepts_to_show = set(\n            np.random.choice(\n                available_concepts_indices, len(available_concepts_indices)\n            ).tolist()\n        )\n        # Remove those already presented to an expert\n        concepts_to_show = concepts_to_show - self._checked_concepts\n        self._checked_concepts.update(concepts_to_show)\n        # Print message for an expert and concepts to be classified\n        if concepts_to_show:\n            print(\"\\nAre those concepts related to medicine?\\n\")\n            print(\n                \"\\n\".join(\n                    f\"{i}. {concept}\"\n                    for i, concept in enumerate(\n                        self.concepts[list(concepts_to_show)[: self.samples]]\n                    )\n                ),\n                \"\\n\",\n            )\n            return input(\"[y]es / [n]o / [any]quit \")\n        return \"y\"\n\n    # True - keep asking, False - stop the algorithm\n    def _parse_expert_decision(self, decision) -> bool:\n        if decision.lower() == \"y\":\n            # You can't go higher as current threshold is related to medicine\n            self._max_threshold = self.threshold_\n            if self.threshold_ - self.step < self._min_threshold:\n                return False\n            # Lower the threshold\n            self.threshold_ -= self.step\n            return True\n        if decision.lower() == \"n\":\n            # You can't got lower than this, as current threshold is not related to medicine already\n            self._min_threshold = self.threshold_\n            # Multiply threshold to pinpoint exact spot\n            self.step *= self.change_multiplier\n            if self.threshold_ + self.step < self._max_threshold:\n                return False\n            # Lower the threshold\n            self.threshold_ += self.step\n            return True\n        return False\n\n    def fit(self):\n        for _ in range(self.max_steps):\n            available_concepts_indices = np.nonzero(\n                self.concepts_similarity >= self.threshold_\n            )[0]\n            if available_concepts_indices.size != 0:\n                decision = self._ask_expert(available_concepts_indices)\n                if not self._parse_expert_decision(decision):\n                    break\n            else:\n                self.threshold_ -= self.step\n        return self\n\n\nclass Classifier:\n    def __init__(self, centroid, threshold: float):\n        self.centroid = centroid\n        self.threshold: float = threshold\n\n    def predict(self, concepts_pipe):\n        predictions = []\n        for concept in concepts_pipe:\n            predictions.append(self.centroid.similarity(concept) > self.threshold)\n        return predictions\n\n\nif __name__ == \"__main__\":\n    nlp = spacy.load(\"en_vectors_web_lg\")\n\n    centroid = nlp(\"medicine\")\n\n    concepts = json.load(open(\"concepts_new.txt\"))\n    concepts_similarity = Similarity(centroid, nlp, n_threads=-1, batch_size=4096)(\n        concepts\n    )\n\n    learner = ActiveLearner(\n        np.array(concepts), concepts_similarity, samples=20, max_steps=50\n    ).fit()\n    print(f\"Found threshold {learner.threshold_}\\n\")\n\n    classifier = Classifier(centroid, learner.threshold_)\n    pipe = nlp.pipe(concepts, n_threads=-1, batch_size=4096)\n    predictions = classifier.predict(pipe)\n    print(\n        \"\\n\".join(\n            f\"{concept}: {label}\"\n            for concept, label in zip(concepts[20:40], predictions[20:40])\n        )\n    )\n", "kartagener s syndrome: True\nsummer season: True\ntaq: False\natypical neuroleptic: True\nanterior cingulate: False\nacute respiratory distress syndrome: True\ncircularity: False\nmutase: False\nadrenergic blocking drug: True\nsystematic desensitization: True\nthe turning point: True\n9l: False\npyridazine: False\nbisoprolol: False\ntrq: False\npropylhexedrine: False\ntype 18: True\ndarpp 32: False\nrickettsia conorii: False\nsport shoe: True\n"], ["address = contacts.split('Phone')\nprint(address[0]) \n"], ["import wikipedia\n\ndef categorySorter(targetCats, pagesToCheck, mainCategory):\n    targetList = []\n    nonTargetList = []\n    targetCats = [i.lower() for i in targetCats]\n\n    print('Sorting pages...')\n    print('Sorted:', end=' ', flush=True)\n    for page in pagesToCheck:\n\n        e = openPage(page)\n\n        def deepList(l):\n            for item in l:\n                if item[1] == 'SUBPAGE_ID':\n                    deepList(item[2])\n                else:\n                    catComparator(item[0], item[1], targetCats, targetList, nonTargetList, pagesToCheck[-1])\n\n        if e[1] == 'SUBPAGE_ID':\n            deepList(e[2])\n        else:\n            catComparator(e[0], e[1], targetCats, targetList, nonTargetList, pagesToCheck[-1])\n\n    print()\n    print()\n    print('Results:')\n    print(mainCategory, ': ', targetList, sep='')\n    print()\n    print('Non-', mainCategory, ': ', nonTargetList, sep='')\n\ndef openPage(page):\n    try:\n        pageList = [page, wikipedia.WikipediaPage(page).categories]\n    except wikipedia.exceptions.PageError as p:\n        pageList = [page, 'NONEXIST_ID']\n        return\n    except wikipedia.exceptions.DisambiguationError as e:\n        pageCategories = []\n        for i in e.options:\n            if '(disambiguation)' not in i:\n                pageCategories.append(openPage(i))\n        pageList = [page, 'SUBPAGE_ID', pageCategories]\n        return pageList\n    finally:\n        return pageList\n\ndef catComparator(pageTitle, pageCategories, targetCats, targetList, nonTargetList, lastPage):\n\n    # unhash to view the categories of each page\n    #print(pageCategories)\n    pageCategories = [i.lower() for i in pageCategories]\n\n    any_in = False\n    for i in targetCats:\n        if i in pageTitle:\n            any_in = True\n    if any_in:\n        print('', end = '', flush=True)\n    elif compareLists(targetCats, pageCategories):\n        any_in = True\n\n    if any_in:\n        targetList.append(pageTitle)\n    else:\n        nonTargetList.append(pageTitle)\n\n    # Just prints a pretty list, you can comment out until next hash if desired\n    if any_in:\n        print(pageTitle, '(T)', end='', flush=True)\n    else:\n        print(pageTitle, '(F)',end='', flush=True)\n\n    if pageTitle != lastPage:\n        print(',', end=' ')\n    # No more commenting\n\n    return any_in\n\ndef compareLists (a, b):\n    for i in a:\n        for j in b:\n            if i in j:\n                return True\n    return False\n", "medicalCategories = ['surgery', 'medic', 'disease', 'drugs', 'virus', 'bact', 'fung', 'pharma', 'cardio', 'pulmo', 'sensory', 'nerv', 'derma', 'protein', 'amino', 'unii', 'chlor', 'carcino', 'oxi', 'oxy', 'sis', 'disorder', 'enzyme', 'eine', 'sulf']\nlistOfPages = ['juvenile chronic arthritis', 'climate', 'alexidine', 'mouthrinse', 'sialosis', 'australia', 'artificial neural network', 'ricinoleic acid', 'bromosulfophthalein', 'myelosclerosis', 'hydrochloride salt', 'cycasin', 'aldosterone antagonist', 'fungal growth', 'describe', 'liver resection', 'coffee table', 'natural language processing', 'infratemporal fossa', 'social withdrawal', 'information retrieval', 'monday', 'menthol', 'overturn', 'prevailing', 'spline function', 'acinic cell carcinoma', 'furth', 'hepatic protein', 'blistering', 'prefixation', 'january', 'cardiopulmonary receptor', 'extracorporeal membrane oxygenation', 'clinodactyly', 'melancholic', 'chlorpromazine hydrochloride', 'level of evidence', 'washington state', 'cat', 'year elevan', 'trituration', 'gold alloy', 'hexoprenaline', 'second molar', 'novice', 'oxygen radical', 'subscription', 'ordinate', 'approximal', 'spongiosis', 'ribothymidine', 'body of evidence', 'vpb', 'porins', 'musculocutaneous']\ncategorySorter(medicalCategories, listOfPages, 'Medical')\n"], ["embed = hub.Module(\"https://tfhub.dev/google/universal-sentence-encoder/2\")\nembeddings = embed([\"Input Text here as\",\" List of strings\"])\nsession.run(embeddings)\n", "def AllTopics():\n    topics = []# list all your topics, not added here for space restricitons\n    for i in range(len(topics)-1):\n        yield topics[i]\n", "import wikipedia\nimport pickle\nfrom content import Alltopics\nsummary = []\nfailed = []\nfor topic in Alltopics():\n    try:\n        summary.append(wikipedia.summary(tuple((topic,str(topic)))))\n    except Exception as e:\n        failed.append(tuple((topic,e)))\nwith open(\"summary.txt\", \"wb\") as fp:\n    pickle.dump(summary , fp)\nwith open('failed.txt', 'wb') as fp:\n    pickle.dump('failed', fp)\n", "import tensorflow as tf\nimport tensorflow_hub as hub\nimport numpy as np\nimport os\nimport pandas as pd\nimport re\nimport pickle\nimport sys\nfrom sklearn.cluster import AgglomerativeClustering\nfrom sklearn import metrics\nfrom scipy.cluster import hierarchy\nfrom scipy.spatial import distance_matrix\n\n\ntry:\n    with open(\"summary.txt\", \"rb\") as fp:   # Unpickling\n        summary = pickle.load(fp)\nexcept Exception as e:\n    print ('Cannot load the summary file, Please make sure that it exists, if not run Summary Generator first', e)\n    sys.exit('Read the error message')\n\nmodule_url = \"https://tfhub.dev/google/universal-sentence-encoder-large/3\"\nembed = hub.Module(module_url)\n\ntf.logging.set_verbosity(tf.logging.ERROR)\nmessages = [x[1] for x in summary]\nlabels = [x[0] for x in summary]\nwith tf.Session() as session:\n    session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n    message_embeddings = session.run(embed(messages)) # In message embeddings each vector is a second (1,512 vector) and is numpy.ndarray (noOfElemnts, 512)\n\nX = message_embeddings\nagl = AgglomerativeClustering(n_clusters=5, affinity='euclidean', memory=None, connectivity=None, compute_full_tree='auto', linkage='ward', pooling_func='deprecated')\nagl.fit(X)\ndist_matrix = distance_matrix(X,X)\nZ = hierarchy.linkage(dist_matrix, 'complete')\ndendro = hierarchy.dendrogram(Z)\ncluster_labels = agl.labels_\n"], [], ["lst=[('Jeffery Medina','Officer','1254','101442.00','23'),('Katrina Peters','Officer','3423','94122.00','45'),('Kim Alan','Captain','6434','101592.00','29'),('Vincente Mendez','Officer','3235','110064.00','32'),('Chris Boalen','Captain','8769','50436.00','56'),('James Vito','Clerk','4451','23500.00','61'),('Terry George','Fireman','3342','93354.00','32'),('Zaid Dane','Officer','2345','84054.00','19'),('Ernesto Rodriguez','Officer','9091','87006.00','35'),('Josefine White','Fireman','3401','102228.00','26'),('Mario Infante','Officer','3234','84054.00','22'),('Juan Almonte','Fireman','4103','91272.00','50'),('Kevin Smith','Fireman','3450','111492.00','62'),('Abdum Smith','Captain','2234','95484.00','20'),('Juan Gomez','Clerk','9023','23890.00','49')]\n\nname = input(\"Who are you looking for? :\")\n\nfor i in range(len(lst)):\n    try:\n        if name == lst[i][i]:\n            print(\"Employe Name: {} \\nSalary: {} \\nAge: {} \".format(lst[i][i], lst[i][i+3], lst[i][i+4]))\n    except IndexError:\n        pass\n", "Who are you looking for? :Jeffery Medina\nEmploye Name: Jeffery Medina \nSalary: 101442.00 \nAge: 23 \n", "for i in range(len(lst)):\n    try:\n        if re.search(name, lst[i][i], re.IGNORECASE):\n            print(\"Employe Name: {} \\nSalary: {} \\nAge: {} \".format(lst[i][i], lst[i][i+3], lst[i][i+4]))\n    except IndexError:\n        pass\n", "Who are you looking for? :jeFFerY mEdinA\nEmploye Name: Jeffery Medina \nSalary: 101442.00 \nAge: 23 \n"], ["while True:\n    name = input(\"Who are you looking for?: \")\n\n    for person in people:\n        if person[0] == name:\n            print(\"Name: {},\\nRank: {},\\nNumber: {},\\nSalary: {},\\nAge: {}\".format(person[0],person[1],person[2],person[3],person[4]))\n            break\n        else:\n            print(\"This person does not exist. Try Another\")\n"], ["list=[('Jeffery Medina','Officer','1254','101442.00','23'),('Katrina Peters','Officer','3423','94122.00','45'),('Kim Alan','Captain','6434','101592.00','29'),('Vincente Mendez','Officer','3235','110064.00','32'),('Chris Boalen','Captain','8769','50436.00','56'),('James Vito','Clerk','4451','23500.00','61'),('Terry George','Fireman','3342','93354.00','32'),('Zaid Dane','Officer','2345','84054.00','19'),('Ernesto Rodriguez','Officer','9091','87006.00','35'),('Josefine White','Fireman','3401','102228.00','26'),('Mario Infante','Officer','3234','84054.00','22'),('Juan Almonte','Fireman','4103','91272.00','50'),('Kevin Smith','Fireman','3450','111492.00','62'),('Abdum Smith','Captain','2234','95484.00','20'),('Juan Gomez','Clerk','9023','23890.00','49')]\n\nname = input(\"Who are you looking for? :\")\nfor i in range(len(list)):\n    if list[i][0] == name:\n        print(\"Employe Name: {} \\nSalary: {} \\nAge: {} \".format(name,str(list[i][3]),str(list[i][4])))\n"], ["name = input(\"Who are you looking for? :\")\nlst = [('Jeffery Medina','Officer','1254','101442.00','23'),('Katrina Peters','Officer','3423','94122.00','45'),('Kim Alan','Captain','6434','101592.00','29'),('Vincente Mendez','Officer','3235','110064.00','32'),('Chris Boalen','Captain','8769','50436.00','56'),('James Vito','Clerk','4451','23500.00','61'),('Terry George','Fireman','3342','93354.00','32'),('Zaid Dane','Officer','2345','84054.00','19'),('Ernesto Rodriguez','Officer','9091','87006.00','35'),('Josefine White','Fireman','3401','102228.00','26'),('Mario Infante','Officer','3234','84054.00','22'),('Juan Almonte','Fireman','4103','91272.00','50'),('Kevin Smith','Fireman','3450','111492.00','62'),('Abdum Smith','Captain','2234','95484.00','20'),('Juan Gomez','Clerk','9023','23890.00','49')]\n\nfor x in lst:\n    if name in x:\n        do_something_with_this_tuple(x)\n"], ["data = [('Jeffery Medina','Officer','1254','101442.00','23'),('Katrina Peters','Officer','3423','94122.00','45'),('Kim Alan','Captain','6434','101592.00','29'),('Vincente Mendez','Officer','3235','110064.00','32'),('Chris Boalen','Captain','8769','50436.00','56'),('James Vito','Clerk','4451','23500.00','61'),('Terry George','Fireman','3342','93354.00','32'),('Zaid Dane','Officer','2345','84054.00','19'),('Ernesto Rodriguez','Officer','9091','87006.00','35'),('Josefine White','Fireman','3401','102228.00','26'),('Mario Infante','Officer','3234','84054.00','22'),('Juan Almonte','Fireman','4103','91272.00','50'),('Kevin Smith','Fireman','3450','111492.00','62'),('Abdum Smith','Captain','2234','95484.00','20'),('Juan Gomez','Clerk','9023','23890.00','49')]\nname = input('Who are you looking for: ')\nprint([x for x in data if name in x[0]])\n", "Who are you looking for: Jeffery\n[('Jeffery Medina', 'Officer', '1254', '101442.00', '23')]\n"], ["numpy.array(object, dtype=None, copy=True, order='K', subok=False, ndmin=0)\n", "import numpy as np\na = np.array([[0.0, 0.2, 0.4, 0.6, 0.8],\n              [0.0, 0.2, 0.4, 0.6, 0.8],\n              [0.0, 0.2, 0.4, 0.6, 0.8]])\nb=np.array(a)\nb[0] += 1\na\n\nOut[6]: \narray([[0. , 0.2, 0.4, 0.6, 0.8],\n       [0. , 0.2, 0.4, 0.6, 0.8],\n       [0. , 0.2, 0.4, 0.6, 0.8]])\nc = np.asarray(a)\nc[0] +=1\na\n\nOut[9]: \narray([[1. , 1.2, 1.4, 1.6, 1.8],\n       [0. , 0.2, 0.4, 0.6, 0.8],\n       [0. , 0.2, 0.4, 0.6, 0.8]])\n"], ["geolocation = i.get('geolocation',{\"lat\": 0,\"lng\":0})\naddress_lat = geolocation['lat']\naddress_lng = geolocation['lng']\n"], [">>> class A:\n...     i = 10\n...\n>>> hasattr(A(), 'i')\nTrue\n", "data = {'geolocation': 0.0}\nif 'geolocation' in data:\n     ...do something\n"], [], ["try:\n    address_lat = i['geolocation']['lat']\n    address_lng = i['geolocation']['lng']\nexcept KeyError:\n    address_lat = 0.0\n    address_lng = 0.0\n"], ["geolocation = i.get('geolocation', {\"lat\": 0., \"lng\": 0.})\n"], ["address_lat = i['geolocation']['lat'] if 'geolocation' in i else 0.0\naddress_lng = i['geolocation']['ing'] if 'geolocation' in i else 0.0\n"], ["import os\nimport datetime\n\nSchoolDB = [5002, 5006, 5020, 5021, 5022, 5025, 5028, 5030, 5102, 5103, 5104,\n5105, 5109, 5117, 5119, 5120, 5121, 5126, 5130, 5131, 5132, 5133, 5134, 5135,\n5136, 5137, 5205, 5211, 5238, 5244]\n\ntodayd = datetime.datetime.now().strftime (\"%#d/%#m/%Y\")\ntodayt = datetime.datetime.now().strftime (\"%H:%M:%S\")\n\nfor number in SchoolDB:\n    os.makedirs('{}'.format(str(number)), exist_ok=True)\n    with open(\"{}/readme.ini\".format(str(number)), 'w+') as dbs:\n        dbs.write(\"[SCHOOL] \\n{} \\n\\n[DATE] \\n{} \\n\\n'[TIME]' \\n{} \\n\".format(number, todayd, todayt))\n"], ["In [1]: a = [np.array([0.0, 0.2, 0.4, 0.6, 0.8]), \n   ...:      np.array([0.0, 0.2, 0.4, 0.6, 0.8]), \n   ...:      np.array([0.0, 0.2, 0.4, 0.6, 0.8])]                               \nIn [2]:                                                                         \nIn [2]: a                                                                       \nOut[2]: \n[array([0. , 0.2, 0.4, 0.6, 0.8]),\n array([0. , 0.2, 0.4, 0.6, 0.8]),\n array([0. , 0.2, 0.4, 0.6, 0.8])]\n", "In [3]: b = np.array(a)                                                         \nIn [4]: b                                                                       \nOut[4]: \narray([[0. , 0.2, 0.4, 0.6, 0.8],\n       [0. , 0.2, 0.4, 0.6, 0.8],\n       [0. , 0.2, 0.4, 0.6, 0.8]])\nIn [5]: b[0] += 1                                                               \nIn [6]: b                                                                       \nOut[6]: \narray([[1. , 1.2, 1.4, 1.6, 1.8],\n       [0. , 0.2, 0.4, 0.6, 0.8],\n       [0. , 0.2, 0.4, 0.6, 0.8]])\n", "In [8]: b = np.array(a)                                                         \nIn [9]: b                                                                       \nOut[9]: \narray([array([0. , 0.2, 0.4, 0.6, 0.8]), array([0. , 0.2, 0.4, 0.6, 0.8]),\n       array([0. , 0.2, 0.4, 0.6])], dtype=object)\n", "In [17]: b = np.empty(3, object)                                                \nIn [18]: b[:] = a[:]                                                            \nIn [19]: b                                                                      \nOut[19]: \narray([array([0. , 0.2, 0.4, 0.6, 0.8]), array([0. , 0.2, 0.4, 0.6, 0.8]),\n       array([0. , 0.2, 0.4, 0.6, 0.8])], dtype=object)\n"], ["a = [np.array([0.0, 0.2, 0.4, 0.6, 0.8]),\n     np.array([0.0, 0.2, 0.4, 0.6, 0.8]),\n     np.array([0.0, 0.2, 0.4, 0.6, 0.8])]\nb = np.array(a)\nid(a[0])\n# 139663994327728\nid(b[0])\n# 139663994324672\n", "a2 = [np.array([0. , 0.2, 0.4, 0.6, 0.8]), \n     np.array([0. , 0.2, 0.4, 0.6, 0.8]), \n     np.array([0. , 0.2, 0.4, 0.6])]\nb2 = np.array(a2)\nb2\narray([array([1. , 1.2, 1.4, 1.6, 1.8]), array([0. , 0.2, 0.4, 0.6, 0.8]),\n       array([0. , 0.2, 0.4, 0.6])], dtype=object)\n", "for s in a2:\n    print(id(s))\n# 139663994330128\n# 139663994328448\n# 139663994329488\n\nfor s in b2:\n    print(id(s))\n# 139663994330128\n# 139663994328448\n# 139663994329488\n"], [], ["Import os\nos.chdir('PARENT_DIRECTORY_PATH')\n", "for x in SchoolDB:\n    os.mkdir(x)\n    os.chdir(x)\n    dbs = open(\"readme.ini\" , 'w+')\n"], ["import os\n...\nfor x in SchoolDB:\n    folder = os.mkdir(\"%s\"%x) ## this will creare a folder with the name of x\n    dbs = file.open(\"%s/readme.ini\"%x,\"w+\") ## relative path to your file\n    dbs.write(\"now write what ever you want\")\n"], ["dbs.write(\"\"\"[SCHOOL]\\n{}\\n\\n[DATE]\\n{}\\n\\n[TIME]\\n{}\\n\"\"\".format(x, todayd, todayt)\n"], ["filename = '{} hello{}'.format(varname1,varname2)\n"], ["import re\nfrom mediawiki import MediaWiki\n\n#TermFind will search through a list a given term\ndef TermFind(term,termList):\n    responce=False\n    for val in termList:\n        if re.match('(.*)'+term+'(.*)',val):\n            responce=True\n            break\n    return responce\n\n#Find if the links and backlinks lists contains a given term \ndef BoundedTerm(wikiPage,term):\n    aList=wikiPage.links\n    bList=wikiPage.backlinks\n    responce=False\n    if TermFind(term,aList)==True and TermFind(term,bList)==True:\n         responce=True\n    return responce\n\ncontainer=[]\nwikipedia = MediaWiki()\nfor val in termlist:\n    cpage=wikipedia.page(val)\n    if BoundedTerm(cpage,'term')==True:\n        container.append('medical')\n    else:\n        container.append('nonmedical')\n"], ["my_dict = [\n        {'first': 'James', 'middle': 'Smith', 'last': 'Joule'}, \n        {'first': 'James', 'middle': 'smith', 'last': 'joule'},\n        {'first': 'Christian', 'middle': 'Edward', 'last': 'Doppler'},\n        {'first': 'Robert', 'middle': 'Edward', 'last': 'Antonio'},\n        {'first': 'Robert', 'middle': 'edward', 'last': 'antonio'},\n        {'first': 'Robert', 'middle': 'edwrd', 'last': 'Antonio'},\n        {'first': 'James', 'middle': 'Jackson', 'last': 'harden'}, \n        {'first': 'James', 'middle': 'jackson', 'last': 'Harden'},\n      ]\nkeys = [\"first\",\"last\"]\nfields = [''.join([x.lower() for x in \\\n                   list(map(lambda x : my_dict[i].__getitem__(x), keys))]) \\\n          for i,v in enumerate(my_dict)]\nfiltered_dict = [my_dict[i] for i,v in enumerate(fields) if fields.index(v) == i]\n", "filtered_dict = [ my_dict[i] for i,v in enumerate(fields) if i == 0 or v != fields[i-1] ]\n"], ["from operator import itemgetter\n\nallBins = [[(3,20)],[(1,11),(0,6)],[(4,16),(2,5)]]\n\ndef func(bin_num, all_bins):\n    bin = itemgetter(bin_num)(all_bins)\n    s = sum(map(itemgetter(-1), bin))\n    return s\n\nprint(func(2, allBins))\n# 21\n"], ["values = list(map(lambda x: set(i.lower() for i in x.values()), my_dict))\nmy_filter_list = [my_dict[i] for i,x in enumerate(values) if values.index(x)==i]\n"], ["from itertools import groupby\n# https://docs.python.org/3/library/itertools.html#itertools.groupby\n\nmy_dict = [\n        {'first': 'James', 'middle': 'Smith', 'last': 'Joule'}, \n        {'first': 'James', 'middle': 'smith', 'last': 'joule'},\n        {'first': 'Christian', 'middle': 'Edward', 'last': 'Doppler'},\n        {'first': 'Robert', 'middle': 'Edward', 'last': 'Antonio'},\n        {'first': 'Robert', 'middle': 'edward', 'last': 'antonio'},\n        {'first': 'Robert', 'middle': 'edwrd', 'last': 'Antonio'},\n        {'first': 'James', 'middle': 'Jackson', 'last': 'harden'}, \n        {'first': 'James', 'middle': 'jackson', 'last': 'Harden'},\n      ]\n\nkeys = [\"first\",\"last\"]\n\nk = [list(data)[0] for key,data in groupby(my_dict, \n                                           key=lambda x: tuple(x[i].lower() for i in keys))]\n\nprint(k) \n", "[{'first': 'James', 'middle': 'Smith', 'last': 'Joule'}, \n {'first': 'Christian', 'middle': 'Edward', 'last': 'Doppler'}, \n {'first': 'Robert', 'middle': 'Edward', 'last': 'Antonio'}, \n {'first': 'James', 'middle': 'Jackson', 'last': 'harden'}]\n"], ["my_list = [\n    {'first': 'James', 'middle': 'Smith', 'last': 'Joule'},\n    {'first': 'James', 'middle': 'smith', 'last': 'joule'},\n    {'first': 'Christian', 'middle': 'Edward', 'last': 'Doppler'},\n    {'first': 'Robert', 'middle': 'Edward', 'last': 'Antonio'},\n    {'first': 'Robert', 'middle': 'edward', 'last': 'antonio'},\n    {'first': 'Robert', 'middle': 'edwrd', 'last': 'Antonio'},\n    {'first': 'James', 'middle': 'Jackson', 'last': 'harden'},\n    {'first': 'James', 'middle': 'jackson', 'last': 'Harden'}\n]\nkeys = [\"first\", \"last\"]\n", "import collections\ntemp = collections.OrderedDict([\n    (\n        tuple(e[k].lower() for k in keys),    # only some keys will determine duplicates\n        e,\n    )\n    for e in my_list])\n\nmy_new_list = list(temp.values())\n"], ["import pandas as pd\n\nmy_dict = [\n    {'first': 'James', 'middle': 'Smith', 'last': 'Joule'},\n    {'first': 'James', 'middle': 'smith', 'last': 'joule'},\n    {'first': 'Christian', 'middle': 'Edward', 'last': 'Doppler'},\n    {'first': 'Robert', 'middle': 'Edward', 'last': 'Antonio'},\n    {'first': 'Robert', 'middle': 'edward', 'last': 'antonio'},\n    {'first': 'Robert', 'middle': 'edwrd', 'last': 'Antonio'},\n    {'first': 'James', 'middle': 'Jackson', 'last': 'harden'},\n    {'first': 'James', 'middle': 'jackson', 'last': 'Harden'}\n]\n\n\nkeys = [\"first\", \"last\"]\n\ndf = pd.DataFrame(my_dict)\n\ndf = df.drop_duplicates(keep=\"first\")\nprint(df)\n"], ["words = ['This', 'is', 'an', 'example', 'of', 'a', 'short', 'sentence.']\nwords_without_e = [ word for word in words if 'e' not in word ]\n\nprint(words_without_e)\n"], ["count = 0\nfin   = open('words.txt', 'r') #Open the file for reading\nwords = fin.readlines()        #Read words from file\nfin.close()                    #Close the file\n\nfor word in words:              \n    word = word.strip()\n    if not 'e' in word:        #If there is NO letter e in the word\n        count = count + 1\n        print(word)\n\npercent = (count / 113809.0) * 100\nprint(str(percent))\n", "if 'e' in word:\n    return True\nelse:\n    return False\n"], [], ["def sum_bin(bin_num, data):\n    my_bin = data[bin_num]\n    return sum(t[1] for t in my_bin)\n\n>>> sum_bin(0, allBins)\n20\n>>> sum_bin(1, allBins)\n17\n>>> sum_bin(2, allBins)\n21\n", "sum(t[1] for t in allBins[bin_idx])\n"], ["filename = '/etc/dictionaries-common/words'\nwords = [word for word in open(filename).read().split() \n         if 'e' not in word]\nprint(words[:10])\n"], ["if 'e' in word:\n    return False\nelse:\n    return True\n"], ["def has_no_e(word):\n  if 'e' in word:\n    return True\n  else:\n    return False\n"], [], ["allBins = [[(3,20)],[(1,11),(0,6)],[(4,16),(2,5)]]\n\nprint([sum(y[1] for y in x) for x in allBins])\n# [20, 17, 21]\n", "allBins = [[(3,20)],[(1,11),(0,6)],[(4,16),(2,5)]]\n\nbin_number = 2\nprint(sum(x[1] for x in allBins[bin_number-1]))\n# 17\n"], [], [">>> from operator import itemgetter\n\n>>> allBins = [[(3,20)],[(1,11),(0,6)],[(4,16),(2,5)]]\n>>> [sum(map(itemgetter(1), bin)) for bin in allBins]\n[20, 17, 21]\n"], ["def nested_values(v):\n    return map(nested_values, v.values()) if isinstance(v, dict) else v\n", "from itertools import chain\n\ndef is_duplicated_value(d):\n    flat = list(chain.from_iterable(nested_values(d)))\n    return len(flat) != len(set(flat))\n", "print is_duplicated_value( {1:'a', 2:'b', 3:{1:'c', 2:'a'}} )\nprint is_duplicated_value( {1:'a', 2:'b', 3:{1:'c', 2:'d'}} )\n", "True\nFalse\n", "class Duplicated(ValueError): pass\n\ndef is_dup(d):\n    values = set()\n    def add(v):\n        if isinstance(v, dict):\n            map(add, v.values())\n        else:\n            if v in values:\n                raise Duplicated\n            else:\n                values.add(v)\n    try:\n        add(d)\n        return False\n    except Duplicated:\n        return True\n", "print is_dup( {1:'a', 2:'b', 3:{1:'c', 2:'a'}} )\nprint is_dup( {1:'a', 2:'b', 3:{1:'c', 2:'d'}} )\n", "True\nFalse\n"], ["from itertools import chain\nrr = []\npp = [[7,9], [10, 11]]\n# create a unique set of elements from the lists in pp\nunique_items_in_pp = set(chain(*pp))\n\ndef in_pp(items):\n    \"\"\"Takes an iterable, returns bool, True if an element of iterable is in pp\"\"\"\n    return set(items).isdisjoint(unique_items_in_pp)\n\n# reject anything into rr if in the set\nprint(list(filter(rr_add, [[1,2], [3,4], [5,6], [7,8]])))\n", ">>>[[1, 2], [3, 4], [5, 6]]\n"], ["def test_element_existed(list1, list2):\n    a = set([j for i in range(len(list1)) for j in list1[i]])\n    b = set([j for i in range(len(list2)) for j in list2[i]])\n    #check if any element in set(a) and set(b) are common and print it\n    print(bool(set(a) & set(b)), set(a) & set(b))\n    return list(a.union(b) - a.intersection(b))\ntest_element_existed(rr, pp)\n", "True {7}\n[1, 2, 3, 4, 5, 6, 8, 9, 10, 11]\n"], ["rr = [[1,2], [3,4], [5,6], [7,8]]\npp = [[7,9], [10, 11]]\ndo_append = 1\nfor rr_sublist in rr:\n    for j in range(len(rr_sublist)):\n        for pp_sublist in pp:\n            for i in range(len(pp_sublist)):\n                if pp_sublist[i] == rr_sublist[j]:\n                    print(\"duplicate element found\")\n                    do_append = 0\nif do_append:\n    rr.append(pp)\nprint(rr)\n", "duplicate element found\n[[1, 2], [3, 4], [5, 6], [7, 8]]\n"], ["from itertools import chain\n\ndef are_common_elements(rr, qq):\n    return bool(set(chain(*rr))  & set(chain(*qq)))\n"], ["import itertools\n\nrr = [[1,2], [3,4], [5,6], [7,8]]\npp = [[7,9], [10, 11]]  \nresult = []\nignore = []\n\nfor item in itertools.chain.from_iterable(pp):\n    for pair in rr:\n        if item in pair:\n            print('Yepp, {} is in {}. Ignoring!'.format(item, pair))\n            ignore.append(pair)\n        elif not pair in result and pair not in ignore:\n            result.append(pair)\n\nprint('Result: {}'.format(result))\n"], ["attempt < max_attempts:\n", "def main():\n    introduction()\n    attempt=1\n    while attemptValid(attempt) and answerIsWrong(askQuestion(), attempt):\n        attempt += 1\n\ndef attemptValid(attempt):\n    max_attempts=4\n    if attempt < max_attempts:\n        return 1\n    print('You used the maximum number of attempts, sorry. The correct answer is \"Madison\"')\n    return 0\n\ndef answerIsWrong(answer, attempt):\n    if answer != 'Madison':\n        return 1\n    print(f\"Correct! Thanks for playing. It took you {attempt} attempt(s).\")\n    return 0\n\ndef introduction():\n    print('Quiz program!\\n')\n\ndef askQuestion():\n    return input('What is the capital of Wisconsin? ')\n\nmain()\n"], ["print('Quiz program!\\n')\nanswer = input('What is the capital of Wisconsin? ')\nattempt = 1\nmax_attempts = 4\n", "while answer != 'Madison':\n    attempt += 1\n    print('You got it wrong, please try again.\\n')\n    answer = input('What is the capital of Wisconsin? ')\n    if attempt == max_attempts:\n        print('You used the maximum number of attempts, sorry. The correct answer is \"Madison\"')\n        break\n"], ["print('Quiz program!\\n')\nattempt = 1\nmax_attempts = 4\n\nwhile attempt < max_attempts:\n   attempt += 1\n\n   answer = input('What is the capital of Wisconsin? ')\n   if answer == 'Madison':\n      print(\"Correct!\")\n      break\n   else:\n      print('You got it wrong, please try again.\\n')\n\nprint(\"Thanks for playing. It took you %s attempt(s).\" %(attempt-1))\n"], ["print('Quiz program!\\n')\nanswer = input('What is the capital of Wisconsin? ')\nattempt = 1\nmax_attempts = 3\n\nwhile answer != 'Madison':\n    if attempt == max_attempts:\n        print('You used the maximum number of attempts, sorry. The correct answer is \"Madison\"')\n        break\n    attempt += 1\n    print('You got it wrong, please try again.\\n')\n    answer = input('What is the capital of Wisconsin? ')\nelse:\n    print(f\"Correct! Thanks for playing. It took you {attempt} attempt(s).\")\n"], [], [], [">>> s = '1 2 3 4 5 6 7 8 9'\n>>> np.array([s.split(), dtype=int).reshape(3,3)\narray([[1, 2, 3],\n       [4, 5, 6],\n       [7, 8, 9]])\n", ">>> import math\n>>> s = '1 2 3 4 5 6 7 8 9'\n>>> arr = np.array(s.split(), dtype=int)\n>>> size = int(math.sqrt(len(arr)))\n>>> arr.reshape(size, size)\narray([[1, 2, 3],\n       [4, 5, 6],\n       [7, 8, 9]])\n"], ["import math\nstring = \"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16\"\nstringItems = string.split(\" \")\nnumberOfItems = len(stringItems)\nif math.sqrt(numberOfItems) - int(math.sqrt(numberOfItems)) == 0:\n    width = int(math.sqrt(numberOfItems))\n    array = []\n    finalArray = []\n    for i in range (0, width):\n        for j in range (0, width):\n            array.insert(j, stringItems[0])\n            stringItems.pop(0)\n        finalArray.insert(i, array)\n        array = []\n    print finalArray\nelse:\n    print \"I require a string with length equal to a square number please\"\n"], ["import numpy as np\ndef string_to_matrix(str_in):\n   str_in_split = str_in.split()\n   numbers = list(map(int, str_in_split))\n   size = r_shape = int(np.sqrt(len(numbers)))\n   return np.array(numbers).reshape(r_shape, r_shape)\n"], ["def string_to_matrix(str_in):\n    nums = str_in.split()\n    n = int(len(nums) ** 0.5)\n    return list(map(list, zip(*[map(int, nums)] * n)))\n"], ["str_in = '1 2 3 4 5 6 7 8 9'\na = str_in.split(\" \")\nr_shape = int(math.sqrt(len(a)))\nnp.array([int(x) for x in a]).reshape(r_shape, r_shape)\n"], ["import numpy as np\n\ninput_strings = '1 2 3 4 5 6 7 8 9'\narr = np.array(input_strings.split(), dtype=int)\nn = int(len(arr) ** 0.5)\narr.reshape(n, n)\narray([[1, 2, 3],\n       [4, 5, 6],\n       [7, 8, 9]])\n"], ["import collections\nimport itertools\nimport string\n\n\ndef main():\n    words = [\"tree\", \"bone\", \"indigo\", \"developer\"]\n    no_repeated_letters = (set(word) for word in words)\n    letter_stream = itertools.chain.from_iterable(no_repeated_letters)\n    counter = collections.Counter(letter_stream)\n    # set zeros for unseen letters, to match poster's answer.\n    for letter in string.ascii_lowercase:\n        if letter not in counter:\n            counter[letter] = 0\n    # print result.\n    for key in sorted(counter):\n        print(key, counter[key])\n\n\nif __name__ == '__main__':\n    main()\n"], ["def flatten(d):\n    out = {}\n    for key, val in d.items():\n        if isinstance(val, dict):\n            val = [val]\n        if isinstance(val, list):\n            for subdict in val:\n                deeper = flatten(subdict).items()\n                out.update({key + '_' + key2: val2 for key2, val2 in deeper})\n        else:\n            out[key] = val\n    return out\n", "v = flatten(d).values()\nlen(set(v))!=len(v)\n"], ["dictionary = {'hello': 3 , 'world':{'this': 5 , 'is':{'a': 3, 'dict': None}}}\n\ndef get_dups(a, values=None):\n    if values is None: values = []\n    if (a in values): return True\n    values.append(a)\n    if type(a) == dict:\n        for i in a.values():\n            if (get_dups(i, values=values)):\n                return True\n    return False\n\nprint(get_dups(dictionary))\n", "if (a in values): return True\n"], ["import pandas as pd\n\ndef flatten_dict(d):\n    df = pd.io.json.json_normalize(d, sep='_')\n    return df.to_dict(orient='records')[0]\n\ndictionary = {'hello': 3 , 'world':{'this': 5 , 'is':{'a': 3, 'dict': None}}}\n\ndictionary = flatten_dict(dictionary)\nprint('flattend')\nprint(dictionary)\n\nrev_dictionary = {}\n\nfor key, value in dictionary.items():\n    rev_dictionary.setdefault(value, set()).add(key)\n\nprint('reversed')\nprint(rev_dictionary)\n\nis_duplicate = False\nfor key, values in rev_dictionary.items():\n    if len(values) > 1:\n        is_duplicate = True\n        break\n\nprint('is duplicate?', is_duplicate)\n", "flattend\n{'hello': 3, 'world_is_a': 3, 'world_is_dict': None, 'world_this': 5}\nreversed\n{3: {'hello', 'world_is_a'}, None: {'world_is_dict'}, 5: {'world_this'}}\nis duplicate? True\n"], ["def has_dupes(d):\n    def values(d):\n        seen = set()\n        for k, v in d.items():\n            if isinstance(v, dict):\n                s = values(v)\n                if seen & s:\n                    raise RuntimeError()\n                seen.update(s)\n            else:\n                if v in seen:\n                    raise RuntimeError()\n                seen.add(v)\n        return seen\n    try:\n        values(d)\n    except RuntimeError:\n        return True\n    return False\n"], ["from functools import reduce\n\n\ndef seriesrun(x, n):\n\n    return reduce(lambda c, i: c + x**i*(-1)**i , range(n + 1), 0)\n"], ["def seriesrun(x, n):\n    power = 0\n    s = 0\n\n    while power < n:\n        s += (-x)**power\n\n        power +=1\n    return s\n"], ["def seriesrun(x, n):\n    result = 0\n    term = 1\n\n    for _ in range(n):\n        result += term\n        term *= -x  # -x == 1 * -x, x^2 == (-x) * (-x), -x^3 == x^2 * (-x), etc\n    return result\n"], ["result = 1\nfor i in n:\n    result += (-x)**i\n"], ["result = sum((-1)**i * x**i for i in range(5))\n", ">>> [(-1)**i for i in range(5)]\n[1, -1, 1, -1, 1]\n"], ["series = 0\npow = 0\nwhile True:\n    series += (-1*x)**pow\n    pow += 1\n"], ["\"\"\"\nHere you can add the copyright contents\nThis is the overall description of this script \nAnd the available classes/functions in this script\nYou can also add usage\n\"\"\"\n\nimport argparse\nfrom datetime import datetime\nimport re\nimport sys\nfrom xml.etree import ElementTree\n\n\ndef some functions():\n    \"\"\"\n    This is function related description what is this function and how it works\n    You can also add expected input and output information\n    \"\"\"\n    x = x+1 #adding 1 in the input\n    # comment for the below complicated logic\n    # Explain the below logic\n    x = x*x*1*2*x \n"], [], [], ["\"\"\"\nAuthor: YOU\n\"\"\"\n\nimport argparse\nfrom datetime import datetime\nimport re\nimport sys\nfrom xml.etree import ElementTree\n\n\ndef some functions():\n    \"\"\"\n    This is a description .....\n    \"\"\"\n    x = x+1 #adding 1 in the input (this is a comment)\n"], [], ["def string_skip(st):\n    return ''.join([j for i, j in enumerate(x) if not i % 2])\n", "0, string[0]\n1, string[1]\n2, string[2]\n...\n", ">>> for i, j in enumerate('Pizza'):\n...     print i, j\n... \n0 P\n1 i\n2 z\n3 z\n4 a\n>>> \n"], [], [">>> s = \"Pizza\"\n>>> s[::2]\n'Pza'\n", ">>> s[2]\n'z'\n>>> s[2:4]\n'zz'\n>>> s[1::2]\n'iz'\n", ">>> for i, letter in enumerate(s):\n>>>     if i % 2 == 0:\n>>>         print(letter)\n"], ["def string_skip(string):\n    new_string = \"\"\n    iterator = iter(string)\n    for letter in iterator:\n        new_string += letter\n        next(iterator)\n    return new_string\n"], ["def string_skip_2(string):\n   string = list(string)\n   new_string = ''\n   for i in range(len(string)):\n       if int(list(enumerate(string))[i][0]) % 2 == 0:\n           new_string += list(enumerate(string))[i][1]\n   return new_string\n"], ["def string_skip(string):\n    new_string = \"\"\n    for i, n in enumerate(string):\n        if i % 2 == 0:\n            new_string += n\n\n    return new_string\n"], ["s=\"Pizza\"\ns[::2]\nOut[3]: 'Pza'\n"], ["def nth_common(n,p):\n    words=re.split('\\W+',p.lower())\n    word_count={}\n    counter=0\n    for i in words:\n        if i in word_count:\n            word_count[i]+=1\n        else:\n            word_count[i]=1\n\n    sorted_count = sorted(word_count.items(), key=lambda x: x[1],reverse=True)         \n\n    return sorted_count[n-1]\nnth_common(3,paragraph)\n"], ["list(Counter(str_in.lower().split()).most_common(n)[-1]) # n is nth most common word\n"], ["def nth_common(lowered_words, check):\n    m = []\n    for i in lowered_words:\n        m.append((i, lowered_words.count(i)))\n    for i in set(m):\n        # print(i)\n        if i[1] == check: # check if the first index value (occurrance) of tuple == check\n            print(i, \"found\")\n    del m[:] # deleting list for using it again\n\n\nwords = ['apple', 'apple', 'apple', 'blue', 'BLue', 'call', 'cAlL']\nlowered_words = [x.lower() for x in words]   # ignoring the uppercase\ncheck = 2   # the check\n\nnth_common(lowered_words, check)\n", "('blue', 2) found\n('call', 2) found\n"], ["import collections\n\ndef nth_most(str_in, n):\n    c = sorted(collections.Counter(w.lower() for w in str_in.split()).items(),key = lambda x:x[1])\n    return(list(c[-n])) # convert to list as it seems to be the expected output\n\nprint(nth_most(\"apple apple apple blue BlUe call\",2)) \n", "def nth_most(str_in, n):\n    c = collections.Counter(w.lower() for w in str_in.split())\n    nth_occs = sorted(c.values())[-n]\n    return [[k,v] for k,v in c.items() if v==nth_occs]\n\nprint(nth_most(\"apple apple apple call blue BlUe call woot\",2))\n", "[['call', 2], ['blue', 2]]\n"], ["Traceback (most recent call last):\n  File \"/grade/run/test.py\", line 10, in test_one\n    self.assertEqual(nth_most('apple apple apple blue blue call', 3), ['call', 1])\n  File \"/grade/run/bin/nth_most.py\", line 10, in nth_most\n    c = array[len(array) - n]\nIndexError: list index out of range\n", "maxN = 1000 #change according to your max length\narray = [ 0 for _ in range( maxN ) ]\n"], ["def matchs_path(_pattern, _input):\n  _a, _b = filter(None, _pattern.split('/')), filter(None, _input.split('/'))\n  while True:\n    _val, _val2 = next(_a, None), next(_b, None)\n    if _val is None and _val2 is None:\n      return True\n    if _val != '*' and _val != _val2:\n      return False\n    if _val == \"*\":\n      _to_see = next(_a, None)\n      if _to_see is None:\n        return True\n      while True:\n        c = next(_b, None)\n        if c is None:\n          return True\n        if c == _to_see:\n          break\n", "patterns = ['/api/users/*', '/api/account/*', '/new/*/test/here']\ndata = ['/api/users/add/', '/api/users/edit/1', '/api/users/', '/api/account/view/1', '/api/account/', '/going/to/fail/here', '/new/additional/abc/test/here']\nnew_results = {i:{c:matchs_path(i, c) for c in data} for i in patterns}\n", "{\n \"/api/users/*\": {\n    \"/api/users/add/\": true,\n    \"/api/users/edit/1\": true,\n    \"/api/users/\": true,\n    \"/api/account/view/1\": false,\n    \"/api/account/\": false,\n    \"/going/to/fail/here\": false,\n    \"/new/additional/abc/test/here\": false\n },\n  \"/api/account/*\": {\n    \"/api/users/add/\": false,\n    \"/api/users/edit/1\": false,\n    \"/api/users/\": false,\n    \"/api/account/view/1\": true,\n    \"/api/account/\": true,\n    \"/going/to/fail/here\": false,\n    \"/new/additional/abc/test/here\": false\n },\n \"/new/*/test/here\": {\n    \"/api/users/add/\": false,\n    \"/api/users/edit/1\": false,\n    \"/api/users/\": false,\n    \"/api/account/view/1\": false,\n    \"/api/account/\": false,\n    \"/going/to/fail/here\": false,\n    \"/new/additional/abc/test/here\": true\n  }\n}\n"], ["print('sum of input is :',sum(list(map(float,input('Input some comma separated numbers: ').split(',')))))\n"], ["values = input(\"Input some comma seprated numbers: \")\nlst = values.split(\",\")\nlst = [int(curr) for curr in lst]\nsum(lst)\nprint (\"The total sum is: \", sum)\n"], ["# empty list to store the user inputs\nlst = []      \n\n# a loop that will keep taking input until the user wants\nwhile True:\n    # ask for the input\n    value = input(\"Input a number: \")\n    # append the value to the list\n    lst.append(value)\n    # if the user wants to exit\n    IsExit = input(\"enter exit to exit\")\n    if 'exit' in IsExit:\n        break\n\n# take the sum of each element (casted to float) in the lst \nprint(\"The sum of the list: {} \".format(sum([float(x) for x in lst])))\n", "Input a number: 5.5\nenter exit to exitno\nInput a number: 6\nenter exit to exitno\nInput a number: 5.5\nenter exit to exitexit\nThe sum of the list: 17.0 \n"], ["values = input(\"Input some comma seprated numbers: \")\nlst = values.split(\",\")\nlst = [float(x) for x in lst]\ntotal = sum(lst)\nprint(\"The total sum is: \", total)\n"], ["input_str = input(\"Input some comma seprated numbers: \")\n\n# Option1: without error checking\nnumber_list = [float(s) for s in input_str.split(',')]\n\n# Option2: with error checking, if you are not sure if the user will input only valid numbers\nnumber_list = []\nfor s in input_str.split(','):\n    try:\n        n = float(s)\n        number_list.append(n)\n    except ValueError:\n        pass\n\nprint(\"The list of valid numbers is:\", number_list)\nprint(\"The sum of the list is:\", sum(number_list))\n"], ["values = \"5.5,6,5.5\" # input(\"Input some comma seprated numbers: \")\nL = list(map(float, values.split(\",\")))\nprint (\"The total sum is: \", sum(L))\n", "The total sum is:  17.0\n"], ["numbers = input(\"Input some comma seprated numbers: \")\n\nresult = sum([float(n) for n in numbers.split(',')])\n\nprint(result)\n"], ["from fnmatch import fnmatch\n\ndef listglob(path, patterns):\n    return any(fnmatch(path, pat) for pat in patterns)\n\nfor path in paths:\n    print(path, listglob(path, l))\n"], ["l = [\n   '/api/users/*',\n   '/api/account/*'\n]\n\npaths = [\n   '/api/users/add/'\n   '/api/users/edit/1',\n   '/api/users/',\n   '/api/account/view/1',\n   '/api/account/',\n   '/non/existent/path'\n]\n", ">>> import fnmatch\n>>> [any(fnmatch.fnmatch(path, pat) for pat in l) for path in paths]\n[True, True, True, True, False]\n"], ["l = [\n   '/api/users/*',\n   '/api/account/'\n]\n\npaths = [\n'/api/users/add/'\n'/api/users/edit/1',\n'/api/users/',\n'/api/account/view/1',\n'/api/account/'\n]\n\nfor path in paths:\n    if path in l:\n        print(\"Path: {}, found in the list\".format(path))\n", "Path: /api/account/, found in the list\n", "l = [\n   '/api/users/*',\n   '/api/account/'\n]\n\npaths = [\n'/api/users/add/',\n'/api/users/edit/1',\n'/api/users/',\n'/api/account/view/1',\n'/api/account/'\n]\n\ndef checkPath(path):\n        if path in l:\n            return True\n        else:\n            return False\n\nfor i in range(0,len(paths)):\n    print(checkPath(paths[i]))\n", "False\nFalse\nFalse\nFalse\nTrue\n", "def checkPath(path):\n        if path in l_new:\n            return True\n        else:\n            return False\n\n# strip the asterick\nl_new = [s.strip('*') for s in l]\n\nfor i in range(0,len(paths)):\n    print(checkPath(paths[i]))\n", "False\nFalse\nTrue\nFalse\nTrue\n"], ["take = boolarr.sum(axis=1)\n#array([2, 1, 3])\n", "x = arr[boolarr]\n#array([1, 2, 1, 1, 2, 3])\n", "np.split(x, np.cumsum(take)[:-1])\n[array([1, 2]), array([1]), array([1, 2, 3])]\n", "def mask_nd(x, m):\n    '''\n    Mask a 2D array and preserve the\n    dimension on the resulting array\n    ----------\n    x: np.array\n       2D array on which to apply a mask\n    m: np.array\n        2D boolean mask  \n    Returns\n    -------\n    List of arrays. Each array contains the\n    elements from the rows in x once masked.\n    If no elements in a row are selected the \n    corresponding array will be empty\n    '''\n    take = m.sum(axis=1)\n    return np.split(x[m], np.cumsum(take)[:-1])\n", "arr = np.array([[1,2,4],\n                [2,1,1],\n                [1,2,3]])\n\nboolarr = np.array([[True, True, False],\n                    [False, False, False],\n                    [True, True,True]])\n\nmask_nd(arr, boolarr)\n# [array([1, 2]), array([], dtype=int32), array([1, 2, 3])]\n", "arr = np.array([[1,2],\n                [2,1]])\n\nboolarr = np.array([[True, True],\n                    [True, False]])\n\nmask_nd(arr, boolarr)\n# [array([1, 2]), array([2])]\n"], ["paths = ['/api/users/add/',\n         '/api/users/edit/1',\n         '/api/users/',\n         '/api/account/view/1',\n         '/api/account/',\n         '/not/a/valid/path']\nl = ['/api/users/*', '/api/account/*']\npatterns = [re.compile(re.sub(\"\\*$\", \".*\", s)) for s in l]\n\n>>> [path for path in paths if any(p.match(path) for p in patterns)]\n['/api/users/add/',\n '/api/users/edit/1',\n '/api/users/',\n '/api/account/view/1',\n '/api/account/']\n"], ["list1 = [1,2,3]\n\ndef func(list1):\n    list1[0] = 5\n\n>>>list1\n[5,2,3]\n", ">>> tup1 = (1,2,3) # doing tup1[0] = 5 will cause TypeError\n>>> tup2 = tup1 + (5,)\n>>> tup2\n(1, 2, 3, 5)\n", ">>> def func2(tup1):\n        return tup1 + (5,)\n\n>>> func2(tup1=(1,2,3))\n(1, 2, 3, 5)\n"], [], [], [], ["def mystery(list1):\n    return list1 + list1[2:5]\n\nlist1 = [7,82,44,23,11]\nlist1 = mystery(list1)\nprint(list1)\n"], ["p = wikipedia.page('Category:Enzyme inhibitors')\nparents = p.categories\n"], ["import re\n\noriginal_sentence = 'we have good news and bad news about your emissaries to our world,\" the extraterrestrial ambassador informed the Prime Minister. the good news is they tasted like chicken.'\n\ndef replacer(match_obj):                   \n    return match_obj.group(0).upper()\n\n# Replace the very first characer or any other following a dot and a space by its upper case version.\nre.sub(r\"(?<=\\. )(\\w)|^\\w\", replacer, original_sentence)\n\n>>> 'We have good news and bad news about your emissaries to our world,\" the extraterrestrial ambassador informed the Prime Minister. The good news is they tasted like chicken.'\n"], ["import re\n\noriginal_sentence = 'we have good news and bad news about your emissaries to our world,\" the extraterrestrial ambassador informed the Prime Minister. the good news is they tasted like chicken.'\n\nval = re.split('([.!?] *)', original_sentence)\n\nnew_sentence = ''.join([(lambda x: x[0].upper() + x[1:])(each) if len(each) > 1 else each for each in val])\n\nprint(new_sentence)\n", "sentence = []\n\nfor each in val:\n    sentence.append((lambda x: x[0].upper() + x[1:])(each) if len(each) > 1 else each)\n\nprint(''.join(sentence))\n"], ["text = input(\"Enter the text: \\n\")\nlines = text.split('. ')  # Split the sentences\n\nfor index, line in enumerate(lines):\n    lines[index] = line[0].upper() + line[1:]\nprint(\". \".join(lines))\n"], ["text = input(\"Enter the text: \\n\")\noutput = \"\"\nif (text[-1] == '.'):\n    # remove the last period to avoid double periods in the last sentence\n    text = text[:-1] \nlines = text.split('. ') #Split the sentences\n\nfor line in lines:\n    a = line[0].capitalize() # capitalize the first word of sentence\n    for i in range(1, len(line)):\n        a = a + line[i]\n    a = a + '.' # add the removed period\n    output = output + a\nprint (output)\n", "text = input(\"Enter the text: \\n\")\noutput = \"\"\n\nif (text[-1] == '.'):\n    # remove the last period to avoid double periods in the last sentence\n    text = text[:-1] \nlines = text.split('. ') #Split the sentences\n\nfor line in lines:\n    a = line[0].capitalize() + line [1:] + '.'\n    output = output + a\nprint (output)\n"], ["text = input(\"Enter the text: \\n\")\nlines = text.split('. ') #Split the sentences\n\nfinal_text = \". \".join([line[0].upper()+line[1:] for line in lines])\nprint(final_text)\n"], ["string.replace('@@@', '{}', len(kv)).format(*kv.values())\n", "string = 'asfd @@@ fdsfd @@@ ffds @@@ asdf'\nkv = {'1': 'hi', '2': 'there', '3': 'bla'}\n", "string.replace('@@@', '{}', len(kv)).format(*kv.values())\n#Out: 'asfd hi fdsfd there ffds bla asdf'\n", "string.replace('@@@', '{}', len(kv)).format(*kv.values())\n"], ["import re\nstring = 'asfd @@@ fdsfd @@@ ffds @@@ asdf'\nkv = {'1': 'hi', '2': 'there', '3': 'bla'}\nclass repl:\n    def __init__(self):\n        self.called=0\n    def __call__(self,match):\n        self.called+=1\n        return kv[str(self.called)]\nprint(re.sub('@@@',repl(),string))\n", "asfd hi fdsfd there ffds bla asdf\n"], ["kv = {'1': 'hi', '2': 'there', '3': 'bla'}\nstring = 'asfd @@@ fdsfd @@@ ffds @@@ asdf'\nstring_list=string.split('@@@')\nstring_list_out=[]\nfor i in range(len(string_list)):\n    if i==0:\n        string_list_out.append(string_list[0])\n    else:\n        string_list_out.append(kv[str(i)])\n        string_list_out.append(string_list[i])\n\nstring_list_out=''.join(string_list_out)\nprint(string_list_out)\n   'asfd hi fdsfd there ffds bla asdf'\n"], ["string = 'asfd @@@ fdsfd @@@ ffds @@@ asdf'\nkv = {1: 'hi', 2: 'there', 3: 'bla'}\n\nfor k,v in kv.items():\n    string = string.replace('@@@', v, 1)\nprint(string)\n", "asfd hi fdsfd there ffds bla asdf\n"], ["s = 'asfd @@@ fdsfd @@@ ffds @@@ asdf'\nkv = {'1': 'hi', '2': 'there', '3': 'bla'}\n\nfor k, v in sorted(kv.items()):\n    s = s.replace(\"@@@\", v, 1)\nprint(s)\n"], ["import itertools\n\ndef factors(x, numbers):\n    \"\"\" Generate all pairs in list of numbers that multiply to x.\n    \"\"\"\n    for a, b in itertools.combinations(numbers, 2):\n        if a * b == x:\n            yield (a, b)\n\nnumbers = [2, 4, 5, 1, 6, 40, -1]\nfor pair in factors(20, numbers):\n    print(pair)\n"], ["for ii, i in enumerate(given_numbers):\n    for j in given_numbers[ii + 1:]:\n        # ...\n", "for ii, i in enumerate(given_numbers):\n    for jj in range(ii + 1, len(given_numbers)):\n        j = given_numbers[jj]\n        # ...\n", "from itertools import combinations\n\ndef get_mult_num(given_list):\n    return [(i, j) for i, j in combinations(given_list, 2) if i * j == 20]\n", "def get_mult_num(given_list):\n    multiplies_to_20 = (\n        (i, j) for i, j in combinations(given_list, 2)\n        if i * j == 20)\n    return next(multiplies_to_20, None)\n", "def gen_factors_for(target, numbers):\n    possible_j = set(numbers)\n    limit = abs(target) ** 0.5\n    for i in numbers:\n        if abs(i) < limit and target % i == 0:\n            j = target // i\n            if j in possible_j and abs(j) > abs(i):\n                yield i, j\n", ">>> import random, operator\n>>> from timeit import Timer\n>>> def gen_factors_for_division(target, numbers):\n...     possible_j = set(numbers)\n...     limit = abs(target) ** 0.5\n...     for i in numbers:\n...         if abs(i) < limit and target % i == 0:\n...             j = target // i\n...             if j in possible_j and abs(j) > abs(i):\n...                 yield i, j\n...\n>>> def gen_factors_for_combinations(target, given_list):\n...     return ((i, j) for i, j in combinations(given_list, 2) if i * j == target)\n...\n>>> numbers = [random.randint(-10000, 10000) for _ in range(100)]\n>>> targets = [operator.mul(*random.sample(set(numbers), 2)) for _ in range(5)]\n>>> targets += [t + random.randint(1, 100) for t in targets]  # add likely-to-be-unsolvable numbers\n>>> for (label, t) in (('first match:', 'next({}, None)'), ('all matches:', 'list({})')):\n...     print(label)\n...     for f in (gen_factors_for_division, gen_factors_for_combinations):\n...         test = t.format('f(t, n)')\n...         timer = Timer(\n...             f\"[{test} for t in ts]\",\n...             'from __main__ import targets as ts, numbers as n, f')\n...         count, total = timer.autorange()\n...         print(f\"{f.__name__:>30}: {total / count * 1000:8.3f}ms\")\n...\nfirst match:\n      gen_factors_for_division:    0.219ms\n  gen_factors_for_combinations:    4.664ms\nall matches:\n      gen_factors_for_division:    0.259ms\n  gen_factors_for_combinations:    3.326ms\n"], ["for val in num_list:    \n    if 20 / val in num_list:\n        print(val, int(20/val))\n"], ["num_list = [2,4,5,1,6,40,-1]\n\nmult_num = [(num_list[i],num_list[j]) for i in range(len(num_list)) for j in range(i+1, len(num_list)) if num_list[i]*num_list[j] == 20]\nprint mult_num\n", "[(4, 5)]\n"], ["[(i,j) for i in num_list for j in num_list if i<j and i*j==20]\n"], ["def get_mult_num(given_list):\n    return [\n        item1, item2\n        for i, item1 in enumerate(given_list)\n        for item2 in given_list[:i]\n        if item1*item2 == 20\n    ]\n"], [], [], [], ["string = \"Hello world!\"\nsearch_item = \"world\"\nsearch_index = string.find(search_item)\nsearch_index_end = search_index+len(search_item)\n\nprint(string[search_index] : search_index_end])\n", "world\n\nsearch_index = 6\nsearch_index_end = 11\n"], ["8,16\n75,83\n30,38\nno match found\n"], [">>> str1 = 'Here in Americans, people say \"Can I get a bag for the stuff?\"'\n>>> str2 = \"Americans\"\n>>> print(str1.find(str2))\n8\n"], ["def islandlen_perrow(df, trigger_val=0):\n    a=df.values==trigger_val\n    pad = np.zeros((a.shape[0],1),dtype=bool)\n    mask = np.hstack((pad, a, pad))\n    mask_step = mask[:,1:] != mask[:,:-1]\n    idx = np.flatnonzero(mask_step)\n    island_lens = idx[1::2] - idx[::2]\n    n_islands_perrow = mask_step.sum(1)//2\n    out = np.split(island_lens,n_islands_perrow[:-1].cumsum())\n    return out\n", "In [69]: df\nOut[69]: \n   2010  2011  2012  2013  2014\n0     0    12    11     0     0\n1    45    56    22     5     0\n2     5     0     0     0     0\n\nIn [70]: islandlen_perrow(df, trigger_val=0)\nOut[70]: [array([1, 2], dtype=int64), array([1], dtype=int64), array([4], dtype=int64)]\n\nIn [76]: pd.Series(islandlen_perrow(df, trigger_val=0))\nOut[76]: \n0    [1, 2]\n1       [1]\n2       [4]\ndtype: object\n", "In [77]: df = pd.DataFrame(np.random.randint(0,4,(1000,1000)))\n\nIn [78]: from itertools import groupby\n\n# @Daniel Mesejo's soln\nIn [79]: def count_zeros(x):\n    ...:     return [sum(1 for _ in group) for key, group in groupby(x, key=lambda i: i == 0) if key]\n\nIn [80]: %timeit df.apply(count_zeros, axis=1)\n1 loop, best of 3: 228 ms per loop\n\n# @coldspeed's soln-1\nIn [84]: %%timeit\n    ...: v = df.stack()\n    ...: m = v.eq(0)\n    ...: \n    ...: (m.ne(m.shift())\n    ...:   .cumsum()\n    ...:   .where(m)\n    ...:   .dropna()\n    ...:   .groupby(level=0)\n    ...:   .apply(lambda x: x.value_counts(sort=False).tolist()))\n1 loop, best of 3: 516 ms per loop\n\n# @coldspeed's soln-2\nIn [88]: %%timeit\n    ...: v = df.stack()\n    ...: m = v.eq(0)\n    ...: (m.ne(m.shift())\n    ...:   .cumsum()\n    ...:   .where(m)\n    ...:   .dropna()\n    ...:   .groupby(level=0)\n    ...:   .value_counts(sort=False)\n    ...:   .groupby(level=0)\n    ...:   .apply(list))\n1 loop, best of 3: 343 ms per loop\n\n# @jpp's soln\nIn [90]: %timeit [[len(list(grp)) for flag, grp in groupby(row, key=bool) if not flag] \\\n    ...:                 for row in df.values]\n1 loop, best of 3: 334 ms per loop\n\n# @J. Doe's soln\nIn [94]: %%timeit\n    ...: data = df\n    ...: data_transformed = np.equal(data.astype(int).values.tolist(), 0).astype(str)\n    ...: pd.DataFrame(data_transformed).apply(lambda x: [i.count('True') for i in ''.join(list(x)).split('False') if i], axis=1)\n1 loop, best of 3: 519 ms per loop\n\n# From this post\nIn [89]: %timeit pd.Series(islandlen_perrow(df, trigger_val=0))\n100 loops, best of 3: 9.8 ms per loop\n"], ["import pandas as pd\n\nfrom itertools import groupby\n\n\ndef count_zeros(x):\n    return [sum(1 for _ in group) for key, group in groupby(x, key=lambda i: i == 0) if key]\n\n\ndf = pd.DataFrame({'2010':[0, 45, 5], '2011': [12, 56, 0], '2012': [11, 22, 0], '2013': [0, 5, 0], '2014': [0, 0, 0]})\n\nresult = df.apply(count_zeros, axis=1)\nprint(result)\n", "0    [1, 2]\n1       [1]\n2       [4]\ndtype: object\n"], ["v = df.stack()\nm = v.eq(0)\n\n(m.ne(m.shift())\n  .cumsum()\n  .where(m)\n  .dropna()\n  .groupby(level=0)\n  .apply(lambda x: x.value_counts(sort=False).tolist()))\n\n0    [1, 2]\n1       [1]\n2       [4]\ndtype: object\n", "(m.ne(m.shift())\n  .cumsum()\n  .where(m)\n  .dropna()\n  .groupby(level=0)\n  .value_counts(sort=False)\n  .groupby(level=0)\n  .apply(list))\n\n0    [1, 2]\n1       [1]\n2       [4]\ndtype: object\n"], ["from itertools import groupby\n\ndf['counts'] = [[len(list(grp)) for flag, grp in groupby(row, key=bool) if not flag] \\\n                for row in df.values]\n\nprint(df)\n\n   2010  2011  2012  2013  2014  counts\n0     0    12    11     0     0  [1, 2]\n1    45    56    22     5     0     [1]\n2     5     0     0     0     0     [4]\n"], ["data_transformed = np.equal(data.astype(int).values.tolist(), 0).astype(str)\npd.DataFrame(data_transformed).apply(lambda x: [i.count('True') for i in ''.join(list(x)).split('False') if i], axis=1)\n"], ["import argparse\nparser = argparse.ArgumentParser()\nparser.parse_args()\n", "$ python3 prog.py -v\nverbosity turned on\n$ python3 prog.py --help\nusage: prog.py [-h] [-v]\n\noptional arguments:\n  -h, --help     show this help message and exit\n  -v, --verbose  increase output verbosity\n"], ["def fallback():\n    print('That command does not exist')\n    # add any code you want to be run for\n    # a bad input here...\n\nfunctions = {\n    'a': a,\n    'b': b\n}\n", "functions.get(args.function.lower(), fallback)()\n"], ["import click\n\n@click.group()\ndef cli():\n    pass\n\n@cli.command()\ndef a():\n   print(\"I am a\")\n\n@cli.command()\ndef b():\n   print(\"Je suis b\")\n\nif __name__ == '__main__':\n    cli()\n", "bash$ ./ick.py --help\nUsage: ick.py [OPTIONS] COMMAND [ARGS]...\n\nOptions:\n  --help  Show this message and exit.\n\nCommands:\n  a\n  b\n\nbash$ ./ick.py a\nI am a\n"], ["def a():\n   pass\n\ndef b():\n   pass \neval(args.function + \"()\")  \n"], ["d = {\"a\" : a,\n     \"b\" : b}\n", "d[args.function]()\n"], ["from collections import Counter\n\nwordlist = [\"tree\",\"bone\",\"indigo\",\"developer\"]\n\nc = Counter()\nfor word in wordlist:\n    c.update(set(word.lower()))\n\nprint(c)\n", "Counter({'e': 3, 'o': 3, 'r': 2, 'n': 2, 'd': 2, 't': 1, 'b': 1, 'i': 1, 'g': 1, 'v': 1, 'p': 1, 'l': 1})\n"], ["from collections import Counter  \nimport string  \n\nwords=[\"tree\",\"bone\",\"indigo\",\"developer\"]  \ny=Counter(string.ascii_lowercase)  \nnew_dict=dict(y) \n\nfor k in new_dict:  \n    new_dict[k]=0  \ntrial = 0  \nwhile len(words) > trial:  \n    for let in set(words[trial]):    \n        if let in new_dict:  \n            new_dict[str(let)]=new_dict[str(let)]+1  \n\n    trial = trial +1  \nprint(new_dict)\n"], ["freq = {k: sum(k in word for word in words) for k in set(''.join(words))}\n", "{'i': 1, 'v': 1, 'p': 1, 'b': 1, 'e': 3, 'g': 1, 't': 1, 'n': 2, 'd': 2, 'o': 3, 'l': 1, 'r': 2}\n"], ["import string\nprint({k:max(i.count(k) for i in words) for k in string.ascii_lowercase})\n"], ["import string\ncounts = {c: len([w for w in words if c in w.lower()]) for c in string.ascii_lowercase}\n", "{'a': 4, 'b': 2, 'c': 2, 'd': 4, 'e': 7, 'f': 2, 'g': 2, 'h': 3, 'i': 7, 'j': 0, 'k': 0, 'l': 4, 'm': 5, 'n': 4, 'o': 4, 'p': 1, 'q': 0, 'r': 5, 's': 3, 't': 3, 'u': 2, 'v': 0, 'w': 3, 'x': 0, 'y': 2, 'z': 1}\n\n", "        10 words | f1   0.0004 sec | f2   0.0004 sec | f3   0.0003 sec | f4   0.0010 sec\n       100 words | f1   0.0019 sec | f2   0.0014 sec | f3   0.0013 sec | f4   0.0034 sec\n     1,000 words | f1   0.0180 sec | f2   0.0118 sec | f3   0.0140 sec | f4   0.0298 sec\n    10,000 words | f1   0.1960 sec | f2   0.1278 sec | f3   0.1542 sec | f4   0.2648 sec\n   100,000 words | f1   2.0859 sec | f2   1.3971 sec | f3   1.6815 sec | f4   3.5196 sec\n", "import string\nimport timeit\nimport random\nfrom collections import Counter\n\ndef f1(words):\n    c = Counter()\n    for word in words:\n        c.update(set(word.lower()))\n    return c\n\ndef f2(words):\n    return Counter(\n        c\n        for word in words\n        for c in set(word.lower()))\n\ndef f3(words):\n    d = {}\n    for word in words:\n        for i in set(word.lower()):\n            d[i] = d.get(i, 0) + 1\n    return d\n\n\ndef f4(words):\n    d = {c: len([w for w in words if c in w.lower()]) for c in string.ascii_lowercase} \n    return d\n\n\nwith open('words.txt') as word_file:\n    valid_words = set(word_file.read().split())\n\nfor exp in range(5):\n\n    result_list = []\n    for i in range(1, 5):\n        t = timeit.timeit(\n            'f(words)',\n            'from __main__ import f{} as f, valid_words, exp; import random; words = random.sample(valid_words, 10**exp)'.format(i),\n            number=100)\n        result_list.append((i, t))\n\n    print('{:10,d} words | {}'.format(\n        len(words),\n        ' | '.join(\n            'f{} {:8.4f} sec'.format(i, t) for i, t in result_list)))\n\nprint(f4(random.sample(valid_words, 10000)))\nprint(f4(random.sample(valid_words, 1000)))\nprint(f4(random.sample(valid_words, 100)))\nprint(f4(random.sample(valid_words, 10)))\n\n"], ["pd.read_parquet('./path', engine='pyarrow')\n"], ["from collections import Counter\n\nwords = [\"tree\", \"bone\", \"indigo\", \"developer\"]\ncounts = Counter(c for word in words for c in set(word.lower()) if c.isalpha())\n", "Counter({'e': 3, 'o': 3, 'r': 2, 'd': 2, 'n': 2, 'p': 1, 'i': 1, 'b': 1, 'v': 1, 'g': 1, 'l': 1, 't': 1})\n"], ["def f1(words):\n    c = Counter()\n    for word in words:\n        c.update(set(word.lower()))\n    return c\n\ndef f2(words):\n    return Counter(\n        c\n        for word in words\n        for c in set(word.lower()))\n\ndef f3(words):\n    d = {}\n    for word in words:\n        for i in set(word.lower()):\n            d[i] = d.get(i, 0) + 1\n    return d\n", "word_list = [\n    'tree', 'bone', 'indigo', 'developer', 'python',\n    'language', 'timeit', 'xerox', 'printer', 'offset',\n]\n\nfor exp in range(5):\n    words = word_list * 10**exp\n\n    result_list = []\n    for i in range(1, 4):\n        t = timeit.timeit(\n            'f(words)',\n            'from __main__ import words,  f{} as f'.format(i),\n            number=100)\n        result_list.append((i, t))\n\n    print('{:10,d} words | {}'.format(\n        len(words),\n        ' | '.join(\n            'f{} {:8.4f} sec'.format(i, t) for i, t in result_list)))\n", "        10 words | f1   0.0028 sec | f2   0.0012 sec | f3   0.0011 sec\n       100 words | f1   0.0245 sec | f2   0.0082 sec | f3   0.0113 sec\n     1,000 words | f1   0.2450 sec | f2   0.0812 sec | f3   0.1134 sec\n    10,000 words | f1   2.4601 sec | f2   0.8113 sec | f3   1.1335 sec\n   100,000 words | f1  24.4195 sec | f2   8.1828 sec | f3  11.2167 sec\n"], ["words=[\"tree\",\"bone\",\"indigo\",\"developer\"]\nd={}\nfor word in words:         # iterate over words\n    for i in set(word):    # to remove the duplication of characters within word\n        d[i]=d.get(i,0)+1\n", "{'b': 1,\n 'd': 2,\n 'e': 3,\n 'g': 1,\n 'i': 1,\n 'l': 1,\n 'n': 2,\n 'o': 3,\n 'p': 1,\n 'r': 2,\n 't': 1,\n 'v': 1}\n"], ["RUN pip install numpy\n"], ["pip uninstall --yes numpy\n\neasy_install --upgrade numpy\n"], ["In [183]: np.array([x[y] for x,y in zip(arr, boolarr)])\nOut[183]: array([array([1, 2]), array([1]), array([1, 2, 3])], dtype=object)\n"], ["marr = np.ma.array(arr, mask=~boolarr)\n", "masked_array(data=[\n        [ 1  2 --]\n        [-- --  1]\n        [ 1  2  3]],\n    mask=[\n        [False False  True]\n        [ True  True False]\n        [False False False]],\n    fill_value = 999999)\n"], ["from itertools import compress\n\nres = list(map(list, map(compress, arr, boolarr)))\n\n# [[1, 2], [1], [1, 2, 3]]\n"], ["[[arr[row][col] for col in range(3) if boolarr[row][col]] for row in range(3)]\n# [[1,2], [1], [1,2,3]]\n"], [], ["y_pred_prob = gaussian.predict_proba(X_test)\n", "metrics.roc_auc_score(y_test, y_pred_prob[:,1])\n"], ["from sklearn.metrics import precision_score\n>>> y_true = [0, 1, 2, 0, 1, 2]\n>>> y_pred = [0, 2, 1, 0, 0, 1]\n>>> precision_score(y_true, y_pred)  \n0.22\n\nfrom sklearn.metrics import recall_score\n>>> y_true = [0, 1, 2, 0, 1, 2]\n>>> y_pred = [0, 2, 1, 0, 0, 1]\n>>> recall_score(y_true, y_pred, average='macro')  \n0.33\n\nfrom sklearn.metrics import f1_score\n>>> y_true = [0, 1, 2, 0, 1, 2]\n>>> y_pred = [0, 2, 1, 0, 0, 1]\n>>> f1_score(y_true, y_pred, average='macro')  \n0.26\n", "import numpy as np\n>>> from sklearn.metrics import precision_recall_curve\n>>> y_true = np.array([0, 0, 1, 1])\n>>> y_scores = np.array([0.1, 0.4, 0.35, 0.8])\n>>> precision, recall, thresholds = precision_recall_curve(\n...     y_true, y_scores)\n>>> precision  \narray([0.66666667, 0.5       , 1.        , 1.        ])\n>>> recall\narray([1. , 0.5, 0.5, 0. ])\n>>> thresholds\narray([0.35, 0.4 , 0.8 ])\n"], ["from sklearn import metrics\nprint(\"Accuracy: {0:.4f}\".format(metrics.accuracy_score(y_test, y_pred_prob )))\n"], ["y_pred_prob = np.array(gaussian.predict_proba(X_test))\nmetrics.roc_auc_score(y_test, y_pred_prob[:,1])\n"], ["    else:\n        del lineSize_list[-1], ang_list[-1]       #delete wrong values from Size and Angle lists\n        z = 0\n        thresh2 = np.copy(thresh)\n        for x in thresh2[::-1]:                   #check threshold backwards for positive values\n            for e in x:\n                if e > 0:\n                    break\n            z += 1\n            if e > 0:\n                 - first positive value found in threshold (edge of object)\n                 - add object length to this position\n                 - make a cut in threshold (this will be the break for new contours)\n                 - use threshold to find contours ....\n"], ["import cv2\nimport numpy as np\n\nimg = cv2.imread('cont.png')\ngray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n_, threshold = cv2.threshold(gray, 200, 255, cv2.THRESH_BINARY)\n_, contours, hierarchy = cv2.findContours(threshold,cv2.RETR_TREE,cv2.CHAIN_APPROX_NONE)\nk = 2\n\nif len(contours)==1:\n    for i in range (0,1000):\n        kernel = np.ones((1,k),np.uint8)\n        erosion = cv2.erode(threshold,kernel,iterations = 1)\n        _, contours, hierarchy = cv2.findContours(erosion,cv2.RETR_TREE,cv2.CHAIN_APPROX_NONE)\n        if len(contours) == 1:\n            k+=1\n        if len(contours) == 2:\n            break\n        if len(contours) > 2:\n            print('more than one contour')\n\nx,y,w,h = cv2.boundingRect(contours[0])\ncv2.rectangle(threshold,(x-k,y-k),(x+w+k,y+h+k), 0, 1)\n_, contours, hierarchy = cv2.findContours(threshold,cv2.RETR_TREE,cv2.CHAIN_APPROX_NONE)\ncv2.drawContours(img, contours, -1, (0,0,255), 2)\n\n#Object1\nv = np.matrix([[0], [1]])\nrect = cv2.minAreaRect(contours[0])\n\n#determine angle\nif rect[1][0] > rect[1][1]:\n    ang = (rect[2] + 90)* np.pi / 180\nelse:\n    ang = rect[2]* np.pi / 180\nrot = np.matrix([[np.cos(ang), -np.sin(ang)],[np.sin(ang), np.cos(ang)]])\nrv = rot*v\n\n#draw angle line\nlineSize = max(rect[1])*0.45                #length of line\np1 = tuple(np.array(rect[0] - lineSize*rv.T)[0].astype(int))\np2 = tuple(np.array(rect[0] + lineSize*rv.T)[0].astype(int))\ncv2.line(img, p1, p2, (255,0,0), 2)\n\n#Object2\nif len(contours) > 1:\n    rect = cv2.minAreaRect(contours[1])\n\n    #determine angle\n    if rect[1][0] > rect[1][1]:\n        ang = (rect[2] + 90)* np.pi / 180\n    else:\n        ang = rect[2]* np.pi / 180\n    rot = np.matrix([[np.cos(ang), -np.sin(ang)],[np.sin(ang), np.cos(ang)]])\n    rv = rot*v\n\n    #draw angle line\n    lineSize = max(rect[1])*0.45                #length of line\n    p1 = tuple(np.array(rect[0] - lineSize*rv.T)[0].astype(int))\n    p2 = tuple(np.array(rect[0] + lineSize*rv.T)[0].astype(int))\n    cv2.line(img, p1, p2, (255,0,0), 2)\n\n\n#save output img\n\ncv2.imshow('img', img)\ncv2.waitKey(0)\ncv2.destroyAllWindows()\n"], ["from cv2 import erode\nimport numpy as np    \nkernel = np.ones((5,25),dtype=np.uint8) # this must be tuned \n\nim1=erode(im0,kernel)\n"]]