[[], [], ["model = Sequential()\nmodel.add(LSTM(32, return_sequences=True, activation = 'sigmoid', input_shape=(x_train.shape[1], x_train.shape[2])))\n# model.add(Dropout(0.2))\n# model.add(BatchNormalization())\nmodel.add(LSTM(units = 64, return_sequences=False,))\nmodel.add(Dense(y_train.shape[1]))\nmodel.compile(optimizer = 'adam', loss = 'mse')\n", "model.fit(x_train, y_train, batch_size = 64, epochs = 1000, shuffle = True, validation_data = (x_test, y_test))\n"], ["def print_name():\n    fname = input('Enter FIRST name here: ')\n    if len(fname) == 0:\n        raise Exception('No FIRST name entered...')\n\n    lname= input('Enter LAST name here: ')\n    if len(lname) == 0:\n        raise Exception('No LAST name entered...')\n\n    print(f\"your name is {fname} {lname}\")\n"], ["def print_name():\n\n    # store user input in separate variable\n    first_name = input('Enter FIRST name here: ')\n\n    fname = first_name\n\n\n\n    while True:\n        fname = first_name\n\n\n        # throw error if user enters no first name\n        if len(fname) == 0:\n            # error msg\n            print('No FIRST name entered...')\n            first_name = input('Enter FIRST name here: ') \n            # loop back to prompt asking for first name\n            continue\n        else:\n            # if first name given move on to prompting for last name\n            # break loop\n            break\n\n    # loop into prompting user for last name\n    while True:\n        last_name = input('Enter LAST name here: ')\n        lname= last_name\n\n        # throw error if user enters no last name\n        if len(lname) == 0:\n            print('No LAST name entered...')\n            # loop back to prompt asking for last name\n            continue\n        else:\n            # if last name given move on to running print command\n            # break loop\n            break\n\n        return fname, lname\n\n    print(f'your name is {fname} {lname}')\n\nprint_name()\n"], ["while <condition>\n...\n<check_condition>\n...\n", "while (len(fname) == 0)\n<show_error_message>\n<get fname again>\n", "while true\n<get_event>\n"], ["def wait_for_input(prompt):\n    data = \"\"\n    while data == \"\":\n        data = input(prompt).strip()\n    return data\n\n\ndef print_name(fname, lname):\n    print(f'your name is {fname} {lname}')\n\n\nfirst_name = wait_for_input('Enter FIRST name: ')\nlast_name = wait_for_input('Enter LAST name: ')\n\nprint_name(first_name, last_name)\n"], ["def print_name():\n    first_name = \"\"\n    last_name = \"\"\n    # User input for first name\n    while first_name == \"\":\n        first_name = input('Enter FIRST name here: ')\n    # User input for last name\n    while last_name == \"\":\n        last_name = input('Enter LAST name here: ')\n    print(f'your name is {first_name} {last_name}')\n"], ["3\n<__main__.Square_Integers_Below object at 0x000001BCD56B6080>\n", "Traceback (most recent call last):\n  File \"C:/Users/Maria/Downloads/so_1.2.py\", line 24, in <module>\n    Square_Integers_Below(7)\n  File \"C:/Users/Maria/Downloads/so_1.2.py\", line 21, in __init__\n    self.length = int(math.sqrt(cap))\nAttributeError: can't set attribute\n", "class Square_Integers_Below(Math_Set_Base):\n\n    def __init__(self,cap):\n        #Math_Set_Base.__init__(self)\n        self.length = int(math.sqrt(cap))\n        Math_Set_Base.size = self.length\n\n    def __repr__(self):\n        return str(self.size)\n", "3\n2\n"], ["In [1]: A = [[8100, 3], [8200, 5], [8400, 8]]\n\nIn [2]: for i in range(1, len(A)):\n            A[i][-1] += A[i-1][-1]\n\nIn [3]: A\nOut[3]: [[8100, 3], [8200, 8], [8400, 16]]\n"], ["from sklearn.externals import joblib\nscaler_filename = \"scaler.save\"\nif new_s_h5:\n    scaler = MinMaxScaler()\n    df_normalized = scaler.fit_transform(df.values)\n    joblib.dump(scaler, scaler_filename)\n\nelse:\n    scaler = joblib.load(scaler_filename)\n    df_normalized = scaler.transform(df.values)\n"], [], ["myList = [[8100, 3], [8200, 5], [8400, 8]]\n\nacc=0\nnew_list=[[sl1, acc := acc + sl2] for sl1, sl2 in myList]\n>>> new_list\n[[8100, 3], [8200, 8], [8400, 16]]\n"], [], ["col1, col2 = zip(*myList)\n# col1 == (8100, 8200, 8400), col2 == (3, 5, 8)\nsums = [ sum(col2[:i]) for i, _ in enumerate(col2, 1) ]\n# sums == [3, 8, 16]\nmyNewList = [ list(x) for x in zip(col1, sums) ]\n# myNewList == [[8100, 3], [8200, 8], [8400, 16]]\n"], ["L = [[8100, 3], [8200, 5], [8400, 8]]\n\ndef newList(L):\n    gen = []\n    for subL in L:\n        if len(gen) > 0:\n            gen.append(gen[-1] + subL[1])\n        else:\n            gen.append(subL[1])\n\n    for idx, subL in enumerate(L):\n        subL[1] = gen[idx]\n\n    print(L)\n\nnewList(L)\n", "[[8100, 3], [8200, 8], [8400, 16]]\n"], ["myNewList = []\nvalue = 0\nfor sublist in myList:\n    value = sublist[1]+value\n    newSublist = [sublist[0],value]\n    myNewList.append(newSublist) \n"], ["a = np.array(myList)\na[:, 1] = a[:, 1].cumsum()\n", "array([[8100,    3],\n       [8200,    8],\n       [8400,   16]])\n"], ["batch_size = 1\nepochs = 200\nshuffle = False\n"], [], [], ["import tensorflow as tf\nfrom pprint import pprint\n\n\nfor shape in [(None,784,), (None, 784,1), (None, 32,28), (None, 32,28,1)]:\n    shapes_list = []\n\n    input_layer_1 = tf.compat.v1.placeholder(dtype=tf.float32, shape=shape, name=None)\n    shapes_list.append(input_layer_1.shape)\n    d1 = tf.compat.v1.layers.dense(\n        inputs=input_layer_1, units=4, activation=None, use_bias=True, kernel_initializer=None,\n        bias_initializer=tf.zeros_initializer(), kernel_regularizer=None,\n        bias_regularizer=None, activity_regularizer=None, kernel_constraint=None,\n        bias_constraint=None, trainable=True, name=None, reuse=None\n    )\n    shapes_list.append(d1.shape)\n    d2 = tf.compat.v1.layers.dense(\n        inputs=d1, units=10, activation=tf.compat.v1.nn.softmax, use_bias=True, kernel_initializer=None,\n        bias_initializer=tf.zeros_initializer(), kernel_regularizer=None,\n        bias_regularizer=None, activity_regularizer=None, kernel_constraint=None,\n        bias_constraint=None, trainable=True, name=None, reuse=None\n    )\n    shapes_list.append(d2.shape)\n    print('++++++++++++++++++++++++++')\n    pprint(shapes_list)\n    print('++++++++++++++++++++++++++')\n"], ["for i in range(32):\n    for j in range(28):\n        output[i, j, :] = input[i, j, :] @ layer.weights + layer.bias\n"], ["self.color = (color) -> self.color = color\n", "particle = Particle()\nparticle.draw()\n"], ["Dense layer is applied on the last axis independently. [1]\n", "input_shape=(784,)\nmodel.add(Dense(units=4,activation='linear',input_shape=(784,)))\n", "Output shape=  (None, 4) \n", "input_shape=(784,1)\nUnits = 4\n", " input_shape=(32,28)\n", "output_shape=(None,32,4)\n", "model.add(Dense(units=4,activation='linear',input_shape=(32,28,1)))   \n", "Output Shape =(None,32,28,4)\n"], [], [], ["parameters -> 784*4 + 4 = 3140\n", "parameters -> 4(output units) + 4(bias) = 8\n"], [], [], ["from pandas.compat.pickle_compat import _class_locations_map\n\n_class_locations_map.update({\n    ('pandas.core.internals.managers', 'BlockManager'): ('pandas.core.internals', 'BlockManager')\n})\n"], ["def word_with(word, char):\n    return [x for x in word.split() if char.lower() in x.lower()]\n"], [], ["def word_with(word, char):\n    return [x for x in word.split() if re.search(char, x, re.IGNORECASE)]\n"], ["import re\ndef word_with(word, char):\n    word_string = word.split()\n    print(word_string)\n    word_with = [x for x in word_string if re.search(r'^[s]',x,re.I)]\n    return(word_with)\n\nword = \"She sells seashells by the seashore\"\nprint(word_with(word,'s'))\n"], [], ["[x for x in word_string if char_lower in x.lower()]\n", "def word_with(word, char):\n    char_lower = char.lower()\n    word_string = word.split()\n    word_with = [x for x in word_string if char_lower in x.lower()]\n    return(word_with)\n\n\nword = \"She sells seashells by the seashore\"\nprint(word_with(word, \"s\"))\n", "['She', 'sells', 'seashells', 'seashore']\n"], [], [], ["orders = [\"screws:20\", \"nails:15\", \"brushes:5\", \"screws:15\", \"nails:20\"]\nmy_dict = {i.split(\":\")[0]:i.split(\":\")[1] for i in orders}\nmy_dict = {}\n\nfor elem in orders:\n    key, value = elem.split(\":\")\n    if key not in my_dict:\n        my_dict[key] = 0\n    my_dict[key] += int(value)\n\n\n\nprint(my_dict)\n>>>{'screws': 35, 'nails': 35, 'brushes': 5}\n"], ["d = {}\n\nfor s in orders:\n    key, value = s.split(\":\")\n    d[key] = d.get(key, 0) + int(value)\n\nprint (d)\n"], ["from collections import defaultdict\n\norders = [\"screws:20\", \"nails:15\", \"brushes:5\", \"screws:15\", \"nails:20\"]\ndct = defaultdict(int)\n\nfor item in orders:\n    key, value = item.split(\":\")\n    dct[key] += int(value)\n\nprint(dct)\n", "defaultdict(<class 'int'>, {'screws': 35, 'nails': 35, 'brushes': 5})\n", "from collections import defaultdict, Counter\nimport timeit\n\norders = [\"screws:20\", \"nails:15\", \"brushes:5\", \"screws:15\", \"nails:20\"]\n\ndef solution_wjandrea():\n    tally = Counter()\n    for s in orders:\n        item, count = s.split(\":\")\n        tally[item] += int(count)\n    return tally\n\ndef solution_jan():\n    dct = defaultdict(int)\n\n    for item in orders:\n        key, value = item.split(\":\")\n        dct[key] += int(value)\n    return dct\n\nprint(timeit.timeit(solution_wjandrea, number=10**6))\nprint(timeit.timeit(solution_jan, number=10**6))\n", "6.034431410000001\n3.8878112820000004\n"], ["import pandas as pd\n\norders = [\"screws:20\", \"nails:15\", \"brushes:5\", \"screws:15\", \"nails:20\"]\n\nitems_0 = [s.split(':') for s in orders]\nitems = [[item[0], int(item[1])] for item in items_0]  # convert counts to integer\n\n# create the data frame\ndf = pd.DataFrame(items, columns=['Item', 'Count'])\n\n# show the data frame\nprint(df)\n# print again, summing the counts for each item\nprint(df.groupby('Item').sum())\n", "      Item  Count\n0   screws     20\n1    nails     15\n2  brushes      5\n3   screws     15\n4    nails     20\n         Count\nItem          \nbrushes      5\nnails       35\nscrews      35\n"], ["orders = [\"screws:20\", \"nails:15\", \"brushes:5\", \"screws:15\", \"nails:20\"]\nmy_dict = dict()\n\nfor s in orders:\n    key, value = s.split(':')\n    if key in my_dict.keys():\n        my_dict[key] += int(value)\n        continue\n    my_dict[key] = int(value)\nprint(my_dict)\n"], ["from collections import Counter\n\ntally = Counter()\nfor s in orders:\n    item, count = s.split(\":\")\n    tally[item] += int(count)\nprint(tally)  # -> Counter({'screws': 35, 'nails': 35, 'brushes': 5})\n"], ["class Math_Set_Base:\n    @property\n    def size(self):\n        return len(self.elements)\n\n    # size = property(lambda self: self.elements)\n\n\nclass Square_Integers_Below(Math_Set_Base):\n\n    def __init__(self, cap):\n        self._cap = cap\n\n    @property\n    def size(self):\n        return int(math.sqrt(self._cap))\n\n    # size = property(lambda self: int(math.sqrt(self._cap)))\n", "class Square_Integers_Below(Math_Set_Base):\n\n    def __init__(self, cap):\n        self._size = int(math.sqrt(self._cap))\n\n    @property\n    def size(self):\n        return self._size\n"], ["class Math_Set_Base:\n    @property\n    def size(self):\n        try:\n            return self._size\n        except:\n            return len(self.elements)\n\n    @size.setter\n    def size(self, value):\n        self._size = value\n", "class Concrete_Math_Set(Math_Set_Base):\n    def __init__(self,*elements):\n        self.elements = elements\n\nclass Square_Integers_Below(Math_Set_Base):\n    def __init__(self,cap):\n        self.size = int(math.sqrt(cap))\n\nprint(Concrete_Math_Set(1,2,3).size) # 3\nprint(Square_Integers_Below(7).size) # 2\n"], ["class Foo:\n    def __init__(self):\n        self.name = 'Foo!'\n        @property\n        def inst_prop():\n            return f'Retrieving {self.name}'\n        self.inst_prop = inst_prop\n", ">>> Foo.inst_prop\nTraceback (most recent call last):\n  File \"<pyshell#60>\", line 1, in <module>\n    Foo.inst_prop\nAttributeError: type object 'Foo' has no attribute 'inst_prop'\n>>> Foo().inst_prop\n<property object at 0x032B93F0>\n>>> Foo().inst_prop.fget()\n'Retrieving Foo!'\n", "@property\ndef some_prop(self):\n    return \"Family property\"\n\nclass Grandparent:\n    culture = some_prop\n    world_view = some_prop\n\nclass Parent(Grandparent):\n    world_view = \"Parent's new world_view\"\n\nclass Child(Parent):\n    def __init__(self):\n        try:\n            self.world_view = \"Child's new world_view\"\n            self.culture = \"Child's new culture\"\n        except AttributeError as exc:\n            print(exc)\n            self.__dict__['culture'] = \"Child's desired new culture\"\n", "print(\"Instantiating Child class...\")\nc = Child()\nprint(f'c.__dict__ is: {c.__dict__}')\nprint(f'Child.__dict__ is: {Child.__dict__}')\nprint(f'c.world_view is: {c.world_view}')\nprint(f'Child.world_view is: {Child.world_view}')\nprint(f'c.culture is: {c.culture}')\nprint(f'Child.culture is: {Child.culture}')\n", "Instantiating Child class...\ncan't set attribute\nc.__dict__ is: {'world_view': \"Child's new world_view\", 'culture': \"Child's desired new culture\"}\nChild.__dict__ is: {'__module__': '__main__', '__init__': <function Child.__init__ at 0x0068ECD8>, '__doc__': None}\nc.world_view is: Child's new world_view\nChild.world_view is: Parent's new world_view\nc.culture is: Family property\nChild.culture is: <property object at 0x00694C00>\n", "Grandparent.__dict__ is: {\n    '__module__': '__main__', \n    'culture': <property object at 0x00694C00>, \n    'world_view': <property object at 0x00694C00>, \n    ...\n}\n", ">>> del Parent.culture\nTraceback (most recent call last):\n  File \"<pyshell#67>\", line 1, in <module>\n    del Parent.culture\nAttributeError: culture\n", "del Parent.world_view\nprint(f'c.world_view is: {c.world_view}')\nprint(f'Child.world_view is: {Child.world_view}')\n", "c.world_view is: Family property\nChild.world_view is: <property object at 0x00694C00>\n", "Child.world_view = \"Child's independent world_view\"\nprint(f'c.world_view is: {c.world_view}')\nprint(f'Child.world_view is: {Child.world_view}')\n\ndel c.world_view\nprint(f'c.world_view is: {c.world_view}')\nprint(f'Child.world_view is: {Child.world_view}')\n\nChild.world_view = property(lambda self: \"Child's own property\")\nprint(f'c.world_view is: {c.world_view}')\nprint(f'Child.world_view is: {Child.world_view}')\n", "# Creating Child's own world view\nc.world_view is: Child's new world_view\nChild.world_view is: Child's independent world_view\n\n# Deleting Child instance's world view\nc.world_view is: Child's independent world_view\nChild.world_view is: Child's independent world_view\n\n# Changing Child's world view to the property\nc.world_view is: Child's own property\nChild.world_view is: <property object at 0x020071B0>\n", "del Grandparent.culture\nprint(f'c.culture is: {c.culture}')\nprint(f'Child.culture is: {Child.culture}')\n", "c.culture is: Child's desired new culture\nTraceback (most recent call last):\n  File \"<pyshell#74>\", line 1, in <module>\n    print(f'Child.culture is: {Child.culture}')\nAttributeError: type object 'Child' has no attribute 'culture'\n", "@property\ndef some_prop(self):\n    return \"Family property\"\n\n@some_prop.setter\ndef some_prop(self, val):\n    print(f\"property setter is called!\")\n    # do something else...\n", "Instantiating Child class...\nproperty setter is called!\n", "class Grandparent:\n    @property\n    def culture(self):\n        return \"Family property\"\n    \n    # add a setter method\n    @culture.setter\n    def culture(self, val):\n        print('Fine, have your own culture')\n        # overwrite the child class attribute\n        type(self).culture = None\n        self.culture = val\n\nclass Parent(Grandparent):\n    pass\n\nclass Child(Parent):\n    def __init__(self):\n        self.culture = \"I'm a millennial!\"\n\nc = Child()\nprint(c.culture)\n", "Fine, have your own culture\nI'm a millennial!\n", "class Grandparent:\n    # ...\n    @culture.setter\n    def culture(self, val):\n        if isinstance(val, tuple):\n            if val[1]:\n                print('Fine, have your own culture')\n                type(self).culture = None\n                self.culture = val[0]\n        else:\n            raise AttributeError(\"Oh no you don't\")\n\n# ...\n\nclass Child(Parent):\n    def __init__(self):\n        try:\n            # Usual setter\n            self.culture = \"I'm a Gen X!\"\n        except AttributeError:\n            # Trigger the overwrite condition\n            self.culture = \"I'm a Boomer!\", True\n", "class Grandparent:\n    # ...\n    def overwrite_props(self):\n        # reassign class attributes\n        type(self).size = None\n        type(self).len = None\n        # other properties, if necessary\n\n# ...\n\n# Usage\nclass Child(Parent):\n    def __init__(self):\n        self.overwrite_props()\n        self.size = 5\n        self.len = 10\n"], ["class Math_Set_Base:\n    _size = None\n\n    def _size_call(self):\n       return len(self.elements)\n\n    @property\n    def size(self):\n        return  self._size if self._size is not None else self._size_call()\n\nclass Concrete_Math_Set(Math_Set_Base):\n    def __init__(self, *elements):\n        self.elements = elements\n\n\nclass Square_Integers_Below(Math_Set_Base):\n    def __init__(self, cap):\n        self._size = int(math.sqrt(cap))\n"], ["class Square_Integers_Below(Math_Set_Base):\n    size = None\n\n    def __init__(self, cap):\n        self.size = int(math.sqrt(cap))\n"], ["myTuple = (44.0, 34.0, 17.0, 6.0, 15.0)\n\nprint(min(myTuple)) # 6.0\n\nprint(max(myTuple))  #44.0\n"], ["template <typename IT>\nbool next_partial_permutation(IT beg, IT mid, IT end) {\n    if (beg == mid) { return false; }\n    if (mid == end) { return std::next_permutation(beg, end); }\n\n    auto p1 = mid;\n\n    while (p1 != end && !(*(mid - 1) < *p1))\n        ++p1;\n\n    if (p1 != end) {\n        std::swap(*p1, *(mid - 1));\n        return true;\n    } else {\n        std::reverse(mid, end);\n        auto p3 = std::make_reverse_iterator(mid);\n\n        while (p3 != std::make_reverse_iterator(beg) && !(*p3 < *(p3 - 1)))\n            ++p3;\n\n        if (p3 == std::make_reverse_iterator(beg)) {\n            std::reverse(beg, end);\n            return false;\n        }\n\n        auto p2 = end - 1;\n\n        while (!(*p3 < *p2))\n            --p2;\n\n        std::swap(*p3, *p2);\n        std::reverse(p3.base(), end);\n        return true;\n    }\n}\n"], ["expected_keys=('color', 'fruit')\nfor k in expected_keys:\n     new_dict[k]=mydict[k]\n"], ["new_dict[\"color\"] = mydict[\"color\"]\n", "items = [\"color\", \"fruit\"]\nfor item in items:\n    new_dict[item] = mydict[item]\n"], [">>> keys = {\"color\", \"fruit\"}\n>>> new_dict = {k: v for k, v in mydict.items() if k in keys}\n>>> new_dict\n{'color': 'green', 'fruit': 'apple'}\n", ">>> new_dict = {k: v for k, v in mydict.items() if k == \"color\" or k == \"fruit\"}\n>>> new_dict\n{'color': 'green', 'fruit': 'apple'}\n"], ["mydict = {\n    \"color\":\"green\",\n    \"type\":\"veg\",\n    \"fruit\":\"apple\",\n    \"level\": 5\n}\nnew_dict = {\n    \"color\": mydict[\"color\"],\n    \"fruit\": mydict[\"fruit\"]\n}\n", "def copy_dict(original, keys=None):\n    keys = keys or {key for key in original}\n    return {\n        key: value for key, value in original if key in keys\n    }\n\nmydict = {\n    \"color\":\"green\",\n    \"type\":\"veg\",\n    \"fruit\":\"apple\",\n    \"level\": 5\n}\nnew_dict = copy_dict(mydict, {'color', 'fruit'})\n"], ["new_dict = {x:mydict[x] for x in mydict if x in ('color','fruit')}\n"], ["df2 = pd.concat([df, df['Start'].str.split(' ', expand=True)], axis=1).drop('Start', axis=1)\ndf2.rename(columns={0:'Start', 1:'del_1'}, inplace=True)\ndf3 = pd.concat([df2, df2['Finish'].str.split(' ', expand=True)], axis=1).drop('Finish', axis=1)\ndf3.rename(columns={0:'Finish', 1:'del_2'}, inplace=True)\ndf3 = df3.drop(['del_1','del_2'], axis=1)\ndf3 = df3.iloc[:,[3,2,0,1]]\n"], ["In [103]: def extract_date(x):\n     ...:     return x.split(\" \")[0]\n     ...:\n\nIn [104]: extract_date(\"1/5/2020 Yes\")\nOut[104]: '1/5/2020'\n\nIn [105]: df['Start'] = df['Start'].apply(extract_date)\n\nIn [106]: df['Finish'] = df['Finish'].apply(extract_date)\n\nIn [107]: df\nOut[107]:\n      Start    Finish  x1  x2\n0  1/5/2020  5/9/2020   2   6\n1  1/8/2020  5/8/2020   8   9\n2  8/9/2020  5/8/2020   8   9\n", "df['Start'] = df['Start'].str.split(\" \").str[0]\ndf['Finish'] = df['Finish'].str.split(\" \").str[0]\n"], ["df.Start = df.Start.str.replace(r'[a-zA-Z]','').str.strip()\ndf.Finish = df.Finish.str.replace(r'[a-zA-Z]','').str.strip()\n\n    Start         Finish    x1  x2\n0   1/5/2020    5/9/2020    2   6\n1   1/8/2020    5/8/2020    8   9\n2   8/9/2020    5/8/2020    8   9\n"], ["keys = ['Start', 'Finish']\nfor k in keys:\n     for e, i in enumerate(df[k]):\n         a = i.split()\n         df[k][e] = a[0]\n\ndf\n      Start    Finish  x1  x2\n0  1/5/2020  5/9/2020   2   6\n1  1/8/2020  5/8/2020   8   9\n2  8/9/2020  5/8/2020   8   9\n"], ["import dateutil.parser as dparser\ndf.Start.apply(dparser.parse,fuzzy=True)\n0   2020-01-05\n1   2020-01-08\n2   2020-08-09\nName: Start, dtype: datetime64[ns]\n"], ["df.Start = df.Start.str.extract('([0-9]+/[0-9]+/[0-9]+)')\ndf.Finish = df.Finish.str.extract('([0-9]+/[0-9]+/[0-9]+)')\n\ndf.head()\n\n#   Start       Finish      x1  x2\n# 0 1/5/2020    5/9/2020    2   6\n# 1 1/8/2020    5/8/2020    8   9\n# 2 8/9/2020    5/8/2020    8   9\n"], [], [">>> array = [[12.0, 23], [9.0, 24]]\n>>> for i in range(len(array)):\n...     array[i][1] = str(array[i][1])\n...\n>>> array\n[[12.0, '23'], [9.0, '24']]\n>>>\n"], ["[tuple(map(str, xs)) for xs in lst]\n[('12.0', '23',) , ('9.0', '24')]\n\nresult = []\n    for xs in lst:\n     temp = []\n      for x in xs:\n         temp.append(str(x))\n      result.append(tuple(temp))\n\n\n\nresult\n"], ["array = [(12.0, 23),(9.0, 24)]\n\narray = [(a, str(b)) for a,b in array]\n# [(12.0, '23'), (9.0, '24')]\n", "array = [(12.0, 23),(9.0, 24)]\n\nfor i, (a,b) in enumerate(array):\n    array[i] = (a, str(b))\n\narray\n# (12.0, '23'), (9.0, '24')]\n"], [">>> array = [(12.0, 23),(9.0, 24)]\n>>> [(x[0],str(x[1])) for x in array]\n[(12.0, '23'), (9.0, '24')]\n>>>\n"], ["#include <algorithm>\n#include <iostream>\n#include <set>\n#include <vector>\n\nint main() {\n    std::vector<int> job_list;\n    std::set<std::vector<int>> permutations;\n    for (unsigned long i = 0; i < 7; i++) {\n        int job;\n        std::cin >> job;\n        job_list.push_back(job);\n    }\n    std::sort(job_list.begin(), job_list.end());\n    std::vector<int> original_permutation = job_list;\n    do {\n        std::next_permutation(job_list.begin(), job_list.end());\n        permutations.insert(std::vector<int>(job_list.begin(), job_list.begin() + 3));\n    } while (job_list != original_permutation);\n\n    for (auto& permutation : permutations) {\n        for (auto& pair : permutation) {\n            std::cout << pair << \" \";\n        }\n        std::endl(std::cout);\n    }\n\n    return 0;\n}\n"], ["#include <iostream>\n#include <vector>\n#include <algorithm>\n\nvoid nextPartialPerm(std::vector<int> &z, int n1, int m1) {\n\n    int p1 = m1 + 1;\n\n    while (p1 <= n1 && z[m1] >= z[p1])\n        ++p1;\n\n    if (p1 <= n1) {\n        std::swap(z[p1], z[m1]);\n    } else {\n        std::reverse(z.begin() + m1 + 1, z.end());\n        p1 = m1;\n\n        while (z[p1 + 1] <= z[p1])\n            --p1;\n\n        int p2 = n1;\n\n        while (z[p2] <= z[p1])\n            --p2;\n\n        std::swap(z[p1], z[p2]);\n        std::reverse(z.begin() + p1 + 1, z.end());\n    }\n}\n", "int main() {\n    std::vector<int> z = {1, 2, 3, 4, 5, 6, 7};\n    int m = 3;\n    int n = z.size();\n\n    const int nMinusK = n - m;\n    int numPerms = 1;\n\n    for (int i = n; i > nMinusK; --i)\n        numPerms *= i;\n\n    --numPerms;\n\n    for (int i = 0; i < numPerms; ++i) {\n        for (int j = 0; j < m; ++j)\n            std::cout << z[j] << ' ';\n\n        std::cout << std::endl;\n        nextPartialPerm(z, n - 1, m - 1);\n    }\n\n    // Print last permutation\n    for (int j = 0; j < m; ++j)\n            std::cout << z[j] << ' ';\n\n    std::cout << std::endl;\n\n    return 0;\n}\n", "1 2 3 \n1 2 4 \n1 2 5 \n1 2 6 \n1 2 7\n.\n.\n.\n7 5 6 \n7 6 1 \n7 6 2 \n7 6 3 \n7 6 4 \n7 6 5\n"], ["12 34 <\n12 43\n13 24 <\n13 42\n14 23 <\n14 32\n21 34 <\n21 43\n23 14 <\n23 41\n24 13 <\n24 31\n...\n", "std::size_t fact(std::size_t n) {\n    std::size_t f = 1;\n    while (n > 0)\n        f *= n--;\n    return f;\n}\n\ntemplate<class It, class Fn>\nvoid generate_permutations(It first, It last, std::size_t k, Fn fn) {\n    assert(std::is_sorted(first, last));\n\n    const std::size_t size = static_cast<std::size_t>(last - first);\n    assert(k <= size);\n\n    const std::size_t m = fact(size - k);\n    std::size_t i = 0;\n    do {\n        if (i++ == 0)\n            fn(first, first + k);\n        i %= m;\n    }\n    while (std::next_permutation(first, last));\n}\n\nint main() {\n    std::vector<int> vec{1, 2, 3, 4};\n    generate_permutations(vec.begin(), vec.end(), 2, [](auto first, auto last) {\n        for (; first != last; ++first)\n            std::cout << *first;\n        std::cout << ' ';\n    });\n}\n", "12 13 14 21 23 24 31 32 34 41 42 43\n"], ["template <typename F, typename T>\nvoid permutation(F f, std::vector<T> v, std::size_t n)\n{\n    std::vector<bool> bs(v.size() - n, false);\n    bs.resize(v.size(), true);\n    std::sort(v.begin(), v.end());\n\n    do {\n        std::vector<T> sub;\n        for (std::size_t i = 0; i != bs.size(); ++i) {\n            if (bs[i]) {\n                sub.push_back(v[i]);\n            }\n        }\n        do {\n            f(sub);\n        }\n        while (std::next_permutation(sub.begin(), sub.end()));\n    } while (std::next_permutation(bs.begin(), bs.end()));\n}\n"], ["from functools import partial, reduce\n\ndfs = [df1, df2, df3]\nmerge = partial(pd.merge, on=['depth', 'profile'], how='outer')\nreduce(merge, dfs)\n\n   depth       VAR1    profile     VAR2    VAR3\n0    0.6  38.198002  profile_1  0.20440     NaN\n1    0.6  38.198002  profile_1  0.20440     NaN\n2    1.3  38.200001  profile_1      NaN  15.182\n3    1.1        NaN  profile_1  0.20442     NaN\n4    1.2        NaN  profile_1  0.20446  15.188\n5    1.4        NaN  profile_1      NaN  15.182\n"], ["mysql> SHOW VARIABLES LIKE \"%version%\";\n+-------------------------+------------------------------+\n| Variable_name           | Value                        |\n+-------------------------+------------------------------+\n| innodb_version          | 5.7.27                       |\n| protocol_version        | 10                           |\n| slave_type_conversions  |                              |\n| tls_version             | TLSv1,TLSv1.1                |\n| version                 | 5.7.27                       |\n| version_comment         | MySQL Community Server (GPL) |\n| version_compile_machine | x86_64                       |\n| version_compile_os      | Linux                        |\n+-------------------------+------------------------------+\n8 rows in set (0.04 sec)\n", "mysql> SHOW VARIABLES LIKE \"%version%\";\n\n+----------------------------------+-----------------------+\n| Variable_name                    | Value                 |\n+----------------------------------+-----------------------+\n| innodb_polar_restore_old_version | OFF                   |\n| innodb_version                   | 8.0.13                |\n| protocol_version                 | 10                    |\n| rds_audit_log_version            | MYSQL_V1              |\n| rds_version                      | 13                    |\n| slave_type_conversions           |                       |\n| tls_version                      | TLSv1,TLSv1.1,TLSv1.2 |\n| version                          | 8.0.13                |\n| version_comment                  | Source distribution   |\n| version_compile_machine          | x86_64                |\n| version_compile_os               | Linux                 |\n| version_compile_zlib             | 1.2.11                |\n+----------------------------------+-----------------------+\n12 rows in set (0.98 sec)\n", "ssl_disabled=True\n"], [" pip install -U scikit-image\n", " pip install numpy==1.15\n", "python -m pip install --upgrade pip\n"], [], ["import sys\nfrom unicodedata import category\npunctuation_chars =  [chr(i) for i in range(sys.maxunicode) \n                             if category(chr(i)).startswith(\"P\")]\n"], ["import os\nfrom distutils.util import strtobool\nfrom typing import Dict, Any\n\nos.environ[\"SSL\"] = \"0\"\nos.environ[\"PORT\"] = \"99999\"\n\n\ndef type_env() -> Dict[str, Any]:\n    d: Dict[str, Any] = dict(os.environ)\n    for key in d:\n        try:\n            d[key] = bool(strtobool(d[key]))\n            continue\n        except ValueError:\n            pass\n        try:\n            d[key] = int(d[key])\n            continue\n        except ValueError:\n            pass\n        try:\n            d[key] = float(d[key])\n            continue\n        except ValueError:\n            pass\n    return d\n\n\nenv = type_env()\nprint(type(env[\"SSL\"]))\nprint(type(env[\"PORT\"]))\n\nif not env[\"SSL\"]:  # <-- I'd like this to be cast to boolean and typed as a boolean\n    print(\"Connecting w/o SSL!\")\nif 65535 < env[\"PORT\"]:  # <-- I'd like this to be cast to int and typed as an int\n    print(\"Invalid port!\")\n"], [], [], [], [], ["np.random.seed(0)\na = np.random.choice(np.arange(2), 5)\nb = np.random.choice(np.arange(2), 5)\ndf = pd.DataFrame(dict(a = a, b = b))\n\n\ndf[df.a == 0].head()\n\n#   a   b\n# 0 0   0\n# 2 0   0\n# 4 0   1\n\ndf[df.a == df.b].head()\n\n#   a   b\n# 0 0   0\n# 2 0   0\n# 3 1   1\n"], ["with open('.env', 'w') as fp:\n    fp.write('PORT=5000\\nSSL=0')\n", "from pydantic import BaseSettings\n\nclass Settings(BaseSettings):\n    PORT : int\n    SSL : bool\n    class Config:\n        env_file = '.env'\n\nconfig = Settings()\n\nprint(type(config.SSL),  config.SSL)\nprint(type(config.PORT),  config.PORT)\n# <class 'bool'> False\n# <class 'int'> 5000\n", "env = Settings()\n\nif not env.SSL:\n    print(\"Connecting w/o SSL!\")\nif 65535 < env.PORT: \n    print(\"Invalid port!\")\n", "Connecting w/o SSL!\n"], ["# example of converting an image with the Keras API\nfrom keras.preprocessing.image import load_img\nfrom keras.preprocessing.image import img_to_array\nfrom keras.preprocessing.image import array_to_img\n\n# load the image\nimg = load_img('image.jpg')\nprint(type(img))\n\n# convert to numpy array\nimg_array = img_to_array(img)\nprint(img_array.dtype)\nprint(img_array.shape)\n\n# convert back to image\nimg_pil = array_to_img(img_array)\nprint(type(img_pil))\n\n# show image\nfig = plt.figure()\nax = fig.add_subplot()\nax.imshow(img_pil)\n", "from keras.preprocessing.image import save_img\nfrom keras.preprocessing.image import load_img\nfrom keras.preprocessing.image import img_to_array\n\n# load image\nimg = load_img('image.jpg')\n\n# convert image to a numpy array\nimg_array = img_to_array(img)\n\n# save the image with a new filename\nsave_img('image_save.jpg', img_array)\n\n# load the image to confirm it was saved correctly\nimg = load_img('image_save.jpg')\n\nprint(type(img))\nprint(img.format)\nprint(img.mode)\nprint(img.size)\n"], ["print(Math_Set_Base.size)\n# <property object at 0x10776d6d0>\n\nMath_Set_Base.size = 4\nprint(Math_Set_Base.size)\n# 4\n", "class Square_Integers_Below(Math_Set_Base):\n    # explicitly define size at the class level to be literally anything other than a @property\n    size = None\n\n    def __init__(self,cap):\n        self.size = int(math.sqrt(cap))\n\nprint(Square_Integers_Below(4).size)  # 2\nprint(Square_Integers_Below.size)     # None\n"], [], ["import numpy as np \n\ny = np.array([2,2,10,4,4,4,5,6,7,2,6,5,5,7,7,1,1])\nx = np.r_[y[0]+1, y, y[-1]+1]   # pad edges, gives possibility for minima\n\nups,   = np.where(x[:-1] < x[1:])\ndowns, = np.where(x[:-1] > x[1:])\n\nminend = ups[np.unique(np.searchsorted(ups, downs))]\nminbeg = downs[::-1][np.unique(np.searchsorted(-downs[::-1], -ups[::-1]))][::-1]\n\nminlen = minend - minbeg\n\nfor line in zip(minlen, minbeg, minend-1): print(\"set of %d minima %d - %d\" % line)\n", "set of 2 minima 0 - 1\nset of 3 minima 3 - 5\nset of 1 minima 9 - 9\nset of 2 minima 11 - 12\nset of 2 minima 15 - 16\n"], ["first = input(\"what is your firstname? \")\n", "hello\nwhat is your firstname?\n"], ["print(\"hello\")\nfirst = input(\"what is your firstname? \")\nsurname = input(\"what is your surname? \")\nprint(\"thanks\", first, surname)\n", "====== RESTART: C:/Program Files/Python36/Lib/idlelib/myprogram.py ======\nhello\nwhat is your firstname? John\nwhat is your surname? Doe\nthanks John Doe\n>>> \n"], ["def get_team_points(df, teams):\n    team_points = {}\n    for team_name in teams:\n        num_points = ... # as you have it but since you posted an image I'm not rewriting it\n        team_points[team_name] = num_points\n    return team_points\n", "def get_team_points(df, teams):\n    team_points = {team: get_num_points(team, df) for team in teams}\n    return team_points\n", "def get_team_points(df: pd.DataFrame, teams: List[str]) -> Dict[str, int]:\n    team_points = {team: get_num_points(team, df) for team in teams}\n    return team_points\n"], [], [], [], [" print(\"Hello\");  first = input(\"your first name\"); print(\"HELLO 2\");  second = input(\"your last name\")\n"], ["import pandas as pd\ndf = pd.DataFrame({'HomeTeam': list('AABCDA'), 'AwayTeam': list('CBAAAB'),\n                   'HP': [4,5,6,7,8,10], 'AP': [0,0,10,11,4,7]})\n\n  HomeTeam AwayTeam  HP  AP\n0        A        C   4   0\n1        A        B   5   0\n2        B        A   6  10\n3        C        A   7  11\n4        D        A   8   4\n5        A        B  10   7\n", "# Fill value so addition works if a team has exclusively home/away games.\ns = df.groupby('HomeTeam')['HP'].sum().add(df.groupby('AwayTeam')['AP'].sum(),\n                                           fill_value=0).astype(int)\n\ns.to_dict()\n{'A': 44, 'B': 13, 'C': 7, 'D': 8}\n"], [], ["dic = {}\nfor team_name in List:\n    dic[team_name] = num_points\n"], ["def get_team_points(df, teams):\n    Dict = {}\n    for team_name in List:\n        num_points = TeamPoints(...)\n        Dict[team_name] = num_points\n    print(Dict)\n"], ["dict={'a':'b','c':'d'}\n\nkeys = \"\".join(list(dict.keys()))\nvalues = \"\".join(list(dict.values()))\n"], ["import numpy as np\nfrom scipy.signal import argrelmax\nfrom itertools import groupby\n\n\ndef local_max_scipy(a):\n    start = 0\n    result = [[a[0] - 1, 0, 0]]  # this is to guarantee the left edge is included\n    for k, g in groupby(a):\n        length = sum(1 for _ in g)\n        result.append([k, start, length])\n        start += length\n    result.append([a[-1] - 1, 0, 0])  # this is to guarantee the right edge is included\n\n    arr = np.array(result)\n    maxima, = argrelmax(arr[:, 0])\n    return arr[maxima]\n\n\ntest03 = np.array([2, 2, 10, 4, 4, 4, 5, 6, 7, 2, 6, 5, 5, 7, 7, 1, 1])\noutput = local_max_scipy(test03)\n\nfor val, start, length in output:\n    print(f'set of {length} maxima start:{start} end:{start + length}')\n", "set of 1 maxima start:2 end:3\nset of 1 maxima start:8 end:9\nset of 1 maxima start:10 end:11\nset of 2 maxima start:13 end:15\n"], ["def digital_root(n):\n    if n<10 :\n         return n\n    return digital_root( n%10 + digital_root( n//10 ) )\n"], ["s = pd.get_dummies(df.list_of_value.explode()).sum(level=0)\ns.dot(s.T).div(s.sum(1))\n", "          0         1         2         3\n0  1.000000  0.666667  1.000000  1.000000\n1  0.666667  1.000000  0.666667  0.666667\n2  1.000000  0.666667  1.000000  1.000000\n3  1.000000  0.666667  1.000000  1.000000\n", "   a  b  c  d\n0  1  1  1  0\n1  0  1  1  1\n2  1  1  1  0\n3  1  1  1  0\n", "df.list_of_value.explode()\n", "0    a\n0    b\n0    c\n1    d\n1    b\n1    c\n2    a\n2    b\n2    c\n3    a\n3    b\n3    c\nName: list_of_value, dtype: object\n", "   a  b  c  d\n0  1  0  0  0\n0  0  1  0  0\n0  0  0  1  0\n1  0  0  0  1\n1  0  1  0  0\n1  0  0  1  0\n2  1  0  0  0\n2  0  1  0  0\n2  0  0  1  0\n3  1  0  0  0\n3  0  1  0  0\n3  0  0  1  0\n", "s = pd.get_dummies(df.list_of_value.explode()).sum(level=0)\n", "s.dot(s.T).div(s.sum(1))\n"], ["def digital_root(n):\n    # convert to a string\n    as_str = str(n)\n\n    # get the value of the current first digit\n    value = int(as_str[0])\n\n    if len(as_str) > 1:\n        # add the recursive return plus the value\n        # for anything other than our base case.\n        # pass the rest of the digits into our recursive call\n        return digital_root(int(as_str[1:])) + value\n\n    # our base case\n    return value\n\nprint(digital_root(493193))\n"], ["def rec_sum(n):\n    sn = str(n)\n    # base case - return the number\n    if len(sn)==1:\n        return n\n\n    # not the base case,return whatever the recursive output returns\n    return rec_sum(sum(map(int,sn)))\n\n\nfor n in range(1,71):\n    print(f\"{n:3}=>{rec_sum(n):3}\", end = \"|\")\n    if n%7 == 0:\n        print()\n", "  1=>  1|  2=>  2|  3=>  3|  4=>  4|  5=>  5|  6=>  6|  7=>  7|\n  8=>  8|  9=>  9| 10=>  1| 11=>  2| 12=>  3| 13=>  4| 14=>  5|\n 15=>  6| 16=>  7| 17=>  8| 18=>  9| 19=>  1| 20=>  2| 21=>  3|\n 22=>  4| 23=>  5| 24=>  6| 25=>  7| 26=>  8| 27=>  9| 28=>  1|\n 29=>  2| 30=>  3| 31=>  4| 32=>  5| 33=>  6| 34=>  7| 35=>  8|\n 36=>  9| 37=>  1| 38=>  2| 39=>  3| 40=>  4| 41=>  5| 42=>  6|\n 43=>  7| 44=>  8| 45=>  9| 46=>  1| 47=>  2| 48=>  3| 49=>  4|\n 50=>  5| 51=>  6| 52=>  7| 53=>  8| 54=>  9| 55=>  1| 56=>  2|\n 57=>  3| 58=>  4| 59=>  5| 60=>  6| 61=>  7| 62=>  8| 63=>  9|\n 64=>  1| 65=>  2| 66=>  3| 67=>  4| 68=>  5| 69=>  6| 70=>  7|\n"], ["def digital_root(n):\n    answ = 0\n    s = 0\n    x = str(n)\n    for i in range(0, len(x)):\n        s = s + int(x[i])\n    if len(str(s)) > 1:\n       s = digital_root(s)\n    answ = s # You could even return s directly\n    return answ\n\nprint(digital_root(493193))\n"], ["def digital_root(n):\n    # basic scenario: n is 1 digit, ergo <10. \n    if n < 10:\n         return n\n\n    # alternative case: more than 1 digit\n    # cut n into digits with a list comprehension\n    # str(714) => \"714\", list(str(714)) => \"['7', '1', '4']\n    digits = [int(c) for c in list(str(n))]\n\n    # take the digital root of the sum\n    return digital_root(sum(digits))\n"], [], [], ["... import itertools\n... from collections import Counter\n... a=df.list_of_value.tolist()\n... l=np.array([len(Counter(x[0]) & Counter(x[1]))for x in [*itertools.product(a,a)]]).reshape(len(df),-1)\n... out=pd.DataFrame(l/df.list_of_value.str.len().values[:,None],index=df.id,columns=df.id)\n... \nout\nid         0         1         2         3\nid                                        \n0   1.000000  0.666667  1.000000  1.000000\n1   0.666667  1.000000  0.666667  0.666667\n2   1.000000  0.666667  1.000000  1.000000\n3   1.000000  0.666667  1.000000  1.000000\n"], ["from itertools import product\nl = len(df)\nnew_df = pd.DataFrame(data = np.array(list(map(lambda arr: np.isin(*arr),\n                                                product(df['list_of_value'],\n                                                        repeat=2))))\n                               .mean(axis=1).reshape(l,-1),\n                      index = df['id'],\n                      columns=df['id'])\n\nid         0         1         2         3\nid                                        \n0   1.000000  0.666667  1.000000  1.000000\n1   0.666667  1.000000  0.666667  0.666667\n2   1.000000  0.666667  1.000000  1.000000\n3   1.000000  0.666667  1.000000  1.000000\n"], [], ["from dotenv import load_dotenv\nimport os\n\nload_dotenv()\n\nSSL = os.getenv(\"SSL\").lower() == 'true'\nPORT = int(os.getenv(\"PORT\", 5555)) # <-- can also set default\n\n# Check all your other variables and expected keys here...\n", "import config\n\nif not config.SSL:\n    print(\"Connecting w/o SSL!\")\nif 65535 < config.PORT:\n    print(\"Invalid port!\")\n"], ["from scipy.signal import find_peaks\n\ntest03 = np.array([2,2,10,4,4,4,5,6,7,2,6,5,5,7,7,1,1])\nfind_peaks(test03)\n\nOut[]: (array([ 2,  8, 10, 13], dtype=int64), {})\n", "test04 = np.array([1,1,5,5,5,5,5,5,5,5,1,1,1,1,1,5,5,5,1,5,1,5,1])\nfind_peaks(test04, width=1)\n\nOut[]: \n(array([ 5, 16, 19, 21], dtype=int64),\n {'prominences': array([4., 4., 4., 4.]),\n  'left_bases': array([ 1, 14, 18, 20], dtype=int64),\n  'right_bases': array([10, 18, 20, 22], dtype=int64),\n  'widths': array([8., 3., 1., 1.]),\n  'width_heights': array([3., 3., 3., 3.]),\n  'left_ips': array([ 1.5, 14.5, 18.5, 20.5]),\n  'right_ips': array([ 9.5, 17.5, 19.5, 21.5])})\n"], ["(\n    df.assign(s = df.list_of_value.apply(set))\n    .pipe(lambda x: pd.DataFrame([[len(e&f)/len(e) for f in x.s] for e in x.s]))\n)\n\n    0           1           2           3\n0   1.000000    0.666667    1.000000    1.000000\n1   0.666667    1.000000    0.666667    0.666667\n2   1.000000    0.666667    1.000000    1.000000\n3   1.000000    0.666667    1.000000    1.000000\n"], ["[[int(''.join(list(set(str(i))))) for i in x] for x in new]\n"], ["range_of_ids = range(len(ids))\n\ndef score_calculation(s_id1,s_id2):\n    s1 = set(list(df.loc[df['id'] == ids[s_id1]]['list_of_value'])[0])\n    s2 = set(list(df.loc[df['id'] == ids[s_id2]]['list_of_value'])[0])\n    # Resultant calculation s1&s2\n    return round(len(s1&s2)/len(s1) , 2)\n\n\ndic = {indexQFID:  [score_calculation(indexQFID,ind) for ind in range_of_ids] for indexQFID in range_of_ids}\ndfSim = pd.DataFrame(dic)\nprint(dfSim)\n", "     0        1      2       3\n0   1.00    0.67    1.00    1.00\n1   0.67    1.00    0.67    0.67\n2   1.00    0.67    1.00    1.00\n3   1.00    0.67    1.00    1.00\n", "dic = {indexQFID:  [round(len(set(s1)&set(s2))/len(s1) , 2) for s2 in df['list_of_value']] for indexQFID,s1 in zip(df['id'],df['list_of_value']) }\ndfSim = pd.DataFrame(dic)\nprint(dfSim)\n"], [], [], ["[*coords[:,0]].index((2,5))\n", "[*coords.flatten()].index((2,5))//3\n"], ["coords = coords.tolist()\nindex = next((i for i, n in enumerate(coords) if n[0] == (2, 5)), -1)\n", "coords = np.array([[x[0][0], x[0][1], x[1], x[2]] for x in coords])\nindex = np.flatnonzero(np.all(coords[:, :2] == [2, 5], axis=1))\n", "coordt = np.dtype([('x', np.int_), ('y', np.int_)])\ndt = np.dtype([('coord', coordt), ('a', np.int_), ('b', np.int_)])\n\ncoords = np.array([((2, 1), 1613, 655), ((2, 5), 906, 245), ((5, 2), 0, 0)], dtype=dt)\n\nindex = np.flatnonzero(coords['coord'] == np.array((2, 5), dtype=coordt))\n", "coords = np.array(coords[:, 0].tolist())\nindex = np.flatnonzero((coords == [2, 5]).all(axis=1))\n"], ["import numpy as np\ncoords = np.array([[(2, 1), 1613, 655], [(2, 5), 906, 245], [(5, 2), 0, 0]])\ntpl=(2,5)\ni=0 # index of the column in which the tuple you are looking for is listed\n\npos=([t[i] for t in coords].index(tpl))\nprint(pos)\n"], ["np.where([np.array_equal(coords[:, 0][i], (2, 5)) for i in range(len(coords))])[0]\n"], ["a * x1 = b[0]\na * x2 = b[1]\na * x3 = b[2]\n", "a = sum(b[0:3])/sum(x)  # x = [x1, x2, x3]\n", "A_d * x = b[2:]\n", "# choose any initial values\n\nprev = np.ones(4)  ## this includes `a` as the last element\n\nrel_tolerance = 1e-4  # choose a number\nwhile True:\n    x_sol = np.linalg.lstsq(A_d, b[2:])\n    a_sol = sum(b[0:3])/sum(x_sol)\n    sol = np.append(x_sol, a_sol)  \n\n    diff_x = np.abs(sol - prev)\n    # equivalent to max relative difference but avoids 0 division\n    if np.max(diff_x) < rel_tolerance * prev:  \n        break   \n"], ["#You can rewrite matrix A as\n\n[[1, 0, 0],\n [0, 1, 0],\n [0, 0, 1],   * a + \n [0, 0, 0],\n [0, 0, 0]]\n\n[[0, 0, 0],\n [0, 0, 0],\n [0, 0, 0],\n [1, 1, 0],\n [0, 0, 1]]\n\n\n#Define your loss function\ndef lossf(M):\n    Y = np.array([0.4,0.4,0.2,0.1,0.05])\n    a,b,c,d = M\n    A = np.array([[1,0,0],[0,1,0],[0,0,1],[0,0,0],[0,0,0]])*a\n    A = A + np.array([[0,0,0],[0,0,0],[0,0,0],[1,1,0],[0,0,1]])\n    y = A.dot(np.array([b,c,d]).T)\n    return np.sum((Y - y)**2)\n\n#An extra function to calculate the matrix in the end\ndef mat(M):\n    Y = np.array([0.4,0.4,0.2,0.1,0.05])\n    a,b,c,d = M\n    A = np.array([[1,0,0],[0,1,0],[0,0,1],[0,0,0],[0,0,0]])*a\n    A = A + np.array([[0,0,0],[0,0,0],[0,0,0],[1,1,0],[0,0,1]])\n    y = A.dot(np.array([b,c,d]).T)\n    return y\n\nimport numpy as np\nfrom scipy.optimize import least_squares\n\n#this takes some time ** does 100000 rounds which can be changed\n#[0,0,0,0] = random initialization of parameters\nresult = least_squares(lossf,[0,0,0,0], verbose=1, max_nfev = 100000)\n\n\nresult.x #result for parameter estimate\n[6.97838023, 0.05702932, 0.05702932, 0.02908934] # run code and \n\nmat(result.x)\n#The non-linear fit\n[0.39797228, 0.39797228, 0.20299648, 0.11405864, 0.02908934]\n\n#Orignal \n[0.4,0.4,0.2,0.1,0.05]\n\n\n#Also results for other matrix\n#This requires changing the loss function\n#For a permanent solution you can write a flexible loss function\nY = np.array([0.4,0.4,0.2,0.1])\nresult = least_squares(lossf,[0,0,0,0], verbose=1, max_nfev = 10000)\n\n\nresult.x\n[7.14833526, 0.0557289 , 0.0557289 , 0.02797854]\n\nmat(result.x)\n[0.39836889, 0.39836889, 0.2       , 0.11145781]\n#The results are very close to analytical solution\n\n\n\n\n"], ["from collections import deque\nfrom itertools import chain, repeat, starmap\nimport os  \n\ndef bit_lenght_list(n):\n    eights, rem = divmod(n, 8)\n    return chain(repeat(8, eights), (rem,))\n\n\ndef build_bitstring(byte, bit_length):\n    d = deque(\"0\" * 8, 8)\n    d.extend(bin(byte)[2:])\n    return \"\".join(d)[:bit_length]\n\n\ndef bytes_to_bits(byte_string, bits):\n    return \"{!r}B\".format(\n        \" \".join(starmap(build_bitstring, zip(byte_string, bit_lenght_list(bits))))\n    )\n"], [], ["size = int(math.ceil(len(df.columns)**0.5))\nfig, ax = plt.subplots(size, size, figsize=(10, 10))\n\nfor i in range(ax.shape[0]):\n    for j in range(ax.shape[1]):\n        data_index = i*ax.shape[1]+j\n        if data_index < len(df.columns):\n            sns.distplot(df[df.columns.sort_values()[data_index]], ax=ax[i][j])\n\nfor i in range(len(df.columns), size ** 2):\n    fig.delaxes(ax[i // size][i % size])\n"], ["import jmespath\nfrom pprint import pprint\nexpression = jmespath.compile('''{session_id:session_id.*[],\n                                  unix_timestamp : unix_timestamp.*[],\n                                  cities:cities.*[],\n                                  user_id : user.*[][].user_id,\n                                  joining_date : user.*[][].joining_date,\n                                  country : user.*[][].country\n                              }''')\nres = expression.search(data)\npprint(res)\n\n{'cities': ['New York NY, Newark NJ',\n            'New York NY, Jersey City NJ, Philadelphia PA'],\n 'country': ['UK', 'DE'],\n 'joining_date': ['2015-03-22', '2015-03-28'],\n 'session_id': ['X061RFWB06K9V', '5AZ2X2A9BHH5U'],\n 'unix_timestamp': [1442503708, 1441353991],\n 'user_id': [2024, 2853]}\n", "df = (pd.DataFrame(res)\n      .assign(cities = lambda x: x.cities.str.split(','))\n      .explode('cities')\n     )\ndf\n\nsession_id      unix_timestamp  cities       user_id      joining_date  country\n0   X061RFWB06K9V   1442503708  New York NY     2024      2015-03-22    UK\n0   X061RFWB06K9V   1442503708  Newark NJ       2024      2015-03-22    UK\n1   5AZ2X2A9BHH5U   1441353991  New York NY     2853      2015-03-28    DE\n1   5AZ2X2A9BHH5U   1441353991  Jersey City NJ  2853      2015-03-28    DE\n1   5AZ2X2A9BHH5U   1441353991  Philadelphia PA 2853      2015-03-28    DE\n"], ["ab = 0.4,\nac = 0.4,\nad = 0.2,\nb + c = 0.1\n", "(1) + (2) => a(b+c) = 0.8\n(4) b+c = 0.1\n\n=> a=8\n"], [], ["df['Correspond'] = df.lookup(df.index, df['Date'].map(dd))\n", "import pandas as pd\n\nimport numpy as np\n\ninp = [{'Date':2003, 'b1':5,'b2':0,'b3':4,'b4':3},{'Date':2003, 'b1':2,'b2':2,'b3':1,'b4':8},{'Date':2004, 'b1':2,'b2':3,'b3':1,'b4':1},{'Date':2004, 'b1':1,'b2':8,'b3':2,'b4':1},{'Date':2005, 'b1':2,'b2':1,'b3':6,'b4':2},{'Date':2006, 'b1':1,'b2':7,'b3':2,'b4':9}]\ndf = pd.DataFrame(inp)\n\ndd = {2003:'b1', 2004:'b2', 2005:'b3', 2006:'b4'}\n\ndf['Correspond'] = df.lookup(df.index, df['Date'].map(dd))\nprint(df)\n", "   Date  b1  b2  b3  b4  Correspond\n0  2003   5   0   4   3           5\n1  2003   2   2   1   8           2\n2  2004   2   3   1   1           3\n3  2004   1   8   2   1           8\n4  2005   2   1   6   2           6\n5  2006   1   7   2   9           9\n"], ["for file in glob.glob(\"*.csv\"):\n    print(file)\n"], ["import glob\nglob(\"/path/to/my/dir/*.csv\")\n", "import os\n[x for x in os.listdir(\"/path/to/my/dir/\") if x.endswith(\".csv\")]\n", "import os\n[file for root, dirs, files in os.walk(\"/path/to/my/dir/\") for file in files if file.endswith(\".csv\")]\n"], ["the_dir = './'\nfile_list = [f for f in os.listdir(the_dir) if '.csv' in f]\n"], ["from os import listdir\nfrom os.path import isfile, join\nfiles = [f for f in listdir(path) if isfile(join(path, f))]\n        if files:\n            for each_file in files:\n                if each_file.endswith(\".csv\"):\n"], [], ["melted = df.melt(id_vars='Date')\nm = melted.groupby('Date').apply(lambda x: x.variable.eq(Corr_dict[x.name]))\nmelted.loc[m.values]\n\n    Date variable  value\n0   2003       b1      5\n1   2003       b1      2\n10  2005       b2      1\n11  2006       b2      7\n19  2003       b4      8\n"], ["import numpy as np\n\n# initialize the new column\ndf['b5'] = np.nan\ndf['b5'] = df['b5'].astype('Int64')\n\n# modifiy your df in-place row by row\nfor idx, row in df.iterrows():\n    date = row['Date']\n    value = Corr_dict[date]\n    df.at[idx, 'b5'] = row[value]\n", "    Date    b1  b2  b3  b4  b5\n0   2003    5   0   4   3   5\n1   2003    2   2   1   8   2\n2   2004    2   3   1   1   3\n3   2004    1   8   2   1   8\n4   2005    2   1   6   2   2\n5   2006    1   7   2   9   2\n"], ["def extract(df, year):\n    min_year = df['Date'].min()\n    return df.loc[df['Date']==year, df.columns[year+1 - min_year]]\n\nextract(df, 2003)\n# 0    5\n# 1    2\n# Name: b1, dtype: int64\n", "pd.concat(extract(df, year).rename('new_col') for year in df['Date'].unique())\n", "0    5\n1    2\n2    3\n3    8\n4    6\n5    9\nName: new_col, dtype: int64\n"], ["import numpy as np\n\ncol  = df['Date']\n\nconditions = [(col.eq(2003)), (col.eq(2004)),(col.eq(2005)),(col.eq(2006))]\n\nchoices = [df['b1'],df['b2'],df['b3'],df['b4']]\n\ndf['vals'] = np.select(conditions,choices,default=np.nan)\n\nprint(df)\n\n\n   Date  b1  b2  b3  b4  vals\n0  2003   5   0   4   3   5.0\n1  2003   2   2   1   8   2.0\n2  2004   2   3   1   1   3.0\n3  2004   1   8   2   1   8.0\n4  2005   2   1   6   2   6.0\n5  2006   1   7   2   9   9.0\n"], ["s=df.set_index('Date').stack()\ndf['New']=s[s.index.isin(list(d.items()))].values\n"], ["def bytest_to_bit(by, n):\n    bi = \"{:0{l}b}\".format(int.from_bytes(by, byteorder='big'), l=len(by) * 8)[:n]\n    return ' '.join([bi[i:i + 8] for i in range(0, len(bi), 8)])\n\nbytest_to_bit(b'\\xff\\xff\\xff\\xff\\xf0\\x00', 45)\n", "'11111111 11111111 11111111 11111111 11110000 00000'\n", "def bytest_to_bit(by, n):\n    bi = ' '.join(map('{:08b}'.format, by))\n    return bi[:n + len(by) - 1].rstrip()\n\nbytest_to_bit(b'\\xff\\xff\\xff\\xff\\xf0\\x00', 45)\n"], ["def bytes2binstr(b, n=None):\n    s = ' '.join(f'{x:08b}' for x in b)\n    return s if n is None else s[:n + n // 8 + (0 if n % 8 else -1)]\n", "func = bytes2binstr\nargs = (\n    (b'\\x80\\x00', None),\n    (b'\\x80\\x00', 14),\n    (b'\\x0f\\x00', 14),\n    (b'\\xff\\xff\\xff\\xff\\xf0\\x00', 16),\n    (b'\\xff\\xff\\xff\\xff\\xf0\\x00', 22),\n    (b'\\x0f\\xff\\xff\\xff\\xf0\\x00', 45),\n    (b'\\xff\\xff\\xff\\xff\\xf0\\x00', 45),\n)\nfor arg in args:\n    print(arg)\n    print(repr(func(*arg)))\n# (b'\\x80\\x00', None)\n# '10000000 00000000'\n# (b'\\x80\\x00', 14)\n# '10000000 000000'\n# (b'\\x0f\\x00', 14)\n# '00001111 000000'\n# (b'\\xff\\xff\\xff\\xff\\xf0\\x00', 16)\n# '11111111 11111111'\n# (b'\\xff\\xff\\xff\\xff\\xf0\\x00', 22)\n# '11111111 11111111 111111'\n# (b'\\x0f\\xff\\xff\\xff\\xf0\\x00', 45)\n# '00001111 11111111 11111111 11111111 11110000 00000'\n# (b'\\xff\\xff\\xff\\xff\\xf0\\x00', 45)\n# '11111111 11111111 11111111 11111111 11110000 00000'\n", "def bytes2binstr_frombytes(b, n=None, k=8):\n    s = '{x:0{m}b}'.format(m=len(b) * 8, x=int.from_bytes(b, byteorder='big'))[:n]\n    return ' '.join([s[i:i + k] for i in range(0, len(s), k)])\n"], ["`g.map(sns.distplot)` or `g.map_diag(plt.scatter)`\n"], ["fig, ax = plt.subplots(2, 2, figsize=(10, 10))\n\nfor i in range(ax.shape[0]):\n    for j in range(ax.shape[1]):\n        sns.distplot(df[df.columns[i*2+j]], ax=ax[i][j])\n"], [], ["g = sns.FacetGrid(df.melt(), col='variable', col_wrap=2)\ng.map(plt.hist, 'value')\n"], ["s_list =  df.list_of_value.map(set)\noverlap = [[len(s1 & s) for s1 in s_list] for s in s_list]\n\ndf_final = pd.DataFrame(overlap) / df.list_of_value.str.len().to_numpy()[:,None]\n\nOut[76]:\n          0         1         2         3\n0  1.000000  0.666667  1.000000  1.000000\n1  0.666667  1.000000  0.666667  0.666667\n2  1.000000  0.666667  1.000000  1.000000\n3  1.000000  0.666667  1.000000  1.000000\n", "sample df:\nid     list_of_value\n0      ['a','a','c'] #changed\n1      ['d','b','a'] #changed\n2      ['a','b','c']\n3      ['a','b','c']\n\nfrom collections import Counter\n\nc_list =  df.list_of_value.map(Counter)\nc_overlap = [[sum((c1 & c).values()) for c1 in c_list] for c in c_list]\n\ndf_final = pd.DataFrame(c_overlap) / df.list_of_value.str.len().to_numpy()[:,None]\n\n\n Out[208]:\n          0         1         2         3\n0  1.000000  0.333333  0.666667  0.666667\n1  0.333333  1.000000  0.666667  0.666667\n2  0.666667  0.666667  1.000000  1.000000\n3  0.666667  0.666667  1.000000  1.000000\n"], [], [], [" for isin in re.findall(isin_regex, text):\n     If check_isin(isin):\n         print('ISIN found: %s' % isin)\n"], [], ["def find_ISIN(S):\n    ISIN_list = []\n    for i in range(len(S) - 12):\n        if S[i:i+2].isalpha() and S[i+2:i+12].isdigit():\n            ISIN_list.append(S[i:i+12])    \n    return ISIN_list\n", "S = 'LU1234567890-SU1234567890f$3121'\nprint(find_ISIN(S))\n", "def find_ISIN(S):\n    ISIN_list = []\n    i = 0\n    while i <= len(S) - 12:\n        if S[i:i+2].isalpha() and S[i+2:i+12].isdigit():\n            ISIN_list.append(S[i:i+12])\n            i += 12\n        else:\n            i += 1\n    return ISIN_list\n"], [], ["\\b[A-Z]{2}\\d{10}\\b\n", "import re\n\nfor number in re.finditer(r'\\b[A-Z]{2}\\d{10}\\b', your_actual_string):\n    print(number.group(0))\n"], ["import re\n"], [], [], [], ["from itertools import zip_longest\n\nkeys = d.keys()\n\nd2 = [\n    {k: v for k, v in zip(keys, vs) if v is not None}\n    for vs in <b>zip_longest(*d.values())</b>\n]", "from itertools import zip_longest\n\nkeys = d.keys()\ndummy = object()\n\nd2 = [\n    {k: v for k, v in zip(keys, vs) if v is not dummy}\n    for vs in <b>zip_longest(*d.values(), fillvalue=dummy)</b>\n]", ">>> d2\n[{'name': 'bob', 'age': 13, 'height': 164, 'job': 'programmer'}, {'name': 'john', 'age': 19, 'height': 188}, {'name': 'harry', 'age': 23}, {'name': 'mary'}]\n"], [], ["10000000 000000\n11111111 11111111 11111111 11111111 11110000 00000\n"], [], [], ["frame.iloc[[x for x in range(len(frame)) if set(letters).issubset(frame.iloc[x,0])]]\n", "        a\n 0  a,b,c\n 1  a,c,f\n 3  a,z,c\n", "%%timeit\n#hermes\nframe.iloc[[x for x in range(len(frame)) if set(letters).issubset(frame.iloc[x,0])]]\n"], ["rainfall_mi = \"1.65, 1.46, 2.05, 3.03, 3.35, 3.46, 2.83, 3.23, 3.5, 2.52, 2.8, 1.85\"\n\nrainfall_mi_list = rainfall_mi.split(\", \")\n\nnum_rainy_months = 0\nfor n in range(0, len(rainfall_mi_list)):\n    if float(rainfall_mi_list[n]) > 3: \n        num_rainy_months += 1\n\nprint(num_rainy_months)\n"], ["class MoviesViewSet(viewsets.ModelViewSet):\n    queryset            = Movie.objects.all()\n    serializer_class    = MovieSerializer\n    permission_classes  = [IsAuthenticated, ]\n\n    def get_queryset(self):\n        return self.queryset\n\n    def get_object(self):\n        movie_id = self.kwargs['pk']\n        return self.get_queryset().filter(id=movie_id)\n\n    def retrieve(self, request, *args, **kwargs):\n        try:\n            instance = self.get_object()\n        except (Movie.DoesNotExist, KeyError):\n            return Response({\"error\": \"Requested Movie does not exist\"}, status=status.HTTP_404_NOT_FOUND)\n        serializer = self.get_serializer(instance)\n        return Response(serializer.data)\n\n    def list(self, request, *args, **kwargs):\n        queryset    = self.get_queryset()\n        serializer  = self.get_serializer(queryset, many=True)\n        return Response(serializer.data)\n", "class MovieSerializer(serializers.ModelSerializer):\n    class Meta:\n        model   = Movie\n        fields  = '__all__'\n"], ["[packages]\nDjango = \"*\"\ndjangorestframework = \"*\"\niso8601 = \"*\"\ngraypy = \"*\"\nwhitenoise = \"*\"\n\n[requires]\npython_version = \"3.7\"\n"], ["os.path.split(os.path.split(path)[0])[1]\n", "path.parent.name\n", "os.path.basename(os.path.dirname(path))\n"], ["(?<!\\S)india[^\\w\\r\\n]*(?!\\S)\n"], ["(?<![^ .,?!;])india(?![^ .,?!;\\r\\n])\n", "(?<!             # begin a negative lookbehind\n  [^ .,?!;]      # match 1 char other than those in \" .,?!;\"\n)                # end the negative lookbehind\nindia            # match string\n(?!              # begin a negative lookahead   \n  [^ .,?!;\\r\\n]  # match 1 char other than those in \" .,?!;\\r\\n\"\n)                # end the negative lookahead\n"], ["chrs = (chr(i) for i in range(sys.maxunicode + 1))\npunctuation = set(c for c in chrs if category(c).startswith(\"P\"))\n"], ["import re\n\ns = \"india.\"\ns1 = \"indiana\"\nprint(re.search(r'\\bindia[.!?]*\\b', s))\nprint(re.search(r'\\bindia[.!?]*\\b', s1))\n", "<re.Match object; span=(0, 5), match='india'>\nNone\n"], ["r'\\bindia\\W*\\b'\n", "re.search(r'\\bindia\\W*\\b', my_string, re.IGNORECASE).group(0)\n"], [], ["\\\"india(\\W*?)\\\" \n"], ["    import re\n    text = re.sub(r\"[^\\w\\s]\", \"\", str(text), flags=re.UNICODE)\n"], [], ["from pathlib import Path\n\np = Path(\"C:/example/folder/file1.jpg\")\nprint(p.parent.name)  # folder\n"], ["from pathlib import Path\npath = \"C:/example/folder/file1.jpg\"\n", "parent_lv1 = Path(path).parent\n", "parent_lv2 = parent_lv1.parent\n", "imm_parent = parent_lv1.relative_to(parent_lv2)\nprint(imm_parent)\n"], ["path = \"C:/example/folder/file1.jpg\"\ndirectoryName = os.path.dirname(path) \nparent = directoryName.split(\"/\")\nparent.reverse()\nprint(parent[0])\n\n\n"], ["cool\ndumb\n"], ["s = df['Found_IDs'].explode()\ndf['bad_ids'] = s.isin(bad_ids).groupby(s.index).any()\n", ">>> df\n      ID                   Found_IDs  bad_ids\n0  12345        [15443, 15533, 3433]     True\n1  15533  [2234, 16608, 12002, 7654]    False\n2   6789      [43322, 876544, 36789]     True\n", "s = df['Found_IDs'].explode()\ns.where(s.isin(bad_ids)).groupby(s.index).agg(lambda x: list(x.dropna()))\n", "      ID                   Found_IDs   bad_ids\n0  12345        [15443, 15533, 3433]   [15533]\n1  15533  [2234, 16608, 12002, 7654]        []\n2   6789      [43322, 876544, 36789]  [876544]\n"], ["bad_ids = [15533, 876544]\n\ndf['bad_id'] = [any(c in l for c in bad_ids) for l  in df['Found_IDs']]\nprint (df)\n      ID                   Found_IDs  bad_id\n0  12345        [15443, 15533, 3433]    True\n1  15533  [2234, 16608, 12002, 7654]   False\n2   6789      [43322, 876544, 36789]    True\n", "df['bad_id'] = [[c for c in bad_ids if c in l] for l  in df['Found_IDs']]\nprint (df)\n      ID                   Found_IDs    bad_id\n0  12345        [15443, 15533, 3433]   [15533]\n1  15533  [2234, 16608, 12002, 7654]        []\n2   6789      [43322, 876544, 36789]  [876544]\n", "df['bad_id'] = [next(iter([c for c in bad_ids if c in l]), False) for l  in df['Found_IDs']]\nprint (df)\n      ID                   Found_IDs  bad_id\n0  12345        [15443, 15533, 3433]   15533\n1  15533  [2234, 16608, 12002, 7654]   False\n2   6789      [43322, 876544, 36789]  876544\n", "df['bad_id'] = df['Found_IDs'].map(set(bad_ids).intersection)\nprint (df)\n\n      ID                   Found_IDs    bad_id\n0  12345        [15443, 15533, 3433]   {15533}\n1  15533  [2234, 16608, 12002, 7654]        {}\n2   6789      [43322, 876544, 36789]  {876544}\n", "df['bad_id'] = [list(set(bad_ids).intersection(l)) for l  in df['Found_IDs']]\nprint (df)\n      ID                   Found_IDs    bad_id\n0  12345        [15443, 15533, 3433]   [15533]\n1  15533  [2234, 16608, 12002, 7654]        []\n2   6789      [43322, 876544, 36789]  [876544]\n"], ["bad_ids = [15533, 876544, 36789, 11111]\n\ndf2 = pd.concat(\n    [\n        df,\n        pd.merge(\n            df[\"Found_IDs\"].explode().reset_index(),\n            pd.Series(bad_ids, name=\"bad_ids\"),\n            left_on=\"Found_IDs\",\n            right_on=\"bad_ids\",\n            how=\"inner\",\n        )\n        .groupby(\"index\")\n        .agg(bad_ids=(\"bad_ids\", list)),\n    ],\n    axis=1,\n).fillna(False)\nprint(df2)\n\n\n      ID                   Found_IDs          bad_ids\n0  12345        [15443, 15533, 3433]          [15533]\n1  15533  [2234, 16608, 12002, 7654]            False\n2   6789      [43322, 876544, 36789]  [876544, 36789]\n"], ["df['bad_id'] = df['Found_IDs'].apply(lambda x: np.intersect1d(x, bad_ids))\n\n      ID                   Found_IDs    bad_id\n0  12345        [15443, 15533, 3433]   [15533]\n1  15533  [2234, 16608, 12002, 7654]        []\n2   6789      [43322, 876544, 36789]  [876544]\n", "bad_ids_set = set(bad_ids)\ndf['Found_IDs'].apply(lambda x: list(set(x) & bad_ids_set))\n"], ["df['bad_id'] = df['Found_IDs'].apply(lambda x: np.any([c in x for c in bad_ids]))\n", "df['bad_id'] = df['Found_IDs'].apply(lambda x: [*filter(lambda x: c in x, bad_ids)])\n"], ["import numbers\n\nclass Complex:\n    def __add__(self, other):\n        if isinstance(self, Complex):\n            ...\n        elif isinstance(other, numbers.Real):\n            ...\n        else:\n            raise TypeError\n\n    def __radd__(self, other):\n        return self + other\n"], [], ["frame = pd.DataFrame({'a' : ['a,b,c', 'a,c,f', 'b,d,f','a,z,c','x,y']})\nletters = ['a','c']\n\nframe[frame['a'].apply(lambda x: set(letters).issubset(x))]\n\nOut:\n\n       a\n0  a,b,c\n1  a,c,f\n3  a,z,c\n"], ["def serge(frame):\n    contains = [frame['a'].str.contains(i) for i in letters]\n    return frame[np.all(contains, axis=0)]\n\ndef yatu(frame):\n    letters_s = set(letters)\n    return frame[frame.a.str.split(',').map(letters_s.issubset)]\n\ndef austin(frame):\n    mask =  frame.a.apply(lambda x: np.intersect1d(x.split(','), letters).size > 0)\n    return frame[mask]\n\ndef datanovice(frame):\n    s = frame['a'].str.split(',').explode().isin(letters).groupby(level=0).cumsum()\n    return frame.loc[s[s.ge(2)].index.unique()]\n\nperfplot.show(\n    setup=lambda n: pd.concat([frame]*n, axis=0).reset_index(drop=True), \n\n    kernels=[\n        lambda df: serge(df),\n        lambda df: yatu(df),\n        lambda df: df[df['a'].apply(lambda x: np.all([*map(lambda l: l in x, letters)]))],\n        lambda df: austin(df),\n        lambda df: datanovice(df),\n    ],\n\n    labels=['serge', 'yatu', 'bruno','austin', 'datanovice'],\n    n_range=[2**k for k in range(0, 18)],\n    equality_check=lambda x, y: x.equals(y),\n    xlabel='N'\n)\n"], ["pip install scikit-image==0.13.1\npip install numpy==1.15\n"], ["frame[frame['a'].apply(lambda x: np.all([*map(lambda l: l in x, letters)]))]\n"], ["import pandas as pd\nimport numpy as np\n\nframe = pd.DataFrame({'a' : ['a,b,c', 'a,c,f', 'b,d,f','a,z,c']})\nletters = ['a','c']\n\nmask =  frame.a.apply(lambda x: np.intersect1d(x.split(','), letters).size > 0)\nprint(frame[mask])\n\n    a\n0  a,b,c\n1  a,c,f\n3  a,z,c\n"], ["s = frame['a'].str.split(',').explode().isin(letters).groupby(level=0).cumsum()\n\nprint(s)\n\n0    1.0\n0    1.0\n0    2.0\n1    1.0\n1    2.0\n1    2.0\n2    0.0\n2    0.0\n2    0.0\n3    1.0\n3    1.0\n3    2.0\n", "frame.loc[s[s.ge(2)].index.unique()]\n\nout:\n\n       a\n0  a,b,c\n1  a,c,f\n3  a,z,c\n"], ["contains = [frame['a'].str.contains(i) for i in letters]\nresul = frame[np.all(contains, axis=0)]\n", "       a\n0  a,b,c\n1  a,c,f\n3  a,z,c\n"], ["from itertools import zip_longest\n\na = [1,2,3,4,5]\nb = [1.5, 2.5, 3.5, 4.5]\nflat_list = [val for sublist in zip_longest(a,b) for val in sublist if val]\n"], [], ["from itertools import cycle, islice\ndef roundrobin(*iterables):\n    \"roundrobin('ABC', 'D', 'EF') --> A D E B F C\"\n    # Recipe credited to George Sakkis\n    pending = len(iterables)\n    nexts = cycle(iter(it).__next__ for it in iterables)\n    while pending:\n        try:\n            for next in nexts:\n                yield next()\n        except StopIteration:\n            pending -= 1\n            nexts = cycle(islice(nexts, pending))\n\na = [1, 2, 3, 4, 5]\nb = [10, 20, 30, 40]\nab = list(roundrobin(a,b))\nprint(ab)\n", "[1, 10, 2, 20, 3, 30, 4, 40, 5]\n"], [], ["first = [1, 2, 3, 4, 5]\nsecond = []\nfor i in range(0, len(first) - 1):\n    avg = (first[i] + first[i+1]) / 2\n    second.append(first[i])\n    second.append(avg)\nsecond.append(first[-1])\n\nprint(second)\n", "[1, 1.5, 2, 2.5, 3, 3.5, 4, 4.5, 5]\n"], ["sum_array1 =\"\"\nfor string1 in array1:\n    sum_array1 = sum_array1 + string1 + \",\"\nmissing = [string2 for string2 in array2 if string2 not in sum_array1]\nif missing:                                                                     \n    for string in missing:                                                      \n        print(\"No key for value: \" + string)                                    \nelse:                                                                           \n    print(\"All elements of array2 exist in array1\")\n"], ["def missing(arr1, arr2):\n    #arr1 is the array of strings to be searched\n    #arr2 is the array of substrings\n    notFound=\"\"\n    for i in arr2: # i = each element in array 2\n        for j in arr1: # j = each element in array 1\n            if i in j: # if substring of i is in an element in j\n                break # moves onto next element in the array\n            elif j == arr1[-1]: # if not found in the string, checks if  on the last item in the array.\n                notFound = notFound+\" \"+i\n    if notFound != \"\":\n        print(\"No key for value:\", notFound)\n    else:\n        print(\"all elements of array2 exist in array1\")\n"], ["array1 = ['key/value/one123904', 'key/value/two342389', 'key/value/three234093']\narray2 = ['one', 'two', 'three', 'four']\n\n\ndef does_match_in_array_of_string(key: str, search_list : list) -> bool:\n    for item in search_list:\n        if key in item:\n            return True\n    return False;\n\n\nmatch_failures = [key for key in array2 if not does_match_in_array_of_string(key, array1)]\n\nif len(match_failures):\n    print(f'No key for values: {match_failures}')\nelse:\n    print('All keys have values')\n"], ["for string in array2:\n    if not any(string in key_string for key_string in array1):\n        print(\"No key for value: \" + string)\n        break                                                                   \nelse:                                                                           \n    print(\"All elements of array2 exist in array1\")\n", "missing = [string for string in array2                                          \n           if not any(string in ks for ks in array1)]                           \nif missing:                                                                     \n    for string in missing:                                                      \n        print(\"No key for value: \" + string)                                    \nelse:                                                                           \n    print(\"All elements of array2 exist in array1\")\n"], ["print(\n    \"No key for value(s): {}\".format(\n        \" \".join([k for k in array2 if not any(k in v for v in array1) ])\n    )\n)\n", "no_match = [k for k in array2 if not any(k in v for v in array1) ]\nprint(\n    \"No key for value(s): {}\".format(\" \".join(no_match))\n    if no_match\n    else \"All keys have values\"\n)\n"], ["for word_letter in word:\n    if word_letter == letter:\n        word2.append(word_letter)\n    else:\n        word2.append(\"\")\n", "for word_letter in word:\n    word2.append(word_letter if word_letter == letter else \"\")\n", "word2 = [word_letter if word_letter == letter else \"\" for word_letter in word]\n", "tries = []\nword = ['H', 'E', 'L', 'L', 'O']\nword2 = [word_letter if word_letter in tries else \"\" for word_letter in word]\n\nwhile \"\" in word2:  # a letter is still empty\n    letter = input(\"Try a letter :\")\n    tries.append(letter)\n    word2 = [word_letter if word_letter in tries else \"\" for word_letter in word]\n    print(\"Word is now\", word2)\n"], ["def keepL(letter): return letter if letter == \"L\" else \"\"\n\nword2 = [ keepL(letter) for letter in word ]\n", "word2 = [ letter*(letter==\"L\") for letter in word ]\n"], ["letter = 'L'\nword = 'HELLO'\n\nword2 = ''.join(c if c == letter else ' ' for c in word)\n"], ["letter = 'L'  \nword = ['H','E','L','L','O']  \n\nindices = [i for i, w in enumerate(word) if w == letter]\nnew_word = [''] * len(word)\nfor i in indices:\n  new_word[i] = letter\nprint(new_word)\n", "letter = 'L'  \nword = ['H','E','L','L','O']\nnew_word = map(lambda w: letter if w == letter else '', word)\nprint(new_word)\n"], ["letter = 'L'\nword = ['H','E','L','L','O']\nword2 = [w if w == letter else '' for w in word]\nword2\n", "['', '', 'L', 'L', '']\n", "word2 = []\nfor w in word:  \n    if w  == letter:\n        word2.append(letter)\n    else:\n        word2.append('')\n"], ["dataset[dataset['ter_id'].str.slice(-6) != '000000']\n"], ["df = dataset[dataset.ter_id.str[-6:] != \"000000\"]\nprint (df)\n          ter_id shstr value\n8  2018002000002   201   2.0\n"], [], ["df = df.loc[df[\"ter_id\"].str[-6:] != \"000000\"]\n"], ["df[~(df.ter_id%1000000==0)]\nOut[256]: \n          ter_id  shstr  value\n8  2018002000002    201    2.0\n"], ["data = [d for _, g in groupby(data, lambda d: d[0]) for d in [*g][::-1]]\n", "import datetime\nfrom decimal import Decimal\nfrom itertools import groupby\n\ndata = [\n[datetime.date(2019, 3, 29), Decimal('44819.75')],\n[datetime.date(2019, 3, 29), Decimal('45000.00')],\n[datetime.date(2019, 3, 28), Decimal('0.00')],\n[datetime.date(2019, 3, 22), Decimal('-275.00')],\n[datetime.date(2019, 3, 22), Decimal('-350.00')],\n[datetime.date(2019, 3, 22), Decimal('-175.00')]\n]\n\ndata = [d for _, g in groupby(data, lambda d: d[0]) for d in [*g][::-1]]\n\nfor d in data:\n    print(d)\n", "[datetime.date(2019, 3, 29), Decimal('45000.00')]\n[datetime.date(2019, 3, 29), Decimal('44819.75')]\n[datetime.date(2019, 3, 28), Decimal('0.00')]\n[datetime.date(2019, 3, 22), Decimal('-175.00')]\n[datetime.date(2019, 3, 22), Decimal('-350.00')]\n[datetime.date(2019, 3, 22), Decimal('-275.00')]\n"], ["data.sort(key=lambda d: d[0])\ndata.reverse()\n", "import datetime\nfrom decimal import Decimal\n\ndata = [\n[datetime.date(2019, 3, 29), Decimal('44819.75')],\n[datetime.date(2019, 3, 29), Decimal('45000.00')],\n[datetime.date(2019, 3, 28), Decimal('0.00')],\n[datetime.date(2019, 3, 22), Decimal('-275.00')],\n[datetime.date(2019, 3, 22), Decimal('-350.00')],\n[datetime.date(2019, 3, 22), Decimal('-175.00')]\n]\n\ndata.sort(key=lambda d: d[0])\ndata.reverse()\n\nfor d in data:\n    print(d)\n", "[datetime.date(2019, 3, 29), Decimal('45000.00')]\n[datetime.date(2019, 3, 29), Decimal('44819.75')]\n[datetime.date(2019, 3, 28), Decimal('0.00')]\n[datetime.date(2019, 3, 22), Decimal('-175.00')]\n[datetime.date(2019, 3, 22), Decimal('-350.00')]\n[datetime.date(2019, 3, 22), Decimal('-275.00')]\n"], ["# Simplified representation.\n# a few random values at the start and then multiple 2's and that the current order is a,b,c\n# We expect all values to be sorted on the integer part first. And that the order for the 2's is c,b,a at the end.\ndata = [\n    [1, '-'],\n    [5, '-'],\n    [3, '-'],\n\n    [2, 'a'],\n    [2, 'b'],\n    [2, 'c']\n]\n\n\ndata = data[::-1]\ndata = sorted(data, key=lambda x:x[0])\n", "[1, '-']\n[2, 'c']\n[2, 'b']\n[2, 'a']\n[3, '-']\n[5, '-']\n", "data = sorted(data, key=lambda x:x[0], reverse=True)\ndata = data[::-1]\n"], ["[value for _, value in sorted(enumerate(dates), key=lambda x: (x[1], -x[0]), reverse=True)]\n", ">>> pprint([val for _, val in sorted(enumerate(seq), key=lambda x: (x[1][0], -x[0]), reverse=True)])\n[[datetime.date(2019, 3, 29), Decimal('44819.75')],\n [datetime.date(2019, 3, 29), Decimal('45000.00')],\n [datetime.date(2019, 3, 28), Decimal('0.00')],\n [datetime.date(2019, 3, 22), Decimal('-275.00')],\n [datetime.date(2019, 3, 22), Decimal('-350.00')],\n [datetime.date(2019, 3, 22), Decimal('-175.00')]]\n"], [">>> from collections import defaultdict\n\n>>> dd = defaultdict(list)\n>>> for x,y in data:\n    dd[x].insert(0,y) #key is date, value is reverse list of Decimals for each date\n>>> dd\ndefaultdict(<type 'list'>, {datetime.date(2019, 3, 29): [Decimal('45000.00'), Decimal('44819.75')], datetime.date(2019, 3, 28): [Decimal('0.00')], datetime.date(2019, 3, 22): [Decimal('-175.00'), Decimal('-350.00'), Decimal('-275.00')]})\n>>> dataout = [[x,y] for x in sorted(dd.keys(),reverse=True) for y in dd[x]]\n>>> dataout\n[\n [datetime.date(2019, 3, 29), Decimal('45000.00')],\n [datetime.date(2019, 3, 29), Decimal('44819.75')],\n [datetime.date(2019, 3, 28), Decimal('0.00')],\n [datetime.date(2019, 3, 22), Decimal('-175.00')],\n [datetime.date(2019, 3, 22), Decimal('-350.00')],\n [datetime.date(2019, 3, 22), Decimal('-275.00')]\n]\n"], ["... import datetime\n... from decimal import Decimal\n... from operator import itemgetter\n... from itertools import groupby, chain\n... \n... data = [\n...     [datetime.date(2019, 3, 29), Decimal('44819.75')],\n...     [datetime.date(2019, 3, 29), Decimal('45000.00')],\n...     [datetime.date(2019, 3, 28), Decimal('0.00')],\n...     [datetime.date(2019, 3, 22), Decimal('-275.00')],\n...     [datetime.date(2019, 3, 22), Decimal('-350.00')],\n...     [datetime.date(2019, 3, 22), Decimal('-175.00')]\n... ]\n... date_sorted_data = sorted(data, key=itemgetter(0), reverse=True)\n... \n... result = list(\n...     chain.from_iterable(\n...         [\n...             reversed(list(g)) \n...             for k, g in groupby(\n...                 date_sorted_data, key=itemgetter(0)\n...             )\n...         ]\n...     )\n... )\n... \n... print(result)\n... \n[[datetime.date(2019, 3, 29), Decimal('45000.00')], [datetime.date(2019, 3, 29), Decimal('44819.75')], [datetime.date(2019, 3, 28), Decimal('0.00')], [datetime.date(2019, 3, 22), Decimal('-175.00')], [datetime.date(2019, 3, 22), Decimal('-350.00')], [datetime.date(2019, 3, 22), Decimal('-275.00')]]\n"], ["In [4]: dates = [\n   ...: [datetime.date(2019, 3, 29), Decimal('44819.75')],\n   ...: [datetime.date(2019, 3, 29), Decimal('45000.00')],\n   ...: [datetime.date(2019, 3, 28), Decimal('0.00')],\n   ...: [datetime.date(2019, 3, 22), Decimal('-275.00')],\n   ...: [datetime.date(2019, 3, 22), Decimal('-350.00')],\n   ...: [datetime.date(2019, 3, 22), Decimal('-175.00')]\n   ...: ]\n\nIn [5]: sorted(dates, key=lambda x: (x[0].day, x[1]), reverse=True)\n\nOut[5]:\n[[datetime.date(2019, 3, 29), Decimal('45000.00')],\n [datetime.date(2019, 3, 29), Decimal('44819.75')],\n [datetime.date(2019, 3, 28), Decimal('0.00')],\n [datetime.date(2019, 3, 22), Decimal('-175.00')],\n [datetime.date(2019, 3, 22), Decimal('-275.00')],\n [datetime.date(2019, 3, 22), Decimal('-350.00')]]\n"], [], ["    > pip uninstall tensorflow-tensorboard \n    > pip uninstall tensorflow-gpu\n    > pip install --upgrade tensorflow-gpu\n", "conda update --all\npip install --upgrade tensorflow==2.0.0-beta1\n"], ["n=(input(\"How many number you want to insert in a list\"))\nlist=[ ]\nfor i in range(0,n):\n    a=int(input(\"enter elements\"))\n    list.append(a)\n    for i in(list):\n        if(i%3!=0):\n            print(i,\"are not multiply of 3\")\n        else:\n            print(\"multiply of 3\")\n"], ["subfiles = []\nfor dirpath, subdirs, files in os.walk(path):\n    for x in files:\n        if x.endswith(\".txt\"):\n            subfiles.append(os.path.join(dirpath, x))`\n"], ["result = [f\"{x.split(',', 1)[0]},{x.rsplit(',', 1)[1]}\" if x.find(',') > 0 else x\n          for x in strings]\n", "result = pd.Series(result, index=strings.index)\n"], ["s[:3] + s[-1]\n", "refined_list = [ _[:3] + _[-1] for _ in series ]\n"], ["input = pd.Series([\"1, 2, 6, 7, 6\",\n               \"1, 3, 7, 9, 9\",\n               \"1, 1, 3, 5, 6\",\n               \"1, 2, 7, 7, 8\",\n               \"1, 4, 6, 8, 9\",\n               \"1, 2, 6, 8, 8\"])\n", "for line in input:\n    first, last = line[0], line[-1]\n    print(\"first: \" + first + \" last: \" + last)\n", "first: 1 last: 6\nfirst: 1 last: 9\nfirst: 1 last: 6\nfirst: 1 last: 8\nfirst: 1 last: 9\nfirst: 1 last: 8\n", "output = pd.Series()\nfor line in s:\n    first, last = line[0], line[-1]\n    output.at[len(output)] = first, last\n", "0    1, 6\n1    1, 9\n2    1, 6\n3    1, 8\n4    1, 9\n5    1, 8\ndtype: object\n"], [">>> import pandas as pd\n>>> your_series = pd.Series(['1, 2, 6, 7, 6', '1, 3, 7, 9, 9', '1, 1, 3, 5, 6', '1, 2, 7, 7, 8', '1, 4, 6, 8, 9', '1, 2, 6, 8, 8'])\n", ">>> s = your_series.apply(lambda x: ', '.join(map(x.split(',').__getitem__, [0, -1])))\n>>> print(s)\n0    1,  6\n1    1,  9\n2    1,  6\n3    1,  8\n4    1,  9\n5    1,  8\n"], [" series.str.extract('^(\\d+).*\\D(\\d+)$').agg(', '.join, axis=1)\n", " series.str.extract('^(\\d+, ).*\\D(\\d+)$').sum(1)\n", "0    1, 6\n1    1, 9\n2    1, 6\n3    1, 8\n4    1, 9\n5    1, 8\ndtype: object\n"], [], [], ["df['Rate_New'] = df.Rate.apply(lambda x: float(x.replace(\"$\",\"\").replace(\"/Wh\",\"\")))\n", "df[\"Rate\"].str.replace(\"$\",\"\").str.replace(\"/Wh\",\"\")\n", "repl = lambda m: m.group(1)\ndf[\"Rate\"].str.replace(r'\\$(.+?)\\/Wh', repl, regex=True)\n"], ["from collections import Counter\n\ncount = Counter(map(str, ls))\nls = list(filter(lambda x: count[str(x)] == 1, ls))\nls\n", "[[1], [1, 2], [1, 2, 3], [2], [2, 3], [3]]\n"], ["ls = [[1], [1, 2], [1, 2, 3], [], [2], [2, 3], [], [], [3]]\nls = [x for x in ls if x]\n# now ls =  [[1], [1, 2], [1, 2, 3], [2], [2, 3], [3]]\n", "ls = [[1], [1, 2], [1, 2, 3], [], [2], [2, 3], [], [], [3]]\nls = list(filter(None, ls))\n# now ls =  [[1], [1, 2], [1, 2, 3], [2], [2, 3], [3]]\n", "ls = [x for x in ls if x != elem]\n\n##### or #####\n\nls = list(filter(lambda x: x != elem, ls))\n"], ["l = [x for x in ls if x != []]\n", "l = [x for x in ls if x]\n", "l = filter(None, ls)\n"], ["list(filter(None,ls))\n# [[1], [1, 2], [1, 2, 3], [2], [2, 3], [3]]\n", "[lst for lst in ls if lst]\n# [[1], [1, 2], [1, 2, 3], [2], [2, 3], [3]]\n"], ["ls = [[1], [1, 2], [1, 2, 3], [], [2], [2, 3], [], [], [3]]\n[l for l in ls if len(l)!=0]\n"], [], ["while read requirement; do conda install --yes $requirement || pip install $requirement; done < requirements.txt\n", "matplotlib==2.0.0\nnumpy==1.18.1\n"], [], ["export FLASK_ENV=development\n"], ["df[\"Rate_New\"] = df.Rate.str.split(r\"[$/]\").apply(lambda x: x[1]).astype(float)\n", "0    [, 0.25, Wh]\n1    [, 0.25, Wh]\n2    [, 0.25, Wh]\n3    [, 0.25, Wh]\nName: Rate, dtype: object           \n", "0    0.25\n1    0.25\n2    0.25\n3    0.25\nName: Rate, dtype: object\n", "0    0.25\n1    0.25\n2    0.25\n3    0.25\nName: Rate, dtype: float64\n", "       Rate  Rate_New\n0  $0.25/Wh      0.25\n1  $0.25/Wh      0.25\n2  $0.25/Wh      0.25\n3  $0.25/Wh      0.25\n"], ["df[\"Rate_New\"] = df.Rate.str.replace(r\"\\$(.+)/Wh\", lambda m: m.group(1)).astype(float)\n"], ["df[\"Rate_new\"] = df[\"Rate\"].apply(lambda x: x.replace(\"$\", \"\").replace(\"/Wh\", \"\"))\n"], [], ["def extract_rate(rate):\n    return rate.replace('$', '').replace('/Wh', '')\n", "df['Rate_new'] = df.apply(lambda row: extract_rate(row['Rate']), axis = 1)t_rate(row['Rate']), axis = 1)\n"], [], ["import numpy\n\nl1 = ['a', 'b', 'c']\nl2 = ['b', 'c']\nresults = numpy.in1d(l1, l2)\n"], [], ["half = int(sqrt(max)) + 1\n", "half = int(sqrt(x)) + 1\n"], ["import time\nstart_time = time.time()\nbits = [1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0] * 100000\n    ### tested code ###\nprint(\"Execution time: \", time.time() - start_time, \"seconds\")\n\n\n### former solution --> 0.59 seconds\nout_str = \"\"\nfor i in range(0,len(bits),8):\n    x=bits[i:i+8]\n    l=\"\".join([str(j) for j in x[::-1]])\n    out_str += chr(int((\"0b\"+l),base=2))\n\n\n### enumerate and result.append --> 0.48 seconds\nresult = []\nc = 0\nfor i,v in enumerate(bits):\n    i = i % 8\n    c = c | v << i\n    if i == 7:\n        result.append(chr(c))\n        c = 0\nout_str = ''.join(result)\n\n\n### sum and enumerate --> 0.45 seconds\nout_str = \"\"\nfor item in [bits[i:i + 8] for i in range(0, len(bits), 8)]:\n    out_str += chr(sum(x<<i for i,x in enumerate(item)))\n\n\n### map and chars dictionary --> 0.10 seconds\nchars = { tuple(map(int,f\"{n:08b}\"[::-1])):chr(n) for n in range(0,256) }\ndef toChars(bits):\n    return \"\".join(chars[tuple(bits[i:i+8])] for i in range(0,len(bits),8) )\n\n\n### bytes and zip --> 0.06 seconds\nchars = { tuple(map(int,f\"{n:08b}\")):n for n in range(256) }\ndef toChars(bits):\n    return bytes(chars[b] for b in zip(*(bits[7-i::8] for i in range(8)))).decode()\n", "bits = [1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0] * 10\nchars = {tuple(map(int,f\"{n:08b}\")):n for n in range(256)}\ntemp = []\nout = []\nfor i in range(8):\n    temp.append(bits[7-i::8])\nunzipped = zip(*temp)\nfor b in unzipped:\n    out.append(bytes([chars[b]]).decode())\nprint(\"\".join(out))\n"], [], ["bits = [1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0]\n\nchars = { tuple(map(int,f\"{n:08b}\"[::-1])):chr(n) for n in range(0,256) }\n\ndef toChars(bits):\n    return \"\".join(chars[tuple(bits[i:i+8])] for i in range(0,len(bits),8) )\n", "chars = { tuple(map(int,f\"{n:08b}\")):n for n in range(256) }\ndef toChars(bits):\n    return bytes(chars[b] for b in zip(*(bits[7-i::8] for i in range(8)))).decode()\n", " bits[7::8] -> [ 0, 0, ... ]  zip returns: (0,1,0,0,0,1,1)\n bits[6::8] -> [ 1, 1, ... ]               (0,1,1,0,1,1,1)\n bits[5::8] -> [ 0, 1, ... ]               ...\n bits[4::8] -> [ 0, 0, ... ]\n bits[3::8] -> [ 0, 1, ... ]\n bits[2::8] -> [ 0, 1, ... ]\n bits[1::8] -> [ 1, 1, ... ]\n bits[0::8] -> [ 1, 1, ... ] \n"], ["with open(\"old.txt\") as f, open(\"new.txt\", \"w\") as w:\n  for line in f:\n    if \"keyword\" in line:\n      next(f), next(f)\n      continue\n    w.write(line)\n", "with open(\"old.txt\") as f, open(\"new.txt\", \"w\") as w:\n  [w.write(line) if not \"keyword\" in line else [next(f) for _ in range(2)] for line in f]\n"], ["with open('Original_file','r') as f, open('New_file', 'w') as nf\n    for line in f:\n        if 'keyword' in line:\n            for i in range(2): next(f)\n        else:\n            nf.write(line)\n"], [], ["with open('Original_file','r') as f:\n    lines = f.readlines()\n    skip = 0\n    nf = open('New_file', 'w')\n    for line in lines:\n        if skip:\n            skip -=1\n        elif 'keyword' in line:\n            skip = 3\n        else:\n            nf.write(line + \"\\n\")\n"], [], [], ["#!/usr/bin/python                                                                                                                                                                                                                                                                                                                                                         \n\nbits = [1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0]\nresult = []\n\nc = 0\nfor i,v in enumerate(bits):\n    i = i % 8\n    c = c | v << i\n    if i == 7:\n        result.append(chr(c))\n        c = 0\n\nprint(''.join(result))\n", "$ python ./test.py\nCo\n"], ["tmp_list = []\nfor i in range(0,len(output),8):\n    byte_value = 0\n    for digit in output[i:i+8:-1]:\n        byte_value = (byte_value<<1) + digit\n    tmp_list.append(chr(byte_value))\nout_str = ''.join(tmp_list)\n"], ["def to_bin(l):\n    val, length = l\n    bit_str = ''.join(bin(i).replace('0b', '') for i in val)\n    if len(bit_str) < length:\n        # pad with zeros\n        return '0'*(length-len(bit_str)) + bit_str\n    else:\n        # cut to size\n        return bit_str[:length]\n\nbytes_val = [b'\\x80\\x00',14]\nprint(to_bin(bytes_val))\n", "def to_bin(l):\n    val, length = l\n    bit_str = ''.join(bin(ord(i)).replace('0b', '') for i in val)\n    if len(bit_str) < length:\n        # pad with zeros\n        return '0'*(length-len(bit_str)) + bit_str\n    else:\n        # cut to size\n        return bit_str[:length]\n\nbytes_val = [b'\\x80\\x00',14]\nprint(to_bin(bytes_val))\n"], ["# Python3 program to remove the @ from String\n\n\ndef ExceptAtTheRate(string):\n    # Split the String based on the space\n    arrOfStr = string.split()\n\n    # String to store the resultant String\n    res = \"\"\n\n    # Traverse the words and\n    # remove the first @ From every word.\n    for a in arrOfStr:\n        if(a[0]=='@'):\n            res += a[1:len(a)] + \" \"\n        else:\n            res += a[0:len(a)] + \" \"\n\n    return res\n\n\n# Driver code\nstring = \"hello @jon i am @@here or @@@there and want some@thing in '@here\"\n\nprint(ExceptAtTheRate(string))\n"], ["bit_str = ' '.join(bin(i).replace('0b', '') for i in bytes_val)\n"], ["bytes_val = b'\\\\x80\\\\x00'\n\nfor byte in bytes_val:\n    value_in_binary = bin(byte)\n"], ["--touch-reload=/path/to/file.txt\n"], ["if float(i) > 3.0:\n\n    num_rainy_months += 1\n"], ["import numpy as np\n\nindices  = np.arange(x.size)\nzeroes   = x==0\nforward  = indices - np.maximum.accumulate(indices*zeroes)  # forward distance\nforward[np.cumsum(zeroes)==0] = x.size-1                    # handle absence of zero from edge\nforward  = forward * (x!=0)                                 # set zero positions to zero                \n\nzeroes   = zeroes[::-1]\nbackward = indices - np.maximum.accumulate(indices*zeroes) # backward distance\nbackward[np.cumsum(zeroes)==0] = x.size-1                  # handle absence of zero from edge\nbackward = backward[::-1] * (x!=0)                         # set zero positions to zero\n\ndistZero = np.minimum(forward,backward) # closest distance (minimum)\n", "distZero\n# [0, 1, 1, 0, 1, 2, 2, 1, 0, 0]\n\nforward\n# [0, 1, 2, 0, 1, 2, 3, 4, 0, 0]\n\nbackward\n# [0, 2, 1, 0, 4, 3, 2, 1, 0, 0]\n", "x = np.array([3, 1, 2, 0, 4, 5, 6, 0,8,8])\n\nforward:  [9 9 9 0 1 2 3 0 1 2]\nbackward: [3 2 1 0 3 2 1 0 9 9]\ndistZero: [3 2 1 0 1 2 1 0 1 2]\n", "x = [0, 1, 2, 0, 4, 5, 6, 7, 0, 0]\n\nfrom itertools import accumulate\n\nmaxDist  = len(x) - 1\nzeroes   = [maxDist*(v!=0) for v in x]\nforward  = [*accumulate(zeroes,lambda d,v:min(maxDist,(d+1)*(v!=0)))]\nbackward = accumulate(zeroes[::-1],lambda d,v:min(maxDist,(d+1)*(v!=0)))\nbackward = [*backward][::-1]\ndistZero = [min(f,b) for f,b in zip(forward,backward)]                      \n\nprint(\"x\",x)\nprint(\"f\",forward)\nprint(\"b\",backward)\nprint(\"d\",distZero)\n", "x [0, 1, 2, 0, 4, 5, 6, 7, 0, 0]\nf [0, 1, 2, 0, 1, 2, 3, 4, 0, 0]\nb [0, 2, 1, 0, 4, 3, 2, 1, 0, 0]\nd [0, 1, 1, 0, 1, 2, 2, 1, 0, 0]\n", "x = [0, 1, 2, 0, 4, 5, 6, 7, 0, 0]\nforward,backward = [],[]\nfDist = bDist = maxDist = len(x)-1\nfor f,b in zip(x,reversed(x)):\n    fDist = min(maxDist,(fDist+1)*(f!=0))\n    forward.append(fDist)\n    bDist = min(maxDist,(bDist+1)*(b!=0))\n    backward.append(bDist)\nbackward = backward[::-1]\ndistZero = [min(f,b) for f,b in zip(forward,backward)]\n\nprint(\"x\",x)\nprint(\"f\",forward)\nprint(\"b\",backward)\nprint(\"d\",distZero)\n", "x [0, 1, 2, 0, 4, 5, 6, 7, 0, 0]\nf [0, 1, 2, 0, 1, 2, 3, 4, 0, 0]\nb [0, 2, 1, 0, 4, 3, 2, 1, 0, 0]\nd [0, 1, 1, 0, 1, 2, 2, 1, 0, 0]\n"], ["mask_z = x==0\nidx_z = np.flatnonzero(mask_z)\nidx_nz = np.flatnonzero(~mask_z)\n\n# Cover for the case when there's no 0 left to the right\n# (for same results as with posted loop-based solution)\nif x[-1]!=0:\n    idx_z = np.r_[idx_z,len(x)]\n\nout = np.zeros(len(x), dtype=int)\nidx = np.searchsorted(idx_z, idx_nz)\nout[~mask_z] = idx_z[idx] - idx_nz\n", "mask_z = x==0\nidx_z = np.flatnonzero(mask_z)\n\n# Cover for the case when there's no 0 left to the right\nif x[-1]!=0:\n    idx_z = np.r_[idx_z,len(x)]\n\nout = idx_z[np.r_[False,mask_z[:-1]].cumsum()] - np.arange(len(x))\n", "r = np.r_[idx_z[0]+1,np.diff(idx_z)]\nout = np.repeat(idx_z,r)[:len(x)] - np.arange(len(x))\n", "mask_z = x==0\nidx_z = np.flatnonzero(mask_z)\n\npp = np.full(len(x), -1)\npp[idx_z[:-1]] = np.diff(idx_z) - 1\nif idx_z[0]==0:\n    pp[0] = idx_z[1]\nelse:\n    pp[0] = idx_z[0]\nout = pp.cumsum()\n\n# Handle boundary case and assigns 0s at original 0s places\nout[idx_z[-1]:] = np.arange(len(x)-idx_z[-1],0,-1)\nout[mask_z] = 0\n"], ["import numpy as np\n\nx = np.array([0, 1, 2, 0, 4, 5, 6, 7, 0, 0])\n\n# Get the distance to the closest zero from the left:\nzeros = x == 0\nzero_locations = np.argwhere(x == 0).flatten()\nzero_distances = np.diff(np.insert(zero_locations, 0, 0))\n\ntemp = x.copy()\ntemp[~zeros] = 1\ntemp[zeros] = -(zero_distances-1)\nd_left = np.cumsum(temp) - 1\n\n# Get the distance to the closest zero from the right:\nzeros = x[::-1] == 0\nzero_locations = np.argwhere(x[::-1] == 0).flatten()\nzero_distances = np.diff(np.insert(zero_locations, 0, 0))\n\ntemp = x.copy()\ntemp[~zeros] = 1\ntemp[zeros] = -(zero_distances-1)\nd_right = np.cumsum(temp) - 1\nd_right = d_right[::-1]\n\n# Get the smallest distance from both sides:\nsmallest_distances = np.min(np.stack([d_left, d_right]), axis=0)\n# np.array([0, 1, 1, 0, 1, 2, 2, 1, 0, 0])\n"], ["x = np.array([0, 1, 2, 0, 4, 5, 6, 7, 0, 0])\nout = x \ncount = 0 \nhasZero = False \nfor i in range(x.shape[0]-1,-1,-1):\n    if out[i] != 0:\n        if not hasZero: \n            out[i] = x.shape[0]-1\n        else:\n            count += 1\n            out[i] = count\n    else:\n        hasZero = True\n        count = 0\nprint(out)\n"], [" out = [x[i:].index(0) for i,_ in enumerate(x)]\n", " out = [np.where(x[i:]==0)[0][0] for i,_ in enumerate(x)]\n"], ["def run_together(*functions):\n    processes = []\n    for function in functions:\n        process = Process(target=function)\n        process.start()\n        processes.append(process)\n    for process in processes:\n        process.join()\n\n@app.route(\"/first\", methods=[\"POST\"])\ndef main():\n    print(\"Request received\")\n\n    return run_together(func1, func2)\n\ndef func1():\n    time.sleep(100)\n    print(\"Print function executed\")\n\ndef func2():\n    return json.dumps({\"status\": True})\n"], ["import numpy as np \n\n# Setup\ndf = pd.DataFrame({'value': [1, 3, 6, 8, 20, 10000000]})\n\ncondlist = [\n    df['value'].lt(5),\n    df['value'].between(5, 10),\n    df['value'].gt(10)]\n\nchoicelist = ['Below 5', 'between', 'above']\n\ndf['out'] = np.select(condlist, choicelist)\nprint(df)\n", "      value      out\n0         1  Below 5\n1         3  Below 5\n2         6  between\n3         8  between\n4        20    above\n5  10000000    above\n", "df['out'] = pd.cut(df['value'], bins=[-np.inf, 5, 10, np.inf],\n                   labels=['below', 'between', 'above'])\n\n      value      out\n0         1    below\n1         3    below\n2         6  between\n3         8  between\n4        20    above\n5  10000000    above\n"], ["def fun(x):\n    if x in range(0, 5):\n        return 'Below 5'\n    elif x in range(6, 10):\n        return 'between'\n    elif x >= 11:\n        return 'above'\n", "df['range'] = df['value'].map(fun)\n"], ["  range value\n0   0     0\n1   1     1\n2   2     2\n3   3     3\n4   4     4\n5   5     5\n6   6     6\n7   7     7\n8   8     8\n9   9     9\n", "def get_value(range):\n    if range < 5:\n        return 'Below 5'\n    elif range < 10:\n        return 'Between 5 and 10'\n    else:\n        return 'Above 10'\n\ndf['value'] = df.apply(lambda col: get_value(col['range']), axis=1)\n"], ["df['range'] = df['value'].map(range).fillna('above')\n"], [" df['range'] = pd.cut(df['value'], bins = [0, 5, 10, 1000], labels = [\"below 5\", \"between\", \"above\"])\n"], ["range = {\n    range(0, 5) : 'Below 5',\n    range(6,10): 'between',\n\n}\ndf['range'] = 'above'\ndf['range'] = df['value'].map(range)\n"], ["a = [1,2,3,4,5,7,1,2,3,1]\na1_data = []\nfor i in a:\n    if i == 1:\n        i = 10\n        a1_data.append(i)\n    else:\n        a1_data.append(i)\nprint(a1_data)\n"], ["for i in range(len(df)):\n    if(df.loc[i,'column'] == 1):\n        df.at[i, 'column'] = 10\n        Continue;\n"], ["a = [x if x!=1 else 10 for x in a]\n"], ["a_modified = [10 if x == 1 else x for x in a]\n"], ["a = [1, 2, 3, 4, 5, 7, 1, 2, 3, 1, ]\na = [10 if number == 1 else number for number in a]\n", "a = [1, 2, 3, 4, 5, 7, 1, 2, 3, 1, ]\nmapping = {\n# old: new\n  1: 10,\n  2: 20,\n}\na = [mapping.get(number, number) for number in a]\n"], ["a = [1,2,3,4,5,7,1,2,3,1]\nb = [10 if v == 1 else v for v in a]\nprint(b)\n", "[10, 2, 3, 4, 5, 7, 10, 2, 3, 10]\n"], ["a= [1,2,3,4,5,7,1,2,3,1]\nfor i,v in enumerate(a):\n    if v == 1:\n        a[i] = 10\nprint(a)\n", "[10,2,3,4,5,7,10,2,3,10]\n"], ["pip uninstall scikit-image\n", "pip uninstall scikit-image\n"], ["import pdftotext\n\n# Load your PDF\nwith open(\"test.pdf\", \"rb\") as f:\n    pdf = pdftotext.PDF(f)\n\n# creating a text file after iterating through all pages in the pdf\nfile = open(\"test.txt\", \"w\")\nfor page in pdf:\n    file.write(page)\nfile.close()\n"], ["from flask import Flask, request\nimport json\nimport time\nimport os\nfrom concurrent.futures import ThreadPoolExecutor\n\n\napp = Flask(__name__)\n\n\n# Task manager executor\n_threadpool_cpus = int(os.cpu_count() / 2)\nEXECUTOR = ThreadPoolExecutor(max_workers=max(_threadpool_cpus, 2))\n\n\n@app.route(\"/first\", methods=[\"POST\"])\ndef main():\n    print(\"Request received\")\n    EXECUTOR.submit(func1)\n    return json.dumps({\"status\": True})\n\n\ndef func1():\n    time.sleep(2)\n    print(\"Print function executed\")\n\n\nif __name__ == \"__main__\":\n    app.run(\"0.0.0.0\", 8080)\n"], ["from threading import Thread\nfrom multiprocessing import Process #and multiprocessing queue if you use this\nimport queue #for passing messages between main and func1\n\nmessage_queue = queue.Queue()\n@app.route(\"/first\", methods=[\"GET\"])\ndef main():\n    print(\"Request received\")\n    func_thread = Thread(target=func1, args=(), daemon=True).start() #daemon if it needs to die with main program, otherwise daemon=False\n    #or func_process = Process(...) #in case\n\n    return json.dumps({\"status\": True})\n\ndef func1():\n    ...\n    print(\"func 1 \")\n    message_queue.put(...) #if you need to pass something\n    message_queue.get(...) #to get something like stopping signal\n    return\n\n"], ["from pathlib import Path\nfrom fnmatch import fnmatch\nfolder = Path('name of folder')\n", " excel_only_files = [xlsx for xlsx in folder.iterdir()\n                     if fnmatch(xlsx.name.lower(),'asterix_*.xlsx')]\n", "#you'll have to test this, i did not put it though any tests\nexcel_only_files = list(folder.rglob('Asterix_*.[xlsx|XLSX]')\n", " dataframes = [pd.read_excel(f) for f in excel_only_files]\n"], ["files = ['filea.txt', 'fileb.xlsx', 'filec.xlsx', 'notme.txt']\nfiles_xlsx = [f for f in files if f.startswith('file') and f.endswith('xlsx')]\nfiles_xlsx # ['fileb.xlsx', 'filec.xlsx']\n"], ["import pandas as pd\nimport glob\n\nmy_df_list = [pd.read_excel(f) for f in glob.iglob('Asterix_*.xlsx')]\n"], ["files_xlsx = [f for f in files if f[-4:] == \"xlsx\" and \"Asterix_\" in f]\n", "for file in excel_files:\n    df = pd.read_excel(file)\n    print(df)\n"], ["import glob\n\nfor i in glob.glob('Asterix_*.xlsx'):\n    ...\n"], [], [], [], [], [], ["# Pandas encoding the data, dummies function creates different feature for each dataset\ntrain = pd.get_dummies(train)\nvalid = pd.get_dummies(valid)\ntest = pd.get_dummies(test)\n\n# Align the number of features across validation and test sets based on train dataset\ntrain, valid = train.align(valid, join='left', axis=1)\ntrain, test = train.align(test, join='left', axis=1)\n"], ["string = 'hello @jon i am @@here or @@@there and want some@thing in \"@here\"'\nresult = ' '.join(s.replace('@', '', 1) for s in string.split(' '))\n\n# output: hello jon i am @here or @@there and want something in \"here\"\n"], ["(?<!@)@\n"], ["import re\n\ns = \"hello @jon i am @@here or @@@there and want some@thing in '@here\"\ns = re.sub('@(\\w)', r'\\1', s)\nprint(s)\n", "\"hello jon i am @here or @@there and want something in 'here\"\n"], [">>> ' '.join([s_.replace('@', '', 1) if s_[0] in [\"'\", \"@\"] else s_ for s_ in s.split()])\n\"hello jon i am @here or @@there and want some@thing in 'here\"\n", ">>> ' '.join([s_.replace('@', '', 1) if s_.find('@') in range(2) else s_ for s_ in s.split()])\n\"hello jon i am @here or @@there and want some@thing in 'here\"\n"], ["@(@*)\n", "inp = \"hello @jon i am @@here or @@@there and want some@thing in '@here\"\nout = re.sub(r\"@(@*)\", '\\\\1', inp)\nprint(out)\n", "hello jon i am @here or @@there and want something in 'here\n"], [">>> from decimal import Decimal\n>>> Decimal(0.01)\nDecimal('0.01000000000000000020816681711721685132943093776702880859375')\n>>> from fractions import Fractio\n>>> Fraction(0.01)\nFraction(5764607523034235, 576460752303423488) \n", ">>> float((Fraction(1)/Fraction(0.01)) - 100)\n-2.0816681711721685e-15\n", ">>> from numpy import nextafter\n>>> nextafter(100,0)-100\n-1.4210854715202004e-14\n"], [], [">>> 1//.01\n99.0\n>>> -1//.01\n-100.0\n", ">>> 1/.01\n100.0\n>>> -1/.01\n-100.0\n", ">>> int(1/.01)\n100\n>>> int(-1/.01)\n-100\n"], ["from decimal import *\n\nnum = Decimal(1) / Decimal(0.01)\nprint(num)\n", "99.99999999999999791833182883\n"], ["1 * 100000000000 // round(0.00000000001 * 100000000000)\n", "from decimal import Decimal\ncent = Decimal(1) / Decimal(100) # Contrary to floating point, this is exactly 0.01\nprint (Decimal(1) // cent) # 100\n"], [], ["import re\nstr = 'hello, world! 40,000 and 50,000!'\nstr = re.sub(r'(\\d+),(\\d+)', r'\\1\\2', str)\n"], ["    title\n0   Hello, world!\n1   Warhammer 40000\n2   Codename 1337\n3   Total USD 1,27\n4   1080000000 kilometers per hour\n\n"], ["import pandas as pd\nimport re\n\ndf = pd.DataFrame({'col':['Hello, world!', 'Warhammer 40,000', 'Codename 1,337']})\ndf['col'] = df['col'].apply(lambda x: re.sub(r'(\\d+),(\\d+)', r'\\1\\2', x))\n"], [], ["import re\n\nitems = ['Hello, world!', 'Warhammer 40,000', 'Codename 1,337']\n\nfor item in items:\n  item = re.sub(r'(\\d+),(\\d+)', r'\\1\\2', item)\n  print(item)\n", "Hello, world!\nWarhammer 40000\nCodename 1337\n"], ["import re\n\ndef convert_commas(old):\n\n    new = []\n    pattern = re.compile(r\"\\d+,\\d+\")\n    for word in old.split():\n        if re.findall(pattern, word):\n            word = word.replace(',','')\n        new.append(word)\n\n    new = (\" \").join(new)\n    return new\n\nprint(convert_commas(old))\n"], ["n = int(input())\n\nlist1 = list(map(int, input().strip().split()))[:n]\n\nlist2 = list1[::-1]\n\nsum_list = []\n\nfor (item1, item2) in zip(list1, list2):\n\n    sum_list.append(item1+item2)\n\nprint(*sum_list, sep=' ')\n"], ["l_b = np.array( [[[57.5, 2.875],\n   [83.75, 4.1875],\n   [83.75, 18.70923913043478],\n   [57.50000000000001, 18.70923913043478],\n   [57.5, 2.875]],\n  [[83.75, 18.70923913043478],\n   [57.50000000000001, 18.70923913043478],\n   [57.5, 34.08695652173913],\n   [83.75, 34.54347826086956],\n   [83.75, 18.70923913043478]],\n  [[0.0, 0.0],\n   [18.125, 0.90625],\n   [18.125, 16.70108695652174],\n   [-2.530467720685112, 16.70108695652174],\n   [0.0, 0.0]],\n  [[18.125, 16.70108695652174],\n   [-2.530467720685112, 16.70108695652174],\n   [-5.0, 33.0],\n   [18.125, 33.40217391304348],\n   [18.125, 16.70108695652174]]])\n", "a=list(map(lambda x :round(x,2),l_b.flatten() ))\n", "np.array(a).reshape(4,5,2)\n", "l_b.round(2)\n"], ["l_b = [[[round(e, 2) for e in j] for j in i] for i in l_b]\n"], ["In [51]: def recur(lst):\n    ...:     if isinstance(lst,float):\n    ...:         return '%.2f'%lst #use round(lst,2) if you want float instead of string.\n    ...:     else:\n    ...:         return [recur(i) for i in lst]\n\nIn [52]: recur(l_b)\n", "[[['57.50', '2.88'],\n  ['83.75', '4.19'],\n  ['83.75', '18.71'],\n  ['57.50', '18.71'],\n  ['57.50', '2.88']],\n [['83.75', '18.71'],\n  ['57.50', '18.71'],\n  ['57.50', '34.09'],\n  ['83.75', '34.54'],\n  ['83.75', '18.71']],\n [['0.00', '0.00'],\n  ['18.12', '0.91'],\n  ['18.12', '16.70'],\n  ['-2.53', '16.70'],\n  ['0.00', '0.00']],\n [['18.12', '16.70'],\n  ['-2.53', '16.70'],\n  ['-5.00', '33.00'],\n  ['18.12', '33.40'],\n  ['18.12', '16.70']]]\n"], ["try:\n   del freq[w]\nexcept Exception as e:\n   print(e)\n"], [], ["l_b = [[['%.2f' % y[0], '%.2f' % y[1]] for y in x] for x in l_b]\n"], ["l_b = [[['%.2f' % z for z in y] for y in x] for x in l_b]\n"], ["a_list = df['iso'].tolist()\n", "a_list = []\na_list.extend(df['iso'].tolist())\na_list.extend(df['country'].tolist())\nprint (a_list)\n['x', 'y', 'z', 'w', 'a', 'b', 'c', 'd']\n", "a_list = df[['iso','country']].values.T.ravel().tolist()\nprint (a_list)\n['x', 'y', 'z', 'w', 'a', 'b', 'c', 'd']\n"], ["weights ={1:0.5,2:1.2,3:1.7,4:2.4}\n", "value = weights[2]\n", "weights ={1:0.5,2:1.2,3:1.7,4:2.4}\nuser_input = 0 \nwhile user_input not in (weights.keys()):\n    user_input = input(\"Please input the value for weight between 1 to 4: \")\nprint(\"Value of weight = %s\"%weights[user_input])\n"], ["item_count = 0\nfor item in new_lst:\n    item_count += 1\n    if 9<=item_count<=12:\n        print(str(item_count)+\" \"+str(item))\n", "9 sun\n10 ['water', 'air', 'fire', 'earth']\n11 games\n12 2.7\n", "sub_lst = new_lst[8:12]\n", "print(sub_lst)\n['sun', ['water', 'air', 'fire', 'earth'], 'games', 2.7]\n"], ["new_lst = [\"computer\", \"luxurious\", \"basket\", \"crime\", 0, 2.49, \"institution\", \"slice\", \"sun\", [\"water\", \"air\", \"fire\", \"earth\"], \"games\", 2.7, \"code\", \"java\", [\"birthday\", \"celebration\", 1817, \"party\", \"cake\", 5], \"rain\", \"thunderstorm\", \"top down\"]\nsub_lst = new_lst[8:12]\n"], ["new_lst = [\"computer\", \"luxurious\", \"basket\", \"crime\", 0, 2.49, \"institution\", \"slice\", \"sun\", [\"water\", \"air\", \"fire\", \"earth\"], \"games\", 2.7, \"code\", \"java\", [\"birthday\", \"celebration\", 1817, \"party\", \"cake\", 5], \"rain\", \"thunderstorm\", \"top down\"]\nsub_lst = new_lst[8:12]\nprint(sub_lst)\n", "new_lst = new_lst[9:12]\n"], ["weight = int(input(\"Enter your Weight: \"))\n\ndef getScale(weight):\n    return {\n        1 : 0.5,\n        2 : 1.2,\n        3 : 1.7,\n        4 : 2.4\n    }.get(weight, 0.5)\n\n\nprint(getScale(weight))\n"], ["new_lst = [\"computer\", \"luxurious\", \"basket\", \"crime\", 0, 2.49, \"institution\", \"slice\", \"sun\", [\"water\", \"air\", \"fire\", \"earth\"], \"games\", 2.7, \"code\", \"java\", [\"birthday\", \"celebration\", 1817, \"party\", \"cake\", 5], \"rain\", \"thunderstorm\", \"top down\"]\n\nsub_lst=new_lst[8:8+4]\n", "['sun', ['water', 'air', 'fire', 'earth'], 'games', 2.7]\n"], [], ["weights_dictionary = {1: 0.5, 2: 1.2, 3: 1.7, 4: 2.4}\n\nuser_weight = int(input(\"Enter weight from 1 to 4:\"))\n\nprint(weights_dictionary[user_weight])\n"], ["weight_dict = {1 : 0.5, 2 : 1.2, 3 : 1.7, 4 : 2.4}\n\ninput = input(\"enter a weight: \")\n\ninput_weight = int(input.strip())\n\nprint(\"Weight on scale is : {0}\".format(weight_dict[input_weight]))\n"], [" scal3 = {\"1\":0.5, \"2\":1.2, \"3\":1.7, \"4\":2.4}\n\n n = input(\"enter a number: \")\n\n print(scal3[n])\n", "print(scal3.get(n))\n"], [], ["map(lambda x : x if x == \"apple\" else None, ['apple', 'banana', 'cherry'])\n", "list(filter(lambda x : x == \"apple\", ['apple', 'banana', 'cherry']))\n"], ["class Particle:\n\n    # better to make this an implementation attribute\n    _ID = 0\n\n    @classmethod\n    def _next_id(cls):\n        cls._ID += 1\n        return cls._ID\n\n    def __init__(self, rect):\n        self.ID = self._next_id()\n        self.color = (255, 0, 0)\n", "    def __init__(self, rect, color=(255, 0, 0)):\n        self.ID = self._next_id()\n        self.color = color\n"], ["MyParticle = Particle(some_rect)\nMyParticle.color = (255, 0, 255)\n"], ["class Particle:\n    color = (255, 255, 0)\n    ID = 0\n\n    def __init__(self, rect):\n        Particle.ID += 1\n        self.rect = rect\n\n        print(self.ID)\n        print(self.color)\n\np = Particle(None)\n", "1\n(255, 255, 0)\n", "class Particle:\n    color = (255, 255, 0)\n    ID = 0\n    def __init__(self, rect):\n        Particle.ID += 1\n        self.rect = rect\n        self.pcolor = self.color\n        self.pID = self.ID\n"], ["class Particle:\n    color = (255, 255, 0)\n\n    def __init__(self, rect):\n        self.rect = rect\n\n    def move(self, x, y):\n        self.rect.move(x, y)\n\n    def draw(self):\n        print(Particle.color, self.rect) # pygame.draw.rect\n\np = Particle(\"Rectangle dimensions\")                                   \nid(p)                                                                  \n> 4559902608\n\np2 = Particle(\"Rectangle dimensions\")\nid(p2)\n> 4559964496\n"], ["l = (x for x in ['apple', 'banana', 'cherry'] if x=='apple')\n"], ["[x for x in ['apple', 'banana', 'cherry'] if x == \"apple\"]\n"], ["l = filter(lambda x: x is not None, map(lambda x : x if x == \"apple\" else None, ['apple', 'banana', 'cherry']))\n", "l = [ x for x in ['apple', 'banana', 'cherry'] if x == 'apple' ]\n"], ["l = list(filter(lambda x : x == \"apple\", ['apple', 'banana', 'cherry']))\nprint(l)\n"], [], ["import re\n\ndef get_codon_list(codon_string):    \n    return list(re.findall(r\"(\\w{3})\", codon_string))\n"], ["def get_codon_list(codon_string):\n    codon_length = 3\n    codon_list = []\n\n    for codon_start in range(0, len(codon_string), codon_length):\n        codon_end = codon_start + codon_length\n        codon_list.append(codon_string[codon_start:codon_end])\n\n    return codon_list\n", "def get_codon_list(codon_string):\n    codon_length = 3\n\n    codon_list = [codon_string[x:x+codon_length] for x in range(0, len(codon_string), codon_length)]\n\n    return codon_list\n"], [], [">>> s=\"UGGUGUUAUUAAUGGUUU\"\n>>> res = [s[i:i+3] for i in range(0,len(s),3)]\n>>> res\n['UGG', 'UGU', 'UAU', 'UAA', 'UGG', 'UUU']\n"], ["In [1]: from itertools import zip_longest\n\nIn [2]: def grouper(iterable, n, fillvalue=None):\n   ...:     \"Collect data into fixed-length chunks or blocks\"\n   ...:     # grouper('ABCDEFG', 3, 'x') --> ABC DEF Gxx\"\n   ...:     args = [iter(iterable)] * n\n   ...:     return zip_longest(*args, fillvalue=fillvalue)\n   ...:\n\nIn [3]: list(grouper('UGGUGUUAUUAAUGGUUU', 3))\nOut[3]:\n[('U', 'G', 'G'),\n ('U', 'G', 'U'),\n ('U', 'A', 'U'),\n ('U', 'A', 'A'),\n ('U', 'G', 'G'),\n ('U', 'U', 'U')]\n"], ["N=int(input())\nA=list(map(int,input().split()))\ns=[]\nfor i in range(N):\n  s.append(A[i]+A[N-i-1])\nprint (*s,end=\"\")\n"], ["from pathlib import Path\ndoc = []\nline_number_of_each_file = values = 2\n\nfor file in Path('C:/A/B').rglob('*.dat'):\n    doc.append(file.readtext().splitlines()[line_number_of_each_file])\n\nprint(doc)\n"], [], ["import os\nvalues = 2\ndoc = []\nrootdir = 'A/B/C/'\n\nfor subdir, dirs, files in os.walk(rootdir):\n    for file in files:\n        if file.endswith('.txt'):\n            print(file)\n            file = os.path.join(rootdir,subdir,file)\n            with open (file, 'rt') as myfile:\n                    current_line = 0\n                    for mylines in myfile:\n                            if current_line == values:\n                                doc.append(mylines)\n                                break\n                            current_line += 1\n            continue\n\nprint(doc)\n"], ["            with open (subdir + \"/\" + file, 'rt') as myfile:\n"], ["project\n|__dir1\n|  |__file_to_read.txt\n|\n|__dir2\n   |__file_reader.py\n"], ["def substring(strings):\n    final = []\n    for string in strings:\n        while string:\n            final.append(string)\n            string = string[1:]\n    return final\n", "def substring(strings, final=None):\n    if final is None: final = []\n    for string in strings:\n        while string:\n            final.append(string)\n            string = string[1:]\n    return final\n", "def substring(strings, final=None):\n    if final is None: final = []\n    # base case: empty list\n    if not strings: return final\n    # recursive case:\n    # work on first string in list\n    string = strings[0]\n    # add all substrings to final\n    while string:\n        final.append(string)\n        string = string[1:]\n    return substring(strings[1:], final)\n", "def substring(strings, final=None):\n    if final is None: final = []\n    if not strings: return final\n    string = strings[0]\n    if not string: return substring(strings[1:], final)\n    final.append(string)\n    strings[0] = string[1:]\n    return substring(strings, final)\n", "def substring(strings, final=None):\n    if final is None: final = []\n    if not strings: return final\n    if not string[0]: return substring(strings[1:], final)\n    final.append(string)\n    strings[0] = string[0][1:]\n    return substring(strings, final)\n"], ["list=['house','cat','dog']\nfinal=[]\n\nfor word in list:\n    for i in range(len(word)):\n        final.append(word[i:])\n\nprint(final)\n"], ["def substring(stringslist):\n    final = []\n    for string in stringslist:\n        final.append(string)\n        if len(string)==1:\n            return final\n        else:\n            final.extend(substring([string[:-1]]))\n\n    return final\n\n"], ["L = ['house','cat','dog']\nfinal = []\ndef substring(s):\n    global final\n    if len(s)==1:\n        final.append(s)\n    else:\n        final.append(s)\n        substring(s[:-1])\n    return final\n\nfor s in L:\n    substring(s)\nprint(final)\n# ['house', 'hous', 'hou', 'ho', 'h', 'cat', 'ca', 'c', 'dog', 'do', 'd']\n"], ["lst=['house','cat','dog']\n\ndef substring(string, reversed=False):\n    if string:  # if string is not zero-length:\n        yield string  # yield its full length\n        yield from substring(string[:-1] if reversed else string[1:])  # and recurse\n\ndef substrings(stringslist, reversed=False):\n    for string in stringslist:\n        yield from substring(string, reversed)\n", ">>> list(substrings(lst))\n['house', 'ouse', 'use', 'se', 'e', 'cat', 'at', 't', 'dog', 'og', 'g']\n>>> list(substrings(lst, reversed=True))\n['house', 'hous', 'ous', 'us', 's', 'cat', 'ca', 'a', 'dog', 'do', 'o']\n"], [">>> new_list1 = []\n>>> new_list2 = []\n>>> for item in my_list:\n        for index, value in enumerate(item):\n            new_list1.append(item[:len(item)-index])\n            new_list2.append(item[index:])\n\n\n>>> new_list1\n['house', 'hous', 'hou', 'ho', 'h', 'cat', 'ca', 'c', 'dog', 'do', 'd']\n>>> new_list2\n['house', 'ouse', 'use', 'se', 'e', 'cat', 'at', 't', 'dog', 'og', 'g']\n"], ["def full_format(i):\n    # limit of first range is 26 letters (A-Z) times 999 numbers (001-999)\n    if i < 26 * 999:\n        c,n = divmod(i,999)   # quotient c is index of letter 0-25, remainder n is 0-998\n        c = chr(ord('A') + c) # compute letter\n        n += 1\n        return f'{c}{n:03}'\n    # After first range, second range is 26 letters times 26 letters * 99 numbers (01-99)\n    elif i < 26*999 + 26*26*99:\n        i -= 26*999               # remove first range offset\n        cc,n = divmod(i,99)       # remainder n is 0-98, use quotient cc to compute two letters\n        c1,c2 = divmod(cc,26)     # c1 is index of first letter, c2 is index of second letter\n        c1 = chr(ord('A') + c1)   # compute first letter\n        c2 = chr(ord('A') + c2)   # compute second letter\n        n += 1\n        return f'{c1}{c2}{n:02}'\n    else:\n        raise OverflowError(f'limit is {26*999+26*26*99}')\n\nfor i in range(92880, 92898):\n    print(full_format(i))\n"], ["$ pip uninstall scipy\n\n$ pip install scipy==1.2.0\n"], [], ["x, y = input().split(',')\nprint(x, y)\n", "username:/home/path$ python test.py < input.txt\n1 2\n"], ["python a.py < input.txt\n", "import sys\n\n\ncontents = sys.stdin.read()\nprint(contents)\n"], ["import sys\n\nvariable_string = sys.stdin.readline ()\nprint (variable_string)\n"], ["with open(\"File_name.txt\", \"r\") as file:\n       for line in file:\n              #Do something with the line in the file\n"], ["with open(\"input.txt\", \"r\") as file:\n    lines = file.readlines()\n\nfor line in lines:\n  storeInput = line\n\n....\n"], ["hashtable = dict()\nfor idx, val in enumerate(mylist):\n    if val not in hashtable.keys():\n         hashtable[val] = list()\n    hashtable[val].append(idx)\nnewlist = sorted(hashtable.values())\n"], ["$ conda update --prefix # first step\n$ conda 4.8.2  # lates Anaconda\n", "$ jupyter --version # latest jupyter notebook version created with pyton 3.6\njupyter core     : 4.6.1\njupyter-notebook : 6.0.0\n"], ["import numpy as np\nimport timeit\n\n# x = np.array(\"1 2 2 0 0 1 3 5\".split(),int)\nx = np.random.randint(0, 100, 100000)\n\ndef create_index_list(x):\n    d = {}\n    max_value = -1\n    for i,v in enumerate(x):\n        if v > max_value:\n            max_value = v\n        try:\n            d[v].append(i)\n        except:\n            d[v] = [i]\n    result_list = []\n    for i in range(max_value+1):\n        if i in d:\n            result_list.append(d[i])\n        else:\n            result_list.append([])\n    return result_list\n\n# print(create_index_list(x))\nprint(timeit.timeit(stmt='create_index_list(x)', number=1, globals=globals()))\n\n"], ["import numpy as np\nfrom scipy import sparse\n\nx = np.array(\"1 2 2 0 0 1 3 5\".split(),int)\nx\n# array([1, 2, 2, 0, 0, 1, 3, 5])\n\n\nM,N = x.max()+1,x.size\nsparse.csc_matrix((x,x,np.arange(N+1)),(M,N)).tolil().rows.tolist()\n# [[3, 4], [0, 5], [1, 2], [6], [], [7]]\n", "np.split(x.argsort(kind=\"stable\"),np.bincount(x)[:-1].cumsum())\n# [array([3, 4]), array([0, 5]), array([1, 2]), array([6]), array([], dtype=int64), array([7])]\n", "bb = np.bincount(x)[:-1].cumsum()\nnp.split(x.argpartition(bb),bb)\n# [array([3, 4]), array([0, 5]), array([1, 2]), array([6]), array([], dtype=int64), array([7])]\n", "A = x.argsort(kind=\"stable\")\nB = np.bincount(x+1).cumsum()\n[A[B[i-1]:B[i]] for i in range(1,len(B))]\n", "A = x.argsort(kind=\"stable\")\nB = np.bincount(x)\nL = 0\n[A[L:(L:=L+b)] for b in B.tolist()]\n", "import numpy as np\n\n#pythran export sort_to_bins(int[:],int)\n\ndef sort_to_bins(idx, mx):\n    if mx==-1: \n        mx = idx.max() + 1\n    cnts = np.zeros(mx + 2, int)\n    for i in range(idx.size):\n        cnts[idx[i] + 2] += 1\n    for i in range(3, cnts.size):\n        cnts[i] += cnts[i-1]\n    res = np.empty_like(idx)\n    for i in range(idx.size):\n        res[cnts[idx[i]+1]] = i\n        cnts[idx[i]+1] += 1\n    return [res[cnts[i]:cnts[i+1]] for i in range(mx)]\n", "repeat(lambda:enum_bins_numba_buffer(x),number=10)\n# [0.6235917090671137, 0.6071486569708213, 0.6096088469494134]\nrepeat(lambda:sort_to_bins(x,-1),number=10)\n# [0.6235359431011602, 0.6264424560358748, 0.6217901279451326]\n", "import numpy as np\n\n#pythran export bincollect(int[:])\n\ndef bincollect(a):\n    o = [[] for _ in range(a.max()+1)]\n    for i,j in enumerate(a):\n        o[j].append(i)\n    return o\n", "timeit(lambda:bincollect(x),number=10)\n# 3.5732191529823467\ntimeit(lambda:enumerate_bins(x),number=10)\n# 6.7462647299980745\n"], ["@numba.jit(numba.void(numba.int64[:], \n                      numba.int64[:], \n                      numba.int64[:]), \n           nopython=True)\ndef enum_bins_numba_buffer_inner(ints, bins, starts):\n    for x in range(len(ints)):\n        i = ints[x]\n        bins[starts[i]] = x\n        starts[i] += 1\n\n@numba.jit(nopython=False)  # Not 100% sure this does anything...\ndef enum_bins_numba_buffer(ints):\n    ends = np.bincount(ints).cumsum()\n    starts = np.empty(ends.shape, dtype=np.int64)\n    starts[1:] = ends[:-1]\n    starts[0] = 0\n\n    bins = np.empty(ints.shape, dtype=np.int64)\n    enum_bins_numba_buffer_inner(ints, bins, starts)\n\n    starts[1:] = ends[:-1]\n    starts[0] = 0\n    return [bins[s:e] for s, e in zip(starts, ends)]\n", "@numba.jit(nopython=True)\ndef enum_bins_numba(ints):\n    bins = numba.typed.List()\n    for i in range(ints.max() + 1):\n        inner = numba.typed.List()\n        inner.append(0)  # An awkward way of forcing type inference.\n        inner.pop()\n        bins.append(inner)\n\n    for x, i in enumerate(ints):\n        bins[i].append(x)\n\n    return bins\n", "def enum_bins_dict(ints):\n    enum_bins = defaultdict(list)\n    for k, v in enumerate(ints):\n        enum_bins[v].append(k)\n    return enum_bins\n\ndef enum_bins_list(ints):\n    enum_bins = [[] for i in range(ints.max() + 1)]\n    for x, i in enumerate(ints):\n        enum_bins[i].append(x)\n    return enum_bins\n\ndef enum_bins_sparse(ints):\n    M, N = ints.max() + 1, ints.size\n    return sparse.csc_matrix((ints, ints, np.arange(N + 1)),\n                             (M, N)).tolil().rows.tolist()\n", "from distutils.core import setup\nfrom distutils.extension import Extension\nfrom Cython.Build import cythonize\nimport numpy\n\next_modules = [\n    Extension(\n        'enum_bins_cython',\n        ['enum_bins_cython.pyx'],\n    )\n]\n\nsetup(\n    ext_modules=cythonize(ext_modules),\n    include_dirs=[numpy.get_include()]\n)\n", "# cython: language_level=3\n\nimport cython\nimport numpy\ncimport numpy\n\n@cython.boundscheck(False)\n@cython.cdivision(True)\n@cython.wraparound(False)\ncdef void enum_bins_inner(long[:] ints, long[:] bins, long[:] starts) nogil:\n    cdef long i, x\n    for x in range(len(ints)):\n        i = ints[x]\n        bins[starts[i]] = x\n        starts[i] = starts[i] + 1\n\ndef enum_bins_cython(ints):\n    assert (ints >= 0).all()\n    # There might be a way to avoid storing two offset arrays and\n    # save memory, but `enum_bins_inner` modifies the input, and\n    # having separate lists of starts and ends is convenient for\n    # the final partition stage.\n    ends = numpy.bincount(ints).cumsum()\n    starts = numpy.empty(ends.shape, dtype=numpy.int64)\n    starts[1:] = ends[:-1]\n    starts[0] = 0\n\n    bins = numpy.empty(ints.shape, dtype=numpy.int64)\n    enum_bins_inner(ints, bins, starts)\n\n    starts[1:] = ends[:-1]\n    starts[0] = 0\n    return [bins[s:e] for s, e in zip(starts, ends)]\n", "python setup.py build_ext --inplace\n"], ["out = np.array([''] * (x.max() + 1), dtype = object)\nnp.add.at(out, x, [\"{} \".format(i) for i in range(x.size)])\n[[int(i) for i in o.split()] for o in out]\n\nOut[]:\n[[3, 4], [0, 5], [1, 2], [6], [], [7]]\n", "out = np.empty((x.max() + 1), dtype = object)\nout[:] = [[]] * (x.max() + 1)\ncoords = np.empty(x.size, dtype = object)\ncoords[:] = [[i] for i in range(x.size)]\nnp.add.at(out, x, coords)\nlist(out)\n"], ["def excel_format(num):\n    # see https://stackoverflow.com/a/182924/1639625\n    res = \"\"\n    while num:\n        mod = (num - 1) % 26\n        res = chr(65 + mod) + res\n        num = (num - mod) // 26\n    return res\n\ndef full_format(num, d=3):\n    chars = num // (10**d-1) + 1 # this becomes   A..ZZZ\n    digit = num %  (10**d-1) + 1 # this becomes 001..999\n    return excel_format(chars) + \"{:0{}d}\".format(digit, d)\n\nfor i in range(10000):\n    print(i, full_format(i, d=2))\n", "0 A01\n...\n98 A99\n99 B01\n...\n2573 Z99\n2574 AA01\n...\n9998 CW99\n9999 CX01\n"], ["n = int('12AV', 36)\n", "def baseN(num, base, numerals=\"0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ\"):\n      return ((num == 0) and numerals[0]) or (baseN(num // base, base, numerals).lstrip(numerals[0]) + numerals[num % base])\n", "n = int('12AV', 36)\ns = baseN(n + 1, 36)\nprint(s)\n", "12AW\n"], ["def leadingZeros(number, digits):\n    numberString = str(number)\n    for digit in range(1, digits):\n        if number < 10**digit:\n            numberString = '0' + numberString\n    return numberString\n\n\ndef autoIncrement(oldNumber):\n    order = '0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ!'\n    lastDigitOrder = order.find(oldNumber[3])\n    newNumber = ''\n    if order.find(oldNumber[1]) <= 9:\n        # 3 digit number\n        number = int(oldNumber[1:]) + 1\n        letter = oldNumber[0]\n        if 1000 == number:\n            letterOrder = order.find(oldNumber[0])\n            letter = order[letterOrder + 1]\n        newNumber = letter + leadingZeros(number % 1000, 3)\n    elif order.find(oldNumber[2]) <= 9:\n        # 2 digit number\n        number = int(oldNumber[2:]) + 1\n        letters = oldNumber[0:2]\n        if 100 == number:\n            letterOrder = order.find(oldNumber[1])\n            letter = order[letterOrder + 1]\n            letters = oldNumber[0] + letter\n        newNumber = letters + leadingZeros(number % 100, 2)\n    elif order.find(oldNumber[3]) <= 9:\n        # 1 digit number\n        number = int(oldNumber[3]) + 1\n        letters = oldNumber[0:3]\n        if 10 == number:\n            letterOrder = order.find(oldNumber[2])\n            letter = order[letterOrder + 1]\n            letters = oldNumber[0:2] + letter\n        newNumber = letters + leadingZeros(number % 10, 1)\n    else:\n        # just letters\n        print(oldNumber)\n        letterOrder = order.find(oldNumber[3])\n        letter = order[letterOrder + 1]\n        newNumber = oldNumber[0:3] + letter\n\n    # if one of the digits has gone past Z then we need to update the letters\n    if '!' == newNumber[3]:\n        # past Z in 4th digit\n        letterOrder = order.find(oldNumber[2])\n        newNumber = newNumber[0:2] + order[letterOrder + 1] + 'A'\n    if '!' == newNumber[2]:\n        # past Z in 3rd digit\n        letterOrder = order.find(oldNumber[1])\n        newNumber = newNumber[0:1] + order[letterOrder + 1] + 'A' + newNumber[3]\n    if '!' == newNumber[1]:\n        # past Z in 2nd digit\n        letterOrder = order.find(oldNumber[0])\n        newNumber = order[letterOrder + 1] + 'A' + newNumber[2:]\n\n    return newNumber\n\n\nprint(autoIncrement('A999'))\nprint(autoIncrement('AA99'))\nprint(autoIncrement('AAA9'))\nprint(autoIncrement('AAAA'))\nprint(autoIncrement('AZZ9'))\n"], ["def auto_increment(number):\n    if number == 'ZZZZ':\n        return 'ZZZZ'\n\n    digits = \"\".join([i for i in number if i.isdigit()])\n    chars = \"\".join([i for i in number if not i.isdigit()])\n    if int(digits) == int('9' * len(digits)):\n        digits = \"000\"\n        new_char = [ord(i) for i in chars]\n        if new_char[-1] % ord('Z') == 0:\n            new_char = \"\".join([chr(i) for i in new_char]) + 'A'\n        else:\n            new_char[-1] = new_char[-1] + 1\n            new_char = \"\".join([chr(i) for i in new_char])\n    else:\n        new_char = chars\n\n    new_digit = int(digits) + 1\n    l = len(new_char) \n    ll = len(str(new_digit))\n    new_digit = ((\"0\" * (3-ll)) + str(new_digit))[(l-1):]\n    return f\"{new_char}{new_digit}\"\n"], [">>> import numpy as np\n>>> a = np.array([1 ,2 ,2 ,0 ,0 ,1 ,3, 5])\n>>> b = {}\n# Creating an empty list for the numbers that exist in array a\n>>> for i in range(np.min(a),np.max(a)+1):\n    b[str(i)] = []\n\n# Adding indices to the corresponding key\n>>> for i in range(len(a)):\n    b[str(a[i])].append(i)\n\n# Resulting Dictionary\n>>> b\n{'0': [3, 4], '1': [0, 5], '2': [1, 2], '3': [6], '4': [], '5': [7]}\n\n# Printing the result in the way you wanted.\n>>> for i in sorted (b.keys()) :\n     print(b[i], end = \" \")\n\n[3, 4] [0, 5] [1, 2] [6] [] [7] \n"], [], [], ["import mysql.connector\nimport ssl\n", "import ssl\nimport mysql.connector\n"], ["df = pd.read_json(r'C:\\path\\file.json')\n", "final=df.stack().str[0].unstack()\nfinal=final.assign(cities=final['cities'].str.split(',')).explode('cities')\nfinal=final.assign(**pd.DataFrame(final.pop('user').str[0].tolist()))\nprint(final)\n", "      session_id unix_timestamp            cities  user_id joining_date  \\\n0  X061RFWB06K9V     1442503708       New York NY     2024   2015-03-22   \n0  X061RFWB06K9V     1442503708         Newark NJ     2024   2015-03-22   \n1  5AZ2X2A9BHH5U     1441353991       New York NY     2024   2015-03-22   \n1  5AZ2X2A9BHH5U     1441353991    Jersey City NJ     2024   2015-03-22   \n1  5AZ2X2A9BHH5U     1441353991   Philadelphia PA     2024   2015-03-22   \n\n  country  \n0      UK  \n0      UK  \n1      UK  \n1      UK  \n1      UK  \n"], [], ["s=pd.DataFrame(j).apply(lambda x : x.str[0])\ns['cities']=s.cities.str.split(',')\ns=s.explode('cities')\ns.reset_index(drop=True,inplace=True)\ns=s.join(pd.DataFrame(sum(s.user.tolist(),[])))\n      session_id  unix_timestamp  ... joining_date country\n0  X061RFWB06K9V      1442503708  ...   2015-03-22      UK\n1  X061RFWB06K9V      1442503708  ...   2015-03-22      UK\n2  5AZ2X2A9BHH5U      1441353991  ...   2015-03-28      DE\n3  5AZ2X2A9BHH5U      1441353991  ...   2015-03-28      DE\n4  5AZ2X2A9BHH5U      1441353991  ...   2015-03-28      DE\n[5 rows x 7 columns]\n"], ["import pandas as pd\n\n# lets say d is your json\ndf = pd.DataFrame.from_dict(d, orient='index').T.reset_index(drop=True)\n\n# unlist each element\ndf = df.applymap(lambda x: x[0])\n\n# convert user column to multiple cols\ndf = pd.concat([df.drop('user', axis=1), df['user'].apply(lambda x: x[0]).apply(pd.Series)], axis=1)\n\n      session_id  unix_timestamp  \\\n0  X061RFWB06K9V      1442503708   \n1  5AZ2X2A9BHH5U      1441353991   \n\n                                         cities  user_id joining_date country  \n0                        New York NY, Newark NJ     2024   2015-03-22      UK  \n1  New York NY, Jersey City NJ, Philadelphia PA     2853   2015-03-28      DE \n"], [], ["from rest_framework import generics\n\nclass MoviesView(generics.RetrieveAPIView):\n    queryset = Movie.objects.all()\n    serializer_class = MovieSerializer\n", "url(r'movies/(?P<pk>[0-9]+)/$', MoviesView.as_view(), name=\"MoviesView\"),\n"], ["path('snippets/', views.snippet_list),\n\npath('snippets/<int:pk>', views.snippet_detail),\n"], [], [], ["urlpatterns = [\npath('movies', MoviesView.as_view(), name=\"MoviesView\"),]\n"], ["names = [[\"cat\", 9112, \"dog123\", 5625],[\"luck\", 1232, \"bad23\"]]\noutput = [no_duplicate(li) for li in names]\n\ndef no_duplicate(li):\n    no_str = [no for no in li if type(no)==int] #get the numbers\n    newlist = []\n    for number in no_str:\n        number = list(dict.fromkeys([s for s in str(number)])) #remove duplicate from each number\n        number = \"\".join(x for x in number) \n        newlist.append(int(number)) #append back to the list they belong\n    return newlist\n", "[[912, 562], [123]]\n"], ["data  = [[9112, 5625], [1232]]\n\nfor index, value in enumerate(data):\n    for indexY, valueY in enumerate(value):\n        data[index][indexY] = int(\"\".join(list(set(valueY.__str__()))))\n\nprint(data)\n", "[[129, 256], [123]]\n", "def RemoveDuplicate(numbers):\n\n    result = []\n\n    [result.append(e) for e in str(numbers) if not e in result]\n\n    return int(\"\".join(result))\n\ndata  = [[9112, 5625], [1232]]\n\nfor index, value in enumerate(data):\n    for indexY, valueY in enumerate(value):\n        data[index][indexY] = RemoveDuplicate(valueY)\n\nprint(data)\n", "[[912, 562], [123]]\n", "result = [[RemoveDuplicate(item) for item in row] for row in data]\n\nprint(result)\n", "[[912, 562], [123]]\n", "result = [[int(\"\".join(list(dict.fromkeys(str(item))))) for item in row] for row in data]\n\nprint(result)\n", "[[912, 562], [123]]\n"], ["def to_uniq_digit_int(n):\n      seen = set() # A set that collects seen digits\n      result = 0\n      for i in str(n): # A lazy way to iterate over digits in an integer\n          if i not in seen:\n              seen.add(i)\n              # Since we are iterating from the most significant to the least significant, we can multiply the result by ten each time to move the integer one digit left\n              result = result * 10 + int(i)\n      return result\n"], ["names = [ [\"cat\", 9112, \"dog123\", 5625], [\"luck\", 1232, \"bad23\"] ]\n\nli = [[x for x in y if isinstance(x, int)] for y in names]\nfinal = [[\"\".join(sorted(set(str(x)), key=str(x).index)) for x in y] for y in li]\nprint(li)\nprint(final)\n", "[[9112, 5625], [1232]] \n[['912', '562'], ['123']] \n"], ["names = [ [\"cat\", 9112, \"dog123\", 5625], [\"luck\", 1232, \"bad23\"],[\"123\"] ]\nupdated_name=[]\nfor n_list in names:\n    undated_n_list=[]\n    for n in n_list:\n        if type(n)==int:\n            new_str = []\n            for digit in str(n):\n                if digit not in new_str:\n                    new_str.append(digit)\n            undated_n_list.append(int(\"\".join(map(str, new_str))))\n    if undated_n_list:\n        updated_name.append(undated_n_list)\nprint(updated_name)\n", "[[912, 562], [123]]\n"], [], ["cnx = mysql.connector.connect(user='u', password='p', host='localhost', database='db', ssl_ca='', ssl_version=ssl.PROTOCOL_TLSv1_2)\n", "import mysql.connector\nimport ssl\n\ncnx = mysql.connector.connect(user='u', password='p', host='localhost', database='db', ssl_ca='', ssl_version=ssl.PROTOCOL_TLSv1_2)\ncursor = cnx.cursor()\ncursor.execute(\"SELECT 1\")\n\nfor (number,) in cursor:\n    print('Number:', number)\nprint('SSL active:', cnx._ssl_active)\nprint('Connection SSL version:', cnx._ssl.get(\"version\"))\nprint(\"Socket SSL version:\", cnx._socket.sock.ssl_version)\n\ncursor.close()\ncnx.close()\n", "Number: 1\nSSL active: True\nConnection SSL version: _SSLMethod.PROTOCOL_TLSv1_2\nSocket SSL version: _SSLMethod.PROTOCOL_TLSv1_2\n", "Number: 1\nSSL active: True\nConnection SSL version: None\nSocket SSL version: _SSLMethod.PROTOCOL_TLS\n"], [], ["cnx = mysql.connector.connect(user='x', password='y', host='localhost', database='xyz', tls-versions='tls1.2')\n"], ["if(flag_func_1 == True):\n  func_1()\n  flag_func1 = False\n"], ["def func1():\n    print(\"Print function executed1\")\n    time.sleep(10)\n    print(\"Print function executed2\")\n\napp = Flask(__name__)\n\n@app.route(\"/first\")\ndef main():\n    print(\"Request received1\")\n    func1()\n    print(\"Request received2\")\n    return json.dumps({\"status\": True})\n\nif __name__ == \"__main__\":\n    app.run(\"0.0.0.0\", 8080)\n", "Request received1\nPrint function executed1\nPrint function executed2\nRequest received2\n"], ["import subprocess\n\nsubprocess.call(func1())\n"], ["import numpy as np\nNROWS = 10\nARRAY_LENGTH = 5\nnp.random.seed(0)\ndata = [\n    (np.random.randint(0, 100, x).tolist() + [0]*(ARRAY_LENGTH-x),) \n    for x in np.random.randint(0, ARRAY_LENGTH+1, NROWS)\n]\n\ndf = spark.createDataFrame(data, [\"myArray\"])\ndf.show()\n#+--------------------+\n#|             myArray|\n#+--------------------+\n#| [36, 87, 70, 88, 0]|\n#|[88, 12, 58, 65, 39]|\n#|     [0, 0, 0, 0, 0]|\n#|  [87, 46, 88, 0, 0]|\n#|  [81, 37, 25, 0, 0]|\n#|   [77, 72, 9, 0, 0]|\n#|    [20, 0, 0, 0, 0]|\n#|  [80, 69, 79, 0, 0]|\n#|[47, 64, 82, 99, 88]|\n#|   [49, 29, 0, 0, 0]|\n#+--------------------+\n", "from pyspark.sql.functions import coalesce, col, when, lit, \ndf.withColumn(\n    \"trailingZeroes\",\n    coalesce(\n        *[\n            when(col('myArray').getItem(index) != 0, lit(ARRAY_LENGTH-(index+1)))\n            for index in range(ARRAY_LENGTH-1, -1, -1)\n        ] + [lit(ARRAY_LENGTH)]\n    )\n).show()\n#+--------------------+--------------+\n#|             myArray|trailingZeroes|\n#+--------------------+--------------+\n#| [36, 87, 70, 88, 0]|             1|\n#|[88, 12, 58, 65, 39]|             0|\n#|     [0, 0, 0, 0, 0]|             5|\n#|  [87, 46, 88, 0, 0]|             2|\n#|  [81, 37, 25, 0, 0]|             2|\n#|   [77, 72, 9, 0, 0]|             2|\n#|    [20, 0, 0, 0, 0]|             4|\n#|  [80, 69, 79, 0, 0]|             2|\n#|[47, 64, 82, 99, 88]|             0|\n#|   [49, 29, 0, 0, 0]|             3|\n#+--------------------+--------------+\n"], ["import pyspark.sql.functions as F\nfrom functools import reduce\n\ncols = [F.col('myArray').getItem(index) for index in range(ARRAY_LENGTH-1, -1, -1)]\ntrailing_count_column = F.abs(reduce(lambda col1, col2: F.when((col1 < 0) & (col2 != 0), -col1).othewise(\n    F.when((col1 < 0) & (col2 == 0), col1 - 1).otherwise(col1)), cols, F.lit(-1))) - 1\n\ndf = df.withColumn('trailingZeroes', trailing_count_column)\n"], ["from pyspark.sql.functions import reverse\n\n(\n  df.withColumn(\"arr_rev\", reverse(\"A\"))\n  .selectExpr(\n    \"arr_rev\", \n    \"AGGREGATE(arr_rev, (1 AS p, CAST(0 AS LONG) AS sum), (buffer, value) -> (if(value != 0, 0, buffer.p), if(value=0, buffer.sum + buffer.p, buffer.sum)), buffer -> buffer.sum) AS result\"\n  )\n)\n"], [], ["ERROR: tensorboard 2.0.2 has requirement setuptools>=41.0.0, but you'll have setuptools 40.6.2 which is incompatible.\n", "Installing collected packages: tensorflow-gpu, setuptools\nFound existing installation: setuptools 40.6.2\nUninstalling setuptools-40.6.2:\nSuccessfully uninstalled setuptools-40.6.2\n"], ["from pdfreader import SimplePDFViewer, PageDoesNotExist\n\nfd = open(you_pdf_file_name, \"rb\")\nviewer = SimplePDFViewer(fd)\n\nplain_text = \"\"\npdf_markdown = \"\"\n\ntry:\n    while True:\n        viewer.render()\n        pdf_markdown += viewer.canvas.text_content\n        plain_text += \"\".join(viewer.canvas.strings)\n        viewer.next()\nexcept PageDoesNotExist:\n    pass\n\n"], ["l1 = sorted(l, key=lambda x: ((x == 'q') - (x == 'p'), x))\n\nprint(l1)\n# ['p', 'p', 'a', 'b', 'c', 'd', 'f', 'g', 'n', 't', 'z', 'q', 'q']\n", "func = lambda x: ((x == 'q') - (x == 'p'), x)\n\nfor i in l1:\n    print(func(i))\n", "(-1, 'p')\n(-1, 'p')\n(0, 'a')\n(0, 'b')\n...\n(0, 't')\n(0, 'z')\n(1, 'q')\n(1, 'q')\n"], ["import PyPDF2\n\nwith open(\"pdf file path here\",'rb') as file_obj:\npdf_reader = PyPDF2.PdfFileReader(file_obj)\nraw = pdf_reader.getPage(0).extractText()\n\nprint(raw)\n"], [], ["pip3 install tensorflow==2.0.0a0\n", "pip3 install tensorflow --upgrade\n"], [], ["arr = [(1, 4), (2, 4)]\n\na = [*zip(*arr)]\nb = [list(i) for i in zip(*arr)]\n\nprint(a)\n# [(1, 2), (4, 4)]\n\nprint(b)\n# [[1, 2], [4, 4]]\n"], ["arr = [(1,4), (2,4)]\nres = list(zip(*arr))  #  res = [(1, 2), (4, 4)]\narr1 = res[0] # arr1 = (1, 2)\narr2 = res[1] # arr2 = (4,4)\n"], ["arr1 = [t[0] for t in arr]\narr2 = [t[1] for t in arr]\n", "arr1 = []\narr2 = []\nfor first, second in arr:\n    arr1.append(first)\n    arr2.append(second)\n"], ["arr1 = [x[0] for x in arr]\narr2 = [x[1] for x in arr]\n"], [], ["In [248]: from collections import defaultdict\n\nIn [249]: d = defaultdict(list)\n\nIn [250]: l = np.random.randint(0, 100, 100000)\n\nIn [251]: %%timeit\n     ...: for k, v in enumerate(l):\n     ...:     d[v].append(k)\n     ...:\n10 loops, best of 3: 22.8 ms per loop\n"], [], [], [">>> conn = pymysql.connect(host='localhost', user='root', password='root', db='test')\n>>> c.execute('select * from hosts where ip in %s', (('ip1', 'ip2'),))\n>>> c.fetchall()\n((1, 'mac1', 'ip1'), (3, None, 'ip2'))\n"], ["\"'\" + \"','\".join(name.replace(\"'\", r\"\\'\") for name in name_list) + \"'\") + \"'\"\n", "query = 'select * from table where name in ({})'.format(str(name_list)[1:-1])\n"], ["connection.execute('SELECT * FROM table WHERE name IN (?)', (names,))\n"], [], ["d = {'name': ['bob', 'john', 'harry', 'mary'], 'age': [13, 19, 23], 'height': [164, 188], 'job': ['programmer']}\n\nrecordset = [{k: v[i] for k, v in d.items() if i < len(v)} for i in range(max([len(l) for l in d.values()]))]\n\nprint(recordset)  # >> [{'name': 'bob', 'age': 13, 'height': 164, 'job': 'programmer'}, \n                        {'name': 'john', 'age': 19, 'height': 188}, \n                        {'name': 'harry', 'age': 23}, \n                        {'name': 'mary'}]\n"], ["d = {'name': ['bob', 'john', 'harry', 'mary'], 'age': [13, 19, 23], 'height': [164, 188], 'job': ['programmer']}\nm = max(map(len, d.values()))\nd1 = {k : (v if len(v)==m else v+['']*(m-len(v))) for k,v in d.items()}\nd2 = [{k:v for k,v in zip(d, t) if v} for t in zip(*d1.values())]\nprint(d2)\n", "[{'height': 164, 'age': 13, 'job': 'programmer', 'name': 'bob'}, {'height': 188, 'age': 19, 'name': 'john'}, {'age': 23, 'name': 'harry'}, {'name': 'mary'}]\n"], ["from itertools import zip_longest\n\n[{x: y for x, y in zip(d, t) if y is not None} for t in zip_longest(*d.values())]\n# [{'name': 'bob', 'age': 13, 'height': 164, 'job': 'programmer'}, \n#  {'name': 'john', 'age': 19, 'height': 188}, \n#  {'name': 'harry', 'age': 23}, \n#  {'name': 'mary'}]\n"], [], ["def __add__(self, other):\n    c = make_complex(other)\n    return Complex(self.real + c.real, self.imag + real.imag)\n", "e = Complex(1.718, 0) # e (well, not very exactly)\ni = Complex(0, 1) # sqrt(-1)\npi = Complex(3.14, 0) # pi\n# you know what to do next\n", "e = Complex(1.718)\npi = make_complex(3.14)\n"], ["def __add__(self, other):\n    if isinstance(other, Complex):\n        # do addition\n    else:\n        return self + Complex(other, 0)\n"], ["if type(other) != type(self):\n    # raise some error\n# do addition\nreturn \n"], ["a,b = eval(input()) # input() is returning str, with eval convert string into lists\n# print (a) # [1, 3, 5, 7, 9, 10]\n# print (b) # [2, 4, 6, 8]\n\n# use slicing to return list a without last element\n# use operator + to conconate lists\nresult = a[:-1] + b\n\nprint (result)\n", ">>[1, 3, 5, 7, 9, 10], [2, 4, 6, 8]\n[1, 3, 5, 7, 9, 2, 4, 6, 8]\n"], ["a = [1, 3, 5, 7, 9, 10]\nb = [2, 4, 6, 8]\na.pop() # get rid of last element\na.extend(b) # extend list a with b data\nprint(a)\n"], ["li1 = [1, 3, 5, 7, 9, 10]\nli2 = [2, 4, 6, 8]\nnew_list = li1[:-1] + li2\nprint(new_list)\n"], [], [">>> a = [[1, 3, 5, 7, 9, 10], [2, 4, 6, 8]]\n>>> b = a[0][:-1] + a[1]\n>>> b\n[1, 3, 5, 7, 9, 2, 4, 6, 8]\n"], ["import os\nos.system('clear')\n\nnumList = input(\"Enter an array/list separated by space : \").split(\" \")\nprint (numList)\nprint (numList[::-1])\n\nsumList = list()\n\nsumList = [int(x)+int(y) for x,y in zip(numList, numList[::-1])]\n\nprint(sumList)\nprint(\"\\n\")\n"], ["import numpy as np\nfrom PIL import Image\n\n\n_errstr = \"Mode is unknown or incompatible with input array shape.\"\n\n\ndef bytescale(data, cmin=None, cmax=None, high=255, low=0):\n    \"\"\"\n    Byte scales an array (image).\n    Byte scaling means converting the input image to uint8 dtype and scaling\n    the range to ``(low, high)`` (default 0-255).\n    If the input image already has dtype uint8, no scaling is done.\n    This function is only available if Python Imaging Library (PIL) is installed.\n    Parameters\n    ----------\n    data : ndarray\n        PIL image data array.\n    cmin : scalar, optional\n        Bias scaling of small values. Default is ``data.min()``.\n    cmax : scalar, optional\n        Bias scaling of large values. Default is ``data.max()``.\n    high : scalar, optional\n        Scale max value to `high`.  Default is 255.\n    low : scalar, optional\n        Scale min value to `low`.  Default is 0.\n    Returns\n    -------\n    img_array : uint8 ndarray\n        The byte-scaled array.\n    Examples\n    --------\n    >>> from scipy.misc import bytescale\n    >>> img = np.array([[ 91.06794177,   3.39058326,  84.4221549 ],\n    ...                 [ 73.88003259,  80.91433048,   4.88878881],\n    ...                 [ 51.53875334,  34.45808177,  27.5873488 ]])\n    >>> bytescale(img)\n    array([[255,   0, 236],\n           [205, 225,   4],\n           [140,  90,  70]], dtype=uint8)\n    >>> bytescale(img, high=200, low=100)\n    array([[200, 100, 192],\n           [180, 188, 102],\n           [155, 135, 128]], dtype=uint8)\n    >>> bytescale(img, cmin=0, cmax=255)\n    array([[91,  3, 84],\n           [74, 81,  5],\n           [52, 34, 28]], dtype=uint8)\n    \"\"\"\n    if data.dtype == np.uint8:\n        return data\n\n    if high > 255:\n        raise ValueError(\"`high` should be less than or equal to 255.\")\n    if low < 0:\n        raise ValueError(\"`low` should be greater than or equal to 0.\")\n    if high < low:\n        raise ValueError(\"`high` should be greater than or equal to `low`.\")\n\n    if cmin is None:\n        cmin = data.min()\n    if cmax is None:\n        cmax = data.max()\n\n    cscale = cmax - cmin\n    if cscale < 0:\n        raise ValueError(\"`cmax` should be larger than `cmin`.\")\n    elif cscale == 0:\n        cscale = 1\n\n    scale = float(high - low) / cscale\n    bytedata = (data - cmin) * scale + low\n    return (bytedata.clip(low, high) + 0.5).astype(np.uint8)\n\n\ndef toimage(arr, high=255, low=0, cmin=None, cmax=None, pal=None,\n            mode=None, channel_axis=None):\n    \"\"\"Takes a numpy array and returns a PIL image.\n    This function is only available if Python Imaging Library (PIL) is installed.\n    The mode of the PIL image depends on the array shape and the `pal` and\n    `mode` keywords.\n    For 2-D arrays, if `pal` is a valid (N,3) byte-array giving the RGB values\n    (from 0 to 255) then ``mode='P'``, otherwise ``mode='L'``, unless mode\n    is given as 'F' or 'I' in which case a float and/or integer array is made.\n    .. warning::\n        This function uses `bytescale` under the hood to rescale images to use\n        the full (0, 255) range if ``mode`` is one of ``None, 'L', 'P', 'l'``.\n        It will also cast data for 2-D images to ``uint32`` for ``mode=None``\n        (which is the default).\n    Notes\n    -----\n    For 3-D arrays, the `channel_axis` argument tells which dimension of the\n    array holds the channel data.\n    For 3-D arrays if one of the dimensions is 3, the mode is 'RGB'\n    by default or 'YCbCr' if selected.\n    The numpy array must be either 2 dimensional or 3 dimensional.\n    \"\"\"\n    data = np.asarray(arr)\n    if np.iscomplexobj(data):\n        raise ValueError(\"Cannot convert a complex-valued array.\")\n    shape = list(data.shape)\n    valid = len(shape) == 2 or ((len(shape) == 3) and\n                                ((3 in shape) or (4 in shape)))\n    if not valid:\n        raise ValueError(\"'arr' does not have a suitable array shape for \"\n                         \"any mode.\")\n    if len(shape) == 2:\n        shape = (shape[1], shape[0])  # columns show up first\n        if mode == 'F':\n            data32 = data.astype(np.float32)\n            image = Image.frombytes(mode, shape, data32.tostring())\n            return image\n        if mode in [None, 'L', 'P']:\n            bytedata = bytescale(data, high=high, low=low,\n                                 cmin=cmin, cmax=cmax)\n            image = Image.frombytes('L', shape, bytedata.tostring())\n            if pal is not None:\n                image.putpalette(np.asarray(pal, dtype=np.uint8).tostring())\n                # Becomes a mode='P' automagically.\n            elif mode == 'P':  # default gray-scale\n                pal = (np.arange(0, 256, 1, dtype=np.uint8)[:, np.newaxis] *\n                       np.ones((3,), dtype=np.uint8)[np.newaxis, :])\n                image.putpalette(np.asarray(pal, dtype=np.uint8).tostring())\n            return image\n        if mode == '1':  # high input gives threshold for 1\n            bytedata = (data > high)\n            image = Image.frombytes('1', shape, bytedata.tostring())\n            return image\n        if cmin is None:\n            cmin = np.amin(np.ravel(data))\n        if cmax is None:\n            cmax = np.amax(np.ravel(data))\n        data = (data*1.0 - cmin)*(high - low)/(cmax - cmin) + low\n        if mode == 'I':\n            data32 = data.astype(np.uint32)\n            image = Image.frombytes(mode, shape, data32.tostring())\n        else:\n            raise ValueError(_errstr)\n        return image\n\n    # if here then 3-d array with a 3 or a 4 in the shape length.\n    # Check for 3 in datacube shape --- 'RGB' or 'YCbCr'\n    if channel_axis is None:\n        if (3 in shape):\n            ca = np.flatnonzero(np.asarray(shape) == 3)[0]\n        else:\n            ca = np.flatnonzero(np.asarray(shape) == 4)\n            if len(ca):\n                ca = ca[0]\n            else:\n                raise ValueError(\"Could not find channel dimension.\")\n    else:\n        ca = channel_axis\n\n    numch = shape[ca]\n    if numch not in [3, 4]:\n        raise ValueError(\"Channel axis dimension is not valid.\")\n\n    bytedata = bytescale(data, high=high, low=low, cmin=cmin, cmax=cmax)\n    if ca == 2:\n        strdata = bytedata.tostring()\n        shape = (shape[1], shape[0])\n    elif ca == 1:\n        strdata = np.transpose(bytedata, (0, 2, 1)).tostring()\n        shape = (shape[2], shape[0])\n    elif ca == 0:\n        strdata = np.transpose(bytedata, (1, 2, 0)).tostring()\n        shape = (shape[2], shape[1])\n    if mode is None:\n        if numch == 3:\n            mode = 'RGB'\n        else:\n            mode = 'RGBA'\n\n    if mode not in ['RGB', 'RGBA', 'YCbCr', 'CMYK']:\n        raise ValueError(_errstr)\n\n    if mode in ['RGB', 'YCbCr']:\n        if numch != 3:\n            raise ValueError(\"Invalid array shape for mode.\")\n    if mode in ['RGBA', 'CMYK']:\n        if numch != 4:\n            raise ValueError(\"Invalid array shape for mode.\")\n\n    # Here we know data and mode is correct\n    image = Image.frombytes(mode, shape, strdata)\n    return image\n"], [], [], [], ["for root, dirs, files in os.walk(path):\n    print(root) # print text to keep track the process\n    count += sum(1 for f in files if f.endswith('txt'))\n\n    # This second line matches your existing behavior, but might not be intended\n    # Remove it if directories ending in .txt should not be included in the count\n    count += sum(1 for d in files if d.endswith('txt'))\n", "import os\ncount = 0  # set count default\npaths = ['E:\\\\']  # Make stack of paths to process\nwhile paths:\n    # paths.pop() gets top of directory stack to process\n    # os.scandir is easier and more efficient than os.listdir,\n    # though it must be closed (but with statement does this for us)\n    with os.scandir(paths.pop()) as entries:\n        for entry in entries:  # loop through the folder\n            print(entry.name)  # print text to keep track the process\n            if entry.name.endswith('.txt'):\n                count += 1\n                print('+1')\n            elif entry.is_dir():  #if it is a subfolder\n                print(entry.path, 'is dir')\n                # Add to paths stack to get to it eventually\n                paths.append(entry.path)\n"], [], ["import pandas as pd\nfrom sklearn.preprocessing import OneHotEncoder\n\n# create some example data\ndf= pd.DataFrame({'x': [1, 2, 3], 'y': [2, 4, 8]})\n\n# create a one hot encoder to create the dummies and fit it to the data\nohe= OneHotEncoder(handle_unknown='ignore', sparse=False)\nohe.fit(df[['x']])\n\n# now let's simulate the two situations A and B\ndf.loc[1, 'x']= 1\ndf= df.append(dict(x=5, y=5), ignore_index=True)\n\n# the actual feature generation is done in a separate step\ntr=ohe.transform(df[['x']])\n\n# if you need the columns in your existing data frame, you can glue them together\ndf2=pd.DataFrame(tr, columns=['oh1', 'oh2', 'oh3'], index=df.index)\nresult= pd.concat([df, df2], axis='columns')\n"], ["import pandas as pd  \ntrain = pd.DataFrame([1,2,3], columns= ['A'])\ntest= pd.DataFrame([7,8], columns= ['A'])\n\n#creating dummy for train \npd.get_dummies(train, columns= ['A'])\n\no/p\n   A_1  A_2  A_3  A_4  A_5  A_6\n0    1    0    0    0    0    0\n1    0    1    0    0    0    0\n2    0    0    1    0    0    0\n3    0    0    0    1    0    0\n4    0    0    0    0    1    0\n5    0    0    0    0    0    1\n\n\n\n# creating dummies for test data\npd.get_dummies(test, columns = ['A'])\n    A_7  A_8\n0    1    0\n1    0    1\n", "final_df = pd.concat([train, test]) \n\ndummy_created = pd.get_dummies(final_df)\n\n# now you can split it into train and test \nfrom sklearn.model_selection import train_test_split\ntrain_x, test_x = train_test_split(dummy_created, test_size=0.33)\n"], ["df.col_1=df.col_1.astype('category')\ndf1=df.iloc[:1,:].copy()\ndf2=df.drop(df1.index)\npd.get_dummies(df1,columns=['col_1'])\nOut[701]: \n      col_2 col3  col_1_A  col_1_D  col_1_G  col_1_J\nindex                                               \n0         B    C        1        0        0        0# it will show zero even missing in the sub-set\npd.get_dummies(df2,columns=['col_1'])\nOut[702]: \n      col_2 col3  col_1_A  col_1_D  col_1_G  col_1_J\nindex                                               \n1         E    F        0        1        0        0\n2         H    I        0        0        1        0\n3         K    L        0        0        0        1\n"], [], ["myList = df['iso'].tolist() \nprint(myList)\n"], ["df = pd.DataFrame({'country':['a','b','c','d'],'gdp':[1,2,3,4],'iso':['x','y','z','w']})\na_list = []\nfor i in range((df.shape[0])):\ncur_row =[]\nfor j in range(df.shape[1]):\n    cur_row.append(df.iat[i, j])            \na_list.append(cur_row) \n"], ["import itertools\na_list = []\na_list.append(df.iso.tolist())\na_list.append(df.country.tolist())\na_list=list(itertools.chain.from_iterable(a_list))\nprint(a_list)\n", "['x', 'y', 'z', 'w', 'a', 'b', 'c', 'd']\n"], ["a_list.extend(df['iso'].tolist())\n"], ["res = x%y\nif res==0:\n    sum = sum + x\n    break\n", "from math import sqrt\n\nT = int(input())\n\nfor _ in range(T):\n    N = int(input())\n\n    sum_of_primes = 0\n\n    if N < 2:\n        pass\n    elif N == 2:\n        sum_of_primes = 2\n    else:\n        sum_of_primes = 2\n\n        for number in range(3, N + 1, 2):\n\n            for odd in range(3, int(sqrt(number)) + 1, 2):\n                if (number % odd) == 0:\n                    break\n            else:  # no break\n                sum_of_primes += number\n\n    print(sum_of_primes)\n", "> python3 test.py\n3\n5\n10\n10\n17\n23\n100\n>\n"], [], ["l1 = ['a', 'b', 'c']\nl2 = ['b', 'c']\n\nres = list(map(lambda x: x in l2, l1))\n\nprint(res)\n", "[False, True, True]\n"], [], ["def in1d(l1, l2):\n  s2 = set(l2)\n  return [x in s2 for x in l1]\n"], ["l1 = ['a', 'b', 'c']\nl2 = ['b', 'c']\n\nresult = []\nfor i in l1 : \n  result.append(i in l2)\n"], ["[x in l2 for x in l1]\n"], [], ["sshfs OWN_USER@SERVER:/PATH_TO_FILES/ MOUNT_POINT                   \n", "sshfs -o sftp_server=\"sudo -u SYSTEM_USER /usr/libexec/openssh/sftp-server\" \\\n    OWN_USER@SERVER:/PATH_TO_FILES/ MOUNT_POINT                   \n"], ["pip install YourPackage\n", "pip install -r requirements.txt YourPackage\n"], [], [], ["pip uninstall scikit-image\n", "conda uninstall scikit-image\n", "pip install scikit-image\n", "conda install -c conda-forge scikit-image\n"], ["from statistics import mean\n\naverage = mean(value[1] for value in array)\n", "average = sum(value[1] for value in array) / len(array)\n", "value[1] for value in array\n", ">>> 25 / 4\n6\n\n>>> 25 / float(4)\n6.25\n", "average = sum((value[1] for value in array), 0.0) / len(array)\n", "from math import fsum\n\naverage = fsum(value[1] for value in array) / len(array)\n"], [], ["import numpy as np\n\narray = np.array([('a', 5) , ('b', 10), ('c', 20), ('d', 3), ('e', 2)])\nprint(array[:,1].astype(float).mean())\n# 8.0\n"], ["print(sum(tup[1] for tup in array) / len(array))\n", "print(sum(tup[1] for tup in array) / float(len(array)))\n", "from math import fsum\n\nprint(fsum(tup[1] for tup in array) / len(array))\n"], ["sum(map(lambda x:int(x[1]), array)) / len(array)\n", "import functools\nfunctools.reduce(lambda acc, y: acc + y[1], array, 0) / len(array)\n"], ["array = [('a', 5) , ('b', 10), ('c', 20), ('d', 3), ('e', 2)]\navg = float(sum(value[1] for value in array)) / float(len(array))\nprint(avg)\n#8.0\n"], ["from operator import itemgetter\n\nacc = 0\ncount = 0\n\nfor value in map(itemgetter(1), array):\n    acc += value\n    count += 1\n\nmean = acc / count\n", "data = [sub[1] for sub in array]\nmean = sum(data) / len(data)\n", "a = np.array(array)\n\nmean = a[:, 1].astype(int).mean()\n"], [], [], [], [], [], ["$ python3 -m venv .venv\n", "$ source .venv/bin/activate\n", "$ deactivate\n"], [], ["dfs = [df1, df2, df3]\ndf = pd.merge(dfs[0], dfs[1], left_on=['depth','profile'], right_on=['depth','profile'], how='outer')\nfor d in dfs[2:]:\n    df = pd.merge(df, d, left_on=['depth','profile'], right_on=['depth','profile'], how='outer')\n\n   depth       VAR1    profile     VAR2    VAR3\n0    0.5  38.196202  profile_1      NaN     NaN\n1    0.6  38.198002  profile_1  0.20440     NaN\n2    1.3  38.200001  profile_1      NaN  15.182\n3    1.1        NaN  profile_1  0.20442     NaN\n4    1.2        NaN  profile_1  0.20446  15.188\n5    1.4        NaN  profile_1      NaN  15.182\n"], ["df=pd.melt(pd.concat([df1,df2,df3]),id_vars=['profile','depth'])\ndf_pivot=df.pivot_table(index=['profile','depth'],columns='variable',values='value')\n", "variable              VAR1     VAR2    VAR3\nprofile   depth                            \nprofile_1 0.5    38.196202      NaN     NaN\n          0.6    38.198002  0.20440     NaN\n          1.1          NaN  0.20442     NaN\n          1.2          NaN  0.20446  15.188\n          1.3    38.200001      NaN  15.182\n          1.4          NaN      NaN  15.182\n"], [">>> df1.append(df2).append(df3).sort_values('depth')\n\n        VAR1     VAR2    VAR3  depth    profile\n0  38.196202      NaN     NaN    0.5  profile_1\n1  38.198002      NaN     NaN    0.6  profile_1\n0        NaN  0.20440     NaN    0.6  profile_1\n1        NaN  0.20442     NaN    1.1  profile_1\n2        NaN  0.20446     NaN    1.2  profile_1\n0        NaN      NaN  15.188    1.2  profile_1\n2  38.200001      NaN     NaN    1.3  profile_1\n1        NaN      NaN  15.182    1.3  profile_1\n2        NaN      NaN  15.182    1.4  profile_1\n"], ["dfs = [df.set_index(['profile', 'depth']) for df in [df1, df2, df3]]\n\nprint(pd.concat(dfs, axis=1).reset_index())\n#      profile  depth       VAR1     VAR2    VAR3\n# 0  profile_1    0.5  38.198002      NaN     NaN\n# 1  profile_1    0.6  38.198002  0.20440     NaN\n# 2  profile_1    1.1        NaN  0.20442     NaN\n# 3  profile_1    1.2        NaN  0.20446  15.188\n# 4  profile_1    1.3  38.200001      NaN  15.182\n# 5  profile_1    1.4        NaN      NaN  15.182\n"], [], [" from PyPDF2 import PdfFileReader\n    import os\n    def text_extractor(path):\n        with open(os.path.join(path,file), 'rb') as f:\n            pdf = PdfFileReader(f)\n###Here i can specify page but i need to convert whole pdf without specifying pages###\n            text = \"\"\n            for page_num in range(pdf.getNumPages()):\n                page = pdf.getPage(page_num)\n                text += page.extractText()\n            print(text)\n    if __name__ == '__main__':\n        path=\"C:\\\\Users\\\\AAAA\\\\Desktop\\\\BB\"\n        for file in os.listdir(path):\n            if not file.endswith(\".pdf\"):\n                continue\n            text_extractor(path)\n", "page_text = []\nfor page_num in range(pdf.getNumPages()): # For each page\n    page = pdf.getPage(page_num) # Get that page's reference\n    page_text.append(page.extractText()) # Add that page to our array\nfor page in page_text:\n    print(page) # print each page\n"], ["from tika import parser\n\nparse_entire_pdf = parser.from_file('mypdf.pdf', xmlContent=True)\nparse_entire_pdf = parse_entire_pdf['content']\nprint (parse_entire_pdf)\n", "from PyPDF2 import PdfFileReader\n\ndef pdf_text_extractor(path):\n  with open(path, 'rb') as f:\n  pdf = PdfFileReader(f)\n\n  # Get total pdf page number.\n  totalPageNumber = pdf.numPages\n\n  currentPageNumber = 0\n\n  while (currentPageNumber < totalPageNumber):\n    page = pdf.getPage(currentPageNumber)\n\n    text = page.extractText()\n    # The encoding put each page on a single line.  \n    # type is <class 'bytes'>\n    print(text.encode('utf-8'))\n\n    #################################\n    # This outputs the text to a list,\n    # but it doesn't keep paragraphs \n    # together \n    #################################\n    # output = text.encode('utf-8')\n    # split = str(output, 'utf-8').split('\\n')\n    # print (split)\n    #################################\n\n    # Process next page.\n    currentPageNumber += 1\n\npath = 'mypdf.pdf'\npdf_text_extractor(path)\n"], [], ["int x = 0\nfor rainfall in rainfall_mi.split(\",\"):\n    if float(rainfall) > 3.0:\n        x += 1\n", "print(len([x for x in rainfall_mi.split(\",\") if float(x) > 3.0]))\n"], ["rainfall_mi = \"1.65, 1.46, 2.05, 3.03, 3.35, 3.46, 2.83, 3.23, 3.5, 2.52, 2.8, 1.85\"\nrainfall_mi_split = rainfall_mi.split(\",\")\nnum_rainy_months = 0\nfor x in rainfall_mi_split:\n    x = float(x)\n    if x > 3.0:\n        num_rainy_months += 1\n\nprint(num_rainy_months)\n", "num_rainy_months = sum(1 for x in rainfall_mi.split(\",\") if float(x) > 3.0)\n"], ["num_rainy_months = 0 # this is fine\nfor x in rainfall_mi:\n    if x > 3.0: \n        # code\n", "num_rainy_months = 0 # this is fine\nfor x in rainfall_mi:\n    if float(x.strip()) > 3.0: \n       # code \n", "num_rainy_months = 0 # this is fine\nfor x in rainfall_mi: # each x is a rainfall value\n    if float(x.strip()) > 3.0: # if the rainfall value, as float, is greater than 3\n        num_rainy_months += 1 # add 1 to rainy months\n"], ["rainfall_mi = \"1.65, 1.46, 2.05, 3.03, 3.35, 3.46, 2.83, 3.23, 3.5, 2.52, 2.8, 1.85\"\nrainfall_mi_split = rainfall_mi.split(\",\")\nrainfall_mi_split=[float(x) for x in rainfall_mi_split]\nnum_rainy_months = 0\nfor x in rainfall_mi_split:\n\n    if x > 3.0:\n        num_rainy_months +=1\n"], [], ["pip3 install pandas==0.24.1\n"], ["if (File_Extn.contentEquals(\"msg\")) // put extns like msg, pdf etc.. \n                    {           \n                        for (int j=1; j<=TabCount; j++) // manually count total no. of tabs and replace with TabCount to reach keep button\n                        {   \n                            sleep(1);\n                            System.out.println(\"hit tab keys to reach keep/discard button\");\n                            robot.keyPress(KeyEvent.VK_TAB);\n                        }\n                        System.out.println(\"hit enter key to click on keep button\");\n                         robot.keyPress(KeyEvent.VK_ENTER);\n                    }\n"], ["System.setProperty(\"webdriver.chrome.driver\", \"chromedriver.exe file path\")\nString downloadFilepath = \"C:\\\\Downloads\";\nHashMap<String, Object> chromePrefs = new HashMap<String, Object>();\nchromePrefs.put(\"profile.default_content_settings.popups\", 0);\nchromePrefs.put(\"download.default_directory\", downloadFilepath);\nchromePrefs.put(\"safebrowsing.enabled\", \"false\"); \nchromePrefs.put(\"download.prompt_for_download\", \"false\");\nDesiredCapabilities capabilities = DesiredCapabilities.chrome();\nChromeOptions options = new ChromeOptions();\noptions.addArguments(\"--safebrowsing-disable-download-protection\");\noptions.addArguments(\"--safebrowsing-disable-extension-blacklist\");\noptions.addArguments(\"disable-extensions\");\noptions.addArguments(\"test-type\");\noptions.addArguments(\"start-maximized\");\noptions.setExperimentalOption(\"prefs\", chromePrefs);\ncapabilities.setCapability(ChromeOptions.CAPABILITY, options);  \ncapabilities.setCapability(CapabilityType.ACCEPT_SSL_CERTS, true);\ndriver = new ChromeDriver(capabilities);\n"], [], [], [], [], ["a=list(map(int,input().split()))\nb=list()\nfor i in range(len(a)):\n    if a[i]%3!=0:\n        b.append(a[i])      \nprint(*b,sep=\" \")\n"], [], [">>> # sort=False to return the rows in the order they originally occurred\n>>> df.loc[df.groupby(\"A\", sort=False)[\"B\"].idxmin()]\n\n     A  B    C\n0  foo  1  2.0\n1  bar  2  5.0\n"], ["numbers = input()\nlist = numbers.split()\n\nnewList = [item for item in list if int(item)%3!=0]\nprint(' '.join(newList))\n", "numbers = input()\n\nnewList = [item for item in numbers.split() if int(item)%3!=0]\nprint(' '.join(newList))\n", "numbers = input()\n\nprint(' '.join([item for item in numbers.split() if int(item)%3!=0]))\n"], ["print(*(item for item in map(int, input().split()) if item % 3))\n"], ["x = input()\nnum = list(map(int, x.split()))\nl =[]\nfor i in num:  \n    if i%3 != 0:\n        l.append(i)\nprint(*l, sep = \" \")\n"], ["list(filter(lambda x: x%3 != 0 , yourlist))\n"], ["numbers = input()\nlist = numbers.split()\n\nfor item in list:\n    if int(item)%3==0:\n        list.remove(item)\n\nprint(' '.join(list)) \n"], [], ["grouped.apply(lambda x: x[x['B'] == x['B']].min())\n", "In[25]: for df in grouped:\n   ...:     print(df)\n   ...:     \n('bar',      \n     A  B    C\n1  bar  2  5.0\n3  bar  4  1.0\n5  bar  6  9.0)\n\n('foo',      \n     A  B    C\n0  foo  1  2.0\n2  foo  3  8.0\n4  foo  5  2.0)\n", "group['B'] == group['B'].min()\n", "In[26]: def select_min_b(group):\n   ...:     return group[group['B'] == group['B'].min()]\n", "In[27]: grouped.apply(select_min_b)\nOut[27]: \n         A  B    C\nA                 \nbar 1  bar  2  5.0\nfoo 0  foo  1  2.0\n", "grouped.apply(lambda group: group[group['B'] == group['B']].min())\n"], ["df.sort_values('B').groupby('A').head(1)\n\n#     A  B    C\n#0  foo  1  2.0\n#1  bar  2  5.0\n", "df[df.groupby('A').B.transform(lambda x: x == x.min())]\n\n#     A  B    C\n#0  foo  1  2.0\n#1  bar  2  5.0\n"], ["df.sort_values('B').drop_duplicates('A')\nOut[288]: \n     A  B    C\n0  foo  1  2.0\n1  bar  2  5.0\n"], ["df.groupby('A').apply(lambda x: x.loc[x['B'].idxmin(), ['B','C']]).reset_index()\n"], ["import math\nsize = int(input())\nlist1 = []\n\nfor x in input().split():\n    num = int(x)\n    list1 = list1 + [num]\n\nfor i in range(math.ceil(size/2)):\n    list1[i] = list1[size -1 -i] = list1[i] + list1[size -1 -i]\n\nfor i in range(size-1):\n    print(list1[i], end=\" \")\n\nprint(list1[size-1], end=\"\")\n"], [], ["arr = [1,2,3]\nresult = []\nfor i, j in zip(arr, arr[::-1]):\n    print (i, j)\n    result.append(i+j)\n\nprint(result)\n"], [], ["from selenium import webdriver\nimport requests\n\nurl = \"https://www.online-convert.com/file-format/eml\"\n\ndirf = r\"C:\\Users\\WCS\\Desktop\\emlfolder\"\n\ndef download_file(link):\n    driver.get(link)\n    linkElement = driver.find_element_by_css_selector(\"a[href$='example.eml']\")\n    r = requests.get(linkElement.get_attribute('href'))\n    file = open(\"C:\\Users\\WCS\\Desktop\\emlfolder\\example.eml\", 'wb')\n    file.write(r.content)\n    file.close()\n\nif __name__ == '__main__':\n    chromeOptions = webdriver.ChromeOptions()\n    prefs = {'download.default_directory' : dirf}\n    chromeOptions.add_experimental_option('prefs', prefs)\n    driver = webdriver.Chrome(chrome_options=chromeOptions)\n    download_file(url)\n    driver.quit()\n"], ["prefs = {\n    'download.default_directory': dirf,\n    'download.prompt_for_download': False,\n    'download.extensions_to_open': 'eml',\n    'safebrowsing.enabled': False\n}\n\noptions.add_experimental_option('prefs', prefs)\ndriver = webdriver.Chrome(chrome_options=options)\n"], [], [], ["age = models.IntegerField(null=True)\n"], [], ["chromeOptions = webdriver.ChromeOptions()\nchromeOptions.add_argument('--safebrowsing-disable-download-protection')\ndriver = webdriver.Chrome(chrome_options=chromeOptions)\n"], ["  chromeOptions = webdriver.ChromeOptions()\n  prefs = {'safebrowsing.enabled': 'false'}\n  chromeOptions.add_experimental_option(\"prefs\", prefs)\n  driver = webdriver.Chrome(chrome_options=chromeOptions)\n"], [">>> d = { 'a': 'b' }\n>>> key, value = list(d.items())[0]\n>>> key\n'a'\n>>> value\n'b'\n", ">>> key, value = next(iter(d.items()))\n>>> key\n'a'\n>>> value\n'b'\n", ">>> key = list(d.keys())[0]\n>>> key\n'a'\n>>> value = list(d.values())[0]\n>>> value\n'b'\n", ">>> key = next(iter(d.keys()))\n>>> key\n'a'\n>>> value = next(iter(d.values()))\n'b'\n", ">>> d = {'some_key': 1}\n>>> key, value = next((str(k), str(v)) for k, v in d.items())\n>>> key\n'some_key'\n>>> value\n'1'\n>>> type(key)\n<class 'str'>\n>>> type(value)\n<class 'str'>\n"], [">>> d = { 'a': 'b' }\n>>> d.items()\ndict_items([('a', 'b')])\n", ">>> [[key, value]] = d.items()\n>>> key\n'a'\n>>> value\n'b'\n", ">>> d = { 'a': 'b', 'c':'d' }\n>>> [[key, value]] = d.items()\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nValueError: too many values to unpack (expected 1)\n", ">>> d = { 1: 2 }\n>>> [[key, value]] = ((str(key), str(value)) for key,value in d.items())\n>>> key\n'1'\n>>> value\n'2'\n"], ["dict={'a':'b'}\n\nkeys = list(dict.keys())\nvalues = list(dict.values())\n", "key = keys[0]\nvalue = values[0]\n"], [], ["sed \"s/async/_async/g\" \"/usr/lib/python3/dist-packages/pexpect/spawnbase.py\" > tmp.txt && cat tmp.txt > \"/usr/lib/python3/dist-packages/pexpect/spawnbase.py\" && rm tmp.txt\n"], [], [], ["pip install --upgrade scikit-image\n", "    Installing collected packages: dask, scikit-image\n  Found existing installation: dask 0.19.1\n    Uninstalling dask-0.19.1:\n      Successfully uninstalled dask-0.19.1\n  Found existing installation: scikit-image 0.13.0\n    Uninstalling scikit-image-0.13.0:\n      Successfully uninstalled scikit-image-0.13.0\nSuccessfully installed dask-1.0.0 scikit-image-0.14.2\n"], ["# convert the elements of tupple to float\ntupple = tuple(float(i) for i in tupple)\nprint(tupple)\n# returns (44.0, 34.0, 17.0, 6.0, 15.0)\n\n# take the max of tupple\nmax(tupple)\n# returns 44.0\n\n# take the min of tupple\nmin(tupple)\n# returns 6.0\n"], ["t = ('44.0', '34.0', '17.0', '6.0','15.0')\nprint(min(map(float,t))) #prints 6.0\nprint(max(map(float,t))) #prints 44.0\n"], [" max(tupple, key=float) 44.0\n min(tupple, key=float) 6.0\n"], ["max(yourTupple, key = float)\n"], ["max(tupple, key=float)\n# '44.0'\n\nmin(tupple, key=float)\n# '6.0'\n"], ["sorted(l, key = lambda s: (s!='p', s=='q', s))\n['p', 'p', 'a', 'b', 'c', 'd', 'f', 'g', 'n', 't', 'z', 'q', 'q']\n", "t = [(s!='p', s=='q', s) for s in pl]\n\nprint(t)\n[(True, False, 'f'),\n (True, False, 'g'),\n (False, False, 'p'),\n (True, False, 'a'),\n (False, False, 'p'),\n (True, False, 'c'),\n (True, False, 'b'),\n (True, True, 'q'),\n (True, False, 'z'),\n (True, False, 'n'),\n (True, False, 'd'),\n (True, False, 't'),\n (True, True, 'q')]\n", "sorted(t)\n[(False, False, 'p'),\n (False, False, 'p'),\n (True, False, 'a'),\n (True, False, 'b'),\n (True, False, 'c'),\n (True, False, 'd'),\n (True, False, 'f'),\n (True, False, 'g'),\n (True, False, 'n'),\n (True, False, 't'),\n (True, False, 'z'),\n (True, True, 'q'),\n (True, True, 'q')]\n"], [" from django.contrib import admin\n from django.urls import path, include\n\n urlpatterns = [\n     path('admin/', admin.site.urls),\n     path('', include('static_pages.urls')), #included urls from static_pages app\n ]\n", " from django.contrib import admin\n from django.urls import path\n from . import views\n\n urlpatterns = [\n      path('', views.index, name=\"index\"),\n ]\n", " from django.shortcuts import render\n from django.http import HttpResponse\n\n def index(request):\n     return HttpResponse(\"First Django2 Message!\")\n"], ["path('', views.index, name='index'),\npath('', views.myapp_index, name='myapp_index'),\n", "path('', include('myapp.urls')),\n", "path('index/', include('myapp.urls')),\n", "path('', views.index, name='index'),\n", "path('index/', views.index, name='index'),\n", "path('', include('myapp.urls')),\n", "path('^$', include('myapp.urls')),\n", "path('', views.index, name='index'),\n", "path('^$', views.index, name='index'),\n"], ["from collections import defaultdict\n\nl = [\"f\", \"g\", \"p\", \"a\", \"p\", \"c\", \"b\", \"q\", \"z\", \"n\", \"d\", \"t\", \"q\"]\n\nkeys = {\"p\": \"front\", \"q\": \"end\"}\n\nd = defaultdict(list)\nfor item in l:\n    d[keys.get(item, \"middle\")].append(item)\n\nprint(d[\"front\"] + sorted(d[\"middle\"]) + d[\"end\"])\n# ['p', 'p', 'a', 'b', 'c', 'd', 'f', 'g', 'n', 't', 'z', 'q', 'q']\n"], ["list = ['f','g','p','a','p','c','b','q','z','n','d','t','q'];\nnoOfPs = [i for i in l if i == 'p']; \nnoOfQs = [i for i in l if i == 'q'];\nresultList= noOfPs + sorted(filter(lambda x:x not in {'q', 'p'}, l))+ noOfQs \n"], [" ...\n path(r'^', include('myapp.urls')),\n ...\n", " ...\n path(r'^$', views.index, name='index'),\n # path('', views.myapp_index, name='myapp_index'), ## REMOVE THIS ROW ##\n ...\n"], ["path('myapp/', include('myapp.urls'))\npath('index/', include('myapp.urls'))\n"], ["path('', views.index, name='index')\n"], [">>> def _key(x):\n...     if x == 'p':\n...         return -1\n...     elif x == 'q':\n...         return float('inf')\n...     else:\n...         return ord(x)\n...\n>>> l = ['f','g','p','a','p','c','b','q','z','n','d','t','q']\n>>> sorted(l, key=_key)\n['p', 'p', 'a', 'b', 'c', 'd', 'f', 'g', 'n', 't', 'z', 'q', 'q']\n"], ["L = ['f','g','p','a','p','c','b','q','z','n','d','t','q']\n\ndef sort_func(x):\n    priority = {'p': 0, 'q': 2}\n    return priority.get(x, 1), x\n\nres = sorted(L, key=sort_func)\n\nprint(res)\n\n['p', 'p', 'a', 'b', 'c', 'd', 'f', 'g', 'n', 't', 'z', 'q', 'q']\n"], ["l = ['f','g','p','a','p','c','b','q','z','n','d','t','q']\n_ps, _qs = [i for i in l if i == 'p'], [i for i in l if i == 'q']\nnew_l = _ps+sorted(filter(lambda x:x not in {'q', 'p'}, l))+_qs\n", "['p', 'p', 'a', 'b', 'c', 'd', 'f', 'g', 'n', 't', 'z', 'q', 'q']\n"], ["l = ['f','g','p','a','p','c','b','q','z','n','d','t','q']\n\ndef key(c):\n    if c == 'q':\n        return (2, c)\n    elif c == 'p':\n        return (0, c)\n    return (1, c)\n\n\nresult = sorted(l, key=key)\nprint(result)\n", "['p', 'p', 'a', 'b', 'c', 'd', 'f', 'g', 'n', 't', 'z', 'q', 'q']\n"], ["for y in range(2,half):\n    res = x%y\n    if res==0:\n        sum = sum + x\n        break\n", "from math import sqrt \n\ntest = int(input())\nfor i in range(test):\n    sum = 0\n    max = int(input())\n    if max==1:\n        sum = 0\n    elif max==2:\n        sum += 2\n    else:    \n        sum = sum + 2\n        for x in range(3,max+1):\n            half = int(sqrt(x)) + 1\n            if all(x%y!=0 for y in range(2,half)):\n                sum = sum + x\n   print(sum)     \n"], ["from math import sqrt \nsum = 0\ntest = int(input())\nmax = int(input())\n\n\nfor x in range(test,max+1):\n    if x == 1:\n        pass\n    else:\n        half = int(sqrt(x)) + 1\n        for y in range(2,half):\n            res = x%y\n            if res==0:\n                break\n        else:\n            sum = sum + x\n\nprint(sum)    \n"], ["def primeAddition(ip): \n    # list to store prime numbers...\n    prime = [True] * (ip + 1) \n\n    p = 2\n    while p * p <= ip: \n        # If prime[p] is not changed, then it is a prime...\n        if prime[p] == True: \n            # Update all multiples of p...\n            i = p * 2\n            while i <= ip: \n                prime[i] = False\n                i += p \n        p += 1    \n\n    # Return sum of prime numbers...\n    sum = 0\n    for i in range (2, ip + 1): \n        if(prime[i]): \n            sum += i \n    return sum\n\n#The program is ready... Now, time to call the primeAddition() function with any argument... Here I pass 5 as an argument...\n#Function call...\n\nprint primeAddition(5)\n"], ["for x in range(3,max+1):\n        half = int(sqrt(max)) + 1\n", "for x in range(3,max+1):\n        half = int(sqrt(x)) + 1\n"], ["from collections import Counter\n\ns = \"aaabbbd\"\n\ncounts = {k: v for k, v in Counter(s).items() if v > 2}\n\nprint(counts)\n# {'a': 3, 'b': 3}\n", "from collections import Counter\n\ns = \"aaabbbd\"\n\ncounts = Counter(s)\n\ncount_items = list(counts.items())\nfor k, v in count_items:\n    if v <= 2:\n        counts.pop(k) # Or del counts[k]\n\nprint(counts)\n# Counter({'a': 3, 'b': 3})\n", ">>> from collections import Counter\n>>> x = Counter({'a': 1})\n>>> y = {'a': 1}\n>>> x['b']\n0\n>>> y['b']\nTraceback (most recent call last):\nFile \"<stdin>\", line 1, in <module>\nKeyError: 'b'\n"], [" for w in sorted(freq, key=freq.get, reverse=True):\n     if freq[w] == 1:\n         del freq[w]\n     else:\n         print (w, freq[w])\n"], ["if freq[w] == 1:\n    del freq[w]\n    print (w, freq[w])\n", "s = \"aaabbbd\"\ndef check_freq(s):\n    freq = {}\n    for c in s:\n        freq[c] = s.count(c)\n    for w in sorted(freq, key=freq.get, reverse=True):\n        if freq[w] == 1 or freq[w] == 2:\n            del freq[w]\n        else:\n            print (w, freq[w])\nprint(freq)\n\ncheck_freq(s)\n", "a 3\nb 3\n{'a': 3, 'b': 3}\n"], ["s = \"aaabbbd\"\n\ndef check_freq(s):\n    freq = {}\n    for c in s:\n        freq[c] = s.count(c)\n\n    for key, value in freq.items():\n        if value == 1:\n            del freq[key]\n\n    return freq\n\nprint check_freq(s)\n"], ["s = \"aaabbbd\"\ndef check_freq(s):\n    freq = {}\n    for c in s:\n        freq[c] = s.count(c)\n    for w in sorted(freq, key=freq.get, reverse=True):\n        if freq[w] == 1:\n            del freq[w]\n            continue\n        print (w, freq[w])\n    return freq\nresult = check_freq(s)\n\n>a 3\nb 3\n\nresult \n> {'a': 3, 'b': 3}\n"], ["test03 = np.array([2,2,10,4,4,4,5,6,7,2,6,5,5,7,7,1,1])  # Size 17\nextended = np.empty(len(test03)+2)  # Rooms to manage edges, size 19\nextended[1:-1] = test03\nextended[0] = extended[-1] = np.inf\n\nflag_left = extended[:-1] <= extended[1:]  # Less than successor, size 18\nflag_right = extended[1:] <= extended[:-1]  # Less than predecessor, size 18\n\nflagmini = flag_left[1:] & flag_right[:-1]  # Local minimum, size 17\nmini = np.where(flagmini)[0]  # Indices of minimums\nspl = np.where(np.diff(mini)>1)[0]+1  # Places to split\nresult = np.split(mini, spl)\n", "[0, 1] [3, 4, 5] [9] [11, 12] [15, 16]\n", "import numpy as np\ntest03=np.array([12,13,12,4,4,4,5,6,7,2,6,5,5,7,7,17,17])\nextended=np.full(len(test03)+2,np.inf)\nextended[1:-1]=test03\n\nslope = np.sign(np.diff(extended))  # 1 if ascending,0 if flat, -1 if descending\nnot_flat,= slope.nonzero() # Indices where data is not flat.   \nlocal_min_inds, = np.where(np.diff(slope[not_flat])==2) \n\n#local_min_inds contains indices in not_flat of beginning of local mins. \n#Indices of End of local mins are shift by +1:   \nstart = not_flat[local_min_inds]\nstop =  not_flat[local_min_inds+1]-1\n\nprint(*zip(start,stop))\n#(0, 1) (3, 5) (9, 9) (11, 12) (15, 16)    \n", "#@numba.njit\ndef localmins(a):\n    begin= np.empty(a.size//2+1,np.int32)\n    end  = np.empty(a.size//2+1,np.int32)\n    i=k=0\n    begin[k]=0\n    search_end=True\n    while i<a.size-1:\n         if a[i]>a[i+1]:\n                begin[k]=i+1\n                search_end=True\n         if search_end and a[i]<a[i+1]:   \n                end[k]=i\n                k+=1\n                search_end=False\n        i+=1\n    if search_end and i>0  : # Final plate if exists \n        end[k]=i\n        k+=1 \n    return begin[:k],end[:k]\n\n    print(*zip(*localmins(test03)))\n    #(0, 1) (3, 5) (9, 9) (11, 12) (15, 16)  \n"], ["import numpy as np\nfrom numpy.lib.stride_tricks import as_strided\n\ndef windowstride(a, window):\n    return as_strided(a, shape=(a.size - window + 1, window), strides=2*a.strides)\n\ndef local_min(a, maxwindow=None, doends=True):\n    if doends: a = np.pad(a.astype(float), 1, 'constant', constant_values=np.inf)\n    if maxwindow is None: maxwindow = a.size - 1\n\n    mins = []\n    for i in range(3, maxwindow + 1):\n        for j,w in enumerate(windowstride(a, i)):\n            if (w[0] > w[1]) and (w[-2] < w[-1]):\n                if (w[1:-1]==w[1]).all():\n                    mins.append((j, j + i - 2))\n\n    mins.sort()\n    return mins\n", "test03=np.array([2,2,10,4,4,4,5,6,7,2,6,5,5,7,7,1,1])\nlocal_min(test03)\n", "[(0, 2), (3, 6), (9, 10), (11, 13), (15, 17)]\n", "for s in local_mins(test03):\n    print(test03[slice(*s)])\n", "[2 2]\n[4 4 4]\n[2]\n[5 5]\n[1 1]\n"], ["import numpy as np\na = np.array([2,2,10,4,4,4,5,6,7,2,6,5,5,7,7,1,1])\n\ndef local_min(a):\n    temp_list = list(a)\n    maxval = max(a) #use max while finding minima\n    temp_list = temp_list + [maxval] #handles last value edge case.\n\n    prev = maxval #prev stores last value seen\n    loc = 0 #used to store starting index of minima\n    count = 0 #use to count repeated values\n    #match_start = False\n    matches = []\n    for i in range(0, len(temp_list)): #need to check all values including the padded value\n        if prev == temp_list[i]:\n            if count > 0: #only increment for minima candidates\n                count += 1\n        elif prev > temp_list[i]:\n            count = 1\n            loc = i\n    #        match_start = True\n        else: #prev < temp_list[i]\n            if count > 0:\n                matches.append((loc, count))\n            count = 0\n            loc = i\n        prev = temp_list[i]\n    return matches\n\nresult = local_min(a)\n\nfor match in result:\n    print (\"{} minima found starting at location {} and ending at location {}\".format(\n            match[1], \n            match[0],\n            match[0] + match[1] -1))\n"]]