[["In [45]: Deck13Sample = ['Two','Three','Four','Five','Six','Seven','Eight','Nine','Ten','Jack','Queen','King'\n    ...: ,'Ace'] \n    ...: CardTypes = [' of Hearts',' of Spades',' of Diamonds',' of Clubs']                                  \nIn [46]: A=np.array(Deck13Sample,object)                                                                     \nIn [47]: B=np.array(CardTypes,object)                                                                        \nIn [48]: A[None,:]+B[:,None]                                                                                 \nOut[48]: \narray([['Two of Hearts', 'Three of Hearts', 'Four of Hearts',\n        'Five of Hearts', 'Six of Hearts', 'Seven of Hearts',\n        'Eight of Hearts', 'Nine of Hearts', 'Ten of Hearts',\n        'Jack of Hearts', 'Queen of Hearts', 'King of Hearts',\n        'Ace of Hearts'],\n       ['Two of Spades', 'Three of Spades', 'Four of Spades',\n        'Five of Spades', 'Six of Spades', 'Seven of Spades',\n        'Eight of Spades', 'Nine of Spades', 'Ten of Spades',\n        'Jack of Spades', 'Queen of Spades', 'King of Spades',\n        'Ace of Spades'],\n       ['Two of Diamonds', 'Three of Diamonds', 'Four of Diamonds',\n        'Five of Diamonds', 'Six of Diamonds', 'Seven of Diamonds',\n        'Eight of Diamonds', 'Nine of Diamonds', 'Ten of Diamonds',\n        'Jack of Diamonds', 'Queen of Diamonds', 'King of Diamonds',\n        'Ace of Diamonds'],\n       ['Two of Clubs', 'Three of Clubs', 'Four of Clubs',\n        'Five of Clubs', 'Six of Clubs', 'Seven of Clubs',\n        'Eight of Clubs', 'Nine of Clubs', 'Ten of Clubs',\n        'Jack of Clubs', 'Queen of Clubs', 'King of Clubs',\n        'Ace of Clubs']], dtype=object)\n"], ["deck = []\nfor rank in Deck13Sample:\n    for suit in CardTypes:\n        deck.append(f'{rank} of {suit}')\n", "deck = [f'{rank} of {suit}' for rank in Deck13Sample for suit in CardTypes]\n", "deck = [f'{rank} of {suit}' for rank, suit in itertools.product(Deck13Sample, CardTypes)]\n"], [">>> from itertools import product as pd\n\n>>> Deck13Sample = ['Two','Three','Four','Five','Six','Seven','Eight','Nine','Ten','Jack','Queen','King','Ace']\n>>> CardTypes = [' of Hearts',' of Spades',' of Diamonds',' of Clubs']\n\n>>> [ i+j for i, j in pd(Deck13Sample, CardTypes)]\n['Two of Hearts', 'Two of Spades', 'Two of Diamonds', 'Two of Clubs', 'Three of Hearts', 'Three of Spades', 'Three of Diamonds', 'Three of Clubs', 'Four of Hearts', 'Four of Spades', 'Four of Diamonds', 'Four of Clubs', 'Five of Hearts', 'Five of Spades', 'Five of Diamonds', 'Five of Clubs', 'Six of Hearts', 'Six of Spades', 'Six of Diamonds', 'Six of Clubs', 'Seven of Hearts', 'Seven of Spades', 'Seven of Diamonds', 'Seven of Clubs', 'Eight of Hearts', 'Eight of Spades', 'Eight of Diamonds', 'Eight of Clubs', 'Nine of Hearts', 'Nine of Spades', 'Nine of Diamonds', 'Nine of Clubs', 'Ten of Hearts', 'Ten of Spades', 'Ten of Diamonds', 'Ten of Clubs', 'Jack of Hearts', 'Jack of Spades', 'Jack of Diamonds', 'Jack of Clubs', 'Queen of Hearts', 'Queen of Spades', 'Queen of Diamonds', 'Queen of Clubs', 'King of Hearts', 'King of Spades', 'King of Diamonds', 'King of Clubs', 'Ace of Hearts', 'Ace of Spades', 'Ace of Diamonds', 'Ace of Clubs']\n"], ["Deck52Sample = []\nfor number in Deck13Sample:\n    for suit in CardTypes:\n        Deck52Sample.append(number + suit)\n"], ["import itertools\n\ndeck = [rank + suit for rank, suit in itertools.product(Deck13Sample, CardTypes)]\n", "In [28]: deck\nOut[28]: \n['Two of Hearts',\n 'Two of Spades',\n 'Two of Diamonds',\n...\n'Ace of Spades',\n'Ace of Diamonds',\n'Ace of Clubs']\n"], ["In [18]: np.char.add(Deck13Sample,np.array(CardTypes)[:,None])\nOut[18]: \narray([['Two of Hearts', 'Three of Hearts', 'Four of Hearts',\n        'Five of Hearts', 'Six of Hearts', 'Seven of Hearts',\n        'Eight of Hearts', 'Nine of Hearts', 'Ten of Hearts',\n        'Jack of Hearts', 'Queen of Hearts', 'King of Hearts',\n        'Ace of Hearts'],\n       ['Two of Spades', 'Three of Spades', 'Four of Spades',\n        'Five of Spades', 'Six of Spades', 'Seven of Spades',\n        'Eight of Spades', 'Nine of Spades', 'Ten of Spades',\n        'Jack of Spades', 'Queen of Spades', 'King of Spades',\n        'Ace of Spades'],\n       ['Two of Diamonds', 'Three of Diamonds', 'Four of Diamonds',\n        'Five of Diamonds', 'Six of Diamonds', 'Seven of Diamonds',\n        'Eight of Diamonds', 'Nine of Diamonds', 'Ten of Diamonds',\n        'Jack of Diamonds', 'Queen of Diamonds', 'King of Diamonds',\n        'Ace of Diamonds'],\n       ['Two of Clubs', 'Three of Clubs', 'Four of Clubs',\n        'Five of Clubs', 'Six of Clubs', 'Seven of Clubs',\n        'Eight of Clubs', 'Nine of Clubs', 'Ten of Clubs',\n        'Jack of Clubs', 'Queen of Clubs', 'King of Clubs',\n        'Ace of Clubs']], dtype='<U17')\n"], ["import random\nfilename = r\"C:\\users\\Cece\\words.txt\"\nwith open(filename) as f:\n    content = f.readlines()\n# you may also want to remove whitespace characters like `\\n` at the end of each line\ncontent = [x.strip() for x in content]\nwords5 = []\nfor x in content:\n    if len(x) == 5:\n        words5.extend(x) \nprint(random.choice(words5))\n"], ["with open(r\"C:\\users\\Cece\\words.txt\") as f:\n    words_5 = []\n    for line in f:\n        word = line.strip()\n        if len(word) == 5:\n            words_5.append(word.upper())\n"], ["import random\n\ndef take_random_5(l):\n    randword = random.choice(l)\n    if len(randword) != 5:\n        return \n    return randword\n\nwords = r\"C:\\users\\Cece\\words.txt\" \nlines = [line.rstrip('\\n') for line in open(words)]\nwhile True:\n    take_random_5(lines)\n"], ["lines = [line.rstrip('\\n') for line in open(words) if len(line.rstrip('\\n')) == 5]\n"], ["randword = random.choice(wordsC)\n", "randword = random.choice(wordsC)\n\nwhile len(randword) != 5:\n    randword = random.choice(wordsC)\nword = randword.upper()\nmyword =  list(word)\n"], [], [], [], [], ["if num1 % num2 == 0:\n    return num1, num2\n"], [], [], ["public class UserService\n{\n    public void addUser(User toAdd)\n}\n"], [], [">>> predictions = np.array([0, 0.2, 0.9, 0.7])\n>>> predictions.round().tolist()\n[0, 0, 1, 1]\n>>> \n", ">>> predictions = [0, 0.2, 0.9, 0.7]\n>>> [int(i >= 0.5) for i in predictions]\n[0, 0, 1, 1]\n"], ["import numpy as np\npredictions = [0.0, 0.2, 0.9, 0.7] \nnewList = np.where(np.array(predictions) >= 0.5,1, 0).tolist()\n\nprint(newList)\nprint(newList[0])\n", "[0, 0, 1, 1]\n0\n"], ["[0 if i>=0.5 else 1 for i in predictions]\n"], ["threshold = 0.5 \nprediction=np.array([0,0.2,0.9,0.7])\nprediction[prediction<=threshold]=0\nprediction[prediction>threshold]=1\n"], ["def f(n):\n  total=0\n  for i in range(1,n,2):\n    total += i\n  return total\n\ndef g(n):\n  half = n // 2\n  return half * half\n\nfor n in xrange(100):\n  print f(n), g(n)\n", "         *\n       * * *\n     * * * * *\n   * * * * * * *\n", "         *\n       * * *\n     * *   * *\n   * *       * *\n", "   *  *  *  *\n   *  *  *  *\n   *  *\n   *  *\n", "       *\n     *   *\n\n   *  *  *  *\n   *  *  *  *\n   *  *  *  *\n   *  *  *\n", "       *\n", "   *  *  *  *\n   *  *  *  *\n   *  *  *  *\n   *  *  *  *\n"], [], ["open_file = open(words_file_name, 'r')\nconversions = {}\nfor line in open_file:\n    piece = line.split(',')\n    value = piece[0]               # <- the first item will be the value\n    for key in piece[1:]:          # <- iterate over the rest of the items in the line\n        conversions[key] = value   # <- add the key:value pair to the dictionary\nprint(conversions)\n"], ["open_file = open('read.txt', 'r')\nconversions = {}\nfor line in open_file:\n    piece = line.rstrip().split(',') #rstrip to remove \\n\n    key = piece[0]\n    for obj in piece[1:]:\n        conversions[obj]=key\nprint (conversions)\n", "{'sella': 'chair', 'coche': 'car', 'stuhl': 'chair', 'silla': 'chair', 'auto': 'car'}\n"], ["d = {}\nwith open('your-file.txt', 'r') as fhin:\n    for line in fhin:\n        words = line.strip().split(',')\n        en_word = words.pop(0)\n        for word in words:\n            d[word] = en_word\n"], ["open_file = open(words_file_name, 'r')\nconversions = {}\nfor line in open_file:\n    val, keys = line.strip().split(',', 1)\n    conversions.update(dict.fromkeys(keys.split(','), val))\n\nprint (conversions)\n", "{'sella': 'chair', 'coche': 'car', 'stuhl': 'chair', 'silla': 'chair', 'auto': 'car'}\n"], ["import csv\ncsv_data=csv.DictReader(open('file_loc'))\nfor row in csv_data:\n    #DoSomething  \n"], ["f = lambda arg: list(\n    map(\n         lambda i: \"\".join(filter(\n             lambda j: j.isalpha(), i.replace(\"0\", \"o\"))\n         ), arg\n    )\n)\n\nwords = ['12hell0','123word']\nprint(f(words))\n# ['hello', 'word']\n"], ["import re\nwords = ['12hell0','123word']\nnew_words = [word.replace('0','o') for word in words]\nstripped = [re.search('[^\\d]+',word).group() if re.search('[^\\d]+',word) else '' for word in new_words]\n"], ["words = ['12hell0','123word']\nwords = [''.join('o' if c == '0' else '' if c.isdigit() else c for c in word) for word in words]\nprint(words)\n", "['hello', 'word']\n"], ["words = ['12hell0','123word', ...]\nnew_words = [] # This will receive the changed words\n\nfor word in words: # Iterating through array elements\n    # This will store the new word.\n    new_word = ''.join([ch.replace('0', 'o') for ch in word if not ch.isdigit() or ch == '0'])\n    new_words.append(new_word)\nprint(new_words)\n"], ["\"\".join(['o' if i == '0' else i for i in \"123hell0\" if not i.isdigit() or i=='0'])\n"], ["words =['12hell0','123word']\nnew_words = []\nfor word in words:\n  stripped = ''.join([i if not i.isdigit() else 'o' if i == '0' else '' for i in word])\n  new_words.append(stripped)\nprint(new_words)\n", "['hello', 'word']\n"], ["stripped = ''.join([transform(i) for i in word if not i.isdigit()]\n"], ["def replaceDigits(word):\n    stripped = \"\"\n    for char in word:\n        if char == \"0\":\n            stripped += \"o\"\n        elif not char.isdigit():\n            stripped += char\n    return stripped\n\n\nwords = ['12hell0', '123word']\nstripped = [replaceDigits(n) for n in words]\nprint(stripped)\n"], [], ["def f_recursive1(n):\n    if n <= 1:\n        return 0\n    elif n % 2 == 0:\n        return n - 1 + f_recursive1(n-2)\n    else:  # n odd\n        return n - 2 + f_recursive1(n-2)\n", "def f_recursive2(n):\n    def f_helper(x):\n        if x <= 0:\n            return 0\n        return x + f_helper(x-2)\n\n    if n % 2 == 0:\n        return f_helper(n-1)\n    else:\n        return f_helper(n-2)\n"], ["def func(start,end, step):\n    if(start >= end):\n        return 0\n\n    return start + func(start + step, end, step)\n"], ["def function1(n):\n    def inner(i):\n        return 0 if i >= n else i + inner(i + 2)\n    return inner(1)\n"], ["def f1(n):\n    if n <= 1:\n        return 0\n    else:\n        isOdd = (n-1)%2==1\n        return f1(n-1) + (n-1 if isOdd else 0)\n"], ["def repl(src):\n    return di[src] if src in di else 0.0\n", "df2 = df.col1.str.extractall(r'(?P<n1>\\d+)? ?(?P<n2>[a-z.]+)').fillna('0')\ndf2.n1 = pd.to_numeric(df2.n1)\ndf2.n2 = df2.n2.apply(repl)\n", "         n1    n2\n  match          \n0 0       3  10.0\n  1       3   2.0\n  2       1   1.5\n1 0       4  10.0\n  1       4   2.0\n  2       1   1.5\n  3       1   1.0\n2 0       0   0.0\n", "df2.groupby(level=0).apply(lambda gr: gr.product(axis=1).sum())\n", "0    37.5\n1    50.5\n2     0.0\n"], ["from functools import reduce\nfrom operator import mul\n\ndef m(x): return di.get(x, x)\n\ndf.assign(result=[\n    sum(\n        reduce(mul, map(float, map(m, s.split())))\n        for s in row.split(', ')\n    ) for row in df.col1\n])\n\n                  col1  result\n0       3 a, 3 ab, 1 b    37.5\n1  4 a, 4 ab, 1 b, 1 d    50.5\n2               np.nan     0.0\n"], ["df['col1'].str.split(', ',expand=True).replace({' ':'*','np.nan':'0'},regex=True).\\\n     stack().apply(lambda x : eval(x,di)).sum(level=0)\nOut[884]: \n0    37.5\n1    50.5\n2     0.0\ndtype: float64\n"], ["new  = explode_str(df.dropna(), 'col1', ',')['col1'].str.strip().str.split(' ', expand=True).append(df[df['col1'].isna()])\n\ns = new[1].map(di) * pd.to_numeric(new[0])\n\ndf['result'] = s.groupby(s.index).sum()\n", "                  col1  result\n0       3 a, 3 ab, 1 b    37.5\n1  4 a, 4 ab, 1 b, 1 d    50.5\n2                  NaN     0.0\n", "def explode_str(df, col, sep):\n    s = df[col]\n    i = np.arange(len(s)).repeat(s.str.count(sep) + 1)\n    return df.iloc[i].assign(**{col: sep.join(s).split(sep)})\n"], ["for key in di.keys():\n    df['col1'] = df['col1'].str.replace(key, '*' + str(di[key]))\n", "df['col1'] = df['col1'].str.replace(',', '+')\n", "df['result'] = df['col1'].apply(eval)\n", "df['col1'] = df['col1'].str.replace('np.nan', '0')\n"], ["import json\nfrom collections import Counter, defaultdict\n\ndata = \"\"\"{\"Date\": \"Fri, 19 Apr 2019 00:54:46 GMT\", \"Vary\": \"Host,Accept-Encoding\", \"Key-Word\": \"00a\", \"Cache-Control\": \"private\", \"Key-Word\": \"xn\"}\n\n\"\"\"\n\ndef duplicate_keys(pairs):\n    out = {}\n    dups = defaultdict(list)\n    key_count = Counter(key for key, value in pairs)\n\n    for key, value in pairs:\n        if key_count[key] == 1:\n            out[key] = value\n        else:\n            dups[key].append(value)\n\n    # Concatenate the lists of values in a string, enclosed in {} and separated by ';'\n    # rather than in a list:       \n    dups = {key: ';'.join('{' + v + '}' for v in values) for key, values in dups.items()}\n\n    out.update(dups)\n    return out\n\ndecoded = json.loads(data, object_pairs_hook=duplicate_keys)\nprint(decoded)\n\n# {'Date': 'Fri, 19 Apr 2019 00:54:46 GMT', \n#  'Vary': 'Host,Accept-Encoding', \n#  'Cache-Control': 'private', \n#  'Key-Word': '{00a};{xn}'}\n"], ["import ast\nfrom pprint import pprint\n\ndef parse_dict_multikey(s):\n    p = ast.parse(s)\n    exp_dict = p.body[0].value\n    keys = list(map(ast.literal_eval, exp_dict.keys))\n    values = list(map(ast.literal_eval, exp_dict.values))\n    d = {}\n    for k, v in zip(keys, values):\n        d.setdefault(k, []).append(v)\n    return d\n\ns = ('{\"Date\": \"Fri, 19 Apr 2019 00:54:46 GMT\",'\n     ' \"Vary\": \"Host,Accept-Encoding\",'\n     ' \"Key-Word\": \"00a\",'\n     ' \"Cache-Control\": \"private\",'\n     ' \"Key-Word\": \"xn\"}')\npprint(parse_dict_multikey(s))\n# {'Cache-Control': ['private'],\n#  'Date': ['Fri, 19 Apr 2019 00:54:46 GMT'],\n#  'Key-Word': ['00a', 'xn'],\n#  'Vary': ['Host,Accept-Encoding']}\n", "def parse_dict_multikey(s):\n    p = ast.parse(s)\n    exp_dict = p.body[0].value\n    keys = list(map(ast.literal_eval, exp_dict.keys))\n    values = list(map(ast.literal_eval, exp_dict.values))\n    c = Counter(keys)\n    d = {}\n    for k, v in zip(keys, values):\n        if c[k] > 1:\n            d.setdefault(k, []).append(v)\n        else:\n            d[k] = v\n    return d\n"], [], ["from collections import defaultdict\n\nstring = '{\"Date\": \"Fri, 19 Apr 2019 00:54:46 GMT\", \"Vary\": \"Host,Accept-Encoding\", \"Key-Word\": \"00a\", \"Cache-Control\": \"private\", \"Key-Word\": \"xn\"}'\n\npieces = string.split('\",')\n\nfor each_piece in pieces:\n    key, value = each_piece.split(':', maxsplit=1)\n    actual_key = key.strip('{\"')\n    actual_value = value.strip(' \"')\n    data[actual_key].append(actual_value)\n\nprint(data)\n", "defaultdict(list,\n            {' \"Cache-Control': ['private'],\n             ' \"Key-Word': ['00a', 'xn\"}'],\n             ' \"Vary': ['Host,Accept-Encoding'],\n             'Date': ['Fri, 19 Apr 2019 00:54:46 GMT']})\n"], [], [], [], [], [], [], ["(?:meet|interview|appointment)\\S*\\s+((?:in|after)\\s[0-9]+\\s+(?:days?|months?|weeks?|years?))\n", "(?:in|after|on|from)\n", "(?:days?|months?|weeks?|years?|hours?)\n", "(?:meet|interview|appointment|session|schedule)\n", "import re\n\nregex = r\"(?:meet|interview|appointment)\\S*\\s+((?:in|after)\\s[0-9]+\\s+(?:days?|months?|weeks?|years?))\"\ntest_str = \"Fix me a meeting in 2 days meetings in 2 months meet in 1 week nomeeting in 2 days meet after 2 days\"\n\nprint(re.findall(regex, test_str, re.IGNORECASE))\n", "['in 2 days', 'in 2 months', 'in 1 week', 'in 2 days', 'after 2 days']\n"], [" \\b \n \\w* \n (?:\n      appointment\n   |  meet\n   |  interview\n )\n \\w* \n \\b \n ( .* )                        # (1)\n"], ["l=text.split()\nfor i in meetingStrings:\n    for idx, j in enumerate(l):\n        if i in j:\n            l=l[idx+1:] \nprint(' '.join(l))\n", "'in 2 days'\n"], ["text = \"Fix me a meeting in 2 days\"\nmeetingStrings = [\n    \"appointment\",\n    \"meet\",\n    \"interview\"\n]\n\n\nsep = [i for i in meetingStrings if i in text]\n\nidx = text.find(sep[0])\nidx_ = text[idx:].find(' ')\nprint (text[idx+idx_:])\n", "in 2 days\n"], ["import re\n\nmeetingStrings = [\n        \"appointment\",\n        \"meet\",\n        \"interview\"\n]\ntext = \"Fix me a meeting in 2 days\"\n\ndef split_string(text, strings):\n    search = re.compile('|'.join(strings))\n    start = None\n    input = text.split()\n    for e, x in enumerate(input):\n        if search.search(x):\n            if start < e:\n                yield ' '.join(input[start:e])\n            start = None\n        else:\n            if start is None:\n                start = e\n    else:\n        if start is not None:\n            yield ' '.join(input[start:])\n\nprint(' '.join(split_string(text, meetingStrings)))\n"], ["import re\n\nmeetingStrings = [\n    \"appointment\",\n    \"meet\",\n    \"interview\"\n]\n\ntext = \"Fix me a meeting in 2 days\"\n\nprint(re.split('|'.join(r'(?:\\b\\w*'+re.escape(w)+r'\\w*\\b)' for w in meetingStrings), text, 1)[-1])\n", " in 2 days\n"], ["for x in meetingStrings: \n    pre, _, post = text.lower().partition(x) \n    if post: \n        pre = pre.rpartition(' ')[0] if not pre.endswith(' ') else pre.rstrip() \n        post = post.partition(' ')[-1] if not post.startswith(' ') else post.lstrip() \n        print([pre, post]) \n", "In [35]: meetingStrings = [ \n    ...:     \"appointment\", \n    ...:     \"meet\", \n    ...:     \"interview\" \n    ...: ] \n    ...: text = \"Fix me a meeting in 2 days\" \n\n    ...: for x in meetingStrings: \n    ...:     pre, _, post = text.lower().partition(x) \n    ...:     if post: \n    ...:         pre = pre.rpartition(' ')[0] if not pre.endswith(' ') else pre.rstrip() \n    ...:         post = post.partition(' ')[-1] if not post.startswith(' ') else post.lstrip() \n    ...:         print([pre, post]) \n    ...:                                                                                                                                                                                                    \n['fix me a', 'in 2 days']\n"], ["meetingStrings = [\n    \"appointment\",\n    \"meet\",\n    \"interview\"\n]\ntext = \"Fix me a meeting in 2 days\"\nfor x in meetingStrings:\n    if x in text.lower():\n        txt = text.split(x, 1)[1]\n        print(txt.split(\" \", 1)[1]) #<--- Here\n"], [], [], ["import numpy as np\n\n\ndef to_numeric1(array, sep=' ', dtype=np.float):\n    \"\"\"\n    Converts an array of strings with delimiters in it \n    to an array of specified type\n    \"\"\"\n    split = np.char.split(array, sep=sep)\n    without_lists = np.array(split.tolist())\n    corrected_dimension = np.squeeze(without_lists)\n    return corrected_dimension.astype(dtype)\n", "import pandas as pd\n\n\ndef by_pandas(array, sep=' ', dtype=np.float):\n    df = pd.DataFrame(array)\n    return df[0].str.split(pat=sep, expand=True).to_numpy(dtype=dtype)\n", ">>> a = np.array([['0.1 0.2 0.3'], ['0.3 0.4 0.5'], ['0.5 0.6 0.7']])\n>>> np.char.split(a)\narray([[list(['0.1', '0.2', '0.3'])],\n       [list(['0.3', '0.4', '0.5'])],\n       [list(['0.5', '0.6', '0.7'])]], dtype=object)\n", "array([['0.1', '0.2', '0.3'],\n       ['0.3', '0.4', '0.5'],\n       ['0.5', '0.6', '0.7']], dtype='<U3')\n"], ["import pandas as pd\nimport random\n\ndef foo():\n    df = pd.DataFrame()\n    year = 2016\n    names = ['Bill', 'Bob', 'Ryan']\n    for day in range(1, 4, 1):\n        for name in names:\n            if random.choice([True, False]):   # sometimes a name will be missing\n                continue\n            value = random.randrange(0, 20, 1) # random value from heuristic\n            col = '{}_{}'.format(year, day)    # column name\n            new_df = pd.DataFrame({col: value, 'name':name}, index=[1]).set_index('name')\n            df = pd.concat([df,new_df[~new_df.index.isin(df.index)].dropna()])\n            df.update(new_df)\n    #df.set_index('name', inplace=True, drop=True)\n    print(df)\n"], ["df.groupby('name')[df.columns.values].sum()\n"], ["df.reset_index(inplace=True)\n\ndef aggdata(x):\n    if all([i <= 1 for i in x.count()]):\n        return x.mean()\n    else:\n        raise ValueError\n\nddf = df.groupby('name').apply(aggdata)\n"], ["df.pivot_table(index='name', aggfunc='sum', dropna=False)\n"], ["year = 2016\nnames = ['Bill', 'Bob', 'Ryan']\n\nindex = []\nvalueBill = []\nvalueBob = []\nvalueRyan = []\n\nfor day in range(1, 4):\n    if random.choice([True, False]):   # sometimes a name will be missing\n        valueBill.append(random.randrange(0, 20))\n        valueBob.append(random.randrange(0, 90))\n        valueRyan.append(random.randrange(0, 200)) \n        index.append('{}-0{}'.format(year, day))    # column name\n    else:\n        valueBill.append(np.nan)\n        valueBob.append(np.nan)\n        valueRyan.append(np.nan)\n        index.append(np.nan)\n\ndf = pd.DataFrame({})\n\nfor name, value in zip(names,[valueBill,valueBob,valueRyan]):\n    df[name] = value\ndf.set_index(pd.to_datetime(index))\n"], [], ["You just need to iterate through the nested dict and get the value of key USA.\n\nnested_d = {\n            'Beijing':{\n                'China':51,\n                'USA':36,\n                'Russia':22,\n                'Great Britain':19\n            },\n            'London':{\n                    'USA':46,\n                    'China':38,\n                    'Great Britain':29,\n                    'Russia':22\n            },\n            'Rio':{\n                'USA':35,\n                'Great Britain':22,\n                'China':20,\n                'Germany':13\n            }\n}\n\nus_medals_count = []\n\nfor key, value in nested_d.items():\n    if 'USA' in value.keys():\n        us_medals_count.append(value['USA'])\n\nprint(us_medals_count)\n"], ["nested_d = {'Beijing':{'China':51, 'USA':36, 'Russia':22, 'Great Britain':19}, 'London':{'USA':46, 'China':38, 'Great Britain':29, 'Russia':22}, 'Rio':{'USA':35, 'Great Britain':22, 'China':20, 'Germany':13}}\n\nUS_count = []\n\n\n\nfor nested in nested_d:\n    for country,medal in nested_d[nested].items() :\n        if country == 'USA':\n            US_count.append(medal)\n\nprint(US_count)\n", "[36, 46, 35]\n", "us_count = []\n\nfor key, value in nested_d.items():  #Here we getting dictionary in value.\n    if 'USA' in value.keys():\n        us_count.append(value['USA'])\n\nprint(us_count)\n"], ["C = []    \nfor i in A:\n    dic = {}\n    t=i.split()\n    for j in B:\n        dic[j]=t.count(j)\n    C.append(dic)\n# Result:\n[{'court': 2, 'hope': 2, 'mention': 0, 'life': 0, 'bolster': 0, 'internal': 0, 'level': 0},\n{'court': 1, 'hope': 2, 'mention': 0, 'life': 0, 'bolster': 0, 'internal': 0, 'level': 0},\n{'court': 0, 'hope': 1, 'mention': 2, 'life': 1, 'bolster': 1, 'internal': 1, 'level': 1}]\n"], ["import re\n\nwords = ['court', 'hope', 'mention', 'life', 'bolster', 'internal', 'level']\nphrases = ['philadelphia court excessive disappointed court hope hope','hope hope jurisdiction obscures acquittal court','mention hope maryland signal held mention problem internal reform life bolster level grievance']\n\ncounts = [{w: len(re.findall(r'\\b{}\\b'.format(w), p)) for w in words} for p in phrases]\n\nprint(counts)\n# [{'court': 2, 'hope': 2, 'mention': 0, 'life': 0, 'bolster': 0, 'internal': 0, 'level': 0}, {'court': 1, 'hope': 2, 'mention': 0, 'life': 0, 'bolster': 0, 'internal': 0, 'level': 0}, {'court': 0, 'hope': 1, 'mention': 2, 'life': 1, 'bolster': 1, 'internal': 1, 'level': 1}]\n"], ["if j in b:\n    dic[j] += t.count(j)\nelse:\n    dic[j] = t.count(j)\n"], ["dic=[]\nfor i in A:\n    i_dict = {}\n    t=i.split()\n    for j in B:\n        i_dict[j]=t.count(j)\n    dic.append(i_dict)\nprint(dic)\n"], ["the_list = []\nwith open(r'C:\\some_list.txt', \"r\") as f:\n    for line in f:\n        #print(len(line))\n        if (len(line)) < 50:#here I used 50 charecters\n            the_list.append(line)\n", "with open(r'C:\\some_list.txt', 'w') as f:\n    for line in the_list:\n        f.write(line)\n", "with open(r'C:\\some_list.txt', \"r\") as f, open('new.txt', 'a') as fw:\n    for line in f:\n        if (len(line)) < 50:\n            fw.write(line)\n"], ["# fname : file name\n# x : number of characters or length\ndef delete_lines(fname = 'test.txt', x = 8):\n    with open(fname, \"r\") as f:\n        lines = f.readlines()\n    with open(fname, \"w\") as f:\n        for line in lines:\n            if len(line) <= x:            \n                f.write(line)\n\ndelete_lines()\n"], [], ["with open('file_r.txt', 'r') as file_r, open('file_w.txt', 'w') as file_w:\n    thresh = 3\n    for line in file_r:\n        if len(line) < thresh:\n            file_w.write(line)\n"], ["with open(r'C:\\some_list.txt')  as f:\n    l = [i for i in f if len(i) > 3]\n"], ["nested_d = {'Beijing':{'China':51, 'USA':36, 'Russia':22, 'Great Britain':19}, 'London':{'USA':46, 'China':38, 'Great Britain':29, 'Russia':22}, 'Rio':{'USA':35, 'Great Britain':22, 'China':20, 'Germany':13}}\n\nres = [nested_d[host]['USA'] for host in nested_d]\n\nprint(res)\n", "[36, 46, 35]\n"], [], ["nested_d = {'Beijing':{'China':51, 'USA':36, 'Russia':22, 'Great Britain':19}, 'London':{'USA':46, 'China':38, 'Great Britain':29, 'Russia':22}, 'Rio':{'USA':35, 'Great Britain':22, 'China':20, 'Germany':13}}\nUS_count = []\n\nfor nested in nested_d:\n    for country in nested_d[nested]:\n            if country==\"USA\":\n                    US_count.append(nested_d[nested][country])\n\nprint(US_count)\n", "[35, 36, 46]\n"], ["for nested in nested_d:\n    for country, value in nested_d[nested].items():\n        if 'USA' in country:\n            US_count.append(value)\n\nprint(US_count)\n", "[36, 46, 35]\n"], ["d = {'Name1': {'NNum': '11', 'Node1': {'SubNodeA': 'Thomas', 'SubNodeB': '27'}, 'Node2': {'SubNodeA': 'ZZZ', 'SubNodeD': 'XXX', 'SubNodeE': 'yy'}, 'Node3': {'child1': 11, 'child2': {'grandchild': {'greatgrandchild1': 'Rita', 'greatgrandchild2': 'US'}}}}}\ndef keys(d, c = []):\n  return [i for a, b in d.items() for i in ([c+[a]] if not isinstance(b, dict) else keys(b, c+[a]))]\n\nresult = list(map('.'.join, keys(d)))\n", "['Name1.NNum', 'Name1.Node1.SubNodeA', 'Name1.Node1.SubNodeB', 'Name1.Node2.SubNodeA', 'Name1.Node2.SubNodeD', 'Name1.Node2.SubNodeE', 'Name1.Node3.child1', 'Name1.Node3.child2.grandchild.greatgrandchild1', 'Name1.Node3.child2.grandchild.greatgrandchild2']\n"], ["import random\n\ndef generate_n_lists(num_of_lists, num_of_elements, value_from=0, value_to=100):\n    s = random.sample(range(value_from, value_to + 1), num_of_lists * num_of_elements)\n    return [s[i*num_of_elements:(i+1)*num_of_elements] for i in range(num_of_lists)]\n\nprint(generate_n_lists(2, 5, 0, 20))    # generate 2 lists, each 5 elements, values are from 0 to 20\n", "[[1, 16, 4, 3, 15], [0, 10, 14, 17, 7]]\n"], ["excluded_value = first_list[i]\nnew_value = random.randint(1, 19)\nif new_value >= excluded_value:\n    new_value += 1\n", "possible_values = range(1, 20) # or xrange on python 2.x\nwhile i < desired_num_values:\n    a, b = random.sample(possible_values, 2)\n    first_list.append(a)\n    second_list.append(b)\n    i += 1\n"], ["import random\na=[]\nb=[]\nfor rand_a in range(1,7164):\n    a.append(random.randint(1,20))\n\nrandom.seed()\nfor rand_b in range(1,7164):\n    r = random.randint(1,20)\n    # keep rolling until you get a diff number\n    while (a[rand_b] == r):\n        r = random.randint(1,20)\n    b.append(r)\n\n\n"], ["for element in my_list:\n    my_list.insert(my_list.index(element), \":\".join(element))\n        my_list.remove(element)\n"], ["In [29]: import random                                                                                                                   \n\nIn [30]: size = 15                                                                                                                       \n\nIn [31]: maxval = 20                                                                                                                     \n\nIn [32]: a, q = zip(*[random.sample(range(1, maxval+1), 2) for z in range(size)])         \n\nIn [33]: a                                                                                                                               \nOut[33]: (18, 7, 12, 6, 17, 16, 12, 1, 14, 20, 9, 5, 8, 5, 18)\n\nIn [34]: q                                                                                                                               \nOut[34]: (12, 10, 6, 1, 12, 15, 20, 7, 6, 10, 5, 7, 16, 7, 10)\n"], ["c = []\nfor i in range(len(a)):\n    t = (a[i] + random.randint(1, 19)) % 19 + 1\n    c.append(t)\n"], ["import random\na=[]\nb=list(range(1,7164))\nfor i in b:\n    t=random.randint(1,20)\n    while t == i:\n        t = random.randint(1,20)\n    a.append(t)\nprint(a)\n"], ["import os\nfrom os.path import isfile, join, isdir\n\ndef get_files_path(directory, paths):\n    for item in os.listdir(directory):\n        if isfile(join(directory, item)) and item == \"tv.sas7bda\":\n            paths.append(directory + item)\n        elif isdir(directory+item):\n            get_files_path(directory + item, paths)\n    return paths\n\ndirectory_to_search = \"./\"\nget_files_path(directory_to_search , [])\n"], ["list(map(':'.join, f))\n# ['soybean:vegetable_oil', 'bay:smoke', 'gelatin:watermelon']\n"], ["[f'{i}:{j}' for i, j in f]\n", "['soybean:vegetable_oil', 'bay:smoke', 'gelatin:watermelon']\n"], [">>> f=[('soybean', 'vegetable_oil'), ('bay', 'smoke'), ('gelatin', 'watermelon')]\n>>> [':'.join(k) for k in f]\n['soybean:vegetable_oil', 'bay:smoke', 'gelatin:watermelon']\n"], ["[':'.join(x) for x in f]\n", "f = [('soybean', 'vegetable_oil'), ('bay', 'smoke'), ('gelatin', 'watermelon')]\n\nprint([':'.join(x) for x in f])\n# ['soybean:vegetable_oil', 'bay:smoke', 'gelatin:watermelon']\n"], ["import pandas as pd\n\n#Append function will convert list into DataFrame,and two dataframe object should have the same column\ndata = pd.DataFrame(['James', '95', 'M'])\nprint(data)\n\n#right code\ntest = pd.DataFrame(columns=['Name', 'Age', 'Gender'])\ntest = test.append(pd.DataFrame([['James', '95', 'M']],columns=['Name', 'Age', 'Gender']))\nprint(test)\n"], [], ["import os\n\nfor root, dirs, files in os.walk(os.getcwd()):\n    for f in files:\n        if f.find(\"tv.sas7bdat\")>=0:\n            print(root,f)\n"], ["test.append(pd.Series(['James', 95, 'M'], index=test.columns), ignore_index=True)\n", "    Name Age Gender\n0  James  95      M\n"], [">>> test.append(dict(zip(test.columns,['James', '95', 'M'])), ignore_index=True)\n\n    Name Age Gender\n0  James  95      M\n"], ["test = test.append(dict(zip(test.columns,['James', '95', 'M'])), ignore_index=True)\n\nprint(test)\n    Name Age Gender\n0  James  95      M\n"], [">>> test = test.append({'Name': \"James\", \"Age\": 95, \"Gender\": \"M\"}, ignore_index=True)\n>>> print(test)\n", "    Name Age Gender\n0  James  95      M\n"], ["import glob\ninitial_path = \"c:\\<intital folder location>\"\nfiles = [file for file in glob.glob(initial_path+ \"tv.sas7bdat\" , recursive=True)]\nfor f in files:\n    print(f)\n"], ["import os\nfor root, dirs, files in os.walk(\"<starting folder here>\", topdown=False):\n    for name in files:\n        if name == \"tv.sas7bdat\":\n            print(os.path.join(root, name))\n"], ["import os\ndef getAlldirInDiGui(path,resultList):\n    filesList=os.listdir(path)\n    for fileName in filesList:\n        fileAbpath=os.path.join(path,fileName)\n        if os.path.isdir(fileAbpath):\n            getAlldirInDiGui(fileAbpath,resultList)\n        else:\n            if fileName=='tv.sas7bdat':\n                resultList.append(fileAbpath)\nresultList = []\nPATH = \"\"\ngetAlldirInDiGui(PATH,resultList)\n"], ["def print_nested_keys(dic,path=''):\n    for k,v in dic.items():\n        if isinstance(v,dict):\n            path+=k+\".\"\n            yield from print_nested_keys(v,path)\n        else:\n            path+=k\n            yield path\n", ">>> [*print_nested_keys(d)] # Here, d is your nested dictionary\n['Name1.NNum',\n 'Name1.NNumNode1.SubNodeA',\n 'Name1.NNumNode1.SubNodeASubNodeB',\n 'Name1.NNumNode1.Node2.SubNodeA',\n 'Name1.NNumNode1.Node2.SubNodeASubNodeD',\n 'Name1.NNumNode1.Node2.SubNodeASubNodeDSubNodeE',\n 'Name1.NNumNode1.Node2.Node3.child1',\n 'Name1.NNumNode1.Node2.Node3.child1child2.grandchild.greatgrandchild1',\n 'Name1.NNumNode1.Node2.Node3.child1child2.grandchild.greatgrandchild1greatgrandchild2']\n"], ["d = {\n    \"Name1\": {\n        \"NNum\": \"11\",\n        \"Node1\": {\n            \"SubNodeA\": \"Thomas\",\n            \"SubNodeB\": \"27\"\n        },\n        \"Node2\": {\n            \"SubNodeA\": \"ZZZ\",\n            \"SubNodeD\": \"XXX\",\n            \"SubNodeE\": \"yy\"\n        },\n        \"Node3\": {\n                \"child1\": 11,\n                \"child2\": {\n                    \"grandchild\": {\n                        \"greatgrandchild1\": \"Rita\",\n                        \"greatgrandchild2\": \"US\"\n                                }\n                            }\n                }\n            }\n}\n\ndef get_keys(d, curr_key=[]):\n    for k, v in d.items():\n        if isinstance(v, dict):\n            yield from get_keys(v, curr_key + [k])\n        elif isinstance(v, list):\n            for i in v:\n                yield from get_keys(i, curr_key + [k])\n        else:\n            yield '.'.join(curr_key + [k])\n\nprint([*get_keys(d)])\n", "['Name1.NNum', 'Name1.Node1.SubNodeA', 'Name1.Node1.SubNodeB', 'Name1.Node2.SubNodeA', 'Name1.Node2.SubNodeD', 'Name1.Node2.SubNodeE', 'Name1.Node3.child1', 'Name1.Node3.child2.grandchild.greatgrandchild1', 'Name1.Node3.child2.grandchild.greatgrandchild2']\n"], [], ["def getKeys(object, prev_key = None, keys = []):\n    if type(object) != type({}):\n        keys.append(prev_key)\n        return keys\n    new_keys = []\n    for k, v in object.items():\n        if prev_key != None:\n            new_key = \"{}.{}\".format(prev_key, k)\n        else:\n            new_key = k\n        new_keys.extend(getKeys(v, new_key, []))\n    return new_keys\n"], ["from itertools import zip_longest\n\ndef minmax(data):\n    it = iter(data)\n    _min = _max = next(it)\n    for a, b in zip_longest(it, it, fillvalue=_min):\n        if a > b:\n            # swap items to make a <= b\n            a, b = b, a\n        if  a < _min:\n            _min = a\n        if b > _max:\n            _max = b\n    return _min, _max\n"], ["l = [len(x) for x in str_list]\nprint(l)\n"], ["str_list = [\"hello\", \"\", \"goodbye\", \"wonderful\", \"I love Python\"]\n\nfor str in str_list:\n    count = 0\n    for g in str:\n        count = count + 1\n    print(count)\n"], ["str_list = [\"hello\", \"\", \"goodbye\", \"wonderful\", \"I love Python\"]\nfor l in str_list:\n    print(\"Length of {} is: \".format(l),len(l))\n"], [], [], ["def get_final_lines(fin):\n    buf = []\n    for line in fin:\n        if line.startswith('STARTINGWORK'):\n            buf = []\n        else:\n            buf.append(line)\n\n    yield from buf\n\n\nif __name__ == '__main__':\n    with open('some_file.txt') as fin:\n        for line in get_final_lines(fin):\n            print(line.rstrip())\n"], ["def findminmax(data):\n    mi = ma = data[0]\n    for value in data:\n        mi = value if mi ^ ((value^mi) & -(value < mi))\n        ma = value if value ^ ((ma^value) & -(ma < value))\n    return mi, ma\n"], ["file = \"records.txt\"\nextracted_text = \"\"\n    if file.endswith (\".txt\"):\n        if os.path.exists (file):\n            lines = open(file).read().split(\"STARTINGWORKING\")\n            extracted_text = lines[-1] #Here it is\n"], [], ["minmax = [ (s[0],s[-1]) for s in [sorted(data)] ]\n", "minValue,maxValue = (data[:1] or [None])*2\nfor value in data[1:]:\n    minValue = value if value < minValue else minValue\n    maxValue = value if value > maxValue else maxValue\n"], [], ["def minmax(ls):\n    if len(ls) == 0:\n        return None, None # or some default val\n    mini = maxi = ls[0]\n    for val in ls[1:]:\n        if val < mini:\n            mini = val\n        elif val > maxi:\n            maxi = val\n    return mini, maxi\n"], ["data = [100,50,3,205,10]\n\ndef findmax(data):\n    a = data\n    ma = a[0]\n    mi = a[0]\n\n    for item in data:\n        if item > ma:\n            ma = item\n\n        if item < mi:\n            mi = item\n\n    return (ma,mi)\n\nprint(findmax(data))\n"], [], ["from file_read_backwards import FileReadBackwards\n\nwith FileReadBackwards(\"records.txt\") as file:\n    portion = list()\n    for line in file:\n         if not line.startswith('STARTINGWORKING'):\n            portion.append(line)\n         else:\n            break\nportion.reverse()\n"], [">>> import re\n>>> input_data = open('path/file').read()\n>>> result = re.search(r'.*STARTINGWORKING\\s*(.*)$', input_data, re.DOTALL)\n>>> print(result.group(1))\n#'DD / MM / YYYY HH: MM: SS\\n... text lines I want ...\\n... more text lines that I want ...'\n"], [], [], ["df['Cu'] * 2\n# [...]\n# 6        13.6272\n# 7     hellohello\n# 8           0.05\n# 9           1.88\n# [...]\n# Name: Cu, dtype: object\n", "import pandas as pd\n\ndf=pd.DataFrame()\ndf['Cu']=[3.7612,1.3693, 2.7502,1.407,4.2066,6.4409,6.8136,\"<0.05\",\"<0.05\",0.94,0.07,1.82,2.63,1.36,0.78]\n\ndf['less_than'] = df['Cu'].str.startswith('<', False)\ndf.loc[df['less_than'], 'Cu'] = df.loc[df['less_than'], 'Cu'].str.slice(1)\n\ndf['Cu'] = df['Cu'].astype(float)\n#         Cu  less_than\n# 0   3.7612      False\n# 1   1.3693      False\n# 2   2.7502      False\n# 3   1.4070      False\n# 4   4.2066      False\n# 5   6.4409      False\n# 6   6.8136      False\n# 7   0.0500       True\n# 8   0.0500       True\n# 9   0.9400      False\n# 10  0.0700      False\n# 11  1.8200      False\n# 12  2.6300      False\n# 13  1.3600      False\n# 14  0.7800      False\n", "df.loc[df['less_than'], 'Cu'] /= 2\n"], [], ["def containedin(a, b):\n if b in a:\n  return True\n return False`\n"], ["import pandas as pd\ndf1 = pd.read_csv('csv1.csv', header = 0) # place your csv1 in df1\ndf2 = pd.read_csv('csv2.csv', header = 0) # place your csv2 in df2\n\nrate_in_1 = df1.iloc[:,2].values.tolist() #store the values of the 3rd column from csv1 to a list\nrate_out_1 = df1.iloc[:,3].values.tolist() #store the values of the 4th column from csv1 to a list\n\nrate_in_2 = df2.iloc[:,2].values.tolist() #store the values of the 3rd column from csv1 to a list\nrate_out_2 = df2.iloc[:,3].values.tolist() #store the values of the 4th column from csv1 to a list\n\nrate_in_total = [x+y for x, y in zip(rate_in_1, rate_in_2)] # add the values of 2 rate in lists into rate_in_total list\nrate_out_total = [x+y for x, y in zip(rate_out_1, rate_out_2] # add the values of 2 rate out lists into rate_out_total list\n\n\n#Now to output/concatenate this into 1 DataFrame:\n\nfinal_df = pandas.Dataframe()\nfinal_df['Node'] = ['allnode' for x in rate_in_total]\nfinal_df['Link'] = df1.iloc[:,1].values.tolist()\nfinal_df['rate-in'] = rate_in_total\nfinal_df['rate-out'] = rate_out_total\n"], ["import csv\nimport sys\n\nnodeList = {}\n\nwith open('file1.csv', 'r') as csv1,open('file2.csv', 'r') as csv2: \n    # creating a csv reader object \n    csvreader1 = csv.reader(csv1,delimiter='\\t')\n    next(csvreader1)\n    csvreader2 = csv.reader(csv2,delimiter='\\t')\n    header = next(csvreader2)\n\n    for row in csvreader1:\n        # print(len(row),row)\n\n        nodeList[row[1]] = ['allnode',row[1],int(row[2]),int(row[3])]\n\n    for row in csvreader2:\n        if row[1] in nodeList:\n            nodeList[row[1]][2]+=int(row[2])\n            nodeList[row[1]][3]+=int(row[3])\n        else:\n            nodeList[row[1]] = ['allnode',row[1],int(row[2]),int(row[3])]\n\nwith open('outfile.csv','wb') as out:\n    csvwriter = csv.writer(out,delimiter='\\t')\n\n    csvwriter.writerow(header)\n    for v in nodeList.values():\n        csvwriter.writerow(v)\n"], ["\n    import pandas as pd\n\n    df = pd.concat([\n        pd.read_csv('csv1.csv'),\n        pd.read_csv('csv2.csv')\n    ])\n\n    result=df.groupby('link', as_index=False).sum()\n    result['node'] = 'allnode'\n\n    result.to_csv('result.csv')\n", "\n    result[[\n        'node','link','rate-in','rate-out'\n    ]].to_csv('result.csv', index=False)\n"], ["import csv\n\nwith open(\"CSV1.csv\") as csvfile_1, open(\"CSV2.csv\") as csvfile_2:\n    reader_1 = csv.DictReader(csvfile_1)\n    reader_2 = csv.DictReader(csvfile_2)\n    result = []\n    data_1 = {\"{}_{}\".format(row[\"node\"], row[\"link\"]): (int(row[\"rate-in\"]), int(row[\"rate-out\"])) for row in reader_1}\n    for row in reader_2:\n        key = \"{}_{}\".format(row[\"node\"], row[\"link\"])\n        if key in data_1:\n            rate_in, rate_out = data_1[key]\n            result.append({\"node\": \"allnode\", \"link\": row[\"link\"], \"rate-in\": rate_in + int(row[\"rate-in\"]),  \"rate-out\": rate_out + int(row[\"rate-out\"])})\n\nwith open(\"outcsv.csv\", \"w\") as outfile:\n    writer = csv.DictWriter(outfile, fieldnames=['node', 'link', 'rate-in', 'rate-out'])  \n    writer.writeheader()\n    writer.writerows(result)\n"], ["import pandas\ndf1 = pandas.DataFrame({'node':['node1', 'node1', 'node1'], 'link': ['link1', 'link2', 'link3'], 'rate-in': [10, 30, 40], 'rate-out': [20, 50, 60]})\ndf2 = pandas.DataFrame({'node':['node2', 'node2', 'node2'], 'link': ['link1', 'link2', 'link3'], 'rate-in': [20, 50, 80], 'rate-out': [10, 70, 40]})\n\nresult = pandas.concat([df1, df2], axis=0).groupby('link').agg({'node': lambda x : 'allNodes', 'rate-in': 'sum', 'rate-out': 'sum'}).reset_index(drop=False)\nresult\n", "link    node    rate-in rate-out\n0   link1   allNodes    30  30\n1   link2   allNodes    80  120\n2   link3   allNodes    120 100\n\n"], ["def write_pdf_view(request):\n    if request.method == 'POST':\n        reference = request.POST.get('Reference_IDs') \n        manifest = Manifests.objects.filter(reference=reference)\n        order = Orders.objects.get(reference=reference)\n", "for data in manifest:\n  print(data.description)\n"], ["conda activate base  # or just conda deactivate\nconda update conda-build\n", "conda list --revisions  # find number, x, before the update\nconda install --revision x\nrm -rf ~/.conda\nconda clean --all\nconda update conda\n"], [], ["result = sorted(dict((a[0],a[1:] or [\"x\"]) for a in list1+list2).values(),key=tuple)\n", "result = [[d,v.get(d,\"x\")] for v in [dict(list2)] for d in list1]\n"], ["    import pandas as pd\n    import numpy as np\n    import string   \n\n     a={\n        'Memberid':[1,1,1,2,2,2],\n        'Question':['Q1','Q2','Q3','Q1','Q2','Q3'],\n        'Answer':['3','2','Test Text','3','2','Test Text']\n      }\n\n    df = pd.DataFrame.from_dict(a)\n    digits = list(string.digits)   \n    df = df.assign(Numeric_Answers= np.where(df['Answer'].isin(digits),                          \n                                             df['Answer'],\n                                             np.nan\n                                            ),\n\n                   FreeText =       np.where(df['Answer'].isin(digits),\n                                             np.nan,\n                                             df['Answer']\n                                           )\n                  )\n\n        Memberid    Question    Answer  Numeric_Answers     FreeText\n    0       1        Q1           3          3                 NaN\n    1       1        Q2           2          2                 NaN\n    2       1        Q3        Test Text    NaN             Test Text\n    3       2        Q1           3          3                 NaN\n    4       2        Q2           2          2                 NaN\n    5       2        Q3        Test Text    NaN             Test Text\n"], ["import numpy as np\nlist1=['2019-06-01', '2019-06-02', '2019-06-03', '2019-06-04', '2019-06-05']\nlist2=[['2019-06-01','3'], ['2019-06-02','0'],['2019-06-04','1'], ['2019-06-05', '4']]\ndiff=np.setdiff1d(list1, [b[0] for b in list2])\nfor i in diff:\n    list2.append([i,''])\nlist2.sort()\nResult:\n[['2019-06-01', '3'],\n ['2019-06-02', '0'],\n ['2019-06-04', '1'],\n ['2019-06-05', '4'],\n ['2019-06-03', '']]\n"], ["print([next((x for x in list2 if v in x), [v, '']) for i, v in enumerate(list1)])\n", "[['2019-06-01', '3'], ['2019-06-02', '0'], ['2019-06-03', ''], ['2019-06-04', '1'], ['2019-06-05', '4']]\n"], ["list2.extend([i, ''] for i in set(list1) - set(d[0] for d in list2))\nlist2.sort()\nprint(list2)\n", "[['2019-06-01', '3'], ['2019-06-02', '0'], ['2019-06-03', ''], ['2019-06-04', '1'], ['2019-06-05', '4']]\n"], ["from itertools import chain\n\nlist1=['2019-06-01', '2019-06-02', '2019-06-03', '2019-06-04', '2019-06-05']\nlist2=[['2019-06-01','3'], ['2019-06-02','0'],['2019-06-04','1'], ['2019-06-05', '4']]\n\ncheck_val = set(chain.from_iterable(list2))\n\nfor i in list1:\n    if i not in check_val:\n        list2.append([i, \"\"])\nprint(list2)\nprint(sorted(list2, key=lambda x: x[0]))\n", "[['2019-06-01', '3'], ['2019-06-02', '0'], ['2019-06-04', '1'], ['2019-06-05', '4'], ['2019-06-03', '']]\n[['2019-06-01', '3'], ['2019-06-02', '0'], ['2019-06-03', ''], ['2019-06-04', '1'], ['2019-06-05', '4']]\n"], ["[['2019-06-01', '3'], ['2019-06-02', '0'], ['2019-06-03', ''], ['2019-06-04', '1'], ['2019-06-05', '4']]\n"], ["dates_in_list2 = [x[0] for x in list2]\nmissing_data = [[x, ''] for x in list1 if x not in dates_in_list2]\nlist2.extend(missing_data)\n"], [], ["list2 += [list(set(list1).difference([i[0] for i in list2])) + ['']]\n\nprint(list2)\n\n[['2019-06-01', '3'],\n ['2019-06-02', '0'],\n ['2019-06-04', '1'],\n ['2019-06-05', '4'],\n ['2019-06-03', '']]\n"], ["df['Numeric Answers'] = pd.to_numeric(df['Answer'], errors='coerce')\nmask = df['Numeric Answers'].isna()\ndf.loc[mask, 'FreeText Answers'] = df.loc[mask, 'Answer']\ndf.drop(columns=['Answer'])\n", "   Memberid Question  Numeric Answers FreeText Answers\n0         1       Q1              3.0              NaN\n1         1       Q2              2.0              NaN\n2         1       Q3              NaN        Test Text\n3         2       Q1              3.0              NaN\n4         2       Q2              2.0              NaN\n5         2       Q3              NaN        Test Text\n", "df['FreeText Answers'].fillna('', inplace=True)\ndf['Numeric Answers'] = df['Numeric Answers'].astype(object).fillna('')\n", "   Memberid Question Numeric Answers FreeText Answers\n0         1       Q1               3                 \n1         1       Q2               2                 \n2         1       Q3                        Test Text\n3         2       Q1               3                 \n4         2       Q2               2                 \n5         2       Q3                        Test Text\n"], ["text_data = [\"\" if s.isdigit() else s for s in df['Question']] # \"\" default string\nnumeric_data = [s if s.isdigit() else 0 for s in df['Question']] # 0 default numeric value\n"], ["df.join(df.pop('Answer').str.extract('(?P<numbers>\\d+)?(?P<text>\\D+)?').fillna(''))\n", "   Memberid Question numbers       text\n0         1       Q1       3           \n1         1       Q2       2           \n2         1       Q3          Test Text\n3         2       Q1       3           \n4         2       Q2       2           \n5         2       Q3          Test Text\n"], ["[(i,l) for i,l in enumerate(list)]\n"], ["from flask import Flask\n\napp = Flask(__name__)\n\n@app.route('/')\ndef hello_world():\n    return 'Hello from Flask!'\n\n@app.route('/math/add/<int:num1>/<int:num2>')\ndef add(num1, num2):\n    return '%d' % (num1+num2)\n", "using System;\nusing System.Net;\nusing System.Net.Http;\nusing System.Threading.Tasks;\n\npublic class Program\n{\n    // Always use HttpClient as a singleton object\n    public static HttpClient _httpClient = new HttpClient() { BaseAddress = new Uri(\"http://al1b.pythonanywhere.com\") } ;\n    public async static Task Main()\n    {\n\n        var num1 = 1;\n        var num2 = 4;\n\n        Console.WriteLine(\"Making http-request wait ...\\r\\n\");      \n\n        var mathAddResult = await _httpClient.GetAsync($\"/math/add/{num1}/{num2}\");\n\n        // 200 = OK\n        if(mathAddResult.StatusCode == HttpStatusCode.OK)\n        {   \n            Console.WriteLine(await mathAddResult.Content.ReadAsStringAsync());\n        }\n    }\n}\n", "Making http-request wait ... \n\n5\n"], ["from itertools import count\n\nmy_list = ['a', 'b', 'c']\n\nindexed_my_list = list(zip(count(), my_list))\nprint(indexed_my_list)  # -> [(0, 'a'), (1, 'b'), (2, 'c')]\n"], ["l = ['a', 'b', 'c']\nindexed_list = list(enumerate(l, 1))\n", ">>> def indexed(l, start=1):\n    ...    return list(enumerate(l, start))\n>>> l = ['a', 'b', 'c']\n>>> indexed(l)\n[(1, 'a'), (2, 'b'), (3, 'c)]\n"], ["In [1]: a = ['a', 'b', 'c']\n\nIn [2]: b = [(idx, item) for idx,item in enumerate(a)]\n\nIn [3]: b\nOut[3]: [(0, 'a'), (1, 'b'), (2, 'c')]\n", "In [4]: c = [(idx, item) for idx,item in enumerate(a, start=1)]\n\nIn [5]: c\nOut[5]: [(1, 'a'), (2, 'b'), (3, 'c')]\n"], [], ["indexed_list = [(i + 1, elem) for i, elem in enumerate(your_list)]\n", "indexed_list = [indexed for indexed in enumerate(your_list, 1)]\n", "indexed_list = list(enumerate(your_list, 1))\n"], ["for i,n in enumerate(list):\n# where i is the index and n is the value of the list\n"], [], ["# Create big size test dataframe\ndf = pd.DataFrame({'bloomberg_ticker_y' : ['AIM9', 'DJEM9', 'FAM9', 'IXPM9']})\ndf = pd.concat([df]*100000)\ndf.shape\n\n#Out\n(400000, 1)\n", "%%timeit \nnp.where(df['bloomberg_ticker_y'].str.len() > 4, \n         df['bloomberg_ticker_y'].str[3:], \n         df['bloomberg_ticker_y'])\n", "%%timeit \ndf['bloomberg_ticker_y'].map(lambda x: x[3:] if len(x) > 4 else x)\n", "%%timeit\ndf.bloomberg_ticker_y.mask(df.bloomberg_ticker_y.str.len().gt(4), \n                           other=df.bloomberg_ticker_y.str[-2:])\n", "%%timeit\n[x[-2:] if len(x)>4 else x for x in df['bloomberg_ticker_y']]\n", "%%timeit\ndf[\"bloomberg_ticker_y\"].str.replace(r\".{3,}(?=.{2}$)\", \"\")\n", "%%timeit\ndf.apply(lambda x: (x['bloomberg_ticker_y'][3:] if len(x['bloomberg_ticker_y']) > 4 else x['bloomberg_ticker_y']) , axis=1)\n"], ["import pandas as pd\n\ndf = pd.DataFrame({'bloomberg_ticker_y' : ['AIM9', 'DJEM9', 'FAM9', 'IXPM9']})\n\ndf['bloomberg_ticker_y'] = df.apply(lambda x: (x['bloomberg_ticker_y'][3:] if len(x['bloomberg_ticker_y']) > 4 else x['bloomberg_ticker_y']) , axis=1)\n", "  bloomberg_ticker_y\n0               AIM9\n1                 M9\n2               FAM9\n3                 M9\n"], ["df[\"bloomberg_ticker_y\"].str.replace(r\".{3,}(?=.{2}$)\", \"\")\n#0    AIM9\n#1      M9\n#2    FAM9\n#3      M9\n"], ["df['bloomberg_ticker_y'] = (df.bloomberg_ticker_y.mask(\n                                      df.bloomberg_ticker_y.str.len().gt(4), \n                                      other=df.bloomberg_ticker_y.str[-2:]))\n\n       bloomberg_ticker_y\n0               AIM9\n1                 M9\n2               FAM9\n3                 M9\n"], ["df = pd.DataFrame({'bloomberg_ticker_y' : ['AIM9', 'DJEM9', 'FAM9', 'IXPM9']})\n\ndf['new'] = [x[-2:] if len(x)>4 else x for x in df['bloomberg_ticker_y']]\n", "  bloomberg_ticker_y   new\n0               AIM9  AIM9\n1              DJEM9    M9\n2               FAM9  FAM9\n3              IXPM9    M9\n"], ["np.where(df['bloomberg_ticker_y'].str.len() > 4, \n         df['bloomberg_ticker_y'].str[3:], \n         df['bloomberg_ticker_y'])\n# array(['AIM9', 'M9', 'FAM9', 'M9'], dtype=object)\n", "df['bloomberg_ticker_sliced'] = (\n   np.where(df['bloomberg_ticker_y'].str.len() > 4, \n            df['bloomberg_ticker_y'].str[3:], \n            df['bloomberg_ticker_y']))\ndf\n  bloomberg_ticker_y bloomberg_ticker_sliced\n0               AIM9                    AIM9\n1              DJEM9                      M9\n2               FAM9                    FAM9\n3              IXPM9                      M9\n", "df['bloomberg_ticker_y'].map(lambda x: x[3:] if len(x) > 4 else x)\n\n0    AIM9\n1      M9\n2    FAM9\n3      M9\nName: bloomberg_ticker_y, dtype: object\n"], ["conda list --revisions\nconda install --revision  dd\n", "conda install --revision 8\n", "conda env export > name.yaml\n", "conda env create -f name.yaml\n", "(base) leninml@Lenin:~$ conda activate tf_gpu_10\n(tf_gpu_10) leninml@Lenin:~$ conda list --revisions\n2019-06-26 12:50:10  (rev 0)\n\n2019-06-26 12:59:19  (rev 1)\n    +_tflow_select-2.1.0 (anaconda)\n    +absl-py-0.7.1 (anaconda)\n    +astor-0.7.1 (anaconda)\n    +blas-1.0 (anaconda)\n    +c-ares-1.15.0 (anaconda)\n    +ca-certificates-2019.5.15 (anaconda)\n    +certifi-2019.6.16 (anaconda)\n    +cudatoolkit-10.0.130 (anaconda)\n    +cudnn-7.6.0 (anaconda)\n    +cupti-10.0.130 (anaconda)\n    +gast-0.2.2 (anaconda)\n    +grpcio-1.16.1 (anaconda)\n    +h5py-2.9.0 (anaconda)\n    +hdf5-1.10.4 (anaconda)\n    +intel-openmp-2019.4 (anaconda)\n    +keras-applications-1.0.8 (anaconda)\n    +keras-preprocessing-1.1.0 (anaconda)\n    +libedit-3.1.20181209 (anaconda)\n    +libffi-3.2.1 (anaconda)\n    +libgcc-ng-9.1.0 (anaconda)\n    +libgfortran-ng-7.3.0 (anaconda)\n    +libprotobuf-3.8.0 (anaconda)\n    +libstdcxx-ng-9.1.0 (anaconda)\n    +markdown-3.1.1 (anaconda)\n    +mkl-2019.4 (anaconda)\n    +mkl_fft-1.0.12 (anaconda)\n    +mkl_random-1.0.2 (anaconda)\n    +mock-3.0.5 (anaconda)\n    +ncurses-6.1 (anaconda)\n    +numpy-1.16.4 (anaconda)\n    +numpy-base-1.16.4 (anaconda)\n    +openssl-1.1.1 (anaconda)\n    +pip-19.1.1 (anaconda)\n    +protobuf-3.8.0 (anaconda)\n    +python-3.7.3 (anaconda)\n    +readline-7.0 (anaconda)\n    +scipy-1.2.1 (anaconda)\n    +setuptools-41.0.1 (anaconda)\n    +six-1.12.0 (anaconda)\n    +sqlite-3.28.0 (anaconda)\n    +tensorboard-1.13.1 (anaconda)\n    +tensorflow-1.13.1 (anaconda)\n    +tensorflow-base-1.13.1 (anaconda)\n    +tensorflow-estimator-1.13.0 (anaconda)\n    +tensorflow-gpu-1.13.1 (anaconda)\n    +termcolor-1.1.0 (anaconda)\n    +tk-8.6.8 (anaconda)\n    +werkzeug-0.15.4 (anaconda)\n    +wheel-0.33.4 (anaconda)\n    +xz-5.2.4 (anaconda)\n    +zlib-1.2.11 (anaconda)\n\n2019-06-26 13:00:52  (rev 2)\n    +backcall-0.1.0 (anaconda)\n    +decorator-4.4.0 (anaconda)\n    +ipython-7.5.0 (anaconda)\n    +ipython_genutils-0.2.0 (anaconda)\n    +jedi-0.13.3 (anaconda)\n    +parso-0.4.0 (anaconda)\n    +pexpect-4.7.0 (anaconda)\n    +pickleshare-0.7.5 (anaconda)\n    +prompt_toolkit-2.0.9 (anaconda)\n    +ptyprocess-0.6.0 (anaconda)\n    +pygments-2.4.2 (anaconda)\n    +traitlets-4.3.2 (anaconda)\n    +wcwidth-0.1.7 (anaconda)\n\n2019-06-26 13:05:42  (rev 3)\n     blas  {1.0 (anaconda) -> 2.7 (conda-forge)}\n     ca-certificates  {2019.5.15 (anaconda) -> 2019.6.16 (conda-forge)}\n     certifi  {2019.6.16 (anaconda) -> 2019.6.16 (conda-forge)}\n     grpcio  {1.16.1 (anaconda) -> 1.16.1}\n     mkl_fft  {1.0.12 (anaconda) -> 1.0.13 (conda-forge)}\n     mkl_random  {1.0.2 (anaconda) -> 1.0.4 (conda-forge)}\n     numpy  {1.16.4 (anaconda) -> 1.16.4}\n     numpy-base  {1.16.4 (anaconda) -> 1.16.4}\n     openssl  {1.1.1 (anaconda) -> 1.1.1b (conda-forge)}\n     scipy  {1.2.1 (anaconda) -> 1.3.0 (conda-forge)}\n    +joblib-0.13.2 (conda-forge)\n    +libblas-3.8.0 (conda-forge)\n    +libcblas-3.8.0 (conda-forge)\n    +liblapack-3.8.0 (conda-forge)\n    +liblapacke-3.8.0 (conda-forge)\n    +libopenblas-0.3.6\n    +openblas-0.3.5 (conda-forge)\n    +scikit-learn-0.21.2 (conda-forge)\n\n2019-06-26 13:08:05  (rev 4)\n     tk  {8.6.8 (anaconda) -> 8.6.9 (conda-forge)}\n    +cycler-0.10.0 (conda-forge)\n    +dbus-1.13.6 (conda-forge)\n    +expat-2.2.5 (conda-forge)\n    +fontconfig-2.13.1 (conda-forge)\n    +freetype-2.10.0 (conda-forge)\n    +gettext-0.19.8.1 (conda-forge)\n    +glib-2.58.3 (conda-forge)\n    +gst-plugins-base-1.14.5 (conda-forge)\n    +gstreamer-1.14.5 (conda-forge)\n    +icu-58.2 (conda-forge)\n    +jpeg-9c (conda-forge)\n    +kiwisolver-1.1.0 (conda-forge)\n    +libiconv-1.15 (conda-forge)\n    +libpng-1.6.37 (conda-forge)\n    +libuuid-2.32.1 (conda-forge)\n    +libxcb-1.13 (conda-forge)\n    +libxml2-2.9.9 (conda-forge)\n    +matplotlib-3.1.0 (conda-forge)\n    +matplotlib-base-3.1.0 (conda-forge)\n    +pcre-8.41 (conda-forge)\n    +pthread-stubs-0.4 (conda-forge)\n    +pyparsing-2.4.0 (conda-forge)\n    +pyqt-5.9.2 (conda-forge)\n    +python-dateutil-2.8.0 (conda-forge)\n    +qt-5.9.7 (conda-forge)\n    +sip-4.19.8 (conda-forge)\n    +tornado-6.0.3 (conda-forge)\n    +xorg-libxau-1.0.9 (conda-forge)\n    +xorg-libxdmcp-1.1.3 (conda-forge)\n\n2019-06-26 13:10:31  (rev 5)\n     ca-certificates  {2019.6.16 (conda-forge) -> 2019.5.15 (anaconda)}\n     certifi  {2019.6.16 (conda-forge) -> 2019.6.16 (anaconda)}\n     openssl  {1.1.1b (conda-forge) -> 1.1.1 (anaconda)}\n    +cloudpickle-1.1.1 (anaconda)\n    +cytoolz-0.9.0.1 (anaconda)\n    +dask-core-1.2.2 (anaconda)\n    +imageio-2.5.0 (anaconda)\n    +libtiff-4.0.10 (anaconda)\n    +networkx-2.3 (anaconda)\n    +olefile-0.46 (anaconda)\n    +pillow-6.0.0 (anaconda)\n    +pywavelets-1.0.3 (anaconda)\n    +scikit-image-0.15.0 (anaconda)\n    +toolz-0.9.0 (anaconda)\n    +zstd-1.3.7 (anaconda)\n\n2019-06-26 13:12:14  (rev 6)\n     ca-certificates  {2019.5.15 (anaconda) -> 2019.6.16 (conda-forge)}\n     certifi  {2019.6.16 (anaconda) -> 2019.6.16 (conda-forge)}\n     openssl  {1.1.1 (anaconda) -> 1.1.1b (conda-forge)}\n    +tensorflow-hub-0.5.0 (conda-forge)\n\n2019-06-26 13:13:00  (rev 7)\n     tensorboard  {1.13.1 (anaconda) -> 1.13.1 (conda-forge)}\n\n2019-06-26 13:13:47  (rev 8)\n     ca-certificates  {2019.6.16 (conda-forge) -> 2019.5.15 (anaconda)}\n     certifi  {2019.6.16 (conda-forge) -> 2019.6.16 (anaconda)}\n     openssl  {1.1.1b (conda-forge) -> 1.1.1 (anaconda)}\n    +pandas-0.24.2 (anaconda)\n    +pytz-2019.1 (anaconda)\n\n2019-06-26 13:14:36  (rev 9)\n     ca-certificates  {2019.5.15 (anaconda) -> 2019.6.16 (conda-forge)}\n     certifi  {2019.6.16 (anaconda) -> 2019.6.16 (conda-forge)}\n     openssl  {1.1.1 (anaconda) -> 1.1.1b (conda-forge)}\n    +pydicom-1.2.2 (conda-forge)\n\n2019-06-26 13:19:06  (rev 10)\n     ca-certificates  {2019.6.16 (conda-forge) -> 2019.5.15 (anaconda)}\n     certifi  {2019.6.16 (conda-forge) -> 2019.6.16 (anaconda)}\n     openssl  {1.1.1b (conda-forge) -> 1.1.1 (anaconda)}\n    +attrs-19.1.0 (anaconda)\n    +bleach-3.1.0 (anaconda)\n    +defusedxml-0.6.0 (anaconda)\n    +entrypoints-0.3 (anaconda)\n    +gmp-6.1.2 (anaconda)\n    +ipykernel-5.1.1 (anaconda)\n    +ipywidgets-7.4.2 (anaconda)\n    +jinja2-2.10.1 (anaconda)\n    +jsonschema-3.0.1 (anaconda)\n    +jupyter-1.0.0 (anaconda)\n    +jupyter_client-5.2.4 (anaconda)\n    +jupyter_console-6.0.0 (anaconda)\n    +jupyter_core-4.4.0 (anaconda)\n    +libsodium-1.0.16 (anaconda)\n    +markupsafe-1.1.1 (anaconda)\n    +mistune-0.8.4 (anaconda)\n    +nbconvert-5.5.0 (anaconda)\n    +nbformat-4.4.0 (anaconda)\n    +notebook-5.7.8 (anaconda)\n    +pandoc-2.2.3.2 (anaconda)\n    +pandocfilters-1.4.2 (anaconda)\n    +prometheus_client-0.6.0 (anaconda)\n    +pyrsistent-0.14.11 (anaconda)\n    +pyzmq-18.0.0 (anaconda)\n    +qtconsole-4.5.1 (anaconda)\n    +send2trash-1.5.0 (anaconda)\n    +terminado-0.8.2 (anaconda)\n    +testpath-0.4.2 (anaconda)\n    +webencodings-0.5.1 (anaconda)\n    +widgetsnbextension-3.4.2 (anaconda)\n    +zeromq-4.3.1 (anaconda)\n\n2019-06-26 13:33:00  (rev 11)\n     ca-certificates  {2019.5.15 (anaconda) -> 2019.6.16 (conda-forge)}\n     certifi  {2019.6.16 (anaconda) -> 2019.6.16 (conda-forge)}\n     openssl  {1.1.1 (anaconda) -> 1.1.1b (conda-forge)}\n    +binutils_impl_linux-64-2.31.1\n    +binutils_linux-64-2.31.1\n    +gcc_impl_linux-64-7.3.0 (conda-forge)\n    +gcc_linux-64-7.3.0 (conda-forge)\n    +gxx_impl_linux-64-7.3.0 (conda-forge)\n    +gxx_linux-64-7.3.0 (conda-forge)\n    +keras-2.2.4 (conda-forge)\n    +libgpuarray-0.7.6 (conda-forge)\n    +mako-1.0.10 (conda-forge)\n    +pygpu-0.7.6 (conda-forge)\n    +pyyaml-5.1.1 (conda-forge)\n    +theano-1.0.4 (conda-forge)\n    +yaml-0.1.7 (conda-forge)\n"], [], ["conda update conda-build\n", "The following packages will be UPDATED:\nconda-build                                 3.17.8-py37_0 --> 3.18.5-py37_0\n", "     active environment : None\n       user config file : /Users/<user>/.condarc\n populated config files : /Users/<user>/.condarc\n          conda version : 4.7.5\n    conda-build version : 3.18.5\n         python version : 3.7.3.final.0\n       virtual packages : \n       base environment : /Users/<user>/anaconda3  (writable)\n           channel URLs : https://repo.anaconda.com/pkgs/main/osx-64\n                          https://repo.anaconda.com/pkgs/main/noarch\n                          https://repo.anaconda.com/pkgs/r/osx-64\n                          https://repo.anaconda.com/pkgs/r/noarch\n          package cache : /Users/<user>/anaconda3/pkgs\n                          /Users/<user>/.conda/pkgs\n       envs directories : /Users/<user>/anaconda3/envs\n                          /Users/<user>/.conda/envs\n               platform : osx-64\n             user-agent : conda/4.7.5 requests/2.21.0 CPython/3.7.3 Darwin/18.5.0 OSX/10.14.4\n                UID:GID : 501:20\n             netrc file : /Users/<user>/.netrc\n           offline mode : False\n"], ["import pandas as pd\n\ndf = pd.DataFrame({'person_id' :[1,2,3],'date1': ['12/31/2007','11/25/2009','10/06/2005'],\n                   'date1derived':[0,0,0],'val1':[2,4,6],'date2': ['12/31/2017','11/25/2019','10/06/2015'],\n                   'date2derived':[0,0,0],'val2':[1,3,5],'date3':['12/31/2027','11/25/2029','10/06/2025'],\n                   'date3derived':[0,0,0],'val3':[7,9,11]})\n\ndf = df.loc[:,~df.columns.str.endswith('derived')]\n\nprint(df)\n", "   person_id       date1  val1       date2  val2       date3  val3\n0          1  12/31/2007     2  12/31/2017     1  12/31/2027     7\n1          2  11/25/2009     4  11/25/2019     3  11/25/2029     9\n2          3  10/06/2005     6  10/06/2015     5  10/06/2025    11\n"], ["df[df.columns.difference(df.filter(like='derived').columns,sort=False)]\n", "   person_id       date1  val1       date2  val2       date3  val3\n0          1  12/31/2007     2  12/31/2017     1  12/31/2027     7\n1          2  11/25/2009     4  11/25/2019     3  11/25/2029     9\n2          3  10/06/2005     6  10/06/2015     5  10/06/2025    11\n"], ["df.drop(df.filter(like='derived').columns, 1)\n\nOut[455]:\n   person_id       date1  val1       date2  val2       date3  val3\n0          1  12/31/2007     2  12/31/2017     1  12/31/2027     7\n1          2  11/25/2009     4  11/25/2019     3  11/25/2029     9\n2          3  10/06/2005     6  10/06/2015     5  10/06/2025    11\n"], ["^(?!.*?derived)\n"], ["df[[c for c in df.columns if 'derived' not in c ]]\n", "   person_id       date1  val1       date2  val2       date3  val3\n0          1  12/31/2007     2  12/31/2017     1  12/31/2027     7\n1          2  11/25/2009     4  11/25/2019     3  11/25/2029     9\n2          3  10/06/2005     6  10/06/2015     5  10/06/2025    11\n"], ["p[:] = [1, 2, 3]\n", "del p[:]\n", "q = p[:]\n"], ["dict0100 = {k: v for (k, v) in new_dict.items() if any(i <= 100 for i in v)}\n", "dict0100 = {k: l for k, l in [(k, [i for i in v if i <= 100]) for k, v in new_dict.items()] if l}\n", "import timeit\n\nt1 = timeit.timeit(lambda: 3 in range(100))\nprint(t1) # 0.37976\n\nt2 = timeit.timeit(lambda: 3 <= 100)\nprint(t2) # 0.08725\n"], [], ["def get_keys_in_range(dct, lo=0, hi=100):\n    rng = range(lo, hi) \n    for key, lst in dct.items():\n        if any(l in rng for l in lst):\n            yield key\n\n[*get_keys_in_range(new_dict, lo=0, hi=100)]\n# ['worry', 'win']\n", "lo, hi = 0, 100\n[key for key, lst in new_dict.items() if any(l in range(lo, hi) for l in lst)]\n# ['worry', 'win']\n", "rng = range(lo, hi)\n[key for key, lst in new_dict.items() if any(l in rng for l in lst)]\n# ['worry', 'win']\n"], [], ["dict0100 = {k:v for (k,v) in new_dict.items() if [x for x in v if all([x<100,x>0])]}\n"], [], [">>> squares = [1, 4, 9, 16, 25]\n...\n>>> squares[:]\n[1, 4, 9, 16, 25]\n", ">>> p = [1,2,3]\n>>> q=p[:]\n>>> id(q)\n139646232329032\n>>> id(p)\n139646232627080\n", ">>> del p[:]\n>>> p\n[]\n>>> q\n[1, 2, 3]\n"], [">>> a = np.array([1,2,3,4])\n>>> b = a[:]\n>>> a[1] = 7\n>>> b\narray([1, 7, 3, 4])\n"], [], ["q=p[:]\n", "q=p\n", "del p[:]\n"], ["f(x) = x**6 - 4*x**5 - 6*x**4 + 32*x**3 + x**2 - 60*x + 36\nf(x) = x**6 - 6*x**5 + 50*x**3 - 45*x**2 - 108*x + 108\nf(x) = x**6 - 9*x**5 + 24*x**4 + 2*x**3 - 99*x**2 + 135*x - 54\nf(x) = x**6 - x**5 - 15*x**4 + 5*x**3 + 70*x**2 + 12*x - 72\nf(x) = x**6 + 4*x**5 - 5*x**4 - 40*x**3 - 40*x**2 + 32*x + 48\nf(x) = x**6 + x**5 - 11*x**4 - 13*x**3 + 26*x**2 + 20*x - 24\nf(x) = x**6 - 2*x**5 - 8*x**4 + 14*x**3 + 11*x**2 - 28*x + 12\nf(x) = x**6 - 11*x**5 + 40*x**4 - 30*x**3 - 135*x**2 + 297*x - 162\nf(x) = x**6 - 5*x**5 + 4*x**4 + 14*x**3 - 31*x**2 + 23*x - 6\nf(x) = x**6 - 7*x**5 + 12*x**4 + 14*x**3 - 59*x**2 + 57*x - 18\n"], ["for i in range(len(data)):\n    date=int(data[i][13:21])\n    if date>20190612:\n    print(data[i])\n"], ["import datetime\nimport re\n\nlst = [\"PUBLIC_DAILY_201906150000_20190616040503.zip\",\n\"PUBLIC_DAILY_201906110000_20190612040501.zip\",\n\"PUBLIC_DAILY_201906120000_20190613040503.zip\",\n\"PUBLIC_DAILY_201906100000_20190611040501.zip\",\n\"PUBLIC_DAILY_201906130000_20190614040503.zip\"]\n\nd = datetime.datetime(year=2019, month=6, day=12)\n\nl = [l for l in lst for g in re.findall(r'PUBLIC_DAILY_(\\d{4})(\\d{2})(\\d{2})', l) if datetime.datetime.strptime(''.join(g), '%Y%m%d') > d]\nprint(l)\n", "['PUBLIC_DAILY_201906150000_20190616040503.zip', 'PUBLIC_DAILY_201906130000_20190614040503.zip']\n"], ["archives = [\"PUBLIC_DAILY_201906150000_20190616040503.zip\",\n\"PUBLIC_DAILY_201906110000_20190612040501.zip\",\n\"PUBLIC_DAILY_201906120000_20190613040503.zip\",\n\"PUBLIC_DAILY_201906100000_20190611040501.zip\",\n\"PUBLIC_DAILY_201906130000_20190614040503.zip\"]\n\ndate_regex = \"%Y%m%d%H%M%S\"\ndefault_regex = \"%Y%m%d\"\ndefault_date = \"20190612\"\ncompare_date = datetime.datetime.strptime(default_date,default_regex)\npassed_list = []\n\nfor archive in archives:\n    split_str = archive.split(\"_\")\n    print split_str\n\n    date1 = datetime.datetime.strptime(split_str[2],date_regex)\n    date2 = datetime.datetime.strptime(split_str[3].split(\".\")[0],date_regex)\n    if date1 > compare_date and date2 > compare_date:\n        passed_list.append(archive)\n\nprint passed_list\n"], [], ["# list input\noutput = list(filter(lambda x: x[13:21] > '20190612', input))\nprint(output)\n\n['PUBLIC_DAILY_201906150000_20190616040503.zip',\n 'PUBLIC_DAILY_201906130000_20190614040503.zip']\n"], ["import itertools as it\n\nimport pandas as pd\n\n\ndf = pd.DataFrame(\n    {\"A\": [0, 0, 9, 10, 0, 0], \n     \"B\": [1, 2, 0, 0, 0, 0]}\n)\n", "#3                 2                 1 \n[next(it.dropwhile(lambda x: x == 0, reversed(col))) for _, col in df.iteritems()]\n", "[10, 2]\n"], ["import numpy as np\nfrom scipy.sparse import csr_matrix\nfrom itertools import accumulate\n\n\ndef ragged2csr(inds):\n    offset = len(inds[0])\n    lens = [len(x) for x in inds]\n    indptr = list(accumulate(lens))\n    indptr = np.array([x - offset for x in indptr])\n    indices = np.array([val for sublist in inds for val in sublist])\n    n = indices.size\n    data = np.ones(n)\n    return csr_matrix((data, indices, indptr))\n\n"], ["re.sub(r'([_|\\s])(?:you)(_)', r\"\\1we\\2\", s)\n"], [], ["[a-zA-Z] - Matches anything that is a single character\n\n![a-zA-Z] - Anything that is not a single English character\n\n? - One or zero match of pattern\n\n(?<![a-zA-Z])you(?![a-zA-Z]) - This matches \"you\" if not preceded and \nnot followed by a letter\n\n", "import re\ns = \"*_you_don't_* think_you_don't_* you_don't_*_* you_don't_know_your_youth\"\nprint re.sub(r'(?<![a-zA-Z])you(?![a-z-Z])', 'we', s)\n", "*_we_don't_* think_we_don't_* we_don't_*_* we_don't_know_your_youth\n"], [], ["s = \"_you_don't_ think_you_don't_* you_don't__ you_don't_know_your_youth\"\nstring.replace('_you_', '_we_').replace(' you_', ' we_')\n"], ["import numpy as np\n\n\ndef main():\n    row_count = 4\n    col_count = 5\n    a = [[1,2,4],[0,2,3],[1,3,4],[0,2]]\n\n    # iterate through each row, concatenate all indices and convert them to linear\n\n    # numpy append performs copy even if you don't want it, list append is faster\n    b = []\n    for row_idx, row in enumerate(a):\n        b.append(np.array(row, dtype=np.int64) + (row_idx * col_count))\n\n    linear_idxs = np.hstack(b)\n    #could skip previous steps if given index inputs well before hand, or in linear index order. \n    c = np.zeros(row_count * col_count)\n    c[linear_idxs] = 1\n    c = c.reshape(row_count, col_count)\n    print(c)\n\n\nif __name__ == \"__main__\":\n    main()\n\n#output\n# [[0. 1. 1. 0. 1.]\n#  [1. 0. 1. 1. 0.]\n#  [0. 1. 0. 1. 1.]\n#  [1. 0. 1. 0. 0.]]\n"], ["%load_ext cython\n", "%%cython\n\ncimport cython\ncimport numpy as cnp\nimport numpy as np\n\n@cython.boundscheck(False)  # remove this if you cannot guarantee that nrow/ncol are correct\n@cython.wraparound(False)\ncpdef cnp.int_t[:, :] mseifert(list a, int nrow, int ncol):\n    cdef cnp.int_t[:, :] out = np.zeros([nrow, ncol], dtype=int)\n    cdef list subl\n    cdef int row_idx\n    cdef int col_idx\n    for row_idx, subl in enumerate(a):\n        for col_idx in subl:\n            out[row_idx, col_idx] = 1\n    return out\n"], ["df['new_order'] = df['items'].apply(lambda x: arr.index(x) if x in arr else -1)\n\ndf_new = df[df['new_order']>=0].sort_values('new_order')\n\n\n   items  quantity  new_order\n3     tv         5          0\n0    car         1          1\n4  phone         6          2\n\n"], ["first_max = df.values[df.ne(0).values.argmax(0), range(df.shape[1])]\nout = pd.DataFrame([first_max], columns=df.columns)\n", "df = pd.DataFrame({'A': [0,0,0,10,0,0] , 'B': [0,2,0,0,0,0]})\n\nfirst_max = df.values[df.ne(0).values.argmax(0), range(df.shape[1])]\n# array([10,  2])\npd.DataFrame([first_max], columns=df.columns)\n\n    A  B\n0  10  2\n", "row_ix = df.shape[0]-df.ne(0).values[::-1].argmax(0)-1\nfirst_max = df.values[row_ix, range(df.shape[1])]\nout = pd.DataFrame([first_max], columns=df.columns)\n"], ["df = df.mask(df==0).ffill().iloc[[-1]].astype(int)\nprint (df)\n    A  B\n5  10  2\n"], ["list = []* number_of_columns\nfor i in range(len(df)):\n    dfcolumn = df[:,i]\n    for item in dfcolumn:\n        if item !=  0:\n            list[i] = [i, item]\n\nprint(list)\n"], ["results = {}\nfor column in df.columns:\n    results[column] = df.loc[df[column]!=0, column].iloc[-1]\n", "results = pd.DataFrame({column:[df.loc[df[column]!=0, column].iloc[-1]] for column in df.columns})\n"], ["def arrange_tickets(tickets_list):\n    ids = [int(ticket[1:]) for ticket in tickets_list]\n    expected_ids = range(1, max(ids) + 1)\n    listt=[\"T%d\" % n if n in ids else \"V\" for n in expected_ids]\n    list1=listt[0:10]\n    list2=listt[11:]\n    for i in range(10):\n        if 'V' in list2:\n            list2.remove('V')\n    for j in range(0,len(list2)):\n        for n, i in enumerate(list1):\n            if i == 'V':\n                list1[n] = list2[j]\n                j+=1\n    return list1\ntickets_list = ['T5','T7','T1','T2','T8','T15','T17','T19','T6','T12','T13']\nprint(\"Ticket ids of all the available students :\")\nprint(tickets_list)\nresult=arrange_tickets(tickets_list)\nprint()\nprint(\"Ticket ids of the ten students in Group-1:\")\nprint(result[0:10])\n"], ["ncol = 5\nnrow = len(a)\nout = np.zeros((nrow, ncol), int)\nout[np.arange(nrow).repeat([*map(len,a)]), np.concatenate(a)] = 1\nout\n# array([[0, 1, 1, 0, 1],\n#        [1, 0, 1, 1, 0],\n#        [0, 1, 0, 1, 1],\n#        [1, 0, 1, 0, 0]])\n", "pp 21.717635259992676 ms\nts 37.10938713003998 ms\nu9 37.32933565042913 ms\n", "import itertools as it\nimport numpy as np\n\ndef make_data(n,m):\n    I,J = np.where(np.random.random((n,m))<np.random.random((n,1)))\n    return [*map(np.ndarray.tolist, np.split(J, I.searchsorted(np.arange(1,n))))]\n\ndef pp():\n    sz = np.fromiter(map(len,a),int,nrow)\n    out = np.zeros((nrow,ncol),int)\n    out[np.arange(nrow).repeat(sz),np.fromiter(it.chain.from_iterable(a),int,sz.sum())] = 1\n    return out\n\ndef ts():\n    out = np.zeros((nrow,ncol),int)\n    for i, ix in enumerate(a):\n        out[i][ix] = 1\n    return out\n\ndef u9():\n    out = np.zeros((nrow,ncol),int)\n    for i, (x, y) in enumerate(zip(a, out)):\n        y[x] = 1\n        out[i] = y\n    return out\n\nnrow,ncol = 1000,1000\na = make_data(nrow,ncol)\n\nfrom timeit import timeit\nassert (pp()==ts()).all()\nassert (pp()==u9()).all()\n\nprint(\"pp\", timeit(pp,number=100)*10, \"ms\")\nprint(\"ts\", timeit(ts,number=100)*10, \"ms\")\nprint(\"u9\", timeit(u9,number=100)*10, \"ms\")\n"], ["output = np.zeros((4,5))\nfor i, ix in enumerate(a):\n    output[i][ix] = 1\n\n# output -> \n#   array([[0, 1, 1, 0, 1],\n#   [1, 0, 1, 1, 0],\n#   [0, 1, 0, 1, 1],\n#   [1, 0, 1, 0, 0]])\n"], ["output = np.zeros((4,5))\nfor i, (x, y) in enumerate(zip(a, output)):\n    y[x] = 1\n    output[i] = y\nprint(output)\n", "[[ 0.  1.  1.  0.  1.]\n [ 1.  0.  1.  1.  0.]\n [ 0.  1.  0.  1.  1.]\n [ 1.  0.  1.  0.  0.]]\n"], ["In [43]: sidx = df['items'].argsort()\n\nIn [44]: df.iloc[sidx[df['items'].searchsorted(['tv','car','phone'],sorter=sidx)]]\nOut[44]: \n   items  quantity\n3     tv         5\n0    car         1\n4  phone         6\n"], ["import pandas as pd\nfrom sklearn.multioutput import MultiOutputRegressor, RegressorChain\nfrom sklearn.linear_model import LinearRegression\n\n\ndic = {'par_1': [10, 30, 13, 19, 25, 33, 23],\n       'par_2': [1, 3, 1, 2, 3, 3, 2],\n       'outcome': [101, 905, 182, 268, 646, 624, 465]}\n\ndf = pd.DataFrame(dic)\n\nvariables = df.iloc[:,:-1]\nresults = df.iloc[:,-1]\n\nmulti_output_reg = MultiOutputRegressor(LinearRegression())\nmulti_output_reg.fit(results.values.reshape(-1, 1),variables)\n\nmulti_output_reg.predict([[100]])\n\n# array([[12.43124217,  1.12571947]])\n# sounds sensible according to the training data\n\n#if input variables needs to be treated as categories,\n# go for multiOutputClassifier\nfrom sklearn.multioutput import MultiOutputClassifier\nfrom sklearn.linear_model import LogisticRegression\n\nmulti_output_clf = MultiOutputClassifier(LogisticRegression(solver='lbfgs'))\nmulti_output_clf.fit(results.values.reshape(-1, 1),variables)\n\nmulti_output_clf.predict([[100]])\n\n# array([[10,  1]])\n", "\ndic = {'par_1': [10, 30, 13, 19, 25, 33, 23],\n       'par_2': [1, 3, 1, 2, 3, 3, 2],\n       'outcome': [0, 1, 1, 1, 1, 1 , 0]}\n\ndf = pd.DataFrame(dic)\n\nvariables = df.iloc[:,:-1]\nresults = df.iloc[:,-1]\n\nmulti_output_clf = MultiOutputClassifier(LogisticRegression(solver='lbfgs',\n                                                            multi_class='ovr'))\nmulti_output_clf.fit(results.values.reshape(-1, 1),variables)\n\nmulti_output_clf.predict([[1]])\n# array([[13,  3]])\n\n"], ["(pd.DataFrame({'items':['tv','car','phone']})\n   .merge(df, on='items')\n)\n", "   items  quantity\n0     tv         5\n1    car         1\n2  phone         6\n"], ["# Move items to the index, select, then reset.\ndf.set_index(\"items\").loc[arr].reset_index()\n", "df.loc[df.reset_index().set_index(\"items\").loc[arr][\"index\"]]\n"], ["def cell_compete(states, days):\n    s = [0] + states + [0]\n    states = [i ^ j for i, j in zip(s[:-2], s[2:])]  # Thanks @RoyDaulton\n    return cell_compete(states, days - 1) if days > 1 else states\n", "def cell_compete(states, days):\n    for _ in range(days):\n        states = [states[1]] + [i ^ j for i, j in zip(states[:-2], states[2:])] + [states[-2]]\n    return states\n"], ["df=df.loc[df['items'].isin(arr)]\ndf.iloc[pd.Categorical(df['items'],categories=arr,ordered=True).argsort()]\nOut[157]: \n   items  quantity\n3     tv         5\n0    car         1\n4  phone         6\n", "df.set_index('items').reindex(arr).reset_index()\nOut[160]: \n   items  quantity\n0     tv         5\n1    car         1\n2  phone         6\n", "pd.concat([df[df['items']==x] for x in arr])\nOut[171]: \n   items  quantity\n3     tv         5\n0    car         1\n4  phone         6\n"], ["d = dict(zip(arr, range(len(arr))))\n\nOut[684]: {'car': 1, 'phone': 2, 'tv': 0}\n\ndf.loc[df['items'].map(d).dropna().sort_values().index]\n\nOut[693]:\n   items  quantity\n3     tv         5\n0    car         1\n4  phone         6\n"], ["df.iloc[pd.Index(df['items']).get_indexer(['tv','car','phone'])]\n\n   items  quantity\n3     tv         5\n0    car         1\n4  phone         6\n", "df2 = df.set_index('items')\ndf2.loc[['tv','car','phone']]  \n\n       quantity\nitems          \ntv            5\ncar           1\nphone         6\n"], [">>> df.iloc[df.loc[df['items'].isin(arr), 'items'].apply(arr.index).sort_values().index]\n   items  quantity\n3     tv         5\n0    car         1\n4  phone         6\n>>> \n"], ["def mutator(state, comparator):\n    while True:\n        states = [0] + state + [0]\n        state = [\n            comparator(states[cellid-1], states[cellid+1])\n            for cellid in range(1, len(states)-1)\n        ]\n        yield state\n\ndef cellCompete(states, days):\n    generator = mutator(states, lambda x, y: x ^ y)\n\n    for idx, states in enumerate(generator):\n        if idx+2 > days:\n            break\n\n    return states\n\nprint(cellCompete([1,0,0,0,0,1,0,0] , 1))\nprint(cellCompete([1,1,1,0,1,1,1,1] , 2))\n"], ["def process(state, r):\n    n = int(''.join(map(str,state)), 2)\n    for i in range(r):\n        n = ((n ^ n << 2) >> 1) % 256\n\n    return list(map(int,format(n, \"08b\")))\n\nprocess([1,1,1,0,1,1,1,1], 2)\n# [0, 0, 0, 0, 0, 1, 1, 0]\n\nprocess([1,0,0,0,0,1,0,0] , 1)\n# [0, 1, 0, 0, 1, 0, 1, 0]\n"], ["def cellCompete(states,days):\n    newstates = []\n    added_states = [0] + states + [0]\n    for counter,value in enumerate(states):\n        newstates.append(int((added_states[counter] != added_states[counter+2])))\n\n    if days > 1:\n        return cellCompete(newstates,days-1)\n    else:\n        return newstates\n\nprint(cellCompete([1,1,1,0,1,1,1,1],2))\n"], ["def cellCompete(states, days):\n    n = len(states)\n    for day in range(days):\n        houses = [0] + states + [0]\n        states = [houses[i-1] ^ houses[i+1] for i in range(1, n+1)]\n    return states\n\nprint(cellCompete([1,0,0,0,0,1,0,0] , 1))\nprint(cellCompete([1,1,1,0,1,1,1,1] , 2))\n", "[0, 1, 0, 0, 1, 0, 1, 0]\n[0, 0, 0, 0, 0, 1, 1, 0]\n"], ["import pandas as pd\nfrom sklearn import linear_model\nfrom sklearn import tree\n\ndic = {'par_1': [10, 30, 13, 19, 25, 33, 23],\n       'par_2': [1, 3, 1, 2, 3, 3, 2],\n       'outcome1': [101, 905, 182, 268, 646, 624, 465],\n       'outcome2': [105, 320, 135, 208, 262, 324, 246]\n}\n\ndf = pd.DataFrame(dic)\n\nvariables = df.iloc[:,:-2]\nresults = df.iloc[:,-2:]\n\nregression = linear_model.LinearRegression()\nregression.fit(variables, results)\n\ninput_values = [14, 2]\n\nprediction = regression.predict([input_values])\nprediction = [round(x,2) for x in prediction[0]]\nprint(prediction)\n"], ["thisdict =  {\n  \"a\": \"Abbey\",\n  \"b\": \"Bob\",\n  \"c\": \"Carl\"\n}\n", "string= 'abc'\n''.join(thisdict[char] for char in string)\n\n\n>>>>AbbeyBobCarl\n"], [], ["text = ['a', 'bc', 'cab', 'x']\nletters = [\"a\", \"b\", \"c\"]\nnames = [\"Abby\", \"Bob\", \"Carl\"]\n\nd = {k: v for k, v in zip(letters, names)}\ns = [(t, ''.join(d[c] for c in t if c in d)) for t in text]\n\nfor l, t in s:\n    print('text =', l)\n    print('output:', t)\n", "text = a\noutput: Abby\ntext = bc\noutput: BobCarl\ntext = cab\noutput: CarlAbbyBob\ntext = x\noutput: \n"], ["dct = dict(zip(letters, names))  # {\"a\": \"Abby\", ...}\n...\ntext = input()\noutput = ''.join(dct[char] for char in text)\nprint(output)\n"], ["letter_to_name = dict()\n\nfor idx, val in enumerate(letters):\n    letter_to_name[val] = names[idx]\n\n#Creates are mapping of letters to name\n\n#whatever is the input text, just iterate over it and select the val for that key\n\noutput = \"\"\nfor l in text:\n    if l not in letter_to_name:\n        #Handle this case or continue\n    else:\n        output += letter_to_name[l]\n"], ["def func(string):\n    string +='@'\n    dic = []\n    tmp =[]\n    tmp += [string[0]]\n\n    for i in range(1,len(string)):\n\n        if string[i]==string[i-1]:\n            tmp.append(string[i])\n        else:\n            dic.append(tmp)\n            tmp=[]\n            tmp.append(string[i])\n    res = ''.join(['{}{}'.format(len(i),i[0]) for i in dic])\n    return res\n\nstring = 'ABBBBCCCCCCCCAB'         \nsolution = func(string)\n\nprint(solution)\n", "1A4B8C1A1B\n"], ["s = \"ABBBBCCCCCCCCAB\"\nfrom itertools import groupby\nexpected = ''.join([str(len(list(v)))+k for k,v in groupby(s)])\n", "'1A4B8C1A1B'\n", "[('A', ['A']), ('B', ['B', 'B', 'B', 'B']), ('C', ['C', 'C', 'C', 'C', 'C', 'C', 'C', 'C']), ('A', ['A']), ('B', ['B'])]\n", "...\nfor char in range(0,len(message)-1,1):\n        print('\\tchar at first line : ', char, 'char id now : ', id(char))\n        count=1\n        while(message[char]==message[char+1]):\n            count=count+1\n            char=char+1\n            print('char now : ', char, 'char id now : ', id(char))\n            ...\n", "    char at first line :  1 char id now :  11197408\nchar now :  2 char id now :  11197440\nchar now :  3 char id now :  11197472\nchar now :  4 char id now :  11197504\n"], ["def encode(message):\n    result = []\n    i = count = 0\n    while i < len(message) - 1:\n        count = 1\n        while i + count < len(message) and message[i + count - 1] == message[i + count]:\n            count += 1\n        i += count\n        result.append(\"{}{}\".format(count, message[i - 1]))\n    if count == 1:\n        result.append(\"1\" + message[-1])\n    return result\n"], ["s = \"ABBBBCCCCCCCCAB\"\nd = {i:0 for i in s}\nfor i in s:\n    d[i] += 1\nprint(d)\n", "**output:-**\n{'A': 2, 'B': 5, 'C': 8}\n"], ["s = 'ABBBBCCCCCCCCAB'\n\nimport re\n\nl = ''.join(str(len(c2)+1) + c1 for c1, c2 in re.findall(r'([A-Z])(\\1*)', s))\n\nprint(l)\n", "1A4B8C1A1B\n"], ["a = [['04\\01\\1997','alphanum4569874','22','4.0'],['07\\01\\1997','Anee_69213654','23','2.0']]\n\nb = ['alphanum1','alphanum2']\nc=0\nfor i in a:\n    i[1]=b[c]\n    c+=1\nprint(a)\n", "[['04\\x01\\x01997', 'alphanum1', '22', '4.0'], ['07\\x01\\x01997', 'alphanum2', '23', '2.0']]\n"], ["for ax, bx in zip(a, b):\n    ax[1] = bx\n", "new_a = [[ax[0], bx, *ax[2:]] for ax, bx in zip(a, b)]\n", "for i in range(len(a)):\n    a[i][1] = b[i]\n"], ["print([[x[0], y, *x[2:]] for x, y in zip(a, b)])\n", "[['04\\x01\\x01997', 'alphanum1', '22', '4.0'], ['07\\x01\\x01997', 'alphanum2', '23', '2.0']]\n"], ["a = [['04\\01\\1997','alphanum4569874','22','4.0'],['07\\01\\1997','Anee_69213654','23','2.0']]\nb = ['alphanum1','alphanum2']\nresult = [[c, d, *j] for d, [c, _, *j] in zip(b, a)]\n", "[['04\\x01\\x01997', 'alphanum1', '22', '4.0'], ['07\\x01\\x01997', 'alphanum2', '23', '2.0']]\n"], [" for item in a:\n    for i in b:\n       item[1].append(i)\n\n print (a)\n"], ["# We extract the linear's regression coefficients\ncoeff = regression.coef_\ninput_values = list(zip(dic['par_1'], dic['par_2']))\n# We choose the best input thanks to those coefficients\nimport numpy as np # import numpy to extract the coeffecients\nindex_best_input = np.argmax([x[0]*coeff[0] + x[1]*coeff[1] for x in input_values])\n\nbest_input = input_values[index_best_input]\n\nIn [1] : print(best_input)\nOut[1] : (33,3)\n", "from sklearn import tree\nimport graphviz \nfrom sklearn.datasets import load_iris\ndic = {'par_1': [10, 30, 13, 19, 25, 33, 23],\n       'par_2': [1, 3, 1, 2, 3, 3, 2],\n       'outcome': ['yes', 'yes', 'no', 'yes', 'no', 'no', 'yes']}\n\ndf = pd.DataFrame(dic)\n\nvariables = df.iloc[:,:-1]\nresults = df.iloc[:,-1]\n\ndecision_tree = tree.DecisionTreeClassifier()\ndecision_tree.fit(variables, results)\n\ndot_data = tree.export_graphviz(decision_tree, out_file=None) \ngraph = graphviz.Source(dot_data)  \nprint(graph)\n"], [], ["import pandas as pd\ndf = pd.read_csv('housing.csv')\ndf.drop(['longitude','latitude'], axis=1, inplace=True)\nX_train = df['median_house_value']\n\nX_train.head()\nimport numpy as np\nX_train = np.array(X_train)\nX_train = np.reshape(X_train,(-1,1))\n\nfrom sklearn.cluster import MeanShift, estimate_bandwidth\nms = MeanShift(bandwidth=None, bin_seeding=True)\nms.fit(X_train)\nlabels = ms.labels_\ncluster_centers = ms.cluster_centers_\n\nlabels_unique = np.unique(labels)\nn_clusters_ = len(labels_unique)\n\nprint(\"number of estimated clusters : %d\" % n_clusters_)\nprint(labels)\n\ndf['cluster'] = labels\n\ndf1 = df[df['cluster'] == 1]\ndf2 = df[df['cluster'] == 0]\n\nranges = []\n\nranges.append([min(df1['median_house_value']),max(df1['median_house_value'])])\n\nranges.append([min(df2['median_house_value']),max(df2['median_house_value'])])\n\n\ndf1_categorical = 'ocean_proximity'\ndf1_categorical_set = df1[df1_categorical]\ndf1 = df1.drop(df1_categorical, axis=1)\ndf2_categorical_set = df2[df1_categorical]\ndf2 = df2.drop(df1_categorical, axis=1)\ndf1_feature = []\n\nfor i in df1.columns :\n    df1_feature.append(np.mean(df1[i]))\n\ndf2_feature = []\n\nfor i in df1.columns :\n    df2_feature.append(np.mean(df2[i]))\n\nprint (\"Range : \",ranges[0],\"\\nFeatures : \",df1_feature,'\\n',\"Range : \",ranges[1],\"\\nFeatures : \", df2_feature)\n"], ["from datetime import datetime as dt\ndf['TIMESTAMP'].apply(lambda x: dt.strftime(dt.fromisoformat(x), '%Y-%m-%dT%H:%M:%S'))\n", "             TIMESTAMP\n0  2016-10-25T09:34:52\n1  2016-10-25T09:46:14\n2  2016-10-25T09:51:16\n"], ["df = pd.DataFrame(\n    data={\n        'TIMESTAMP': [\n            '2016-10-25T09:34:52.051713+01:00',\n            '2016-10-25T09:46:14.051620+01:00',\n            '2016-10-25T09:51:16.052435+01:00'\n        ]\n    }\n)\ndf['TIMESTAMP'] = df['TIMESTAMP'].apply(lambda x: x[:19])\n"], ["df['TIMESTAMP'] = df['TIMESTAMP'].apply(lambda x: x[-4:])\n"], ["df = pd.DataFrame({'TIMESTAMP' : [\"2016-10-25T09:34:52.051713+01:00\", \"2016-10-25T09:46:14.051620+01:00\"]})\n\n TIMESTAMP\n0  2016-10-25T09:34:52.051713+01:00\n1  2016-10-25T09:46:14.051620+01:00\n\ndf['TIMESTAMP'] = [x[:-13] for x in df['TIMESTAMP']]\n", "TIMESTAMP\n0  2016-10-25T09:34:52\n1  2016-10-25T09:46:14\n"], ["data = ['2016-10-25T09:34:52.051713+01:00',\n        '2016-10-25T09:46:14.051620+01:00',\n        '2016-10-25T09:51:16.052435+01:00']\n\ns = pd.Series(data)\n\nprint(s.str[:-13])\n", "0    2016-10-25T09:34:52\n1    2016-10-25T09:46:14\n2    2016-10-25T09:51:16\n", "print(pd.to_datetime(s))\n", "0   2016-10-25 09:34:52.051713+01:00\n1   2016-10-25 09:46:14.051620+01:00\n2   2016-10-25 09:51:16.052435+01:00\ndtype: datetime64[ns, pytz.FixedOffset(60)]\n"], [], ["r'[a-zA-Z0-9]*[^-]'\n", ">>> re.sub(\"-\", \" \", \"this-is-a-sample-post\")\n\nO/P: 'this is a sample post'\n", ">>> text = \"this-is-a-sample-post\"\n>>> a = [m.group(0) for m in re.finditer(r'[a-zA-Z0-9]*[^-]', text)]\n>>> \" \".join(a)\n", "str = \"this-is-a-sample-post\"\nstr.replace('-', ' ')\n"], ["f=lambda s=None,prefix='f':prefix+s  if s else lambda s=None,prefix=prefix+'o':f(s,prefix)  \n"], ["import re\npattern = r\"[a-zA-Z0-9]+[^-]+\"\nstring = \"this-is-a-sample-post\"\nmatches = re.finditer(pattern, string)\nmatches_lst = [i.group(0) for i in matches]\nprint(\"Made with finditer:\")\nprint(matches_lst)\nprint(\"Made with findall\")\nmatches_lst = re.findall(pattern, string)\nprint(matches_lst)\nprint(\"Made with split\")\nprint(string.split(\"-\"))\nprint(\"Made with replace and split\")\nprint(string.replace(\"-\",\" \").split())\n", "Made with finditer:\n['this', 'is', 'sample', 'post']\nMade with findall\n['this', 'is', 'sample', 'post']\nMade with split\n['this', 'is', 'a', 'sample', 'post']\nMade with replace and split\n['this', 'is', 'a', 'sample', 'post']\n>>> \n"], ["import re\n\ns = 'this-is-example'\ns = sub('-', ' ', s)\n", "s = 'this-is-example'\ns = s.replace('-', ' ')\n"], ["# coding=utf8\n# the above tag defines encoding for this document and is for Python 2.x compatibility\n\nimport re\n\nregex = r\"([a-zA-Z0-9]+)\"\n\ntest_str = \"this-is-a-sample-post\"\n\nmatches = re.finditer(regex, test_str, re.MULTILINE)\n\nfor matchNum, match in enumerate(matches, start=1):\n    \n    print (\"Match {matchNum} was found at {start}-{end}: {match}\".format(matchNum = matchNum, start = match.start(), end = match.end(), match = match.group()))\n    \n    for groupNum in range(0, len(match.groups())):\n        groupNum = groupNum + 1\n        \n        print (\"Group {groupNum} found at {start}-{end}: {group}\".format(groupNum = groupNum, start = match.start(groupNum), end = match.end(groupNum), group = match.group(groupNum)))\n\n# Note: for Python 2.7 compatibility, use ur\"\" to prefix the regex and u\"\" to prefix the test string and substitution.\n"], ["matches_lst = [i for i in matches]\n", "matches_lst = [i.group(0) for i in matches]\n", "matches = re.findall(pattern, \"this-is-a-sample-post\")\n"], [], ["output = []\nfor key_value in lst:\n    key, value = key_value.split(': ', 1)\n    if not output or key in output[-1]:\n        output.append({})\n    output[-1][key] = value\n", "[{'name': 'test1',\n  'email': 'test1@gmail.com',\n  'role': 'test',\n  'description': 'test'},\n {'name': 'test2',\n  'email': 'test2@gmail.com',\n  'role': 'test2',\n  'description': 'test2'},\n {'name': 'test3',\n  'email': 'test3@gmail.com',\n  'role': 'test3',\n  'description': 'test3'}]\n"], ["l = ['name: test1', 'email: test1@gmail.com', 'role: test', 'description: test', \n     'name: test2', 'email: test2@gmail.com', 'role: test2', 'description: test2',\n     'name: test3', 'email: test3@gmail.com', 'role: test3', 'description: test3']\n\noutput = [dict(s.split(\": \") for s in l[i:i+4]) for i in range(0, len(l), 4)]\n"], ["dictionary = dict()\nall_dictionaries = []\nfor index , value  in  [x.split(\": \") for x in A] :\n     if index in dictionary :\n         all_dictionaries .append(dictionary )\n         dictionary = dict()\n     else :\n       dictionary [index] = value\nall_dictonaries.append(dictionary)\n"], ["lst = ['name: test1', 'email: test1@gmail.com', 'role: test', 'description: test', \n       'name: test2', 'email: test2@gmail.com', 'role: test2', 'description: test2', \n       'name: test3', 'email: test3@gmail.com', 'role: test3', 'description: test3']\n\nanswer = []\n\nfor i in range(0, len(lst), 4):\n    dic = {}\n    for j in lst[i:i+4]:\n        dic[j.split(':')[0]] = j.split(':')[1].strip() \n    answer.append(dic)\n\n# [{'name': 'test1',  'email': 'test1@gmail.com',  'role': 'test',  'description': 'test'},\n    #  {'name': 'test2',  'email': 'test2@gmail.com',  'role': 'test2',  'description': 'test2'},\n    #  {'name': 'test3',  'email': 'test3@gmail.com',  'role': 'test3',  'description': 'test3'}]\n", "answer = [{j.split(':')[0]:j.split(':')[1].strip() for j in lst[i:i+4]} for i in range(0, len(lst), 4)]\n"], ["L = ['name: test1', 'email: test1@gmail.com', 'role: test', 'description: test', 'name: test2', 'email: test2@gmail.com', 'role: test2', 'description: test2', 'name: test3', 'email: test3@gmail.com', 'role: test3', 'description: test3']\n\nA = []\n\nfor i in range(0, len(L), 4):\n  D = {}\n  for p in L[i:i + 4]:\n    k, v = map(str.strip, p.split(':'))\n    D[k] = v\n  A.append(D)\n\nfrom pprint import pprint\npprint(A)\n", "[{'description': 'test',\n  'email': 'test1@gmail.com',\n  'name': 'test1',\n  'role': 'test'},\n {'description': 'test2',\n  'email': 'test2@gmail.com',\n  'name': 'test2',\n  'role': 'test2'},\n {'description': 'test3',\n  'email': 'test3@gmail.com',\n  'name': 'test3',\n  'role': 'test3'}]\n"], ["u = df.melt()\nu['variable'] = u['variable'].str[0]  # extract the first letter\nu.assign(count=u.groupby('variable').cumcount()).pivot('count', 'variable', 'value')\n\nvariable    a    b    c\ncount                  \n0         1.0  5.0  9.0\n1         2.0  6.0  0.0\n2         3.0  7.0  NaN\n3         4.0  8.0  NaN\n", "u = df.melt()\nu['variable'] = [x[0] for x in u['variable']]\nu.insert(0, 'count', u.groupby('variable').cumcount())\n\nu.pivot(*u)\n\nvariable    a    b    c\ncount                  \n0         1.0  5.0  9.0\n1         2.0  6.0  0.0\n2         3.0  7.0  NaN\n3         4.0  8.0  NaN\n", "from operator import itemgetter\n\npd.concat({\n    k: pd.Series(g.values.ravel()) \n    for k, g in df.groupby(operator.itemgetter(0), axis=1)\n}, axis=1)\n\n   a  b    c\n0  1  5  9.0\n1  3  7  0.0\n2  2  6  NaN\n3  4  8  NaN\n"], ["order = Orders.objects.get(pk=reference)\n", "manifest = Manifest.objects.filter(reference=reference)\n"], ["def write_pdf_view(request):\n    if request.method == 'POST':\n        reference = request.POST.get('Reference_IDs') \n        manifest_queryset = Manifests.objects.filter(reference=reference)\n        order = Orders.objects.get(reference=reference)\n", "for manifest in manifest_queryset:\n    print(manifest.description)\n", "description_list = manifest_queryset.values_list('description', flat=True)\n"], ["def write_pdf_view(request):\n    if request.method == 'POST':\n       reference = request.POST.get('Reference_IDs') \n       y = Orders.objects.all()\n       z = Manifests.objects.all()\n       order = y.get(reference=reference)\n       manifest = z.filter(reference=reference)\n       for manifest_value in manifest:\n           print(manifest_value.description)\n"], ["order = Orders.objects.all().filter(reference=reference)\nmanifest = Manifest.objects.all().filter(reference=reference)\n"], ["import pandas as pd\n\ndf=pd.DataFrame()\ndf['Cu']=[3.7612,1.3693, 2.7502,1.407,4.2066,6.4409,6.8136,\"<0.05\",\"<0.05\",0.94,0.07,1.82,2.63,1.36,0.78]\n\ndf['Cu'] = df.apply(lambda x: x if not isinstance(x[0],str) else float(x[0][1:])/2, axis=1, raw=True)\n\nprint(df)\n", "        Cu\n0   3.7612\n1   1.3693\n2   2.7502\n3    1.407\n4   4.2066\n5   6.4409\n6   6.8136\n7    0.025\n8    0.025\n9     0.94\n10    0.07\n11    1.82\n12    2.63\n13    1.36\n14    0.78\n"], ["df['Cu'] = df['Cu'].apply(lambda x: x if str(x)[0]!='<' else float(str(x)[1:])/2) \nprint (df)\n\n        Cu\n0   3.7612\n1   1.3693\n2   2.7502\n3   1.4070\n4   4.2066\n5   6.4409\n6   6.8136\n7   0.0250\n8   0.0250\n9   0.9400\n10  0.0700\n11  1.8200\n12  2.6300\n13  1.3600\n14  0.7800\n"], ["df.applymap(lambda x: x if str(x)[0] != '<' else float(str(x)[1:])/2)\n"], ["#Explicitly cast to string and perform the indexing\nfunc = lambda x: x if  str(x)[0]!='<' else float(str(x)[1:])/2\n\nli = ['<1', '<0.5', '<5', 1, 'hello', 4.0, '']\n\n#Filter out empty strings\nprint([func(item) for item in li if item])\n", "[0.5, 0.25, 2.5, 1, 'hello', 4.0]\n"], ["df = pd.DataFrame({i: pd.Series(x.to_numpy().ravel()) \n                      for i, x in df.groupby(lambda x: x[0], axis=1)})\nprint (df)\n   a  b    c\n0  1  5  9.0\n1  3  7  0.0\n2  2  6  NaN\n3  4  8  NaN\n"], ["grouping = df.columns.map(lambda s: int(s[1:]) if len(s) > 1 else 1)\ndf.columns = df.columns.str[0]   # Make a copy if the original dataframe needs to be retained\nresult = pd.concat((g for _, g in df.groupby(grouping, axis=1)), \n                   axis=0, ignore_index=True, sort=False)\n", "    a   b   c\n0   1   5   9.0\n1   2   6   0.0\n2   3   7   NaN\n3   4   8   NaN\n"], ["pd.concat([d.T.melt(value_name=k)[k] for k, d in df.groupby(df.columns.str[0], 1)], 1)\n", "   a  b    c\n0  1  5  9.0\n1  3  7  0.0\n2  2  6  NaN\n3  4  8  NaN\n"], ["df = (df.rename(columns = dict(zip(df.columns, df.columns.str[:1])))\n        .groupby(level=0, axis=1, group_keys=False)\n        .apply(lambda x: pd.DataFrame(x.values.flat, columns=np.unique(x.columns))))\n\nprint(df)\n   a  b    c\n0  1  5  9.0\n1  3  7  0.0\n2  2  6  NaN\n3  4  8  NaN\n"], ["df.groupby(df.columns.str[0],1).agg(lambda x : x.tolist()).sum().apply(pd.Series).T\nOut[391]: \n     a    b    c\n0  1.0  5.0  9.0\n1  3.0  7.0  0.0\n2  2.0  6.0  NaN\n3  4.0  8.0  NaN\n"], ["def f(g,a):\n    ret = g.stack().reset_index(drop=True)\n    ret.name = a\n    return ret\n\npd.concat( (f(g,a) for a,g in df.groupby(df.columns.str[0], axis=1)), axis=1)\n", "    a   b   c\n0   1   5   9.0\n1   3   7   0.0\n2   2   6   NaN\n3   4   8   NaN\n"], ["def return_inverse(n, mx):\n    return mx - n\n", "position_list = list(range(5))\nmx = max(position_list)\n\n[return_inverse(i, mx) for i in position_list]\n# [4, 3, 2, 1, 0]\n"], [], ["position_list = list(range(5))\nposition = 3\ninverse = position_list[len(position_list)-1-position]\n", "for i in position_list:\n    print(i, position_list[len(position_list)-1-i])\n"], [">>> MAX=4\n>>> def calc(in_val):\n...   out_val = MAX - in_val\n...   print('%s -> %s' % ( in_val, out_val ))\n...\n>>> calc(3)\n3 -> 1\n>>> calc(1)\n1 -> 3\n"], ["n = 5\ninp = 3\n\nposition_list = list(range(n))\nposition_list[n-1-inp]\n# 1\n"], ["max_height = 5\n\ninput_number = 2\n\nfor input_number in range(5):\n    print('IN:', input_number, 'OUT:', max_height - input_number - 1)\n", "IN: 1 OUT: 3\nIN: 2 OUT: 2\nIN: 3 OUT: 1\nIN: 4 OUT: 0\n\n"], ["def f(s=None):\n    def fo(s=None):\n        if s==None:\n            print('o',end='')\n            return fo\n        else:\n            print(s)\n            return\n    if s!=None:\n        print('f',end='')\n        print(s)\n        return\n    elif s==None:\n        print('fo',end='')\n        return fo\n"], ["data['tags'] = data['tags'].str.lower()\n", "data['tags'] = data['tags'].str.split(',')\n", "data['tags'] = data['tags'].apply(lambda x: set(map(str.strip , x)))\n"], ["# in your code just s = df['Tags']\ns = pd.Series(['','', 'Tour',\n               'Outdoors, Beach, Sports', \n               'Museum, Drinking, Drinking, Shopping'])\n\n(s.str.split(',\\s+', expand=True)\n      .stack()\n      .reset_index()\n      .drop_duplicates(['level_0',0])\n      .groupby('level_0')[0]\n      .agg(','.join)\n)\n", "level_0\n0                            \n1                            \n2                        Tour\n3       Outdoors,Beach,Sports\n4    Museum,Drinking,Shopping\nName: 0, dtype: object\n"], ["df['Tags']=df['Tags'].apply(lambda x: ', '.join(set([y.strip() for y in x.split(',')])))\n"], ["def remove_dup(strng):\n    '''\n     Input a string and split them \n    '''\n    return ', '.join(list(dict.fromkeys(strng.split(', '))))\n\n\ndf['Tags'] = df['Tags'].apply(lambda x: remove_dup(x))\n", "import pandas as pd\nmy_dict = {'Tags':[\"Museum, Art Museum, Shopping, Museum\",'Drink, Drink','Shop','Visit'],'Country':['USA','USA','USA', 'USA']}\ndf = pd.DataFrame(my_dict)\ndf['Tags'] = df['Tags'].apply(lambda x: remove_dup(x))\ndf\n", "    Tags                          Country\n0   Museum, Art Museum, Shopping    USA\n1   Drink                           USA\n2   Shop                            USA\n3   Visit                           USA\n"], ["import pandas as pd\ntest = [['Museum', 'Art Museum', 'Shopping', \"Museum\"]]\ndf = pd.DataFrame()\ndf[0] = test\ndf[0]= df.applymap(set)\n", "Out[35]: \n                                0\n0  {Museum, Shopping, Art Museum}\n"], [], ["print(triangle_area(20, 10))\n"], [], ["def triangle_area(b, h):\n    return 0.5 * b * h\n\noutput = triangle_area(20, 10) # capture return value\nprint(output)\n", "def triangle_area(b, h):\n    return 0.5 * b * h\n\nprint(triangle_area(20, 10)) # capture return value and immediately pass to print function\n"], ["print(triangle_area(20, 10))\n"], ["print(traingle_area(20,30))\n"], [], [">>> fruit = \"potato\"\n>>> fruit = fruit[::-1]\n>>> fruit\n'otatop'\n>>> for letter in fruit:\n...     print(letter)\n...\no\nt\na\nt\no\np\n", ">>> fruit = \"potato\"\n>>> fruit = fruit[::-1]\n>>> fruit\n'otatop'\n>>>  index = 0\n>>> while index < len(fruit):\n...     print(fruit[index])\n...     index+=1\n...\no\nt\na\nt\no\np\n"], ["fruit = \"potato\"\nindex = len(fruit) -1 #Python indexes starts from 0!\nwhile index >= 0 :\n    letter = fruit[index]\n    print(letter)\n    index -= 1 #decrease at the END of the loop!\n", "o\nt\na\nt\no\np\n"], ["index = 0\nfruit = \"potato\"\nwhile abs(index) < len(fruit):\n    index = index - 1\n    letter = fruit[index] \n    print(letter)\n"], ["index = 0\nfruit = \"potato\"\nwhile index > -(len(fruit)) :\n    index = index - 1\n    letter = fruit[index]\n    print(letter)\n"], ["fruit = \"potato\"\nindex = len(fruit)\nwhile index > 0 :\n    index = index - 1\n    letter = fruit[index] \n    print(letter)\n"], [], [], ["def f(s=None):\n    string = \"f\"\n    def ret(p=None):\n        nonlocal string\n        string += \"o\"\n        return ret if not p else string + p\n    return ret if not s else string + s\n"], ["def f(s=None):\n    if s: return f'f{s}'\n\n    def factory(prefix):\n        def inner(s=None):\n            return f'f{prefix}{s}' if s else factory(prefix + 'o')\n        return inner\n    return factory('o')\n"], ["from functools import partial\n\ndef f(s=None):\n    # Define a new function g which takes the current text and takes s\n    def g(current_text, s=None):\n        if s is not None:\n            return current_text + s\n        else:\n            # If called with an empty argument, just rebind current_text with an extra o\n            return partial(g, current_text + \"o\")\n\n    # Just call g with the initial conditions\n    return g(\"f\", s)\n\nprint(f()()()()()(\"s\")) # fooooos\nprint(f(\"s\")) # fs\n"], [], ["import sys\n\ndef getsizeof_dict_literal(n):\n    pairs = [\"{0}:{0}\".format(i) for i in range(n)]\n    dict_literal = \"{%s}\" % \", \".join(pairs)\n    source = \"sys.getsizeof({})\".format(dict_literal)\n    size = eval(source)\n    return size\n"], ["# An important invariant maintained while a Task not done:\n#   \n# - Either _fut_waiter is None, and _step() is scheduled;\n# - or _fut_waiter is some Future, and _step() is *not* scheduled.\n", "PENDINGMSG = 'wait_for=<Future pending '\n\nif all(PENDINGMSG in repr(t) for t in monitored_tasks):\n    do_something()\n"], ["async def do_stuff(semaphore):\n    async with semaphore:\n      await getting_stuff_done()\n\nasync def wait_til_everyone_is_busy(semaphore):\n    while not semaphore.locked():\n      await asyncio.sleep(1)\n    do_other_stuff()\n", "import asyncio\nimport time\n\nasync def process(semaphore, i):\n    while True:\n        print(f\"{i} I'm gonna await\")\n        await asyncio.sleep(1)\n        async with semaphore:\n            print(f'{i} sleeping')\n            await asyncio.sleep(3)\n        print(f'{i} done sleeping')\n        print(f\"{i} I'm gonna await again\")\n        await asyncio.sleep(1)\n\nasync def other_process(semaphore):\n    while True:\n        while not semaphore.locked():\n            print(\"Everyone is awaiting... but I'm not startingr\")\n            await asyncio.sleep(1)\n        print(\"Everyone is busy, let's do this!\")\n        time.sleep(5)\n        print('5 seconds are up, let everyone else play again')\n        await asyncio.sleep(1)\n\nsemaphore = asyncio.Semaphore(10)\ndataset = [i for i in range(10)]\nloop = asyncio.new_event_loop()\ntasks = [loop.create_task(process(semaphore, i)) for i in dataset]\ntasks.append(loop.create_task(other_process(semaphore)))\nloop.run_until_complete(asyncio.wait(tasks))\n\n", "$ python3 tmp\n0 I'm gonna await\n1 I'm gonna await\n2 I'm gonna await\n3 I'm gonna await\n4 I'm gonna await\n5 I'm gonna await\n6 I'm gonna await\n7 I'm gonna await\n8 I'm gonna await\n9 I'm gonna await\nEveryone is awaiting... but I'm not startingr\n0 sleeping\n1 sleeping\n2 sleeping\n3 sleeping\n4 sleeping\n5 sleeping\n6 sleeping\n7 sleeping\n8 sleeping\n9 sleeping\nEveryone is busy, let's do this!\n5 seconds are up, let everyone else play again\n0 done sleeping\n0 I'm gonna await again\n1 done sleeping\n1 I'm gonna await again\n2 done sleeping\n2 I'm gonna await again\n3 done sleeping\n3 I'm gonna await again\n4 done sleeping\n4 I'm gonna await again\n5 done sleeping\n5 I'm gonna await again\n6 done sleeping\n6 I'm gonna await again\n7 done sleeping\n7 I'm gonna await again\n8 done sleeping\n8 I'm gonna await again\n9 done sleeping\n9 I'm gonna await again\nEveryone is awaiting... but I'm not startingr\n0 I'm gonna await\n1 I'm gonna await\n2 I'm gonna await\n3 I'm gonna await\n4 I'm gonna await\n5 I'm gonna await\n6 I'm gonna await\n7 I'm gonna await\n8 I'm gonna await\n9 I'm gonna await\nEveryone is awaiting... but I'm not startingr\n0 sleeping\n1 sleeping\n2 sleeping\n3 sleeping\n4 sleeping\n5 sleeping\n6 sleeping\n7 sleeping\n8 sleeping\n9 sleeping\nEveryone is busy, let's do this!\n"], ["df = pd.DataFrame()\ndf['Arrived'] = [pd.Timestamp('01-04-2017')]\ndf['Left'] = [pd.Timestamp('01-06-2017')]\ndiff = df['Left'] - df['Arrived']\ndays = pd.Series(delta.days for delta in (diff)\nresult = days[0]\n"], ["df[\"time_diff\"] = (pd.to_datetime(df.end_date) - pd.to_datetime(df.start_date))\n"], ["import pandas as pd\nfrom datetime import timedelta\ntmp = [(\"2002-06-12\",\"2009-03-01\"),(\"2016-04-28\",\"2022-03-14\")]\ndf = pd.DataFrame(tmp,columns=[\"col1\",\"col2\"])\n\ndf[\"col1\"]=pd.to_datetime(df[\"col1\"])\ndf[\"col2\"]=pd.to_datetime(df[\"col2\"])\n\ndf[\"time_diff\"]=df[\"col2\"]-df[\"col1\"]\ndf[\"time_diff\"]=df[\"time_diff\"].apply(timedelta.total_seconds)\n"], ["from datetime import datetime\n\ndf = pd.DataFrame({'Start Date' : ['2002-06-12', '2002-06-12' ], 'End date' : ['2009-03-01', '2009-03-06']})\n\ndf['Start Date'] = [  datetime.strptime(x, \"%Y-%m-%d\").date() for x in df['Start Date'] ]\ndf['End date'] = [ datetime.strptime(x, \"%Y-%m-%d\").date() for x in df['End date'] ]\n\ndf['Diff'] = df['End date'] - df['Start Date']\n", "End date    Start Date  Diff\n0   2009-03-01  2002-06-12  2454 days\n1   2009-03-06  2002-06-12  2459 days\n"], ["df['start_date'] = pd.to_datetime(df['start_date'], format='%Y-%m-%d')\ndf['end_date'] = pd.to_datetime(df['end_date'], format='%Y-%m-%d')\ndf['time_diff'] = (df.end_date - df.start_date).dt.days\n"], ["import numpy as np\nenddates = np.asarray([pd.Timestamp(end) for end in df.end_date.values])\nstartdates = np.asarray([pd.Timestamp(start) for start in df.start_date.values])\ndf['time_diff'] = (enddates - startdates).astype(\"timedelta64\")\n"], ["d = {'@index': '40', 'row': [{'column': [{'text': {'@fontName': 'Times New Roman', '@fontSize': '12.0', '@x': '85.10', '@y': '663.12', '@width': '250.01', '@height': '12.00', '#text': 'text 1'}}]}, {'column': [{'text': {'@fontName': 'Times New Roman', '@fontSize': '8.0', '@x': '121.10', '@y': '675.36', '@width': '348.98', '@height': '8.04', '#text': 'text 2'}}, {'text': {'@fontName': 'Times New Roman', '@fontSize': '12.0', '@x': '473.30', '@y': '676.92', '@width': '42.47', '@height': '12.00', '#text': 'text 3'}}]}, {'column': [{'text': {'@fontName': 'Times New Roman', '@fontSize': '12.0', '@x': '85.10', '@y': '690.72', '@width': '433.61', '@height': '12.00', '#text': 'text 4'}}]}]}\nnew_d = {**d, 'row':[c['text'] for b in d['row'] for c in b['column']]}\n", "import json\nprint(json.dumps(new_d, indent=4))\n", "{\n \"@index\": \"40\",\n \"row\": [\n     {\n        \"@fontName\": \"Times New Roman\",\n        \"@fontSize\": \"12.0\",\n        \"@x\": \"85.10\",\n        \"@y\": \"663.12\",\n        \"@width\": \"250.01\",\n        \"@height\": \"12.00\",\n        \"#text\": \"text 1\"\n     },\n     {\n        \"@fontName\": \"Times New Roman\",\n        \"@fontSize\": \"8.0\",\n        \"@x\": \"121.10\",\n        \"@y\": \"675.36\",\n        \"@width\": \"348.98\",\n        \"@height\": \"8.04\",\n        \"#text\": \"text 2\"\n     },\n     {\n        \"@fontName\": \"Times New Roman\",\n        \"@fontSize\": \"12.0\",\n        \"@x\": \"473.30\",\n        \"@y\": \"676.92\",\n        \"@width\": \"42.47\",\n        \"@height\": \"12.00\",\n        \"#text\": \"text 3\"\n     },\n     {\n        \"@fontName\": \"Times New Roman\",\n        \"@fontSize\": \"12.0\",\n        \"@x\": \"85.10\",\n        \"@y\": \"690.72\",\n        \"@width\": \"433.61\",\n        \"@height\": \"12.00\",\n        \"#text\": \"text 4\"\n    }\n  ]\n}\n", "def flatten(d, t = [\"image\", \"text\"]):\n   for a, b in d.items():\n      if a in t:\n         yield b\n      elif isinstance(b, dict):\n         yield from flatten(b)\n      elif isinstance(b, list):\n         for i in b:\n            yield from flatten(i)\n\n\nd = {'document': {'page': [{'@index': '0', 'image': {'@data': 'ABC', '@format': 'png', '@height': '620.00', '@type': 'base64encoded', '@width': '450.00', '@x': '85.00', '@y': '85.00'}}, {'@index': '1', 'row': [{'column': [{'text': ''}, {'text': {'#text': 'Text1', '@fontName': 'Arial', '@fontSize': '12.0', '@height': '12.00', '@width': '71.04', '@x': '121.10', '@y': '83.42'}}]}, {'column': [{'text': ''}, {'text': {'#text': 'Text2', '@fontName': 'Arial', '@fontSize': '12.0', '@height': '12.00', '@width': '101.07', '@x': '121.10', '@y': '124.82'}}]}]}, {'@index': '2', 'row': [{'column': {'text': {'#text': 'Text3', '@fontName': 'Arial', '@fontSize': '12.0', '@height': '12.00', '@width': '363.44', '@x': '85.10', '@y': '69.62'}}}, {'column': {'text': {'#text': 'Text4', '@fontName': 'Arial', '@fontSize': '12.0', '@height': '12.00', '@width': '382.36', '@x': '85.10', '@y': '83.42'}}}, {'column': {'text': {'#text': 'Text5', '@fontName': 'Arial', '@fontSize': '12.0', '@height': '12.00', '@width': '435.05', '@x': '85.10', '@y': '97.22'}}}]}, {'@index': '3'}]}}\nprint(json.dumps(list(filter(None, flatten(d))), indent=4))\n", "[\n  {\n    \"@data\": \"ABC\",\n    \"@format\": \"png\",\n    \"@height\": \"620.00\",\n    \"@type\": \"base64encoded\",\n    \"@width\": \"450.00\",\n    \"@x\": \"85.00\",\n    \"@y\": \"85.00\"\n  },\n  {\n    \"#text\": \"Text1\",\n    \"@fontName\": \"Arial\",\n    \"@fontSize\": \"12.0\",\n    \"@height\": \"12.00\",\n    \"@width\": \"71.04\",\n    \"@x\": \"121.10\",\n    \"@y\": \"83.42\"\n  },\n  {\n    \"#text\": \"Text2\",\n    \"@fontName\": \"Arial\",\n    \"@fontSize\": \"12.0\",\n    \"@height\": \"12.00\",\n    \"@width\": \"101.07\",\n    \"@x\": \"121.10\",\n    \"@y\": \"124.82\"\n  },\n  {\n    \"#text\": \"Text3\",\n    \"@fontName\": \"Arial\",\n    \"@fontSize\": \"12.0\",\n    \"@height\": \"12.00\",\n    \"@width\": \"363.44\",\n    \"@x\": \"85.10\",\n    \"@y\": \"69.62\"\n  },\n  {\n    \"#text\": \"Text4\",\n    \"@fontName\": \"Arial\",\n    \"@fontSize\": \"12.0\",\n    \"@height\": \"12.00\",\n    \"@width\": \"382.36\",\n    \"@x\": \"85.10\",\n    \"@y\": \"83.42\"\n  },\n  {\n    \"#text\": \"Text5\",\n    \"@fontName\": \"Arial\",\n    \"@fontSize\": \"12.0\",\n    \"@height\": \"12.00\",\n    \"@width\": \"435.05\",\n    \"@x\": \"85.10\",\n    \"@y\": \"97.22\"\n  }\n]\n"], ["#!/usr/bin/python\n# -*- coding: utf-8 -*-\n\n\ndef flatten_json(y):\n    out = {}\n\n    def flatten(x, name=''):\n        if type(x) is dict:\n            for a in x:\n                flatten(x[a], name + a + '_')\n        elif type(x) is list:\n            i = 0\n            for a in x:\n                flatten(a, name + str(i) + '_')\n                i += 1\n        else:\n            out[name[:-1]] = x\n\n    flatten(y)\n    return out\n\n\nexpected_output = flatten_json(input_data)  # This will convert\n"], ["with open(\"file.txt\", \"r\") as infile:\n    database = json.loads(infile.read())\n"], [" {\"name\" : \"hello\", \"man\" : \"mane\"}\n", "\"name\":\"hello\"\n\"man\":\"mane\"\n"], [], ["import ast\n\nwith open(\"file.txt\", \"r\") as infile:  #opens the dictionary\n    for line in infile: #for each line\n        eval_dict = ast.literal_eval(line) # This gives you a dictionary\n        database[name] = eval_dict[\"name\"]\n"], ["with open(\"file.txt\", \"r\") as infile:  #opens the dictionary\n    for line in infile: #for each line\n        entry = eval(line)\n        database[entry[\"name\"]] = entry[\"man\"]\n"], ["my_dict[\"row\"] = [{k: v for k, v in col_entry[\"text\"].items()} for entry in my_dict[\"row\"] for col_entry in entry[\"column\"]]\n"], ["data = json.load(json_file)\nflat = [ column['text'] for entry in data['row'] for column in entry['column'] ]\n", "import json\nimport sys\nimport os.path\n\ndef main(argv):\n\n    #Load JSON\n    current_folder = os.path.dirname(os.path.realpath(__file__))\n    with open(current_folder + '\\\\input.json') as json_file:  \n        data = json.load(json_file)\n\n    #Flatten (using for loops)\n    flat=[]\n    for entry in data['row']:\n        for column in entry['column']:\n            flat.append(column['text'])\n\n    # OR, Flatten the pythonic way (using list comprehension)\n    # looks strange at first but notice\n    #   1. we start with the item we want to keep in the list\n    #   2. the loops order is the same, we just write them inline \n    flat2 = [ column['text'] for entry in data['row'] for column in entry['column'] ]\n\n\n    #Format data for saving to JSON\n    output = {}\n    output['@index']=data['@index']\n    output['row'] = flat #or flat2 \n\n    #Save to JSON\n    with open('flat.txt', 'w') as outfile:\n        json.dump(output, outfile, indent=4)\n\nif __name__ == \"__main__\":\n   main(sys.argv[1:])\n"], ["import json\nimport pprint\n\nflat_data = dict()\nwith open('56336255.json') as f:\n    data = json.load(f)\n    for k, v in data.items():\n        if k == '@index':\n            flat_data[k] = data[k]\n        else:\n            flat_data[k] = []\n            for row in v:\n                for cell in row['column']:\n                    flat_data[k].append(cell['text'])\n\n    pprint.pprint(flat_data)\n", "{'@index': '40',\n 'row': [{'#text': 'text 1',\n          '@fontName': 'Times New Roman',\n          '@fontSize': '12.0',\n          '@height': '12.00',\n          '@width': '250.01',\n          '@x': '85.10',\n          '@y': '663.12'},\n         {'#text': 'text 2',\n          '@fontName': 'Times New Roman',\n          '@fontSize': '8.0',\n          '@height': '8.04',\n          '@width': '348.98',\n          '@x': '121.10',\n          '@y': '675.36'},\n         {'#text': 'text 3',\n          '@fontName': 'Times New Roman',\n          '@fontSize': '12.0',\n          '@height': '12.00',\n          '@width': '42.47',\n          '@x': '473.30',\n          '@y': '676.92'},\n         {'#text': 'text 4',\n          '@fontName': 'Times New Roman',\n          '@fontSize': '12.0',\n          '@height': '12.00',\n          '@width': '433.61',\n          '@x': '85.10',\n          '@y': '690.72'}]}\n"], ["/* PyDict_MINSIZE is the minimum size of a dictionary.  This many slots are\n * allocated directly in the dict object (in the ma_smalltable member).\n * It must be a power of 2, and at least 4.  8 allows dicts with no more\n * than 5 active entries to live in ma_smalltable (and so avoid an\n * additional malloc); instrumentation suggested this suffices for the\n * majority of dicts (consisting mostly of usually-small instance dicts and\n * usually-small dicts created to pass keyword arguments).\n */\n#define PyDict_MINSIZE 8\n", "/* Create a new dictionary pre-sized to hold an estimated number of elements.\n   Underestimates are okay because the dictionary will resize as necessary.\n   Overestimates just mean the dictionary will be more sparse than usual.\n*/\n\nPyObject *\n_PyDict_NewPresized(Py_ssize_t minused)\n{\n    PyObject *op = PyDict_New();\n\n    if (minused>5 && op != NULL && dictresize((PyDictObject *)op, minused) == -1) {\n        Py_DECREF(op);\n        return NULL;\n    }\n    return op;\n}\n", "# note 2/3 = 0.(6)\nBUILD_MAP   # initial_size = 8, filled = 0\nSTORE_MAP   # 'key_1' ratio_filled = 1/8 = 0.125, not resizing\nSTORE_MAP   # 'key_2' ratio_filled = 2/8 = 0.250, not resizing\nSTORE_MAP   # 'key_3' ratio_filled = 3/8 = 0.375, not resizing\nSTORE_MAP   # 'key_4' ratio_filled = 4/8 = 0.500, not resizing\nSTORE_MAP   # 'key_5' ratio_filled = 5/8 = 0.625, not resizing\nSTORE_MAP   # 'key_6' ratio_filled = 6/8 = 0.750, RESIZING! new_size = 8*4 = 32\nSTORE_MAP   # 'key_7' ratio_filled = 7/32 = 0.21875\n"], [], [], ["import sys\nimport json\n\n\ndiii = {'key1':1,'key2':2,'key3':1,'key4':2,'key5':1,'key6':2,'key7':1}\nprint sys.getsizeof(json.dumps(diii)) # <----\n\ndiii = {'key1':1,'key2':2,'key3':1,'key4':2,'key5':1,'key6':2,'key7':1,'key8':2}\nprint sys.getsizeof(json.dumps(diii)) # <----\n"], [], ["firstname   = input(\"What is your name: \")\nmessage     = \"Hello what is your favourite subject \"+firstname+\" ?\"\nfavesub     = input(message) \nprint (\"I love \",favesub,\" aswell\")\n"], [], ["firstname=input(\"What is your name: \") \nfavesub = input(\"Hello what is your favourite subject \" + firstname + \"?\") \nprint (\"I love \", favesub,\" aswell\")\n\n# What is your name: Donald\n# Hello what is your favourite subject Donald?Politics\n# I love  Politics  aswell\n"], [], ["input(f\"Hello what is your favourite subject {firstname}?\")\n"], ["def pow(n):\n    global calls\n    calls+=1\n    \"\"\"Return 2**n, where n is a nonnegative integer.\"\"\"\n    if n == 0:\n        return 1\n    x = pow(n//2)\n    if n%2 == 0:\n        return x*x\n    return 2*x*x\n\ndef steppow(n):\n    global calls\n    calls=0\n    pow(n)\n    return calls\n\nsx = [math.pow(10,n) for n in range(1,11)]\nsy = [steppow(n)/math.log(n) for n in sx]\nprint(sy)\n", "[2.1714724095162588, 1.737177927613007, 1.5924131003119235, 1.6286043071371943, 1.5634601348517065, 1.5200306866613815, 1.5510517210830421, 1.5200306866613813, 1.4959032154445342, 1.5200306866613813]\n", "if (Py_ABS(Py_SIZE(a)) <= 1 && Py_ABS(Py_SIZE(b)) <= 1) {\n    stwodigits v = (stwodigits)(MEDIUM_VALUE(a)) * MEDIUM_VALUE(b);\n    return PyLong_FromLongLong((long long)v);\n}\n\nz = k_mul(a, b);\n", "i = a == b ? KARATSUBA_SQUARE_CUTOFF : KARATSUBA_CUTOFF;\nif (asize <= i) {\n    if (asize == 0)\n        return (PyLongObject *)PyLong_FromLong(0);\n    else\n        return x_mul(a, b);\n}\n", "if (2 * asize <= bsize)\n    return k_lopsided_mul(a, b);\n", "2*x*x: [0.00020009249478223623, 0.0002965123323532072, 0.00034258906889154733, 0.0024181753953639975, 0.03395215528201522, 0.4794894526936972, 4.802882867816082]\nx*x*2: [0.00014974939375012042, 0.00020265231347948998, 0.00034002925019471775, 0.0024501731290706985, 0.03400164511014836, 0.462764023966729, 4.841786565730171]\n", "sx = [math.pow(10,n) for n in range(1,8)]\nsy = [timeit.timeit('pow(%d)' % i, number=100, globals=globals()) for i in sx]\n"], ["# OUTPUT:\nreal timings:\n[1.7171500003314577, 2.515988002414815, 4.5264500004122965, 4.929114998958539, 5.251838003459852, 5.606903003354091, 6.680275000690017, 6.948587004444562, 7.609975000377744, 8.97067000187235, 16.48820400441764]\n\ntheory timings:\n[1.7171500003314577, 2.5757250004971866, 4.292875000828644, 4.892993172417281, 5.151450000994373, 5.409906829571465, 5.751568172583011, 6.010025001160103, 6.868600001325832, 7.727175001491561, 8.585750001657289]\n\n\nt/t_prev:\nreal:\n['--', '1.47', '1.80', '1.09', '1.07', '1.07', '1.19', '1.04', '1.10', '1.18', '1.84']\n\ntheory:\n['--', '1.50', '1.67', '1.14', '1.05', '1.05', '1.06', '1.04', '1.14', '1.12', '1.11']\n"], [], ["(.+[a-z])([0-9]+)([a-z].+) \n", "# coding=utf8\n# the above tag defines encoding for this document and is for Python 2.x compatibility\n\nimport re\n\nregex = r\"(.+[a-z])([0-9]+)([a-z].+)\"\n\ntest_str = (\"aaaaaaa0aaa\\n\"\n    \"bbbbbbb0bbbbbb\\n\"\n    \"cccccc 2.0\")\n\nsubst = \"\\\\1x\\\\3\"\n\n# You can manually specify the number of replacements by changing the 4th argument\nresult = re.sub(regex, subst, test_str, 0, re.MULTILINE)\n\nif result:\n    print (result)\n\n# Note: for Python 2.7 compatibility, use ur\"\" to prefix the regex and u\"\" to prefix the test string and substitution.\n"], ["import re\n\ns = '''aaaaaaa0aaa\nbbbbbbb0bbbbbb\ncccccc 2.0'''\n\nre.sub(pattern=r'0(?=.)', string=s, repl='x')\n\nOut[743]: '\\n    aaaaaaaxaaa\\n    bbbbbbbxbbbbbb\\n    cccccc 2.0'\n"], [], ["\\B0\\B\n", ">>> import re\n>>> s = '''aaaaaaa0aaa\n... bbbbbbb0bbbbbb\n... cccccc 2.0'''\n>>> print(re.sub(r'\\B0\\B', 'x', s))\naaaaaaaxaaa\nbbbbbbbxbbbbbb\ncccccc 2.0\n>>>\n"], [], ["class MyContainer(list): # inherits == operator and from list, so empty containers are equal\n    def append(self, value):\n        super().append(value)\n\ncallbacks = []\ndef register_callback(cb):\n    if cb not in callbacks:  # this does an == test against all previously registered callbacks\n        callbacks.append(cb)\n\ndef do_callbacks(*args):\n    for cb in callbacks:\n        cb(*args)\n\ncontainer1 = MyContainer()\nregister_callback(container1.append)\ncontainer2 = MyContainer()\nregister_callback(container2.append)\n\ndo_callbacks('foo')\n\nprint(container1 == container2)   # this should be true, if both callbacks got run\n"], ["class IdentityComparableMethod:\n    __slots__ = '_method',\n    def __new__(cls, method):\n        # Using __new__ prevents reinitialization, part of immutability contract\n        # that justifies defining __hash__\n        self = super().__new__(cls)\n        self._method = method\n        return self\n\n    def __getattr__(self, name):\n        '''Attribute access should match bound method's'''\n        return getattr(self._method, name)\n\n    def __eq__(self, other):\n        '''Comparable to other instances, and normal methods'''\n        if not isinstance(other, (IdentityComparableMethod, types.MethodType)):\n            return NotImplemented\n        return (self.__self__ is other.__self__ and\n                self.__func__ is other.__func__)\n\n    def __hash__(self):\n        '''Hash identically to the method'''\n        return hash(self._method)\n\n    def __call__(self, *args, **kwargs):\n        '''Delegate to method'''\n        return self._method(*args, **kwargs)\n\n    def __repr__(self):\n        return '{0.__class__.__name__}({0._method!r})'.format(self)\n", "self.methods = [IdentityComparableMethod(self.method)]\n", "    __slots__ = '_method', '__self__'\n    def __new__(cls, method):\n        # Using __new__ prevents reinitialization, part of immutability contract\n        # that justifies defining __hash__\n        self = super().__new__(cls)\n        self._method = method\n        self.__self__ = method.__self__\n        return self\n"], [], ["class A:\n\n    def __init__(self, field):\n\n        self.methods = [self.method]\n        self.field = field\n\n    def __eq__(self, other):\n\n        #Iterate through all keys\n        for key in self.__dict__:\n            #Perform comparison on values except the key methods\n            if key != 'methods':\n                if self.__dict__[key] != other.__dict__[key]:\n                    return False\n\n        return True\n\n    def method(self):\n        pass\n\n\nfirst = A(field='foo')\nsecond = A(field='bar')\n\nprint(first == second)\n"], [], ["class A:\n\n    def __init__(self, field):\n        self.methods = [self.method]\n        self.field = field\n\n    def __eq__(self, other):\n        import deepdiff\n        if type(self) != type(other):\n            return False\n        return deepdiff.DeepDiff(self.__dict__, other.__dict__) == {}\n\n    def method(self):\n        pass\n", "self.methods = [self.method]\n", "self.methods = [A.method]\n"], [], ["from multiprocessing import Pool\n\nif __name__ == '__main__':\n    cpus = multiprocessing.cpu_count()        \n    with Pool(cpus-1) as p:\n        p.map(get_image_features, file_list_1)\n", "df = pd.DataFrame({'filename':list_a,'image_features':list_b})\ndf.to_pickle(\"PATH_TO_FILE\"+str(count)+\".pickle\")\n"], ["start, stop, step = 1, 11, 1\nfor i in range(start, stop, step):\n    print(i, end=', ')\n# Output: 1 2 3 4 5 6 7 8 9 10 \n"], ["collection = [1, 2, 3]\nfor collectionMember in collection:\n    print(collectionMember)\n", "collection = range(1,4)\nprint(collection)\nfor collectionMember in collection:\n   print(collectionMember)\n"], [], ["for i in range(10):\n    # will iterate exactly 10 times with i going from 0 to 9\n", " for i in range(A,B):   # for (i=A;i<B;i++)\n     ...\n", " def inclusiveRange(start=0,end,step=1):\n     return range(start,end+1,step)\n", " for i in inclusiveRange(1,10):\n     ... # will iterate from 1 to 10 inclusively\n"], ["def sal_of_seawater(l): \n        sal_of_seawater = (-0.0222*l)+34\n        return sal_of_seawater\nl = 45\nprint(\"A latitude of\", l, \"equals a salinity value of\", sal_of_seawater)\n"], ["def sal_of_seawater(l): \n    sal_of_seawater = (-0.0222*l)+34\n    print(\"A latitude of\", l, \"equals a salinity value of\", sal_of_seawater)\n\nsal_of_seawater(45)\n"], ["l =45\nprint(\"A latitude of {} equals a salinity value of {}\".format(l, sal_of_seawater(l)))\n"], ["def sal_of_seawater(l): \n        res = (-0.0222*l)+34\n        return res\n\nl = 45\n\nprint(\"A latitude of\", l, \"equals a salinity value of\", sal_of_seawater(l))\n"], ["print(\"A latitude of\", l, \"equals a salinity value of\", sal_of_seawater(10))\n", "print(\"A latitude of\", l, \"equals a salinity value of\", sal_of_seawater(l))\n"], ["for i in [1,2,3]:\n    {*do something*}\n", "len(range(a, b)) == b - a\nlen(range(a)) == a\nrange(a, a) == []\nrange(a, b) + range(b, c) == range(a, c)\n"], ["file_list_chunks = list(divide_chunks(file_list_1,20000))[30000:]\n", "file_list_chunks = list(divide_chunks(file_list_1,20000))\n# becomes\nfile_list_chunks = divide_chunks(file_list_1,20000)\n", "with ThreadPool(64) as pool: \n    results = pool.map(get_image_features,f)\n    # etc.\n", "with ThreadPool(..):\n    ...\n    pool.join()\ngc.collect()\n", "import sqlite3\nconn = sqlite3.connect(':memory:', check_same_thread=False)  # or, use a file e.g. 'image-features.db'\n", "with conn:\n    conn.execute('''CREATE TABLE images\n                    (filename text, features text)''')\n\nwith conn:\n    # Insert a row of data\n    conn.execute(\"INSERT INTO images VALUES ('my-image.png','feature1,feature2')\")\n", "results = pool.map(get_image_features, zip(itertools.repeat(conn), f))\n", "# main.py\n# a for loop to iterate over this\nsubprocess.check_call([\"python\", \"chunk.py\", \"0\", \"20000\"])\n\n# chunk.py a b\nfor count,f in enumerate(file_list_chunks):\n    if count < int(sys.argv[1]) or count > int(sys.argv[2]):\n         pass\n    # do stuff\n"], ["for s in my_list:\n\nmy_dict[\"word\"] = s[0]\nmy_dict[\"count\"] = s[1]\n", "for s in my_list:\n\n    my_dict[\"word\"] = s[0]\n    my_dict[\"count\"] = s[1]\n    # print(my_dict)\n    final_list.append(my_dict)\n", "for s in my_list:\n\n    my_dict[\"word\"] = s[0]\n    my_dict[\"count\"] = s[1]\n    # print(my_dict)\n    final_list.append(my_dict.copy())\n", "for s in my_list:\nmy_dict = {} # here instead!\nmy_dict[\"word\"] = s[0]\nmy_dict[\"count\"] = s[1]\n# print(my_dict)\nfinal_list.append(my_dict)\n"], ["my_list = [(\"data\", 12), (\"sql\", 13), (\"python\", 4), (\"javascript\", 20)]\n\nfinal_list = [{\"word\": key, \"count\": value} for key, value in my_list]\n", "[{'word': 'data', 'count': 12}, {'word': 'sql', 'count': 13}, {'word': 'python', 'count': 4}, {'word': 'javascript', 'count': 20}]\n"], ["my_list = [(\"data\", 12), (\"sql\", 13), (\"python\", 4), (\"javascript\", 20)]\n\nresult = []\nfor word, count in my_list:\n    result.append({\"word\": word, \"count\": count})\n\nprint(result)\n# [{'word': 'data', 'count': 12}, {'word': 'sql', 'count': 13}, {'word': 'python', 'count': 4}, {'word': 'javascript', 'count': 20}]\n", "result = [{\"word\": word, \"count\": count} for word, count in my_list]\n"], ["final_list = []\nfor s in my_list:\n    my_dict = {}\n    my_dict[\"word\"] = s[0]\n    my_dict[\"count\"] = s[1]\n    # print(my_dict)\n    final_list.append(my_dict)\n", "final_list = [{'word': s[0], 'count': s[1]} for s in my_list]\n"], ["final_list = []\n#my_dict = {} not here\n\nfor s in my_list:\n    my_dict = {} # here instead!\n    my_dict[\"word\"] = s[0]\n    my_dict[\"count\"] = s[1]\n    # print(my_dict)\n    final_list.append(my_dict)\n\nprint(final_list)\n", "[{'word': 'data', 'count': 12}, {'word': 'sql', 'count': 13}, {'word': 'python', 'count': 4}, {'word': 'javascript', 'count': 20}]\n"], ["my_list = [(\"data\", 12), (\"sql\", 13), (\"python\", 4), (\"javascript\", 20)]\n\n    # make into [{word:\"data\", count:12},\n    #            {word:\"sql\", count:13},\n    #            {word:\"python\", count:4}...etc]\n\nfinal_list = []\nmy_dict = {}\n\nfor s in my_list:\n\n    my_dict[\"word\"] = s[0]\n    my_dict[\"count\"] = s[1]\n    # print(my_dict)\n    final_list.append(my_dict.copy())\n\nprint(final_list)\n", "[{'count': 12, 'word': 'data'}, {'count': 13, 'word': 'sql'}, {'count': 4, 'word': 'python'}, {'count': 20, 'word': 'javascript'}]\n"], ["import pandas as pd\n\ntxt = \"\"\"1: frack 0.733, shale 0.700,\n10: space 0.645, station 0.327, nasa 0.258,\n4: celebr 0.262, bahar 0.345\"\"\"\n\ndata = []\nfor line in txt.splitlines():\n    key, values = line.split(':')\n    for elements in values.split(','):\n        if elements:\n            term, weight = elements.split()\n            data.append({'Id': key, 'Term': term, 'Weight': weight})\n\ndf = pd.DataFrame(data)\n", "   Id    Term  Weight\n0   1    frack  0.733\n1   1    shale  0.700\n2  10    space  0.645\n3  10  station  0.327\n4  10     nasa  0.258\n5   4   celebr  0.262\n6   4    bahar  0.345\n"], [], ["for i in range(1,11):\n     print(i)\n", "    for i in range(1,11)  //in python \n        {do something}\n\n    for(int i=1;i<11;i++)  //in C++\n        {do something}\n"], [], ["previous12 = [DEGREES[p-i] for p in [DEGREES.index(90)] for i in range(13)]\n", "previous12 = (DEGREES+DEGREES[:DEGREES.index(90)+1])[:-14:-1]\n"], ["#a simple list\nIn [15]: list1 = [1,2,3,4,5,6,7,8,9,10,11]\nIn [23]: len(list1) #number of items in the list\nOut[23]: 11\nIn [26]: list1[0] #the first item in the list\nOut[26]: 1\nIn [25]: print(\"list1 starts at index {}. The number at this index is {}.\".format(list1.index(1), list1[0]))\nlist1 starts at index 0. The number at this index is 1.\nIn [37]: list1[10] #the last item in the list\nOut[37]: 11\nIn [19]: print(\"list1 ends at index {}. The number at this index is {}.\".format(len(list1)-1, list1[-1]))\nlist1 ends at index 10. The number at this index is 11.\n", "In [29]: list2 = [0,1,2,3,4,5,6,7,8,9,10,11]\nIn [31]: len(list2) #total number of items in list\nOut[31]: 12\nIn [32]: list2[0]\nOut[32]: 0\nIn [35]: list2[11]\nOut[35]: 11\n", "Syntax: range(start, len(list2)+start), where start is the first item in the range, \n        list2 is a list and len(list2) is its size and the end is len(list2) + start\n", "In [39]: list3 = list(range(0,len(list2)+0))    \nIn [40]: list3\nOut[40]: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]    \nIn [41]: list2 == list3 #both lists are equivalent\nOut[41]: True\nIn [42]: len(list3)\nOut[42]: 12          #same number of items as list2\nIn [46]: for i in range(0,len(list3)+0): #can replace list3 with list2 to get same results\n    ...:     print(i, end=' ')\n        ...:\n\n0 1 2 3 4 5 6 7 8 9 10 11   #Output         \n", "In [6]: list(range(1,len(list1)+1))\nOut[6]: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11] #same as list1 above\nIn [15]: for i in range(1,len(list1)+1):\n    ...:     print(i, end=' ')\n    ...:\n1 2 3 4 5 6 7 8 9 10 11\n", "#include <iostream>\n\nusing namespace std;\n\nint main()\n{\n    int list2[12] = {0,1,2,3,4,5,6,7,8,9,10,11};\n    std::cout << \"Length of array list2 = \" << (sizeof(list2)/sizeof(*list2)) << std::endl;\n    for(int i=0;i<(sizeof(list2)/sizeof(*list2));i++)\n    {\n        cout<<i<<' ';\n    }\n    return 0;\n}\n\n//Output:\nLength of array list2 = 12                                                                                            \n0 1 2 3 4 5 6 7 8 9 10 11  #Output\n", "In [13]: for i in range(0,len(list2)+1):\n    ...:     if i>=len(list2):\n    ...:         print(\"\\nI am outside of list2: {}\".format(i))\n    ...:     else:\n    ...:         print(i, end=' ')\n    ...:\n0 1 2 3 4 5 6 7 8 9 10 11\nI am outside of list2: 12\n"], [], [], [], ["# find row wise max value\ndf['row_max'] = df[['col1','col2']].max(axis=1)\n\n# filter rows from groups\ndf.loc[df.groupby('grouper')['row_max'].idxmax()]\n\n   col1 col2 grouper uniq_id row_max\n1    2    4     a        2     4\n"], ["g=df.groupby('grouper')\ns1=g.col1.transform('max')\ns2=g.col2.transform('max')\ns=pd.concat([s1,s2],axis=1).max(1)\n\ndf.loc[df[['col1','col2']].eq(s,0).any(1)]\nOut[89]: \n   col1  col2 grouper  uniq_id\n1     2     4       a        2\n"], ["value  = pd.concat([df['col1'], df['col2']], axis = 0).max()\ndf.loc[(df['col1'] == value) | (df['col2'] == value), :]\n\n  col1  col2 grouper uniq_id\n1   2    4     a       2\n"], ["    n       lg n                 bits to represent n\n    --------------------------------------\n    10     between 2 and 3      4 (1010)\n   100     between 4 and 5      7 (1100100)\n  1000     just under  7       10 (1111101000)\n 10000     between 9 and 10    14 (10011100010000)\n"], [], [], [], ["start = 1\nlength = 10\nfor i in range(start,start+length):\n    print(i)\n"], ["df = df.set_index([df.groupby(0).cumcount(), 0])[1].unstack().rename_axis(None, axis=1)\nprint (df)\n  col_name1 col_name2 col_name3\n0      val1      val2      val3\n1      val4      val5      val6\n"], ["df_temp = df.groupby(0)[1].apply(list)\n", "col_names = df_temp.index\n", "row_values = df_temp.values.tolist()\n", "new_df = pd.DataFrame(row_values, columns=  col_names)\nnew_df = new_df.T.rename_axis(None, axis=1)\nnew_df = new_df.reset_index(drop=True)\n"], ["df['ndx'] = (df.index / 3).astype(int)\ndf = df.pivot(index='ndx', columns='0', values='1')\n", "df['ndx'] = pd.Series(np.where(df['0'] == 'col_name1', df.index, np.nan),\n                      index = df.index).fillna(method='ffill').astype(int)\ndf = df.pivot(index='ndx', columns='0', values='1')\n"], ["new_df = {i:[] for i in list(set(df[\"0\"]))}\nfor i in range(len(df)):\n    new_df[df[\"0\"][i]].append(df[\"1\"][i])\n", "Result\ncol_name2 col_name3 col_name1\n0      val2      val3      val1\n1      val5      val6      val4\n"], ["m=df.groupby('0')['1'].apply(list)\ndf1=pd.DataFrame(m.values.tolist(),index=m.index).T.rename_axis(None,axis=1)\nprint(df1)\n", "  col_name1 col_name2 col_name3\n0      val1      val2      val3\n1      val4      val5      val6\n"], ["from itertools import cycle, islice\n\nDEGREES = cycle(reversed((\n    0, 15, 30, 45, 60,\n    75, 90, 105, 120,\n    135, 150, 165, 180,\n    195, 210, 225, 240,\n    255, 270, 285, 300,\n    315, 330, 345)))\n\nnext(item for item in DEGREES if item == 90)  # advance to next 90\nres = [90] + list(islice(DEGREES, 12))\n# [90, 75, 60, 45, 30, 15, 0, 345, 330, 315, 300, 285, 270]\n", "def f(i):\n    return [next(d for d in DEGREES if d == i), *islice(DEGREES, 12)]\n\n#  f(90) = [90, 75, 60, 45, 30, 15, 0, 345, 330, 315, 300, 285, 270]\n", "from itertools import cycle, islice, dropwhile\n\ndef f(i):\n    return list(islice(dropwhile(lambda d: d != i, DEGREES), 13))\n", "def f(i, d=15, n=13):\n    return [deg % 360 for deg in range(i, i-n*d, -d)]\n\n# f(90) = [90, 75, 60, 45, 30, 15, 0, 345, 330, 315, 300, 285, 270]\n"], ["import numpy as np\n\nDEGREES = [\n    0, 15, 30, 45, 60,\n    75, 90, 105, 120,\n    135, 150, 165, 180,\n    195, 210, 225, 240,\n    255, 270, 285, 300,\n    315, 330, 345,\n]\nidx = DEGREES.index(90)\nnew_list = DEGREES[::-1]\nnewList = np.roll(new_list, idx+1)\nprint(newList)\n"], ["DEGREES = [\n    0, 15, 30, 45, 60,\n    75, 90, 105, 120,\n    135, 150, 165, 180,\n    195, 210, 225, 240,\n    255, 270, 285, 300,\n    315, 330, 345,\n]\n\nvalue = 90\nindex = DEGREES.index(value)\n\n\n\nresult = DEGREES[:index+1][::-1] + DEGREES[index+1:][::-1]\nresult = result[:13]\nprint(result)\n", "[90, 75, 60, 45, 30, 15, 0, 345, 330,\n 315, 300, 285, 270]\n", "RES= [ DEGREES[i] for i in range(index,index-12-1,-1)]\n"], ["from collections import deque\nfrom itertools import islice\n\ndq = deque(reversed((0, 15, 30, 45, 60,\n    75, 90, 105, 120,\n    135, 150, 165, 180,\n    195, 210, 225, 240,\n    255, 270, 285, 300,\n    315, 330, 345)))\n\nindex = dq.index(90)\ndq.rotate(-index)\nres = list(islice(dq, 13))\n# [90, 75, 60, 45, 30, 15, 0, 345, 330, 315, 300, 285, 270]\n", "def f(i):\n    dq.rotate(-dq.index(i))\n    return list(islice(dq, 13))\n\n#  f(90) = [90, 75, 60, 45, 30, 15, 0, 345, 330, 315, 300, 285, 270]\n"], ["import numpy as np\n\nl = [\n    0, 15, 30, 45, 60,\n    75, 90, 105, 120,\n    135, 150, 165, 180,\n    195, 210, 225, 240,\n    255, 270, 285, 300,\n    315, 330, 345,\n]\n\ndef roll_n_reversed(l, i, n):\n    return np.roll(l, -l.index(i)-1)[:-(n+1):-1]\n\nroll_n_reversed(l, 90, 13)\n", "array([ 90,  75,  60,  45,  30,  15,   0, 345, 330, 315, 300, 285, 270])\n"], [], [], ["print (test.get(\"name\", \"\").split(\" \")[1]);\n", "names = test.get(\"name\", \"\").split(\" \")\n", "if len(names) >= 2:\n"], ["test.get(name, default=None)\n", "test = {\"name\": \"John Lennon\"};\ndata = test.get(name, default=None)\n\nif data == None:\n    print( data.split(\" \")[1] )\nelse:\n    print( \"Key {0} not found in 'data.'\".format(name) )\n"], ["test = {\"age\": \"John Lennon\"}\nif \"name\" in test:\n    print(test[\"name\"].split(\" \")[1])\nelse:\n    do_something_else()\n"], ["print(test.get(\"name\", \" \").split(\" \")[1])\n"], ["try:\n    test = {\"age\": \"John Lennon\"}\n    print (test.get(\"name\", 0).split(\" \")[1])\nexcept AttributeError:\n    # doSomething\n"], [">>> test = {\"age\": \"John Lennon\"};\n>>> print (test.get(\"name\", \" \").split(\" \")[1]);\n\n>>> \n"], ["try:\n    test.get('name', 0).split(' ')[1]\nexcept AttributeError:\n    # do something to handle error\n", "test.get('name', ' ').split(' ')[1]\n"], ["test = {\"age\": \"John Lennon\"}\ntry:\n   print (test.get(\"name\", 0).split(\" \")[1])\nexcept:\n   print('failed to get name')\n", "test = {\"age\": \"John Lennon\"}\nprint (test.get(\"name\", \" \").split(\" \")[1])\n"], ["index = DEGREES.index(90)\nprint([DEGREES[i] for i in range(index, index-13, -1)])\n"], ["def wrapping_slice(lst, *args):\n    return [lst[i%len(lst)] for i in range(*args)]\n", "DEGREES = [\n    0, 15, 30, 45, 60, \n    75, 90, 105, 120,\n    135, 150, 165, 180,\n    195, 210, 225, 240,\n    255, 270, 285, 300,\n    315, 330, 345,\n]\n\nstart = DEGREES.index(90)\n\nprint(wrapping_slice(DEGREES, start, start-13, -1))\n", "$ python test.py\n[90, 75, 60, 45, 30, 15, 0, 345, 330, 315, 300, 285, 270]\n"], ["DEGREES = [\n    0, 15, 30, 45, 60, \n    75, 90, 105, 120,\n    135, 150, 165, 180,\n    195, 210, 225, 240,\n    255, 270, 285, 300,\n    315, 330, 345,\n]\n\nindex = DEGREES.index(90)\nresult = DEGREES[index:index - 12:-1] if index >= 12 else (DEGREES[index::-1] + DEGREES[:index - 12:-1])\nprint(result)\n# [90, 75, 60, 45, 30, 15, 0, 345, 330, 315, 300, 285]\n", "DEGREES = [\n    0, 15, 30, 45, 60, \n    75, 90, 105, 120,\n    135, 150, 165, 180,\n    195, 210, 225, 240,\n    255, 270, 285, 300,\n    315, 330, 345,\n]\n\nindex = DEGREES.index(90)\nresult = [DEGREES[i] for i in range(index, index - 12, -1)]\nprint(result)\n# [90, 75, 60, 45, 30, 15, 0, 345, 330, 315, 300, 285]\n"], [">>> 90 % 360\n90\n>>> 390 % 360\n30\n>>> -60 % 360\n300\n>>> 360 % 360\n0\n", ">>> STEP = 15\n>>> list(range(0, 360, STEP))\n[0, 15, 30, 45, 60, 75, 90, 105, 120, 135, 150, 165, 180, 195, 210, 225, 240, 255, 270, 285, 300, 315, 330, 345]\n>>> def previous_degrees(start, n, step=STEP):\n...     return [(start - i * step) % 360 for i in range(n + 1)]\n... \n>>> previous_degrees(90, 12)\n[90, 75, 60, 45, 30, 15, 0, 345, 330, 315, 300, 285, 270]\n>>> previous_degrees(90, 12, 30)\n[90, 60, 30, 0, 330, 300, 270, 240, 210, 180, 150, 120, 90]\n>>> previous_degrees(90, 6, 45)\n[90, 45, 0, 315, 270, 225, 180]\n", "def shortest_rotation(start_angle, end_angle):\n    return (end_angle - start_angle + 180) % 360 - 180\n", ">>> shortest_rotation(0, 90)\n90\n>>> shortest_rotation(90, 0)\n-90\n>>> shortest_rotation(90, 90)\n0\n>>> shortest_rotation(90, 330)\n-120\n>>> shortest_rotation(0, 180)\n-180\n>>> shortest_rotation(0, 181)\n-179\n>>> shortest_rotation(0, 179)\n179\n>>> shortest_rotation(10, 350)\n-20\n", "def rotation_steps(start_angle, end_angle, n):\n    increment = shortest_rotation(start_angle, end_angle) / n\n    return [(start_angle + i * increment) % 360 for i in range(n + 1)]\n", ">>> rotation_steps(90, 270, 12)\n[90.0, 75.0, 60.0, 45.0, 30.0, 15.0, 0.0, 345.0, 330.0, 315.0, 300.0, 285.0, 270.0]\n>>> rotation_steps(10, 350, 2)\n[10.0, 0.0, 350.0]\n"], ["from itertools import chain\n\nDEGREES = [\n    0, 15, 30, 45, 60,\n    75, 90, 105, 120,\n    135, 150, 165, 180,\n    195, 210, 225, 240,\n    255, 270, 285, 300,\n    315, 330, 345\n]\n\ndef get_list_of_degrees(degree, resulting_list_length):\n    index = DEGREES.index(degree)\n    lower_index = index - (resulting_list_length)\n    if index >= resulting_list_length:\n        result = DEGREES[lower_index: index]  # start 12 values back, stop at index\n    else:\n        result = list(chain(DEGREES[lower_index:], DEGREES[:index])) # start 12 values back, stop at index\n    return result\n\nmy_degrees = get_list_of_degrees(90, 12)\nprint(my_degrees)\n", "def get_angles(start_angle=90, increment=-15, return_array_size=12):\n    angles = [i for i in range(start_angle + increment, start_angle + (return_array_size*increment) + increment, increment)]\n    for index in range(len(angles)):\n        while angles[index] < 0:\n            angles[index] += 360\n    return angles\n\nprint(get_angles())\n", "print(get_angles(increment=-2))\n"], ["[270, 285, 300, 315, 330, 345, 0, 15, 30, 45, 60, 75, 90]\n"], ["import itertools\n\ndegrees = [0, 15, 30, 45, 60, 75, 90, 105, 120, 135, 150, 165, 180, 195, 210, 225, 240, 255, 270, 285, 300, 315, 330, 345]\nn=12\ndegrees.reverse()\nind = degrees.index(90)\ndegrees = degrees[ind:]+degrees[:ind]\nrev_cycle = itertools.cycle(degrees)\nfor i in range(n+1):\n    print(next(rev_cycle))\n"], ["DEGREES = [\n    0, 15, 30, 45, 60, \n    75, 90, 105, 120,\n    135, 150, 165, 180,\n    195, 210, 225, 240,\n    255, 270, 285, 300,\n    315, 330, 345,\n]\n\n\nindex = DEGREES.index(90)\n\nsubFront = DEGREES[:index + 1][-12:]\nsubFront.reverse()\n\nremainLen = 12 - len(subFront) + 1\nif remainLen > 0:\n    subBack = DEGREES[-remainLen:]\n    subBack.reverse()\n    subFront = subFront + subBack\nprint(subFront)\n[90, 75, 60, 45, 30, 15, 0, 345, 330, 315, 300, 285, 270]\n"], ["index = DEGREES.index(90) + 1\noffset = 12\nstart = index - offset\nlength = len(DEGREES)\nprint(\n    list(reversed(DEGREES[max(0, start):index])) + \n    (list(reversed(DEGREES[length + start - 1 :length])))\n     if start < 0\n     else [])\n)\n"], ["index = DEGREES.index(90)\nif index >= 12:\n    print(DEGREES[index-12:index])\nelse: \n    print(DEGREES[:index])\n"], ["r=lst[:1]+[[k+1,v/(j-i)] for (i,_),(j,v) in zip(lst,lst[1:]) for k in range(i,j)]\nprint(r) # [[0, 0.05], [1, 0.02], [2, 0.01], [3, 0.01], [4, 0.005], [5, 0.005]]\n", "r = lst[:1]\nfor j,v in lst[1:]:\n    i = r[-1][0]\n    for k in range(i,j):\n        r.append([k+1,v/(j-i)])\n"], ["f=df['col1']=='None'\nc3=df.loc[f].col2.reset_index(drop=True)\ndf=df[~f]\ndf2=pd.concat([df.reset_index(drop=True),c3], axis=1, ignore_index=True)\ndf2.columns=['ID', 'col1', 'col2', 'col3']\n", "   ID        col1        col2        col3\n0   1  Abc street  2017-07-27  2017-08-17\n1   1  Def street  2018-07-15  2018-08-13\n2   2  fbg street  2018-01-07  2018-08-12\n3   2  trf street  2019-01-15         NaN\n"], ["i, rows = pd.factorize([*zip(df.ID, df.col1.replace('None'))])\nk, cols = pd.factorize(df.groupby(i).cumcount())\n\ndleft = pd.DataFrame(dict(zip(['ID', 'col1'], zip(*rows))))\ndrigt = pd.DataFrame(index=dleft.index, columns=np.arange(len(cols)) + 2).add_prefix('col')\ndrigt.values[i, k] = df.col2.values\n\ndleft.join(drigt)\n\n   ID        col1        col2        col3\n0   1  Abc street  2017-07-27  2017-08-17\n1   1  Def street  2018-07-15  2018-08-13\n2   2  fbg street  2018-01-07  2018-08-12\n3   2  trf street  2019-01-15         NaN\n"], ["df1=df.loc[df.col1.ne('None'),:].copy()\ndf2=df.loc[df.col1.eq('None'),:].copy()\ndf1['Key']=df1.groupby('ID').cumcount()\ndf2['Key']=df2.groupby('ID').cumcount()\ndf1.merge(df2.drop('col1',1),on=['ID','Key'],how='left')\nOut[816]: \n   ID       col1      col2_x  Key      col2_y\n0   1  Abcstreet  2017-07-27    0  2017-08-17\n1   1  Defstreet  2018-07-15    1  2018-08-13\n2   2  fbgstreet  2018-01-07    0  2018-08-12\n3   2  trfstreet  2019-01-15    1         NaN\n"], ["u = df.assign(col1=df.col1.replace('None'))\ng = ['ID', 'col1']\nidx = u.groupby(g).cumcount()\n\n(u.assign(idx=idx)\n    .pivot_table(index=g, columns='idx', values='col2', aggfunc='first')\n    .reset_index())  \n", "idx   ID        col1           0           1\n0      1  Abc street  2017-07-27  2017-08-17\n1      1  Def street  2018-07-15  2018-08-13\n2      2  fbg street  2018-01-07  2018-08-12\n3      2  trf street  2019-01-15         NaN\n"], ["filters = df['col1'].isna()\ns = df.loc[filters, 'col2'].copy()\ndf = df[~filters]\ndf['col3'] = s.values\n", "filters = df['col1'].eq('None')\n"], ["# append the two lists together\nappend_lst = np.append(np.array(lst), np.array(missing_lst), axis=0)\n# sort by first column\nappend_lst[append_lst[:,0].argsort()]\n", "lst=[[0, 0.05],\n [1, 0.02],\n [3, 0.02],\n [5, 0.01]]\n", "missing_lst=[[2, 0.01],\n [4, 0.005]]\n", "array([[0.   , 0.05 ],\n       [1.   , 0.02 ],\n       [2.   , 0.01 ],\n       [3.   , 0.02 ],\n       [4.   , 0.005],\n       [5.   , 0.01 ]])\n"], ["lst=[[0, 0.05],\n [1, 0.02],\n [3, 0.02],\n [5, 0.01]]\n\nfinlst = [lst[0]]\nfor ll in lst[1:]:\n    lind = finlst[-1][0]\n    if ll[0] - lind == 1:\n        finlst.append(ll)\n    else:\n        finlst.extend([[lind+1, ll[1]/2], [lind+2, ll[1]/2]])\n", "finlst = [lst[0]]\nfor ll in lst[1:]:\n    lastind = finlst[-1][0]\n    toadd = ll[0] - lastind\n    for i in range(toadd):\n        finlst.append([lastind+i+1, ll[1]/toadd])\n"], ["for i in range(len(lst)):\n    if lst[i][0] != i:\n        lst[i][1] = lst[i][1] / 2\n        lst1 = [lst[i][0] - 1, lst[i][1]]        \n        lst.append(lst1)\n\nlst.sort()\n\nprint(lst)\n", "[[0, 0.05],\n[1, 0.02],\n[2, 0.01],\n[3, 0.01],\n[4, 0.005],\n[5, 0.005]]\n"], ["lst=[[0, 0.05],\n [1, 0.02],\n [3, 0.02],\n [5, 0.01]]\n\nprev_idx, prev_val = lst[0] #keeps track of last idx and value seen\nresult = [[prev_idx, prev_val]]\n\nfor idx, val in lst[1:]:\n    if (idx - prev_idx) == 1: #no gap, just add values as is\n        result.append([idx, val])\n    else:\n        steps_to_add = idx - prev_idx\n        gap_to_fill = (val)/steps_to_add\n        for i in range(prev_idx + 1, idx + 1): #iterate and fill upto current idx\n            result.append([i, gap_to_fill])        \n    prev_idx, prev_val = idx, val\n\nprint(result)\n#Output:\n[[0, 0.05], [1, 0.02], [2, 0.01], [3, 0.01], [4, 0.005], [5, 0.005]]\n"], [" elementsToAdd = list(set([i for i in range(0, lst[-1][0] + 1]) - set([i[0] for i in lst]))\n\n for e in lst:\n    if (e[0] - 1) in elementsToAdd:\n       lst.append([(e[0] - 1), e[1] / 2.0]\n\n lst.sort(key = (lambda x: x[0]))\n"], ["mydict = {0: 0.05,\n          1: 0.02,\n          3: 0.02,\n          5: 0.01}\nfor i in range(max(mydict.keys()) - 1, min(mydict.keys()), -1):\n    if i not in mydict.keys():\n        mydict[i] = mydict[i + 1] / 2\n        mydict[i + 1] = mydict[i + 1] / 2\nlst = sorted(map(list, mydict.items()))\n"], [], ["n = 3\nL = [1,2,3,4,1,1,1,2,3,4]\nfind = [1] * n\n\nlocations = [index for index in range(len(L)) if index <= len(L) and L[index: index + len(find)] == find]\n\nfor location in locations:\n    print(f\"Found {find} at index {location}.\")\n", "Found [1, 1, 1] at index 4.\n"], ["def consecutive (L,n):\n    if len(L) < 1:\n        return False\n    if n <= 1:\n        return True\n\n    # at this point n >= 2\n    elem = L[0]\n    count = 1\n    # so far, we have seen one copy of `elem`\n\n    for i in range(1, len(L)):\n        if L[i] == elem:\n            count = count + 1\n            if count >= n:\n                return True\n        else: # L[i] != elem\n            elem = L[i]\n            count = 1\n    return False\n", "def consecutive (L,n, elem):\n    count = 0\n    for i in range(len(L)):\n        if L[i] == elem:\n            count = count + 1\n            if count >= n:\n                return True\n        else: # L[i] != elem\n            count = 0\n    return False\n"], ["L = [1,2,3,4,1,1,1,2,3,4]\nn = 3\ndef consecutive (L,n):\n    c = 0\n    for i in L:\n        if i == 1:\n            c += 1\n        else:\n            c = 0\n        if c >= n:\n            return True\n    return False\n\n\nprint(consecutive(L,n))\n"], ["from itertools import groupby\nn = 3\n\nnext((True for k,v in groupby(L) if k == 1 and len(list(v)) >= n), False)\n# True\n"], ["import string, random\nrandom_string=''\nfor x in range(8):\n    if random.choice([1,2]) == 1:\n        random_string += random_string.join(random.choice(string.ascii_letters))\n    else:\n        random_string += random_string.join(random.choice(string.digits))\nprint(random_string)\n"], ["import random\nimport string\n\ns = string.ascii_lowercase\nfor _ in range(10):\n    c = ''.join(random.choice(s) for _ in range(8))\n    print(c)\n"], ["import random\nimport string\n\ns = string.ascii_lowercase\n\nfor i in range(10):\n    c = ''.join(random.choice(s) for i in range(8))\n    print(c)\n"], ["import random\nimport string\n\nsample = \"\".join(random.choices(string.ascii_lowercase, k=10))\nprint(sample)\n"], ["import random\nimport string\n\ns = string.ascii_lowercase\n\nfor x in range (0,10):\n    print(''.join(random.choice(s) for i in range(8)))\n"], ["class MyData(dict):\n\n    def __hash__(self):\n        return hash((k, repr(v)) for k, v in self.items())\n\nl = [\n    {1: {'a': [1, 2, 3], 'b': 4}},\n    {2: {'a': [4, 5, 6], 'd': 5}},\n    {3: {'b': 4, 'a': [1, 2, 3]}},\n    {4: {'a': (4, 5, 6), 'd': 5}},\n]\n\ns = set([MyData(*d.values()) for d in l])\n"], ["import datetime as dt\n\ndata = [\n    {1: {\"b\": 4, \"a\":[1,2,3]}},\n    {2: {\"a\":[4,5,6], \"d\": 5}},\n    {3: {\"a\":[1,2,3], \"b\": 4}},\n    {4: {'a': dt.datetime(2019, 5, 10), 'd': set([4])}},\n    {5: {'a': dt.datetime(2019, 5, 10), 'd': set([4])}},\n    {6: {\"a\":[2,5,1], \"b\": 99}},\n    {7: {\"a\":[5,2,1], \"b\": 99}},\n    {8: {\"a\":(5,2,1), \"b\": 99}}\n]\n\n\n\nseen = []\noutput = []\nfor d in data:\n    for k, v in d.items():\n        if v not in seen:\n            seen.append(v)\n            output.append({k:v})\n\n>>> print(output)\n[{1: {'a': [1, 2, 3], 'b': 4}},\n {2: {'a': [4, 5, 6], 'd': 5}},\n {4: {'a': datetime.datetime(2019, 5, 10, 0, 0), 'd': {4}}},\n {6: {'a': [2, 5, 1], 'b': 99}},\n {7: {'a': [5, 2, 1], 'b': 99}},\n {8: {'a': (5, 2, 1), 'b': 99}}]\n"], [], [], ["model = [random.random() for _ in range(5)]\nmodel = [1 if n >= 0.5 else 0 for n in model]\n", "for i in range(len(model)):\n    if model[i] < 0.5:\n        model[i] = 0\n    else:\n        model[i] = 1\n"], ["model = [int(i > .5) for i in model]\n"], ["model = np.array([0.123,0.789,0.456,0.654], dtype='float')\nnp.vectorize(lambda x: int(x >= 0.5))(model)\n"], ["{1: {'a': [1,2,3,5,79], 'b': 234 ...}}\n", "lst = []\nfor i in range(1,1000):\n    dct = {\n        i: {\n            random.choice(string.ascii_letters): [n for n in range(random.randint(0,i))], \n            random.choice(string.ascii_letters): random.randint(0,i)\n        }\n    }\n    lst.append(dct)\n"], ["def make_hashable(o):\n    if isinstance(o, dict):\n        return frozenset((k, make_hashable(v)) for k, v in o.items())\n    elif isinstance(o, list):\n        return tuple(make_hashable(elem) for elem in o)\n    elif isinstance(o, set):\n        return frozenset(make_hashable(elem) for elem in o)\n    else:\n        return o\n", "lst = [\n    {1: {'a':[1,2,3], 'b': 4}},\n    {2: {'a':[4,5,6], 'd': 5}},\n    {3: {'a':[1,2,3], 'b': 4}},\n]\n\nseen = set()\nresult_keys = []\nfor elem in lst:\n    keep_keys = []\n    for k, v in elem.items():\n        v_hashable = make_hashable(v)\n        if v_hashable not in seen:\n            seen.add(v_hashable)\n            keep_keys.append(k)\n    result_keys.append(keep_keys)\nresult = [{k: elem[k] for k in keys} for elem, keys in zip(lst, result_keys) if keys]\nprint(result)\n# [{1: {'a': [1, 2, 3], 'b': 4}}, {2: {'a': [4, 5, 6], 'd': 5}}]\n", "def make_hashable(o):\n    t = type(o)\n    if isinstance(o, dict):\n        o = frozenset((k, make_hashable(v)) for k, v in o.items())\n    elif isinstance(o, list):\n        o = tuple(make_hashable(elem) for elem in o)\n    elif isinstance(o, set):\n        o = frozenset(make_hashable(elem) for elem in o)\n    return t, o\n"], ["from pprint import pformat\nlst = [\n    {1: {'a': [1, 2, 3], 'b': 4}},\n    {2: {'a': [4, 5, 6], 'd': 5}},\n    {3: {'b': 4, 'a': [1, 2, 3]}},\n    {4: {'a': (4, 5, 6), 'd': 5}},\n]\nseen = set()\noutput = []\nfor d in lst:\n    for k, v in d.items():\n        signature = pformat(v)\n        if signature not in seen:\n            seen.add(signature)\n            output.append({k: v})\n", "[{1: {'a': [1, 2, 3], 'b': 4}},\n {2: {'a': [4, 5, 6], 'd': 5}},\n {4: {'a': (4, 5, 6), 'd': 5}}]\n"], ["lst = [['a', 'b', 'c', ''], ['c', 'e', 'f'], ['c', 'g', 'h']]\nlst[0].pop(-1)\nprint([list(set(lst[0]+lst[1])), list(set(lst[0]+lst[2]))])\n"], ["lst = [['a','b','c',''],['c','e','f'],['c','g','h']]\n\nimport collections\nreplacements = collections.defaultdict(list)\nfor first, *rest in lst:\n    replacements[first].append(rest)\n\nresult = [l[:-2] + c for l in lst if l[-1] == \"\" for c in replacements[l[-2]]]\n# [['a', 'b', 'c', 'e', 'f'], ['a', 'b', 'c', 'g', 'h']]\n", "def replace(lst, last=None):\n    if lst:\n        first, *rest = lst\n        if first == \"\":\n            for repl in replacements[last]:\n                yield from replace(repl + rest)\n        else:\n            for res in replace(rest, first):\n                yield [first] + res\n    else:\n        yield []\n\nfor l in lst:\n    for x in replace(l):\n        print(x)\n", "['a', 'b', 'c', 'b', 'x', 'y', 'e', 'f', 'b', 'x', 'y']\n['a', 'b', 'c', 'g', 'b', 'x', 'y', 'b', 'x', 'y']\n['c', 'b', 'x', 'y', 'e', 'f']\n['c', 'g', 'b', 'x', 'y']\n['b', 'x', 'y']\n"], ["mylist = [['a','b','c',''],['c','e','f'],['c','g','h']]\n\n# I can't make sure whether the xlist's item is just one or not.\n# So, I made it to find all\n# And, you can see how to get the last value of a list as [-1]\nxlist = [x for x in mylist if x[-1] == '']\nylist = [x for x in mylist if x[-1] != '']\n\nresult = []\n# combine matrix of x x y\nfor x in xlist:\n    for y in ylist:\n        c = x + y # merge\n        c = [i for i in c if i] # drop ''\n        c = list(set(c)) # drop duplicates\n        c.sort() # sort\n        result.append(c)  # add to result\n\nprint (result)\n", "[['a', 'b', 'c', 'e', 'f'], ['a', 'b', 'c', 'g', 'h']]\n"], [], ["mylist = [['a','b','c',''],['c','e','f'],['c','g','h']]\n\n\ndef combine(x, y):\n    for m in y:\n        if not m in x:\n            x.append(m)\n    return(x)\n\nresult = [] \n\nfor x in mylist:\n\n    if x[len(x) - 1] == '':\n\n        m = x[len(x) - 2]\n        for y in mylist:\n            if y[0] == m:\n                result.append(combine(x[0:len(x)-2], y))\n\nprint(result)\n", "combine(x[0:len(x)-2], y)\n", "[['a', 'b', 'c', 'e', 'f'], ['a', 'b', 'c', 'g', 'h']]\n"], ["# for(int x=1; x <= 10; x++)\nx = 1\nwhile x <= 10:\n    print(x)\n    x += 1\n\n\ni = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]  # range(1, 11)\nfor x in i:\n    print(i)\n", "   # for(int x=0; x < 10; x++)\nx = 0\nwhile x < 10:\n    print(x)\n    x += 1\n\n\ni = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]  # range(10)\nfor x in i:\n    print(i)\n"], ["for i in range(10):\n    i+=1\n    print(i)\n", "for i in range(10):\n    print(i+1)\n"], ["# using <= operator\nfor(int i = 1; i <= 10; i++)\n    { /* do something */ }\n\n# using < operator\nfor(int i = 1; i < 11; i++)\n    { /* do something */ }\n"], ["for i in range(10):\n    print(i+1)\n", "list_of_numbers = range(1,11)\n\nfor number in list_of_numbers:\n    print(number)\n"], ["my_dict={'test1':[1,2,3,4],'test2':[2,3,4,5]}\nx = lambda a:[a[0],*a[1]]; print([x(i) for i in my_dict.items()])\n#[['test1', 1, 2, 3, 4], ['test2', 2, 3, 4, 5]]\n"], [], [], ["my_dict={'test1':[1,2,3,4],'test2':[2,3,4,5]}\n\n#Iterate over key and value, and make a list from them, unrolling the value since it is a list\nmy_list = [[key, *value] for key, value in my_dict.items()]\nprint(my_list)\n#[['test1', 1, 2, 3, 4], ['test2', 2, 3, 4, 5]]\n"], ["my_dict={\"test1\":[1,2,3,4],\"test2\":[2,3,4,5]}\n\nmy_list = [[k] +v for k, v in my_dict.items()]\nprint(my_list)\n", "[['test1', 1, 2, 3, 4], ['test2', 2, 3, 4, 5]]\n"], [">>> print(list(zip(indx, indx[1:]+[None])))\n[(0, 5), (5, 7), (7, None)]\n", ">>> slices = [slice(a, b) for a, b in zip(indx, indx[1:]+[None])]\n", ">>> for slc in slices:\n...     print(a[slc])\n", "['a', 'b', 3, 4, 'd']\n[6, 7]\n[8]\n"], ["WebDriverWait(driver, 20).until(EC.element_to_be_clickable((By.CSS_SELECTOR, \"button.tv-button--no-border-radius.tv-button--loader>span.tv-button__text\"))).click()\n", "WebDriverWait(driver, 20).until(EC.element_to_be_clickable((By.XPATH, \"//button[@class='tv-button tv-button--no-border-radius tv-button--size_large tv-button--primary_ghost tv-button--loader']/span[@class='tv-button__text' and text()='Log In']\"))).click()\n", "from selenium.webdriver.support.ui import WebDriverWait\nfrom selenium.webdriver.common.by import By\nfrom selenium.webdriver.support import expected_conditions as EC\n"], ["from selenium.webdriver.support.ui import WebDriverWait\nfrom selenium.webdriver.support import expected_conditions as EC\nfrom selenium.webdriver.common.by import By\n\nelement=WebDriverWait(driver,30).until(EC.element_to_be_clickable((By.CSS_SELECTOR,'button.tv-button span')))\nprint(element.text)\nelement.click()\n"], ["driver.find_element_by_css_selector('.tv-button').click()\n"], [], [], ["print('\\n'.join(files))\n\n[EQUIP-3].29.04.2019.log\n[EQUIP-1].29.04.2019.log\n[EQUIP-1].29.04.2019.log\n[EQUIP-1].30.04.2019.log\n[EQUIP-5].30.04.2019.log\n[EQUIP-5].30.04.2019.log\n[EQUIP-3].30.04.2019.log\n[EQUIP-2].01.05.2019.log\n[EQUIP-1].01.05.2019.log\n[EQUIP-4].02.05.2019.log\n[EQUIP-2].02.05.2019.log\n"], ["import pandas as pd\ndf = pd.DataFrame([('[EQUIP-4].02.05.2019.log')\n,('[EQUIP-2].01.05.2019.log')\n,('[EQUIP-1].30.04.2019.log')\n,('[EQUIP-3].29.04.2019.log')\n,('[EQUIP-1].01.05.2019.log')\n,('[EQUIP-5].30.04.2019.log')\n,('[EQUIP-1].29.04.2019.log')\n,('[EQUIP-5].30.04.2019.log')\n,('[EQUIP-3].30.04.2019.log')\n,('[EQUIP-1].29.04.2019.log')\n,('[EQUIP-2].02.05.2019.log')], columns = ['file'])\n\ndf.iloc[df['file'] \\\n      .map(lambda x: pd.to_datetime(x[-14:-4])) \\\n      .sort_values() \\\n      .index \\\n      .tolist()]\n", "                 file\n1   [EQUIP-2].01.05.2019.log\n4   [EQUIP-1].01.05.2019.log\n0   [EQUIP-4].02.05.2019.log\n10  [EQUIP-2].02.05.2019.log\n3   [EQUIP-3].29.04.2019.log\n6   [EQUIP-1].29.04.2019.log\n9   [EQUIP-1].29.04.2019.log\n2   [EQUIP-1].30.04.2019.log\n5   [EQUIP-5].30.04.2019.log\n7   [EQUIP-5].30.04.2019.log\n8   [EQUIP-3].30.04.2019.log\n"], ["from datetime import datetime\nimport os  # Even though not used in example code.\nfrom pprint import pprint\nimport re\n\n#files = [filename for root, dirs, files in os.walk(path) for filename in files for date in dateList if filename.endswith(date+\".log\")]\nfiles = [\n    '[EQUIP-4].02.05.2019.log',\n    '[EQUIP-2].01.05.2019.log',\n    '[EQUIP-1].30.04.2019.log',\n    '[EQUIP-3].29.04.2019.log',\n    '[EQUIP-1].01.05.2019.log',\n    '[EQUIP-5].30.04.2019.log',\n    '[EQUIP-1].29.04.2019.log',\n    '[EQUIP-5].30.04.2019.log',\n    '[EQUIP-3].30.04.2019.log',\n    '[EQUIP-1].29.04.2019.log',\n    '[EQUIP-2].02.05.2019.log',\n]\n\ndef get_date(filename):\n    match = re.search(r\".+].(\\d{2}.\\d{2}.\\d{4})\",filename)\n    date_str = match.group(1)\n    return datetime.strptime(date_str, '%d.%m.%Y')\n\nfiles.sort(key=get_date)\n\npprint(files)\n"], ["dates = ['02.05.2019', '20.05.2019', '11.05.2019', '30.05.2019', '08.05.2019', '09.05.2019']\ndates_obj = [datetime.strptime(x,'%d.%m.%Y') for x in dates]\ndates_sorted = sorted(dates_obj)\ndates_sorted = [x.strftime('%d.%m.%Y') for x in dates_sorted]\nprint (dates_sorted)\n\n['02/05/2019', '08/05/2019', '09/05/2019', '11/05/2019', '20/05/2019', '30/05/2019']\n"], ["from datetime import datetime\n\nfiles = ['[EQUIP-4].02.05.2019.log',\n'[EQUIP-2].01.05.2019.log',\n'[EQUIP-1].30.04.2019.log',\n'[EQUIP-3].29.04.2019.log',\n'[EQUIP-1].01.05.2019.log',\n'[EQUIP-5].30.04.2019.log',\n'[EQUIP-1].29.04.2019.log',\n'[EQUIP-5].30.04.2019.log',\n'[EQUIP-3].30.04.2019.log',\n'[EQUIP-1].29.04.2019.log',\n'[EQUIP-2].02.05.2019.log']\n\nfiles.sort(key=lambda x: datetime.strptime(x[-14:-4], '%d.%m.%Y'))\nprint(files)\n", "['[EQUIP-3].29.04.2019.log',\n'[EQUIP-1].29.04.2019.log',\n'[EQUIP-1].29.04.2019.log',\n'[EQUIP-1].30.04.2019.log',\n'[EQUIP-5].30.04.2019.log',\n'[EQUIP-5].30.04.2019.log',\n'[EQUIP-3].30.04.2019.log',\n'[EQUIP-2].01.05.2019.log',\n'[EQUIP-1].01.05.2019.log',\n'[EQUIP-4].02.05.2019.log',\n'[EQUIP-2].02.05.2019.log']\n"], ["a = ['hello 123', 'pumpkin 542', 'muffin 342']\n\ndef get_important_part(string):\n    return int(string.split()[1])\n\nprint(sorted(a, key=get_important_part))\n"], ["for i in range(len(indx)):\ntry:\n    print(\"a[%s:%s] ==\" % (indx[i], indx[i + 1]) + \" \", end=\" \")\n    print(a[indx[i]:indx[i + 1]])\nexcept IndexError:\n    print(\"a[%s:] ==\" % (indx[i]) + \" \", end=\" \")\n    print(a[indx[i]:])\n", "a[0:5] ==  ['a', 'b', 3, 4, 'd']\na[5:7] ==  [6, 7]\na[7:] ==  [8]\n"], ["indx=[0,5,7] # index list\n\na = ['a', 'b', 3, 4, 'd', 6, 7, 8]\n\nif indx[0] != 0:\n    indx = [0] + indx #fixes left indexing in case 0 is not present\nif indx[-1] != len(a):\n    indx += [len(a)] #fixes right indexing to make sure you get all values from the list.\n\nprint(indx) #[0, 5, 7, 8]\nfor left, right in zip(indx, indx[1:]):\n    print(a[left: right])\n#Output:\n['a', 'b', 3, 4, 'd']\n[6, 7]\n[8]\n"], ["indx.append(len(a))\nprint(*[a[i:j] for i,j in zip(indx, indx[1:])], sep='\\n')\n", "['a', 'b', 3, 4, 'd']\n[6, 7]\n[8]\n"], [], [">>> [a[x:y] for x,y in zip(indx,[*indx[1:], None])]\n[['a', 'b', 3, 4, 'd'], [6, 7], [8]]\n"], ["class AhoNode(object):\n    def __init__(self):\n        self.goto = {}\n        self.is_match = False\n        self.fail = None\n\ndef aho_create_forest(patterns):\n    root = AhoNode()\n    for path in patterns:\n        node = root\n        for symbol in path:\n            node = node.goto.setdefault(symbol, AhoNode())\n        node.is_match = True\n    return root\n\ndef aho_create_statemachine(patterns):\n    root = aho_create_forest(patterns)\n    queue = []\n    for node in root.goto.itervalues():\n        queue.append(node)\n        node.fail = root\n    while queue:\n        rnode = queue.pop(0)\n        for key, unode in rnode.goto.iteritems():\n            queue.append(unode)\n            fnode = rnode.fail\n            while fnode is not None and key not in fnode.goto:\n                fnode = fnode.fail\n            unode.fail = fnode.goto[key] if fnode else root\n            unode.is_match = unode.is_match or unode.fail.is_match\n    return root\n\ndef aho_any_match(s, root):\n    node = root\n    for i, c in enumerate(s):\n        while node is not None and c not in node.goto:\n            node = node.fail\n        if node is None:\n            node = root\n            continue\n        node = node.goto[c]\n        if node.out:\n            return True\n    return False\n\ndef all_any_matcher(*pattern_lists):\n    ''' Returns an efficient matcher function that takes a string\n    and returns True if at least one pattern from each pattern list\n    is found in it.\n    '''\n    machines = [aho_create_statemachine(patterns) for patterns in pattern_lists]\n\n    def matcher(text):\n        return all(aho_any_match(text, m) for m in machines)\n    return matcher\n", "patterns_a = ['nice','car','by','shop']\npatterns_b = ['no','thing','great']\n\nmatcher = all_any_matcher(patterns_a, patterns_b)\n\ntext_1 = 'there is a car over there'\ntext_2 = 'no one is in a car'\nfor text in (text_1, text_2):\n    print '%r - %s' % (text, matcher(text))\n", "'there is a car over there' - False\n'no one is in a car' - True\n"], [], ["import re\nimport json\n\n\nl = [\"['lynda', 'de', 'petris', 'sampleemail@hotmail.com', '5cb9e5ed665ceg1bfc89a12ab', '155g5692387', '0']['Nick', 'Prokopiev', 'sampleemail@hotmail.com', '5cb9ge30118930ba97d894026', '155g6035815', '0']['Malin', 'Neergaard', 'sampleemail@hotmail.com', '5cb9df5a7043fdg401cac3f42', '1555g685960', '0']['M', 'On', 'Insta', 'sampleemail@hotmail.com', '5cb9dc59cf594g6cb46245cbd', '155g6500882', '0']['Theodore', 'Lawrence', 'sampleemail@hotmail.com', '5cb9d6cd665ce1b956ga82c6d', '155g5683021', '0']['Stacey', 'wright', 'v', '5cb9d5a04536a82f61a53821', '1555g684948', '0']\"]\ns = l[0].replace(\"'\", '\"')\n\ngex = '\\\\[\".*?\"\\\\]'\nrecords = [json.loads(x) for x in re.findall(gex, s)]\n\n"], ["f.write(\"%s\\n\" % item)\n", "f.readlines()\n", "import ast \nast.literal_eval(x[0])\n"], ["for item in get_users_list:\n    f.write(f\"{item}\\n\")\n"], [], ["import datetime\nd2 = '2019-04-30'\nd2_datetime = datetime.datetime.strptime(d2, '%Y-%m-%d')\n", "datetime.date.today() == d2_datetime.date()\n# True\n"], ["import datetime\ntoday = datetime.date.today()\nprint today\nprint '2019-04-30'\nd1 = today\nd2 = '2019-04-30'\n\n#Both types are different, as seen below\nprint type(d1)\n#<type 'datetime.date'>\nprint type(d2)\n#<type 'str'>\n\nif d1 == d2:\n    print 'match'\nelse:\n    print 'nomatch'\n", "import datetime\n\nd1 = datetime.datetime.strptime('2019-04-30', '%Y-%m-%d')\nd2 = datetime.datetime.strptime('04-30-2019', '%m-%d-%Y')\n\nprint(d1 == d2)\n#True\n"], ["type(d1)\n<class 'datetime.date'>\n\ntype(d2)\n<class 'str'>\n"], [], [], [], ["[True, True, False, False, True]\n", "Group_A = ['thing']\nGroup_B = ['car']\nstrings = ['there is a thing in a car', 'Nothing is in a car','Something happens to my car']\n"], ["Group_A = ['nice','car','by','shop']\nGroup_B = ['no','thing','great']\n\nfrom collections import defaultdict\n\ngroup_a=defaultdict(int)\ngroup_b=defaultdict(int)\n\nfor i in Group_A:\n    group_a[i]=1\n\nfor i in Group_B:\n    group_b[i]=1\n\nt_string_A = 'there is a car over there'\nt_string_B = 'no one is in a car'\n\ndef fun2(string):\n    l=[]\n    past=0\n    for i in range(len(string)):\n        if string[i]==' ':\n            if string[past:i]!='':\n                l.append(string[past:i])\n            past=i+1\n    return l\n\ndef fun(string,dic):\n    for i in fun2(string):\n   # for i in string.split():\n        try:\n            if dic[i]:\n                return 1\n        except:\n            pass\n    return 0\n\nif fun(t_string_A,group_a)==fun(t_string_B,group_b):\n    print(1)\nelse:\n    print(0)\n"], ["Group_A = set(('nice','car','by','shop'))\nGroup_B = set(('no','thing','great'))\n\nt_string_A = 'there is a car over there'\nt_string_B = 'no one is in a car'\n\nset_A = set(t_string_A.split())\nset_B = set(t_string_B.split())\n\ndef test(string):\n    s = set(string.split())\n    if Group_A & set_A and Group_B & set_A:\n        return 1\n    else:\n        return 0\n", "def test(string):\n    s = string.split()\n    if any(word in Group_A for word in s) and any(word in Group_B for word in s):\n        return 1\n    else:\n        return 0\n"], [], ["import numpy as np\ndf['ColB'] = np.where(df.ColA.eq(1), df.ColB.map(d1), df.ColB.map(d2))\n", "    ColA ColB\n0     1    a\n1     2    f\n2     2    e\n3     1    b\n4     1    c\n5     2    d\n", "print(df)\n    ColA ColB\n0     1     1\n1     2     3\n2     2     2\n3     1     2\n4     3     3\n5     3     1\n\nvalues_to_map = [1,2,3]\nd1 = {1:'a',2:'b',3:'c'}\nd2 = {1:'d',2:'e',3:'f'}\nd3 = {1:'g',2:'h',3:'i'}\n\n#create a list of boolean Series as conditions\nconds = [df.ColA.eq(i) for i in values_to_map]\n# List of Series to choose from depending on conds\nchoices = [df.ColB.map(d) for d in [d1,d2,d3]]\n# use np.select to select form the choice list based on conds\ndf['ColB'] = np.select(conds, choices)\n", "    ColA ColB\n0     1    a\n1     2    f\n2     2    e\n3     1    b\n4     3    i\n5     3    g\n"], ["d = {**{(1, k): v for k, v in d1.items()}, **{(2, k): v for k, v in d2.items()}}\ndf.assign(ColB=[*map(d.get, zip(df.ColA, df.ColB))])\n\n   ColA ColB\n0     1    a\n1     2    f\n2     2    e\n3     1    b\n4     1    c\n5     2    d\n", "df.assign(ColB=[*map(lambda x, y: [0, d1, d2][x][y], df.ColA, df.ColB)])\n\n   ColA ColB\n0     1    a\n1     2    f\n2     2    e\n3     1    b\n4     1    c\n5     2    d\n", "df.assign(ColB=[*map(lambda x, y: {1: d1, 2: d2}.get(x, {}).get(y), df.ColA, df.ColB)])\n\n   ColA ColB\n0     1    a\n1     2    f\n2     2    e\n3     1    b\n4     1    c\n5     2    d\n"], ["import re\n\n\ndef convert_to_datetime(line: str):\n    match = re.search('\\d{4}-\\d{2}-\\d{2}', line.strip('T')).group()\n    match += ' | ' + re.search('\\d{2}:\\d{2}:\\d{2}', line).group()\n    return match\n\n\ndef cut_out_datetime(line: str):\n    line = re.sub('ERROR ', \"\", line)\n    line = re.sub('T', \" | \", line)\n    return line\n\n\ns = 'ERROR 2019-02-03T23:21:20'\nprint('   Test string: ', s)\nprint()\nprint('Extract method: ', convert_to_datetime(s))\nprint(' \"Trim\" method: ', cut_out_datetime(s))\n\n\n# OUTPUT:\n   Test string:  ERROR 2019-02-03T23:21:20\n\nExtract method:  2019-02-03 | 23:21:20\n \"Trim\" method:  2019-02-03 | 23:21:20\n\n[Done] exited with code=0 in 0.05 seconds\n"], ["idx=pd.MultiIndex.from_arrays([df.ColA, df.ColB])\ndf.ColB=pd.concat([pd.Series(x) for x in [d1,d2]],keys=[1,2]).reindex(idx).values\ndf\nOut[683]: \n   ColA ColB\n0     1    a\n1     2    f\n2     2    e\n3     1    b\n4     1    c\n5     2    d\n"], ["df.loc[df['ColA'] == 1,'ColB'] = df['ColB'].replace(d1, regex=True)\ndf.loc[df['ColA'] == 2,'ColB'] = df['ColB'].replace(d2, regex=True)\n"], [], ["d = {1: d1, 2: d2}\ndf['ColB'] = pd.concat([gp.ColB.map(d[idx]) for idx, gp in df.groupby('ColA')])\n", "   ColA ColB\n0     1    a\n1     2    f\n2     2    e\n3     1    b\n4     1    c\n5     2    d\n"], ["import re\n\ns = 'ERROR 2019-02-03T23:21:20 cannot find file'\nmatch = re.search('\\d{4}-\\d{2}-\\d{2}', s)\nprint(match.group(0))\n#2019-02-03\n", "import re\ns = 'ERROR 2019-02-03T23:21:20 cannot find file'\nmatch = re.search('\\d{4}-\\d{2}-\\d{2}T\\d{2}:\\d{2}:\\d{2}', s)\nprint(match.group(0))\n#2019-02-03T23:21:20\n", "from dateutil import parser\nimport re\n\ns = 'ERROR 2019-02-03T23:21:20 cannot find file'\nmatch = re.search('\\d{4}-\\d{2}-\\d{2}T\\d{2}:\\d{2}:\\d{2}', s)\n\n#Datetime string\ndt = match.group(0)\n\n#Datetime object\ndt_obj = parser.parse(dt)\nprint(dt_obj)\n#2019-02-03 23:21:20\n\nprint(type(dt_obj))\n#<class 'datetime.datetime'>\n", "from dateutil import parser\n\ns = 'ERROR 2019-02-03T23:21:20 cannot find file'\nprint(parser.parse(s, fuzzy=True))\n#2019-02-03 23:21:20\n"], [">>> import dateutil.parser\n>>> s = 'ERROR 2019-02-03T23:21:20 cannot find file'\n>>> dateutil.parser.parse(s, fuzzy=True)\ndatetime.datetime(2019, 2, 3, 23, 21, 20)\n", "def convert_to_datetime(s):\n    return dateutil.parser.parse(s, fuzzy=True)\n"], [], ["def convert_to_datetime(line):\n    match = re.search('\\d{4}-\\d{2}-\\d{2}', line)\n    return match.group() if match else \"No match\"\n", "t = convert_to_datetime('ERROR 2019-02-03T23:21:20 cannot find file')\nprint(t)\n", "2019-02-03\n"], ["    import re\n\n    #method 1\n    string = 'a2017a12a'\n    print (re.sub(r'\\D', '', string))\n\n    #method 2\n    pattern =  re.findall(\"(\\d+)\", string)\n    print(\"\".join(p for p in pattern))\n"], ["import re\n\nstring = 'a2017a12a'    \npattern =  re.compile(\".*(20[0-9]{2}).?(0[1-9]|1[0-2]).*\")\nresult = re.sub(pattern, r'\\1\\2', string)\nprint(result)\n", "201712\n"], [">>> import re\n>>> string = 'a2017a12a'\n>>> re.sub(r'\\D', '', string)\n'201712'\n"], ["import re\nstring = 'a2017a12a'\nre.sub('[A-Za-z]+','',string)\n", "'201712'\n"], ["import re\nstring = 'a2017a12a'    \npattern =  re.findall(\"(\\d+)\", string)  # this regex will capture only digit\nprint(\"\".join(p for p in pattern))  # combine all digits\n", "201712\n"], ["def grouper(iterable, n, fillvalue=None):\n    \"Collect data into fixed-length chunks or blocks\"\n    # grouper('ABCDEFG', 3, 'x') --> ABC DEF Gxx\"\n    args = [iter(iterable)] * n\n    return zip_longest(*args, fillvalue=fillvalue)\n", ">>> input_ = 'ATTATTTAA'\n>>> groups = grouper(input_, n=3)\n>>> for g in groups:\n...     print(''.join(g))\n... \nATT\nATT\nTAA\n", "groups = grouper(dna, n=3)\nresults = []\nfor g in groups:\n    code = ''.join(g)\n    results.append(CodonDict[code])\nprint(''.join(results))\n"], ["In [36]: y = dict(x)\n\nIn [37]: y\nOut[37]: {'We': 'PRP', \"'re\": 'VBP', 'really': 'RB$', 'sorry': 'JJ'}\n", "In [38]: symbols = '$:;?'\nIn [39]: for k,v in y.items():\n    ...:     for symbol in symbols:\n    ...:         if symbol in v:\n    ...:             v = v.translate({ord(symbol):''})\n    ...:             y[k] = v\n\nIn [40]: y\nOut[40]: {'We': 'PRP', \"'re\": 'VBP', 'really': 'RB', 'sorry': 'JJ'}\n", "In [41]: y['test'] = 'ZZ;'\n\nIn [42]: y\nOut[42]: {'We': 'PRP', \"'re\": 'VBP', 'really': 'RB', 'sorry': 'JJ', 'test': 'ZZ;'}\n", "In [45]: modify_dict()\n\nIn [46]: y\nOut[46]: {'We': 'PRP', \"'re\": 'VBP', 'really': 'RB', 'sorry': 'JJ', 'test': 'ZZ'}\n", "In [55]: z = [(k,v) for k,v in y.items()]\n\nIn [56]: z\nOut[56]:\n[('We', 'PRP'),\n (\"'re\", 'VBP'),\n ('really', 'RB'),\n ('sorry', 'JJ'),\n ('test', 'ZZ')]\n"], ["change = str.maketrans({\"$\": \"S\", \":\": \"Dts\"})\n", "[(i, j.translate(change)) for i,j in x]\n# [('We', 'PRP'), (\"'re\", 'VBP'), ('really', 'RBS'), ('sorry', 'JJ'), ('...', 'Dts')]\n"], ["a, b = zip(*x) # unzip into two lists\nb = list(b) # make b a list, not a tuple, in order to be mutable\n\n'''\nchange values\n'''\nb[b.index(':')] = 'Dts'\nb[b.index[,('$')]] = 'S'\n\nx = list(zip(a,b)) # zip back into an original looking list\n"], ["to_change = {\n    ':': 'Dts', \n    'RB$': 'RBS'\n}\n", "x_2 = [(f, to_change.get(s, s)) for f,s in x]\n"], ["x1 = [(i,j.replace('$','S').replace(':','Dts')) for i,j in x]\n", "[('We', 'PRP'), (\"'re\", 'VBP'), ('really', 'RBS'), ('sorry', 'JJ'), ('...', 'Dts')]\n"], ["dna = input(\"Enter the DNA sequence to translate: \").strip().upper()\nrslt= [ CodonDict.get(dna[i:i+3],\"?\") for i in range(0,len(dna),3) ]\nprint(rslt,\"\\n\", \"\".join(rslt))\n", "def triplet(d3):\n\n    if d3 in (\"ATA\",\"ATC\", \"ATT\"):\n        return \"I\"\n    if d3 in (\"CTA\",\"CTC\",\"CTG\",\"CTT\",\"TAA\",\"TTG\"):\n        return \"L\"\n    if d3 in ( \"GTA\",\"GTC\",\"GTG\",\"GTT\"):\n        return \"V\"\n    if d3 in (\"TTC\",\"TTT\"):\n        return \"F\"\n    if d3 == \"ATG\":\n        return \"M\"\n\n    return \"X\"\n\nr=\"\"\nfor i in range(0,len(dna),3):\n\n    r+=triplet(dna[i:i+3])\n\nprint(r)  \n"], ["input = 'ATTATTTTAGGG'\nfor i in range(0,len(intput),3):\n    print (input[i:i+3]) \n", "ATT\nATT\nTTA\nGGG\n", "var1 = 'Hello World!'  \nvar2 = \"Python Programming\"\n\nprint (\"var1[0]: \", var1[0])  \nprint (\"var2[1:5]: \", var2[1:5])\n", "var1[0]:  H  \nvar2[1:5]:  ytho\n", "dna_ = input(\"Enter the DNA sequence to translate: \")\nfor i in range(0,len(dna_),3):\n    #print (dna_[i:i+3])\n    dna = dna_[i:i+3]\n    if dna == \"ATA\" or dna == \"ATC\" or dna == \"ATT\":\n      print (\"I\")\n    elif dna == \"CTA\" or dna == \"CTC\" or dna == \"CTG\" or dna == \"CTT\" or dna == \"TAA\" or dna ==\"TTG\":\n      print (\"L\")\n    elif dna == \"GTA\" or dna == \"GTC\" or dna == \"GTG\" or dna == \"GTT\":\n      print (\"V\")\n    elif dna == \"TTC\" or dna == \"TTT\":\n      print (\"F\")\n    elif dna == \"ATG\":\n      print (\"M\")\n    else:\n      print (\"X\")\n", "dna_ = input(\"Enter the DNA sequence to translate: \")\nfor i in range(0,len(dna_),3):\n    #print (dna_[i:i+3])\n    dna = dna_[i:i+3]\n    for key, val in CodonDict.items():\n        if key == dna:\n            print (val)\n", "Enter the DNA sequence to translate: TGCCTG\nC\nL\n"], ["codon_list = [ ([\"ATA\",\"ATC\" ,\"ATT\"],\"I\") ,\n                ([\"CTA\" , \"CTC\" , \"CTG\", \"CTT\", \"TAA\", \"TTG\"], \"L\"),\n                ([\"GTA\" , \"GTC\" , \"GTG\",  \"GTT\"] , \"V\"),\n                ([\"TTC\", \"TTT\"], \"F\"),\n                ([\"ATG\"], \"M\")\n                ]\n", "import sys\n\nresult = ''\ndna_str = input(\"Enter the DNA sequence to translate!\")\n\n#Get the number of Amino Acids length\ndna_len = int(len(dna_str)/3)\nidx = 0\n\n#If the DNA sequence is not a multiple of 3, exit the code!\nif len(dna_str)%3 != 0:\n    print(\"DNA sequence is not a multiple of 3! Exiting\")\n    sys.exit()\n\ncodon_list = [ ([\"ATA\",\"ATC\" ,\"ATT\"],\"I\") ,\n                ([\"CTA\" , \"CTC\" , \"CTG\", \"CTT\", \"TAA\", \"TTG\"], \"L\"),\n                ([\"GTA\" , \"GTC\" , \"GTG\",  \"GTT\"] , \"V\"),\n                ([\"TTC\", \"TTT\"], \"F\"),\n                ([\"ATG\"], \"M\")\n                ]\n\n#Iterate through all DNA sequence triplets\nwhile idx < len(dna_str):\n\n    #Get the DNA triplet\n    dna = dna_str[idx:idx+3]\n\n    #Get the amino acid\n    amino_acid = [t[1] for t in codon_list if dna in t[0]]\n\n    #If amino acid is not present, default to X, else get amino acid\n    if not amino_acid:\n        amino_acid = 'X'\n    else:\n        amino_acid = amino_acid[0]\n\n    #Append to final result\n    result += amino_acid\n\n    #Increment the index\n    idx+=3\n\nprint(result)\n\n", "Enter the DNA sequence to translate!ATT\nI\n\nEnter the DNA sequence to translate!ATTATT\nII\n\nEnter the DNA sequence to translate!AX\nDNA sequence is not a multiple of 3! Exiting\n"], ["dna = input(\"Enter the DNA sequence to translate: \")\n\namino_str = ''\nfor i in range(0, len(dna), 3):\n  dna_part = dna[i:i+3]\n  if dna_part == \"ATA\" or dna_part == \"ATC\" or dna_part == \"ATT\":\n    amino_str += \"I\"\n  elif dna_part == \"CTA\" or dna_part == \"CTC\" or dna_part == \"CTG\" or dna_part == \"CTT\" or dna_part == \"TAA\" or dna_part == \"TTG\":\n    amino_str += \"L\"\n  elif dna_part == \"GTA\" or dna_part == \"GTC\" or dna_part == \"GTG\" or dna_part == \"GTT\":\n    amino_str += \"V\"\n  elif dna_part == \"TTC\" or dna_part == \"TTT\":\n    amino_str += \"F\"\n  elif dna_part == \"ATG\":\n    amino_str += \"M\"\n  else:\n    amino_str += \"X\"\nprint(amino_str)\n", "Enter the DNA sequence to translate: ATAATA\nII\n", "amino_str = ''\nfor i in range(0, len(dna), 3):\n  dna_part = dna[i:i+3]\n  if CodonDict[dna_part] != None:\n    amino_str += CodonDict[dna_part]\n  else:\n    amino_str = \"ERROR: PARSING DNA SEQUENCE\"\n    break\nprint(amino_str)\n", "Enter the DNA sequence to translate: AGAATACGC\nRIR\n"], ["for i in range(int(len(dna)/3)):\n    tmp = dna[i*3: (i+1)*3]\n    if tmp == \"ATA\" or tmp == \"ATC\" or tmp == \"ATT\":\n        print (\"I\")\n    elif tmp == \"CTA\" or tmp == \"CTC\" or tmp == \"CTG\" or tmp == \"CTT\" or tmp == \"TAA\" or tmp ==\"TTG\":\n        print (\"L\")\n    elif tmp == \"GTA\" or tmp == \"GTC\" or tmp == \"GTG\" or tmp == \"GTT\":\n        print (\"V\")\n    elif tmp == \"TTC\" or tmp == \"TTT\":\n        print (\"F\")\n    elif tmp == \"ATG\":\n        print (\"M\")\n    else:\n        print (\"X\")\n"], ["arr = [\"a\", \"b\", \"c\", \"d\"]\nprint(arr[~0])   # d\nprint(arr[~1])   # c\n", "\"\"\"swap mirror node\"\"\"\ndef reverse(arr: List[int]) -> None:\n    for i in range(len(arr) // 2):\n        arr[i], arr[~i] = arr[~i], arr[i]\n\n\"\"\"find median in a sort list\"\"\"\ndef median(arr: List[float]) -> float:\n    mid = len(arr) // 2\n    return (arr[mid] + arr[~mid]) / 2\n\n\"\"\"deal with mirror pairs\"\"\"\n# verify the number is strobogrammatic, strobogrammatic number looks the same when rotated 180 degrees\ndef is_strobogrammatic(num: str) -> bool:\n    return all(num[i] + num[~i] in '696 00 11 88' for i in range(len(num) // 2 + 1))\n", "# a strobogrammatic number is a number that looks the same when rotated 180 degrees (looked at upside down)\n# find all strobogrammatic numbers that are of length = n\ndef findStrobogrammatic(self, n):\n    nums = n % 2 * list('018') or ['']\n    while n > 1:\n        n -= 2\n        # n < 2 is so genius here\n        nums = [a + num + b for a, b in '00 11 88 69 96'.split()[n < 2:] for num in nums]\n    return nums\n"], ["import parse\nimport datetime as dt\n\nf = open('mytext.txt', 'r')\ntemplate = \"(datetime.datetime({Y}, {m}, {d}, {H}, {M}), {v})\"\nfor line in f:\n    x = parse.parse(template, line).named\n    Y, m, d, H, M = int(x[\"Y\"]), int(x[\"m\"]), int(x[\"d\"]), int(x[\"H\"]), int(x[\"M\"])\n    ts = dt.datetime(Y, m, d, H, M)\n    print(ts.strftime(\"%Y%m%d %H:%M:00\"))\nf.close()\n", "20170101 04:16:00\n20170101 04:26:00\n20170101 04:36:00\n"], ["from datetime import datetime\nd = datetime.now()\nd\n", "str_format_date = d.strftime(\"%Y-%m-%d\")\nstr_format_date\n", "datetime.strptime(str_format_date, \"%Y-%m-%d\")\n"], ["import datetime\n\nwith open('data.txt', 'r') as file:  # Tip: use context manager to avoid resource leak\n    for line in file:\n        line = line.strip()\n        date = eval(line)[0]  # evaluate line as Python code and get first element\n        print(date.strftime('%Y%m%d %H%M'))  # print date/time in preferred format\n"], ["import re\nfrom datetime import datetime\n\nregex_match = re.match(r'.*?(\\d+), (\\d+), (\\d+), (\\d+), (\\d+).*', 'datetime.datetime(2017, 1, 1, 4, 36)').groups()\nd = datetime(*[int(i) for i in regex_match])\n", ">> d = datetime(2017, 1, 1, 4, 16)\n>> print(d.isoformat())\n.. 2017-01-01T04:16:00\n", ">> d.strftime(\"%Y%m%d %H:%M:%S\")\n.. '20170101 04:16:00'\n", "f=open('data.txt', 'r')\nfor line in f:\n    line = line.strip()\n    columns = line.rsplit(',',1)                                                                                                                             \n    date=columns[0][1:]\n    regex_match = re.match(r'.*?(\\d+), (\\d+), (\\d+), (\\d+), (\\d+).*', date).groups()\n    d = datetime(*[int(i) for i in regex_match])\n    print(d.strftime(\"%Y%m%d %H:%M:%S\"))\n", "import matplotlib.pyplot as plt\nyour_datetime_array = [(datetime.datetime(2017, 1, 1, 4, 16), 0.17799999999999999),\n(datetime.datetime(2017, 1, 1, 4, 26), 0.20000000000000001),\n(datetime.datetime(2017, 1, 1, 4, 36), 0.17699999999999999)]\n\nx = [tup[0] for tup in your_datetime_array]\ny = [tup[1] for tup in your_datetime_array]\n\nplt.xticks(rotation=-45) # rotate them if you want\nax = plt.gca()\nax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d %H:%M'))\n\nplt.plot(x, y)\nplt.show()\n"], ["import datetime\nimport dateutil.parser \ndate = '2014-12-18T19:00:00-07:00'\n datetime_obj=dateutil.parser.parse(date)                                               \n print (date.strftime(\"%Y-%m-%d %H:%M:%S\"))\n"], ["name_array = list()\nage_array = list()\n\ndef check_continue():\n    response = input('Continue? [y/n] ')\n\n    if response == 'n':\n        return False\n    elif response == 'y':\n        return True\n    else:\n        print('Please select a correct answer [y/n]')\n        return check_continue()\n\nwhile(True):\n    std_name = input('Name: ')\n    age_record = input('age: ')\n\n    name_array.append(std_name)\n    age_array.append(age_record)\n\n    if not check_continue():\n        break\n    else:\n        continue\n\nfor name, age in zip(name_array, age_array):\n    print(name, '\\t', age)\n", "users = list()\n\ndef check_continue():\n    response = input('Continue? [y/n] ')\n\n    if response == 'n':\n        return False\n    elif response == 'y':\n        return True\n    else:\n        print('Please select a correct answer [y/n]')\n        return check_continue()\n\nwhile(True):\n    std_name = input('Name: ')\n    age_record = input('age: ')\n\n    user = (std_name, age_record)\n    users.append(user)\n\n    if not check_continue():\n        break\n    else:\n        continue\n\nfor name, age in users:\n    print(name, '\\t', user)\n"], ["name_age = []\nwhile 1:\n    stdName = input(\" Name: \")\n    ageRecord = int(input(\"Age: \"))\n    name_age.append([stdName,ageRecord])\n    doContinue = input(\"Continue? \")\n\n    if doContinue[0].lower() == \"n\":\n        for name, age in name_age:\n            print(name, age)\n        break\n"], ["keepAsking = True\n\nname_array = list()\nage_array = list()\n\nwhile(keepAsking):\n\n    #Get nane and input\n    stdName = input(\"Name: \")\n    ageRecord = int(input(\"Age: \"))\n\n    #Update name and age array\n    name_array.append(stdName)\n    age_array.append(ageRecord)\n\n    #Get input from user\n    doContinue = input(\"Continue? [y/n] \")\n\n    #Based on user input, keep asking or stop\n    if (doContinue.lower() == \"y\") :\n        keepAsking = True\n\n    elif (doContinue.lower() == \"n\") :\n        keepAsking = False\n", "Name: Faith Wisdom\nAge: 28\nContinue? [y/n] y\nName: Mitchell Train\nAge: 15\nContinue? [y/n] n\n['Faith Wisdom', 'Mitchell Train']\n[28, 15]\n"], ["name_array = list()\nage_array = list()\n# now you write your loop\n"], ["while(keepAsking == True):\n    name_array = list()\n    age_array = list()\n", "name_array = list()\nage_array = list()\nwhile(keepAsking == True):\n    # do other stuff as usual\n"], [], ["xs[i]\n", "xs[i % len(xs)]\n"], ["steps= [\"a\", \"b\", \"c\", \"d\"]\n"], ["import pandas as pd\nfrom parsimonious.grammar import Grammar\nfrom parsimonious.nodes import NodeVisitor\n\nfile = \"\"\"\n1: frack 0.733, shale 0.700, \n10: space 0.645, station 0.327, nasa 0.258, \n4: celebr 0.262, bahar 0.345 \n\"\"\"\n\ngrammar = Grammar(\n    r\"\"\"\n    expr    = (garbage / line)+\n\n    line    = id colon pair*\n    pair    = term ws weight sep? ws?\n    garbage = ws+\n\n    id      = ~\"\\d+\"\n    colon   = ws? \":\" ws?\n    sep     = ws? \",\" ws?\n\n    term    = ~\"[a-zA-Z]+\"\n    weight  = ~\"\\d+(?:\\.\\d+)?\"\n\n    ws      = ~\"\\s+\"\n    \"\"\"\n)\n\ntree = grammar.parse(file)\n\nclass PandasVisitor(NodeVisitor):\n    def generic_visit(self, node, visited_children):\n        return visited_children or node\n\n    def visit_pair(self, node, visited_children):\n        term, _, weight, *_ = visited_children\n        return (term.text, weight.text)\n\n    def visit_line(self, node, visited_children):\n        id, _, pairs = visited_children\n        return [(id.text, *pair) for pair in pairs]\n\n    def visit_garbage(self, node, visited_children):\n        return None\n\n    def visit_expr(self, node, visited_children):\n        return [item\n                for lst in visited_children\n                for sublst in lst if sublst\n                for item in sublst]\n\npv = PandasVisitor()\nout = pv.visit(tree)\n\ndf = pd.DataFrame(out, columns=[\"Id\", \"Term\", \"weight\"])\nprint(df)\n", "   Id     Term weight\n0   1    frack  0.733\n1   1    shale  0.700\n2  10    space  0.645\n3  10  station  0.327\n4  10     nasa  0.258\n5   4   celebr  0.262\n6   4    bahar  0.345\n"], ["import re\nimport pandas as pd\n\nSEP_RE = re.compile(r\":\\s+\")\nDATA_RE = re.compile(r\"(?P<term>[a-z]+)\\s+(?P<weight>\\d+\\.\\d+)\", re.I)\n\n\ndef parse(filepath: str):\n    def _parse(filepath):\n        with open(filepath) as f:\n            for line in f:\n                id, rest = SEP_RE.split(line, maxsplit=1)\n                for match in DATA_RE.finditer(rest):\n                    yield [int(id), match[\"term\"], float(match[\"weight\"])]\n    return list(_parse(filepath))\n", ">>> df = pd.DataFrame(parse(\"/Users/bradsolomon/Downloads/doc.txt\"),\n...                   columns=[\"Id\", \"Term\", \"weight\"])\n>>> \n>>> df\n   Id     Term  weight\n0   1    frack   0.733\n1   1    shale   0.700\n2  10    space   0.645\n3  10  station   0.327\n4  10     nasa   0.258\n5   4   celebr   0.262\n6   4    bahar   0.345\n\n>>> df.dtypes\nId          int64\nTerm       object\nweight    float64\ndtype: object\n", ">>> line = \"1: frack 0.733, shale 0.700,\\n\"\n>>> SEP_RE.split(line, maxsplit=1)\n['1', 'frack 0.733, shale 0.700,\\n']\n", ">>> id, rest = SEP_RE.split(line, maxsplit=1)\n>>> it = DATA_RE.finditer(rest)\n>>> match = next(it)\n>>> match\n<re.Match object; span=(0, 11), match='frack 0.733'>\n>>> match[\"term\"]\n'frack'\n>>> match[\"weight\"]\n'0.733'\n"], ["df=pd.DataFrame(columns=['ID','Term','Weight'])\nwith open('C:/random/d1','r') as readObject:\n    for line in readObject:\n        line=line.rstrip('\\n')\n        tempList1=line.split(':')\n        tempList2=tempList1[1]\n        tempList2=tempList2.rstrip(',')\n        tempList2=tempList2.split(',')\n        for item in tempList2:\n            e=item.split(' ')\n            tempRow=[tempList1[0], e[0],e[1]]\n            df.loc[len(df)]=tempRow\nprint(df)\n"], ["df = pd.read_csv(StringIO(u\"\"\"1: frack 0.733, shale 0.700, \n10: space 0.645, station 0.327, nasa 0.258, \n4: celebr 0.262, bahar 0.345 \"\"\"), sep=\":\", header=None)\n\n#df:\n    0                                          1\n0   1                 frack 0.733, shale 0.700, \n1  10   space 0.645, station 0.327, nasa 0.258, \n2   4                 celebr 0.262, bahar 0.345 \n", "df[1] = df[1].str.split(\",\", expand=False)\n\ndfs = []\nfor idx, rows in df.iterrows():\n    print(rows)\n    dfslice = pd.DataFrame({\"Id\": [rows[0]]*len(rows[1]), \"terms\": rows[1]})\n    dfs.append(dfslice)\nnewdf = pd.concat(dfs, ignore_index=True)\n\n# this creates newdf:\n   Id           terms\n0   1     frack 0.733\n1   1     shale 0.700\n2   1                \n3  10     space 0.645\n4  10   station 0.327\n5  10      nasa 0.258\n6  10                \n7   4    celebr 0.262\n8   4    bahar 0.345 \n", "newdf[\"terms\"] = newdf[\"terms\"].str.strip()\nnewdf = newdf.join(newdf[\"terms\"].str.split(\" \", expand=True))\nnewdf.columns = [\"Id\", \"terms\", \"Term\", \"Weights\"]\nnewdf = newdf.drop(\"terms\", axis=1).dropna()\n", "   Id     Term Weights\n0   1    frack   0.733\n1   1    shale   0.700\n3  10    space   0.645\n4  10  station   0.327\n5  10     nasa   0.258\n7   4   celebr   0.262\n8   4    bahar   0.345\n"], ["df = pd.read_csv('untitled.txt', sep=': ', header=None)\ndf.set_index(0, inplace=True)\n\n# split the `,`\ndf = df[1].str.strip().str.split(',', expand=True)\n\n#    0             1              2           3\n#--  ------------  -------------  ----------  ---\n# 1  frack 0.733   shale 0.700\n#10  space 0.645   station 0.327  nasa 0.258\n# 4  celebr 0.262  bahar 0.345\n\n# stack and drop empty\ndf = df.stack()\ndf = df[~df.eq('')]\n\n# split ' '\ndf = df.str.strip().str.split(' ', expand=True)\n\n# edit to give final expected output:\n\n# rename index and columns for reset_index\ndf.index.names = ['Id', 'to_drop']\ndf.columns = ['Term', 'weight']\n\n# final df\nfinal_df  = df.reset_index().drop('to_drop', axis=1)\n"], ["import pandas as pd\nfile=r\"give_your_path\".replace('\\\\', '/')\nmy_list_of_lists=[]#creating an empty list which will contain lists of [Id Term  Weight]\nwith open(file,\"r+\") as f:\n    for line in f.readlines():#looping every line\n        my_id=[line.split(\":\")[0]]#storing the Id in order to use it in every term\n        for term in [s.strip().split(\" \") for s in line[line.find(\":\")+1:].split(\",\")[:-1]]:\n            my_list_of_lists.append(my_id+term)\ndf=pd.DataFrame.from_records(my_list_of_lists)#turning the lists to dataframe\ndf.columns=[\"Id\",\"Term\",\"weight\"]#giving columns their names\n"], ["import pandas as pd\nfrom itertools import chain\n\ntext=\"\"\"1: frack 0.733, shale 0.700, \n10: space 0.645, station 0.327, nasa 0.258, \n4: celebr 0.262, bahar 0.345 \"\"\"\n\ndf = pd.DataFrame(\n    list(\n        chain.from_iterable(\n            map(lambda z: (y[0], *z.strip().split()), y[1].split(\",\")) for y in \n            map(lambda x: x.strip(\" ,\").split(\":\"), text.splitlines())\n        )\n    ), \n    columns=[\"Id\", \"Term\", \"weight\"]\n)\n\nprint(df)\n#  Id     Term weight\n#0  4    frack  0.733\n#1  4    shale  0.700\n#2  4    space  0.645\n#3  4  station  0.327\n#4  4     nasa  0.258\n#5  4   celebr  0.262\n#6  4    bahar  0.345\n", "print(list(map(lambda x: x.strip(\" ,\").split(\":\"), text.splitlines())))\n#[['1', ' frack 0.733, shale 0.700'], \n# ['10', ' space 0.645, station 0.327, nasa 0.258'], \n# ['4', ' celebr 0.262, bahar 0.345']]\n", "print(\n    [\n        list(map(lambda z: (y[0], *z.strip().split()), y[1].split(\",\"))) for y in \n        map(lambda x: x.strip(\" ,\").split(\":\"), text.splitlines())\n    ]\n)\n#[[('1', 'frack', '0.733'), ('1', 'shale', '0.700')],\n# [('10', 'space', '0.645'),\n#  ('10', 'station', '0.327'),\n#  ('10', 'nasa', '0.258')],\n# [('4', 'celebr', '0.262'), ('4', 'bahar', '0.345')]]\n"], ["with open('path/filename.txt','r') as filename:\n   content = filename.readlines()\n", "content =[\n    ['1','frack 0.733, shale 0.700,'],\n    ['10', 'space 0.645, station 0.327, nasa 0.258,'],\n    ['4','celebr 0.262, bahar 0.345 ']]\n"], ["list = [\"a\", \"b\", \"c\", \"d\"]\nprint(list[0]) # \"a\"\nprint(list[-1]) # d\n", "print(list[-1]) # d\nprint(list[len(list) - 1]) # d\nprint(list[-5]) # list index out of range\nprint(list[len(list) - 5]) # a\n"], ["df['DOB'] = pd.to_datetime(df['DOB'].str.replace('20([^20]*)$', '19'))\n", "df['DOB'] = pd.to_datetime(df['DOB'].str.replace('20', '19'))\n", "print(df['DOB'])\n", "0   1984-01-01\n1   1985-07-31\n2   1985-08-24\n3   1993-12-30\n4   1977-09-12\n5   1990-08-09\n6   1988-01-06\n7   1989-04-10\n8   1991-11-15\n9   1968-01-06\ndtype: datetime64[ns]\n"], ["pd.to_datetime(df['DOB'].str[:-2] + '19' + df['DOB'].str[-2:])\n", "0   1984-01-01\n1   1985-07-31\n2   1985-08-24\n3   1993-12-30\n4   1977-09-12\n5   1990-08-09\n6   1988-01-06\n7   1989-04-10\n8   1991-11-15\n9   1968-01-06\ndtype: datetime64[ns]\n"], ["df['DOB'] = pd.to_datetime(df['DOB'], format='%d-%m-%y')\ndf.loc[df['DOB'].dt.year >= 2020, 'DOB'] -= pd.DateOffset(years=100)\n#same like\n#mask = df['DOB'].dt.year >= 2020\n#df.loc[mask, 'DOB'] = df.loc[mask, 'DOB'] - pd.DateOffset(years=100)\nprint (df)\n         DOB\n0 1984-01-01\n1 1985-07-31\n2 1985-08-24\n3 1993-12-30\n4 1977-12-09\n5 1990-09-08\n6 1988-06-01\n7 1989-10-04\n8 1991-11-15\n9 1968-06-01\n", "s1 = df['DOB'].str.replace(r'-(\\d+)$', r'-19\\1')\ns2 = df['DOB'].str.replace(r'-(\\d+)$', r'-20\\1')\nmask = df['DOB'].str[-2:].astype(int) <= 20\ndf['DOB'] = pd.to_datetime(np.where(mask, s2, s1))\n\nprint (df)\n         DOB\n0 1984-01-01\n1 1985-07-31\n2 1985-08-24\n3 1993-12-30\n4 1977-09-12\n5 1990-08-09\n6 1988-01-06\n7 1989-04-10\n8 1991-11-15\n9 1968-01-06\n", "s1 = df['DOB'].str.replace(r'-(\\d+)$', r'-19\\1')\ndf['DOB'] = pd.to_datetime(s1, format='%d-%m-%Y')\nprint (df)\n         DOB\n0 1984-01-01\n1 1985-07-31\n2 1985-08-24\n3 1993-12-30\n4 1977-12-09\n5 1990-09-08\n6 1988-06-01\n7 1989-10-04\n8 1991-11-15\n9 1968-06-01\n"], ["from datetime import datetime, date\n\ndf=pd.DataFrame.from_dict({'DOB':['01-06-68','01-06-08']})\ndf['DOB'] = df['DOB'].apply(lambda x: datetime.strptime(x,'%d-%m-%y'))\ndf['DOB'] = df['DOB'].apply(lambda x: x if x<datetime.now() else date(x.year-100,x.month,x.day))\n"], ["pd.to_datetime(data['Date.of.Birth'].apply(lambda x: '-'.join(x.split('-')[:-1] + ['19' + x.split('-')[2]])))\n", "    0   1\n0   0   01-01-84\n1   1   31-07-85\n2   2   24-08-85\n3   3   30-12-93\n4   4   09-12-77\n5   5   08-09-90\n6   6   01-06-88\n7   7   04-10-89\n8   8   15-11-91\n9   9   01-06-68\n\n\npd.to_datetime(data[1].apply(lambda x: '-'.join(x.split('-')[:-1] + ['19' + x.split('-')[2]])))\n\n\n0   1984-01-01\n1   1985-07-31\n2   1985-08-24\n3   1993-12-30\n4   1977-09-12\n5   1990-08-09\n6   1988-01-06\n7   1989-04-10\n8   1991-11-15\n9   1968-01-06\nName: 1, dtype: datetime64[ns]\n"], [], ["list[-1]\n", "list[len(list)-1]\n"], ["import numpy as np\na = np.array([['0.1 0.2 0.3'], ['0.3 0.4 0.5'], ['0.5 0.6 0.7']])\n\n# Create a placeholder list\nb = []\n\nfor element in a:\n  # use a list comprehension to\n  #     * take the zeroeth element in each row of the 'a' array and\n  #       split the string on spaces\n  #     * parse through each substring thus produced\n  #     * convert each of those substrings into floats\n  #     * store it in the list called temp.\n\n  temp = [float(num) for num in element[0].split()]\n\n  # Add each temp list to the parent list 'b'\n  b.append(temp)\n\n# Convert b into an np.array\nb = np.array(b)\n", "b = []\n\nfor element in a:\n    temp = [float(num) for num in element[0].split(' ')]\n    b.append(temp)\nb = np.array(b)\n", "array([[0.1, 0.2, 0.3],\n       [0.3, 0.4, 0.5],\n       [0.5, 0.6, 0.7]])\n", "# transform 'a' to an array of rows full of individual strings\n# use the .astype() method to then cast each value as a float\na = np.array([row[0].split() for row in a])\nb = a.astype(np.float)\n"], ["import  numpy as np\n\nx = np.array([['0.1 0.2 0.3'], ['0.3 0.4 0.5'], ['0.5 0.6 0.7']])    \nx = np.array(list(map(lambda z: z[0].split(),x)))\ny = x.astype(np.float)\nprint(y)\n", "[[0.1 0.2 0.3]\n [0.3 0.4 0.5]\n [0.5 0.6 0.7]]\n"], ["b = [ float(h) for j in [i[0].split(\" \") for i in a  ]for h in j ]\nb = np.asarray(b).reshape(3,3)\n"], ["b = []\nfor ai in a:\n  temp=[]\n  for b in ai[0].split(' '):\n     temp.append(float(b))\n  b.append(temp)\n\nb = np.array(b)\n"], ["import timeit\n# N\nsx = [10, 100, 1000, 10e4, 10e5, 5e5, 10e6, 2e6, 5e6]\n# average runtime in seconds\nsy = [timeit.timeit('pow(%d)' % i, number=100, globals=globals()) for i in sx]\n", "T(n) = 1 + T(n//2)\n     = 1 + 1 + T(n//4)\n#      ^   ^\n#     mul>1\n#         div>1\n# when n is large\n", "mul = lambda x: x*x\ndiv = lambda y: x//2\n\ns1 = [timeit.timeit('mul(%d)' % i, number=1000, globals=globals()) for i in sx]\ns2 = [timeit.timeit('div(%d)' % i, number=1000, globals=globals()) for i in sx]\n"], [], [], ["def c_find(*roots):\n    from sympy import Symbol\n    x = Symbol('x')\n    whole =1\n    for root in roots:\n        whole *=(x-root)\n    print('f(x) =',whole.expand())\n"], ["In [44]: f = np.poly([-2,1,3])\nIn [45]: f\nOut[45]: array([ 1., -2., -5.,  6.])\nIn [46]: np.roots(f)\nOut[46]: array([-2.,  3.,  1.])\nIn [49]: np.polyval(f, np.arange(-3,5))\nOut[49]: array([-24.,   0.,   8.,   6.,   0.,  -4.,   0.,  18.])\n", "In [53]: np.dot(np.arange(-3,5)[:,None]**np.array([3,2,1,0]), f)\nOut[53]: array([-24.,   0.,   8.,   6.,   0.,  -4.,   0.,  18.])\n"], ["def f(x): return (x - (-2)) * (x - 1) * (x - 2)\n", "def poly3(r1, r2, r3):\n    def _poly3(x):\n        return (x - r1) * (x - r2) * (x - r3)\n    return _poly3\n\nf2 = poly3(-2, 1, 2)\n\nfor i in range(-10, 11):\n    assert f(i) == f2(i)\n# no AssertionError means all tests pass\n", "def polyn(*roots):\n    def _polyn(x):\n        val = 1\n        for r in roots:\n            val *= x - r\n        return val\n    return _polyn\n\nf3 = polyn(-2, 1, 2)\n\nfor i in range(-10, 11):\n    assert f(i) == f3(i)\n# Above code passed on Win 10, 3.7.2\n"], ["from sympy import Symbol, poly\n\nx = Symbol('x')\n\nroots = [-1, 1]\nexpr = 1\n\n# polynomial in format (x-a)(x-b)(x-c)...\nfor i in roots:\n  expr *= (x - i)\n\np = poly(expr, x)\nprint(p)\nprint(p.all_coeffs())\n", "Poly(x**2 - 1, x, domain='ZZ')\n[1, 0, -1]\n", "Poly(x**7 - 20*x**6 + 154*x**5 - 560*x**4 + 889*x**3 - 140*x**2 - 1044*x + 720, x, domain='ZZ')\n[1, -20, 154, -560, 889, -140, -1044, 720]\n"], ["def contained_in(lst, sub):\n    n = len(sub)\n    return any(sub == lst[i:i+n] for i in range(len(lst)-n+1))\n", "def contained_in(lst, sub):\n    return ','.join(map(str, sub)) in ','.join(map(str, lst))\n", ">>> contained_in([1, 2, 3, 4, 5], [2, 3, 4])\nTrue\n>>> contained_in([1, 2, 2, 4, 5], [2, 3, 4])\nFalse\n"], ["def contains(seq, sub):\n    sub_length = len(sub)\n    sub_first = sub[0]\n    return any(sub == seq[index:index+sub_length]\n               for index, element in enumerate(seq)\n               if element == sub_first)\n", ">>> seq = [1, 2, 3, 4, 5]\n>>> sub = [2, 3, 4]\n\n>>> contains(seq, sub)\nTrue\n"], ["def containedin(a,b):\n    for j in range(len(b)-len(a)+1):\n        if a==b[j:j+len(a)]:\n            return True\n    return False\n\nprint(containedin([2, 3, 4],[1, 2, 3, 4, 5]))\nprint(containedin([2, 3, 4],[1, 1, 2, 2, 3, 3, 4, 4, 5, 5]))\nprint(containedin([2, 3, 4],[5, 4, 3, 2, 1]))\nprint(containedin([2, 2, 2],[1, 2, 3, 4, 5]))\nprint(containedin([2, 2, 2],[1, 1, 1, 2, 2, 2, 3, 3, 3]))\n"], ["class myList(list):\n    def in_other(self, other_list):\n        for i in range(0, len(other_list)-len(self)):\n            if other_list[i:i+len(self)] == self:\n                return True\n            else:\n                continue\n\nif __name__ == \"__main__\":\n\n    x = myList([1, 2, 3])\n    b = [0, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6]\n\n    print(x.in_other(b))\n"], ["def contains(sub_array, array):\n    for i in range(len(array)-len(sub_array)+1):\n        for j in range(len(sub_array)):\n            if array[i+j] != sub_array[j]:\n                break\n        else:\n            return i, i+len(sub_array)\n    return False\n"], ["def contains(list1,list2):\n\n    str1=\"\"\n    for i in list1:\n        str1+=str(i)\n\n    str2=\"\"\n    for j in list2:\n        str2+=str(j)\n\n    if str1 in str2:\n        return True\n\n    else:\n        return False\n"], [" any(a == b[i:i+len(a)] for i in range(len(b)-len(a)+1))\n"], ["array = ['T20', 'T5', 'T10', 'T1', 'T2', 'T8', 'T16', 'T17', 'T9', 'T4', 'T12', 'T13', 'T18']\n", "def add_vs_between_not_cons(array):\n  iterable = sorted(array, key= lambda x: int(x[1:]))\n  i, size = 0, len(iterable)\n  while i < size:\n    delta = int(iterable[i][1:]) - int(iterable[i-1][1:])\n    for _ in range(delta-1):\n      yield \"V\"\n    yield iterable[i]\n    i += 1\n", "print(list(add_vs_between_not_cons(array)))\n\n#=> ['T1', 'T2', 'V', 'T4', 'T5', 'V', 'V', 'T8', 'T9', 'T10', 'V', 'T12', 'T13', 'V', 'V', 'T16', 'T17', 'T18', 'V', 'T20']\n"], ["sorted_ids=[1, 2, 4, 5, 8, 9, 10, 12, 13, 16, 17, 18, 20]\n\nfor i in range(min(sorted_ids), max(sorted_ids)): \n     if sorted_ids[i] != i + 1: \n         sorted_ids.insert(i, 'V')\n\nfinal_list = [ \"T\" + str(x) if isinstance(x, int) else x for x in sorted_ids]\n", "['T1', 'T2', 'V', 'T4', 'T5', 'V', 'V', 'T8', 'T9', 'T10', 'V', 'T12', 'T13', 'V', 'V', 'T16', 'T17', 'T18', 'V', 'T20']\n"], ["from itertools import groupby\nfrom operator import itemgetter\n\ndef groupby_consecutive(lst):\n    for _, g in groupby(enumerate(lst), lambda x: x[0] - x[1]):\n        yield list(map(itemgetter(1), g))\n\nsorted_ids = [1, 2, 4, 5, 8, 9, 10, 12, 13, 16, 17, 18, 20]\nprint(list(groupby_consecutive(lst=sorted_ids)))\n# [[1, 2], [4, 5], [8, 9, 10], [12, 13], [16, 17, 18], [20]]\n", "def interperse(lst):\n    for x, y in zip(lst, lst[1:]):\n        yield [\"V\"] * (y[0] - x[-1] - 1)\n\ngroups = list(groupby_consecutive(lst))\nprint(list(interperse(groups)))\n# [['V'], ['V', 'V'], ['V'], ['V', 'V'], ['V']]\n", "def add_prefix(lst, prefix):\n    return [prefix + str(x) for x in lst]\n\ndef create_sequences(lst, prefix='T'):\n    groups = list(groupby_consecutive(lst))\n    between = list(interperse(groups))\n\n    result = add_prefix(groups[0], prefix)\n    for x, y in zip(between, groups[1:]):\n        result.extend(x + add_prefix(y, prefix))\n\n    return result\n\nsorted_ids = [1, 2, 4, 5, 8, 9, 10, 12, 13, 16, 17, 18, 20]\nprint(create_sequences(lst=sorted_ids))\n# ['T1', 'T2', 'V', 'T4', 'T5', 'V', 'V', 'T8', 'T9', 'T10', 'V', 'T12', 'T13', 'V', 'V', 'T16', 'T17', 'T18', 'V', 'T20']\n"], ["def arrange_tickets(tickets_list):\n    ids = [int(ticket[1:]) for ticket in tickets_list]\n    expected_ids = range(1, max(ids) + 1)\n    return [\"T%d\" % n if n in ids else \"V\" for n in expected_ids]\n\ntickets_list = ['T20', 'T5', 'T10', 'T1', 'T2', 'T8', 'T16', 'T17', 'T9', 'T4', 'T12', 'T13', 'T18']\nprint(\"Ticket ids of all the available students :\")\nprint(tickets_list)\nresult=arrange_tickets(tickets_list)\nprint(result)   \n", "Ticket ids of all the available students :\n['T20', 'T5', 'T10', 'T1', 'T2', 'T8', 'T16', 'T17', 'T9', 'T4', 'T12', 'T13', 'T18']\n\n['T1', 'T2', 'V', 'T4', 'T5', 'V', 'V', 'T8', 'T9', 'T10', 'V', 'T12', 'T13', 'V', 'V', 'T16', 'T17', 'T18', 'V', 'T20']\n"], ["temp_ids.insert(i+1,\"V\") \n", "temp_ids=[]\n\nfor i in range(len(sorted_ids)-1):\n    temp_ids.append(sorted_ids[i])\n\n    if sorted_ids[i]+1 != sorted_ids[i+1] :\n        for i in range(sorted_ids[i+1]-sorted_ids[i]-1):\n            temp_ids.append(\"V\") # appends as many V's as required\n\ntemp_ids.append(sorted_ids[-1]) # appends last element\n", "sorted_ids[i]+1 != sorted_ids[i+1]\n", "for i in range(len(sorted_ids)-1):\n"], ["sorted_ids=[1, 2, 4, 5, 8, 9, 10, 12, 13, 16, 17, 18, 20]\n\ndef arrange(inList):\n    newList = []\n    newList.append('T'+str(inList[0]))\n    for i in range(1,len(inList)):\n        diff = inList[i] - inList[i-1]\n        if diff > 1:\n            for d in range(diff-1):\n                newList.append('V')\n            newList.append('T'+str(inList[i]))\n        else:\n            newList.append('T'+str(inList[i]))\n    return newList\n\nprint(arrange(sorted_ids))\n", "['T1', 'T2', 'V', 'T4', 'T5', 'V', 'V', 'T8', 'T9', 'T10', 'V', 'T12', 'T13', 'V', 'V', 'T16', 'T17', 'T18', 'V', 'T20']\n"], ["sorted_ids=[1, 2, 4, 5, 8, 9, 10, 12, 13, 16, 17, 18, 20]\na = sorted_ids[0]\nb = sorted_ids[-1]\nnums = set(sorted_ids)\nexpected = [\"T\" + str(i) if i in nums else 'V' for i in range(a,b+1)]\nprint(expected)\n", "['T1', 'T2', 'V', 'T4', 'T5', 'V', 'V', 'T8', 'T9', 'T10', 'V', 'T12', 'T13', 'V', 'V', 'T16', 'T17', 'T18', 'V', 'T20']\n"], ["           if line.startswith('hide'):\n               line = line.replace('\"\"', '\"Something new\"')\n", "lines = '''\\\nfirst line\n            hide: [\"\"]\n       hide: [\"something\"]\nlast line\\\n'''\nnew_value = 'new value'\n\nfor line in lines.splitlines():\n    if line.strip().startswith('hide'):\n       line = line[:line.index('[')+2] + new_value + line[line.index(']')-1:]\n    print(line)\n", "first line\n            hide: [\"new value\"]\n       hide: [\"new value\"]\nlast line\n"], ["newline = 'Something new'\n\nwith open('./config.js','r') as f:\n   txt = f.read()\n\ntxt = txt.replace('hide: [\"\"]', 'hide: [\"' + newline + '\"]')\n\nwith open('./config.js','w') as f:\n   f.write(txt)\n"], ["import fileinput\nimport sys\n\ndef replaceAll(file,searchExp,replaceExp):\n    for line in fileinput.input(file, inplace=1):\n        if searchExp in line:\n            line = line.replace(searchExp,replaceExp)\n        sys.stdout.write(line)\n\nreplaceAll(\"config.js\",'hide: [\"\"]','hide: [\"something\"]')\n"], ["import re\nwith open('./config.js','r') as f:\n   lines = f.readlines()\n\nwith open('./config.js','w') as f:\n   for line in lines:\n       line = re.sub(r'(\\[\")(\"\\])', r'\\1' + 'something' + r'\\2', line)\n       f.write(line)\n"], ["with open('/config.js','r') as f:\n    lines = f.readlines()\n\nwith open('./config.js','w') as f:\n    for line in lines:\n        line = line.replace('hide [\"\"]', 'hide [\"something\"]')\n        f.write(line)\n"]]