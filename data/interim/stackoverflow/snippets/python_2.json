[["`python -m pip install git+https://github.com/Zeecka/pytube@fix_1060`\n", "`pip install --upgrade pytube`\n", "from pytube import YouTube \n  \n#where to save \nSAVE_PATH = \"C:/YOUR/DESIRED/FILE/PATH/\" \n  \n#link of the video to be downloaded \nlink = input(\"Enter URL >> \")\ntry:\n    yt = YouTube(link)\n    mp4_files = yt.streams.filter(file_extension=\"mp4\")\n    mp4_720p_files = mp4_files.get_by_resolution(\"720p\")\n    mp4_720p_files.download(SAVE_PATH) \nexcept Exception as e: \n    print(\"ERROR: \", e) \n        \n"], [], ["filtered_list = list(filter(lambda x: x % 5 != 0, my_list))\nin above program. Instead of equal to write not equal to it works\n\nmy_list = []\nn = int(input(\"Size of list: \"))\n\nfor i in range(n):\n    my_list.append(int(input(\"Enter value: \")))\n\nfiltered_list = list(filter(lambda x: x % 5 != 0, my_list))\n\nprint(filtered_list)\n"], ["#!/usr/bin/env python3\n\nnumber = \"Enter an integer, \"\nnumber += \"the input ends if a zero is entered: \"\nmsg = \"No numbers were entered except zero\"\n\nsumNum = 0\ncount_positives = 0\ncount_negatives = 0\n\nflag = 1\n\ntry:\n    while flag:\n    \n        prompt = int(input(number))\n        \n        if (prompt < 0):\n            count_negatives += 1\n            \n        if (prompt > 0):\n            count_positives += 1\n\n        sumNum += prompt\n        totalNums = count_positives + count_negatives\n        avg = sumNum / totalNums\n\n        if (prompt == 0):\n            print(f\"The number of positives is {count_positives}\")\n            print(f\"The number of negatives is {count_negatives}\")\n            print(f\"The total is {sumNum}\")\n            print(f\"The average is {avg}\")\n            break\n\nexcept ZeroDivisionError:\n    print(msg)\n"], [], [], [], [], [" sudo apt-get install python-pip\n"], [], ["intersection: tensor([1, 24])\nt1_exclusive: tensor([9, 12, 5])\nt2_exclusive: tensor([3])\n", "+------------------------------+--------+--------+--------+---------+----------+--------+---------+\n|         tensor size          |  1000  |  3162  | 10000  |  31622  |  100000  | 316227 | 1000000 |\n+------------------------------+--------+--------+--------+---------+----------+--------+---------+\n|      torch_intersect1d       | 209.44 | 290.57 | 292.31 |  310.83 |  322.11  | 488.71 | 1018.41 |\n| torch_intersect1d_dense_pair | 138.30 | 186.37 | 549.01 | 4382.19 | 43741.66 |  OOM   |   OOM   |\n+------------------------------+--------+--------+--------+---------+----------+--------+---------+\n"], [], [], ["pip uninstall keras \npip install keras==2.6\n", "pip uninstall TensorFlow\npip install TensorFlow\n"], ["counter = 0\namazing list = [\"hello\",\"hi\"]\nfor x in titles:\n        ok = amazinglist[counter].split(\"\\n\")\n        writer.writerow(ok)\n        counter +=1\n"], ["Parallel(n_jobs=8)\n", "Parallel(n_jobs=8, prefer=\"threads\")\n"], ["pip install pandas-profiling==3.4.0\n"], ["import functools\nimport inspect\n\n@functools.cache\ndef get_dataclass_parameters(cls: type):\n    return inspect.signature(cls).parameters\n\n\ndef instantiate_dataclass_from_dict(cls: type, dic: dict):\n    parameters = get_dataclass_parameters(cls)\n    dic = {k: v for k, v in dic.items() if k in parameters}\n    return cls(**dic)\n"], ["import os.path\n\npd.read_excel(io=os.path.abspath('path\\\\to\\\\excel_file.xlsx'))\n"], ["pip3 uninstall keras\npip3 install keras --upgrade\n"], ["import keras\nfrom keras.models import Model, Sequential\nfrom keras.layers import Input\nfrom keras.layers import LSTM\nfrom keras.layers import Dense\nfrom keras.layers import RepeatVector\nfrom keras.layers import TimeDistributed\n", "from tensorflow import keras\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.layers import Input\nfrom tensorflow.keras.layers import LSTM\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import RepeatVector\nfrom tensorflow.keras.layers import TimeDistributed\n"], [], ["pip install ipykernel\n"], ["from django.db import models\nfrom django.db.models import Sum, Value\nfrom django.db.models.functions import Coalesce\n\n# Create your models here.\nclass AuthorQuerySet(models.QuerySet):\n    def annotate_with_copies_sold(self):\n        return self.annotate(copies_sold=Coalesce(Sum('books__copies_sold'),Value(0)))\n\nclass Author(models.Model):\n    first_name = models.CharField(max_length=30)\n    last_name = models.CharField(max_length=30)\n\n    objects = AuthorQuerySet.as_manager()\n\nclass Book(models.Model):\n    title = models.CharField(max_length=30)\n    copies_sold = models.PositiveIntegerField()\n    author = models.ForeignKey(Author, on_delete=models.CASCADE, related_name=\"books\")\n"], [], [">>> c = Cylinder(0.25, 1.0, 450)\n>>> c.radius\n0.25\n>>> c.length\n1.0\n>>> c.density\n450\n>>> c.volume\nVolume calculated\n0.19634954084936207\n>>> c.mass\nMass calculated\n88.35729338221293\n>>> c.length = c.length*2\n# Raises dataclasses.FrozenInstanceError: cannot assign to field 'length'\n>>> c = dataclasses.replace(c, length=c.length*2)\n# Resets volume and mass\n>>> c.mass\nVolume calculated\nMass calculated\n176.71458676442586\n>>> c.volume\n0.39269908169872414\n"], ["list = [\n   {'a':'p', 'b':2, 'c':'k'},\n   {'a':'e', 'b':'f', 'c':5}\n]\nlist = [{key: str(val) for key, val in dict.items()} for dict in list]\nprint(list)\n"], [], [], [], [], ["def count_even_digits_spyr03_sum(n):\n    return sum(c in \"02468\" for c in str(n))\n", "def count_even_digits_spyr03_for(n):\n    count = 0\n    for c in str(n):\n        if c in \"02468\":\n            count += 1\n    return count\n", "if (PyLong_CheckExact(item)) {\n", "def f5(x):\n    return len([1 for c in str(x) if c in '02468'])\n", "def f6(x):\n    s = str(x)\n    return sum(s.count(c) for c in '02468')\n", ">>> import timeit\n>>> def f(x):\n...     return sum([1 for c in str(x) if c in '02468'])\n... \n>>> def g(x):\n...     return len([1 for c in str(x) if c in '02468'])\n... \n>>> def h(x):\n...     s = str(x)\n...     return sum(s.count(c) for c in '02468')\n... \n>>> x = int('1234567890'*50)\n>>> timeit.timeit(lambda: f(x), number=10000)\n0.331528635986615\n>>> timeit.timeit(lambda: g(x), number=10000)\n0.30292080697836354\n>>> timeit.timeit(lambda: h(x), number=10000)\n0.15950968803372234\n>>> def explicit_loop(x):\n...     count = 0\n...     for c in str(x):\n...         if c in '02468':\n...             count += 1\n...     return count\n... \n>>> timeit.timeit(lambda: explicit_loop(x), number=10000)\n0.3305045129964128\n"], [], [], ["pip uninstall keras\n"], [], [], [], [], ["  def sublist(lst):\n    sub = lst\n    for i in lst:\n       if i == 5:\n          x = lst.index(i)\n          sub = lst[:x]\n    return sub\n\n  list3 = [1,56,34,2,3,1,4,5,5,5]\n  sublist(list3) \n"], ["for i in range(int(input())):#no of testcases eg:1\n  n=int(input())#no of input eg:3\n  x=list(map(int,input().split()))#values in the input eg:1 2 3\n  l=[]\n  for j in range(n):\n    for k in range(j,n):\n      l.append(x[k])\n      print(*l)\n    l=[]\n", "1\n3\n1 2 3\n1\n1 2\n1 2 3\n2\n2 3\n3\n"], ["rounded = round(x)\nif rounded < x:\n    rounded_up_x = rounded + 1\nelse:\n    rounded_up_x = rounded\n"], [], [" def get_current_user_from_token(\n        token: str = Depends(oauth2_scheme), db: Session = Depends(get_db)\n    ):\n        credentials_exception = lambda x : HTTPException(\n            status_code=status.HTTP_401_UNAUTHORIZED,\n            detail=x,\n        )\n        try:\n            payload = jwt.decode(\n                token, settings.SECRET_KEY, algorithms=[settings.ALGORITHM]\n            )\n            username: str = payload.get(\"sub\")\n            print(\"username/email extracted is \", username)\n            if username is None:\n                raise credentials_exception('Could not validate login or error in username/pass')\n        except JWTError as e:\n            raise credentials_exception(str(e))\n        user = get_user(username=username, db=db)\n        if user is None:\n            raise credentials_exception('Could not validate login')\n        return user\n"], [">>> keyfunc = lambda item: item['grade']\n>>> {k:list(v) for k,v in itertools.groupby( sorted(arr,key=keyfunc) , keyfunc) }\n{'A': [{'grade': 'A', 'name': 'James'}, {'grade': 'A', 'name': 'Zelda'}], 'B': [{'grade': 'B', 'name': 'Tom'}]}\n"], [], ["mv mypackage mypackage_git\ncd mypackage_git\npip -e .\n"], [], [], ["arch -x86 /bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/uninstall.sh)\"\n", "/bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/uninstall.sh)\"\n"], [], ["import re\ndef rearrange_name(name):\n  result = re.search(r\"^(\\w*), ([a-zA-Z]*.*)$\", name)\n  if result == None:\n    return name\n  return \"{} {}\".format(result[2], result[1])\n\nname=rearrange_name(\"Kennedy, John F.\")\nprint(name)\n"], [], ["import re\n\ninstr = \"abc123abc456abc7891\"\n\nresult = re.sub('\\d+', lambda x : ''.join(reversed(str(x[0]))), instr)\n\nprint(result)\n\n\"abc321abc654abc1987\"\n\n"], [], ["from inspect import signature, Signature\nfrom itertools import chain\nfrom collections import OrderedDict\n\n\ndef make_signature(subclass, superclass):\n    \"\"\"Returns a signature object for the subclass constructor's __signature__ attribute.\"\"\"\n    sub_params = signature(superclass.__init__).parameters\n    sup_params = signature(subclass.__init__).parameters\n    mixed_params = OrderedDict(chain(sub_params.items(), sup_params.items()))\n    mixed_signature = Signature(parameters=mixed_params.values())\n    return mixed_signature\n\n\nclass Shape:\n    def __init__(self, x: float, y: float):\n        self.x = x\n        self.y = y\n\n\nclass Circle(Shape):\n    def __init__(self, radius: float, **kwargs):\n        super().__init__(**kwargs)\n        self.radius = radius\n\n\nCircle.__signature__ = make_signature(Circle, Shape)\n\nif __name__ == \"__main__\":\n    help(Circle)  # Circle(self, x: float, y: float, radius: float, **kwargs) ...\n"], [], ["sudo apt-get install software-properties-common\nsudo apt-add-repository universe\nsudo apt-get update\nsudo apt-get install python3-pip\n"], ["class Shape:\n    def __init__(x: float, y: float):\n        self.x = x\n        self.y = y\n\n\nclass Circle(Shape):\n    def __init__(x: float, y: float, radius: float):\n        super().__init__(x=x, y=y)\n        self.radius = radius\n\n\n# The expectation is that this should work with all instances of `Shape`\ndef move_shape(shape: Shape, x: float, y: float):\n    shape.x = x\n    shape.y = y\n", "class Shape:\n    def __init__(x: float, y: float, colour: str = \"black\"):\n        self.x = x\n        self.y = y\n        self.colour = colour \n\n\nclass Circle(Shape):\n    def __init__(x: float, y: float, radius: float, **kwargs):\n        super().__init__(x=x, y=y, **kwargs)\n        self.radius = radius\n\n\ndef move_shape(shape: Shape, x: float, y: float):\n    shape.x = x\n    shape.y = y\n\n\ndef colour_shape(shape: Shape, colour: str):\n    shape.colour = colour\n"], ["class Shape:\n\n    def __init__(self, x: float, y: float, name=\"default name\", verbose=False):\n        self.x = x\n        self.y = y\n        self.name = name\n        if verbose:\n            print(\"Initialized:\", self)\n\n    def __repr__(self):\n        return f\"{type(self).__name__}(x={self.x},y={self.y},name={self.name})\"\n\nclass Circle(Shape):\n\n    def __init__(self, x: float, y: float, r: float, **kwargs):\n        self.r = r\n        super().__init__(x, y, **kwargs)\n\n    def __repr__(self):\n        return f\"{type(self).__name__}(r={self.r},x={self.x},y={self.y},name={self.name})\"\n\n", "from dataclasses import dataclass, InitVar, field\n\n@dataclass\nclass Shape:\n    x: float\n    y: float\n    name: str = field(kw_only=True, default=\"default name\")\n    verbose: InitVar[bool] = field(kw_only=True, default=False)\n\n    def __post_init__(self, verbose):\n        if verbose:\n            print(\"Initialized:\", self)\n\n@dataclass\nclass Circle(Shape):\n    r: float\n", "from dataclasses import dataclass, InitVar, field\n\n@dataclass\nclass DCShape:\n    x: float\n    y: float\n    scale: InitVar[float] = field(kw_only=True, default=1)\n    name: str = field(kw_only=True, default=\"default name\")\n    verbose: InitVar[bool] = field(kw_only=True, default=False)\n\n    def __post_init__(self, scale, verbose):\n        self.x = scale * self.x\n        self.y = scale * self.y\n        if verbose:\n            print(\"Initialized:\", self)\n\n@dataclass\nclass DCCircle(DCShape):\n    r: float\n\n    def __post_init__(self, scale, verbose):\n        self.r = scale * self.r\n        super().__post_init__(scale, verbose)\n"], ["#C++ code\n#include <iostream>    \nusing namespace std;    \nclass Shape {                                           \n    public:    \n    string x = \"\";      \n};     \nclass Circle: public Shape                      \n{      \n public:    \n    string x = \"50\";      \n};  \nint main(void) {    \n     Shape r= Circle();      \n    cout<<r.x;     \n}    \n"], ["def dec_to_bin(n):\n    if not n:  # When n==0.\n        return ''\n    return dec_to_bin(n//2) + str(n%2)\n", "print(dec_to_bin(19))\n", "10011\n"], ["import seaborn as sns\nimport matplotlib.pyplot as plt\niris = sns.load_dataset(\"iris\")\n\nsns.pairplot(iris, hue=\"species\", corner=True)\n"], [], ["     def __str__(self):\n     return self.product.product_name\n"], [], [], [], ["from typing import Signature\n\nclass Shape:\n    def __init__(self, x: float, y: float):\n        self.x = x\n        self.y = y\n\nclass Circle(Shape):\n    def __init__(self, radius: float, **kwargs):\n        super().__init__(**kwargs)\n        self.radius = radius\n\n    __signature__ = Signature(\n        parameters=[\n            Parameter('radius', Parameter.POSITIONAL_OR_KEYWORD, annotation=float),\n            Parameter('x', Parameter.POSITIONAL_OR_KEYWORD, annotation=float),\n            Parameter('y', Parameter.POSITIONAL_OR_KEYWORD, annotation=float),\n        ]\n    )\n"], ["var1 = \"22\"\nvar2 = \"2*11\"\nprint(f\"{var1} = {var2}\")\n", "Stud_list = [[123456, 'Course', 1, 'Name', 'Here', \"Birth\", 'HIM', 'HER'],\n             [222222, 'Course', 2, 'Name2', 'Here2', \"Birth\", 'HIM', 'HER']]\n\nfor stud in Stud_list: \n    print(f\"Student Number: {stud[0]}\") \n    print(f\"Student Course: {stud[1]}\")\n    print(f\"Year Level: {stud[2]}\")\n    print(f\"Student Name: {stud[3]}\")\n    print(f\"Address: {stud[4]}\")\n    print(f\"Birthdate: {stud[5]}\")\n    print(f\"Father's Name: {stud[6]}\")\n    print(f\"Mother's Name: {stud[7]}\")\n", "Student Number: 123456\nStudent Course: Course\nYear Level: 1\nStudent Name: Name\nAddress: Here\nBirthdate: Birth\nFather's Name: HIM\nMother's Name: HER\nStudent Number: 222222\nStudent Course: Course\nYear Level: 2\nStudent Name: Name2\nAddress: Here2\nBirthdate: Birth\nFather's Name: HIM\nMother's Name: HER\n"], [], [], [], [], ["import pandas as pd\nimport datetime\n\nbase = pd.to_datetime(\"2022-10-10\")\ndate_list = [datetime.datetime.strftime(pd.to_datetime(base - datetime.timedelta(days=x)),\"%Y-%m-%d\") for x in range(7)]\nprint(date_list)\n", "['2022-10-10',\n '2022-10-09',\n '2022-10-08',\n '2022-10-07',\n '2022-10-06',\n '2022-10-05',\n '2022-10-04']\n"], [], ["xcodebuild -runFirstLaunch\n"], [], ["# Runtime.txt\npython-3.8.5\n", "python-3.10.7\n"], [], ["from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n\ndef confusion_ma(y_true, y_pred, class_names):\n    cm = confusion_matrix(y_true, y_pred, normalize='true')\n    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n    disp.plot(cmap=plt.cm.Blues)\n    return plt.show()\n"], [">>> [(c, df[c].dtype.kind in 'iufcb') for c in df.columns]\n\n[('col', False), ('col2', False), ('col3', True)]\n"], ["class test:\n   def __init__(self):\n      print(\"first class\")\n   def oneplus(self, x):\n      print(x + 1)\n\n   def twoplus(self, x):\n      print(x + 2)\n\nt = test()\nt.oneplus(1)\nt.twoplus(1)  \n"], ["tensorflow==1.15.0\nkeras==2.1.6\n"], ["\n    import pandas as pd\n    import matplotlib.pyplot as plt\n    from matplotlib.ticker import PercentFormatter\n    \n    def plot_pareto_by(df, x, y, hlines=[80]):\n    \n        df['Cumulative Percentage'] = df[y].cumsum()/df[y].sum()*100\n    \n        fig, ax = plt.subplots(figsize=(10,5))\n        ax.bar(df[x], df[y], color='C0')\n        ax2 = ax.twinx()\n        ax2.plot(df[x], df['Cumulative Percentage'], color='C1', ms=7)\n        ax2.yaxis.set_major_formatter(PercentFormatter())\n        ax.tick_params(axis='y', colors='C0')\n        ax2.tick_params(axis='y', colors='C1')\n    \n        for tick in ax.get_xticklabels():\n            tick.set_rotation(45)\n    \n        plt.title(f'Pareto Chart for {x} by {y}')\n        ax.set_xlabel(x)\n        ax.set_ylabel(y)\n        ax2.set_ylabel('Cumulative Percentage')\n    \n        for hline_at in hlines:\n            ax2.axhline(y=hline_at, color='red', linestyle='-.')\n    \n        plt.show()\n\n"], ["df.sort_values('B').drop_duplicates('A')\n", "   A  B   C\n2  1  2  10\n4  2  4   4\n"], [], ["list(filter(lambda x: x < 'c' , y))\n", "my_iter = iter([True, False, True, False])\nlist(filter(lambda x: next(my_iter), y))\n"], [], [], ["driver.find_elements(By.XPATH, 'path').get_attribute('href')\n"], [], ["a = input()\nb = input()\nfor i in range(0,len(a)):\n    c = a[i:i+3]\n    if c[0]==b and len(c)==3:\n        print(c)\n"], ["import datacompy as dc\n\ncomparison = dc.SparkCompare(spark, base_df=df1, compare_df=df2, join_columns=common_keys, match_rates=True)\ncomparison.report()\n", "comparison.rows_both_mismatch.display()\n"], ["pip install --upgrade pytube\n"], ["pip uninstall pillow\npip install \"pillow<7\"\n", "conda install -c anaconda \"pillow<7\"\n"], ["xcodebuild -runFirstLaunch\n", "sudo xcode-select -switch /Library/Developer/CommandLineTools\n"], ["`\ninput=list(\"AABBCCDDEE\")\ninput1=set(input)\ndict1=dict.fromkeys(input1,0)\nprint(\"Hello world\")\nfor i in input:\n    dict1[i]=dict1[i]+1\nprint(dict1)`\n"], ["int(-(-12.4 // 3.3))\n4\n"], ["train_label = np.concatenate([y for x, y in train_data], axis=0)\n\ntest_label = np.concatenate([y for x, y in test_data], axis=0) \n"], ["for image, label in test_ds.take(1):\n    print (label)\n"], ["  function solution(A) {\n    let binarian = 0;\n    // only positive values\n    A = A.filter((x) => x > -1);\n    // get the total of the binarian\n    for (let i = 0; i < A.length; i++) {\n      binarian += Math.pow(2, A[i]);\n    }\n    // time to prepare your own binarian the shortest one!\n    let b = [];\n    while (binarian > 0) {\n      let element = parseInt(Math.log2(binarian), 10);\n      b.push(element);\n      binarian -= Math.pow(2, element);\n    }\n    return b.length;\n  }\n"], [], ["def print_dictionary(dic, indent=0):\n    if len(dic) == 0:\n        print('\\t' * indent + '{}')\n    for key, value in dic.items():\n        print('\\t' * indent + str(key))\n        if isinstance(value, dict):\n            print_dictionary(value, indent + 1)\n        else:\n            print('\\t' * (indent + 1) + str(type(value)))\n"], ["pd.melt(df,id_vars=['ID'],var_name= 'group').query('value') \n\n   ID group  value\n0   0     A   True\n4   1     B   True\n8   2     C   True\n", "   ID group\n0   0     A\n1   1     B\n2   2     C\n"], ["{\"val\": 5.786868768760891, \"name\": \"kjbkjbkj\"}\n{\"val\":5.7868687688,\"name\":\"kjbkjbkj\"}\n{\"val\":5.78687,\"name\":\"kjbkjbkj\"}\n"], ["import re\ndef rearrange_name(name):\n  result = re.search(r\"^(\\w*), (.*)$\", name)\n  if result == None:\n    return name\n  return \"{} {}\".format(result[2], result[1])\n\nname=rearrange_name(\"Kennedy, John F.\")\nprint(name)\n"], ["#We must import first line of code\n**#working module**\n\nfrom google.colab.patches import cv2_imshow\nimport cv2 as cv\n#Replace cv2.imshow() to cv2_imshow()\nimg = cv.imread('python.jpg') #mentioning a path of an image\ncv2_imshow(img)\n"], [], [], [], ["from object_detection.utils import config_util\n\n# PATH_TO_MY_CONFIG_FILE can be whatever the path is to your config file \nconfigs = config_util.get_configs_from_pipeline_file(PATH_TO_MY_CONFIG_FILE)\n", "print(configs['train_config'].data_augmentation_options)\nprint(type(configs['train_config'].data_augmentation_options[0]))\n", "from object_detection.protos import preprocessor_pb2\n\n# Construct a new PreprocessingStep object\nmy_new_data_augmentation = preprocessor_pb2.PreprocessingStep()\n# I would like to randomly change some color images to gray with %20 probability\nmy_new_data_augmentation.random_rgb_to_gray.probability = 0.2\nprint(my_new_data_augmentation)\n", "my_new_data_augmentation.random_rgb_to_gray.probability = 0.2\nmy_new_data_augmentation.random_adjust_hue.max_delta = 0.1\nprint(my_new_data_augmentation)\n", "configs['train_config'].data_augmentation_options.append(my_new_data_augmentation)\nprint(configs['train_config'].data_augmentation_options)\n"], [], [], [], [], [], ["import os\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n"], ["from pytube import YouTube\nfrom sys import argv\n\n\n\nlink = argv[1]\nyt = YouTube(link)\n\n\n\nyd = yt.streams.get_highest_resolution()\n\nyd.download(r'C:/Users/adam/OneDrive/Desktop/video')\n", "urllib.error.HTTPError: HTTP Error 410: Gone\n"], ["s = df.set_index('ID')\ns.idxmax(1).where(s.any(1))\n", "ID\n0    A\n1    B\n2    C\ndtype: object\n"], ["df['group'] = df[['A', 'B', 'C']].dot(df.columns[1:])\n"], ["df.set_index('ID').apply(lambda x : x.index[x][0],axis=1)\nOut[39]: \nID\n0    A\n1    B\n2    C\ndtype: object\n"], ["(df.set_index('ID')\n   .rename_axis(columns='group')\n   .replace(False, pd.NA)\n   .stack().reset_index().drop(columns=0)\n)\n", "   ID group\n0   0     A\n1   1     B\n2   2     C\n"], ["df.set_index(['ID'])\\\n  .rename_axis('group', axis=1)\\ # getting column name correct\n  .stack()\\                      # reshaping getting column headers into dataframe rows\n  .loc[lambda x: x]\\             # filtering for True\n  .reset_index()\\                # moving ID back into dataframe columns\n  .drop(0, axis=1)               # dropping boolean column\n", "   ID group\n0   0     A\n1   1     B\n2   2     C\n"], ["df = df.melt(id_vars = 'ID', var_name = 'group')\ndf.loc[df['value'] == True][['ID', 'group']]\n"], ["def is_palindrome(input_string):\n    # We'll create two strings, to compare them\n    new_string = \"\"\n    reverse_string = \"\"\n    # Traverse through each letter of the input string\n    for letter in input_string.lower():\n        # Add any non-blank letters to the \n        # end of one string, and to the front\n        # of the other string. \n        if letter != \" \":\n            new_string = new_string + letter\n            reverse_string = letter + reverse_string\n    if new_string == reverse_string:\n        return True\n    return False\n\nprint(is_palindrome(\"Never Odd or Even\")) # Should be True\nprint(is_palindrome(\"abc\")) # Should be False\nprint(is_palindrome(\"kayak\")) # Should be True\n"], ["IronPython.dll\nIronPython.Modules.dll\nMicrosoft.Scripting.Core.dll\nMicrosoft.Scripting.dll\nMicrosoft.Scripting.Debugging.dll\nMicrosoft.Scripting.ExtensionAttribute.dll\nMicrosoft.Dynamic.dll\n", "PythonEngine engine = new PythonEngine(); \nengine.LoadAssembly(Assembly.GetAssembly(typeof(GameObject))); \nengine.ExecuteFile(\"Test.py\");\n", "import UnityEngine from UnityEngine \nimport * \nDebug.Log(\"Hello world from IronPython!\")\n"], [], ["import unittest\nfrom fastapi.testclient import TestClient\nfrom engine.routes.base import app\n\n\nclass PostTest(unittest.TestCase):\n    def setUp(self) -> None:\n        self.client = TestClient(app)\n\n    def test_home_page(self):\n        response = self.client.get(\"/\")\n        assert response.status_code == 200\n\n"], ["print(out)\n\n   A  B   C\n2  1  2  10\n4  2  4   4\n"], [], ["\"Passing list-likes to .loc or [] with any missing labels is no longer supported.\nThe following labels were missing: Float64Index([nan], dtype='float64').\nSee https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike\"\n"], ["from dataclasses import dataclass\nfrom dacite import from_dict\n\n\n@dataclass\nclass User:\n    name: str\n    age: int\n    is_active: bool\n\n\ndata = {\n    'name': 'John',\n    'age': 30,\n    'is_active': True,\n    \"extra_1\": 1000,\n    \"extra_2\": \"some value\"\n}\n\nuser = from_dict(data_class=User, data=data)\nprint(user)\n# prints the following: User(name='John', age=30, is_active=True)\n"], ["    response = do_request(url, access_tok, \"GET\", payload={}, headers={}, allow_redirect=False)\n\n    if response.status_code in range(300, 310):\n        new_response = do_request(response.headers['Location'], access_tok, \"GET\", payload={}, headers={},)\n        # print(new_response.status_code)\n        pprint(new_response.json())\n"], ["pip3 uninstall keras\npip3 install keras --upgrade\n", "pip3 uninstall tensorflow\npip3 install tensorflow --upgrade\n", "pip3 install tensorflow==2.6.0\npip3 install keras==2.6.0\n"], [], ["import re\ndef rearrange_name(name):\n  result = re.search(r\"^([\\w \\.-]*), ([\\w \\.-]*)$\", name)\n  if result == None:\n    return name\n  return \"{} {}\".format(result[2], result[1])\n\nname=rearrange_name(\"Kennedy, John F.\")\nprint(name)\n"], ["^(\\w+), ([\\w. ]+)$\n", "^([\\w -]+), ([\\w. ]+)$\n", "def rearrange_name(name):\n    tokens = name.split(\", \")\n    return \" \".join(reversed(tokens))\n\nname=rearrange_name(\"Kennedy, John F.\")\nprint(name)\n"], ["from django.contrib.gis.db.backends.postgis.base import (\n     DatabaseWrapper as PostGISDatabaseWrapper,\n)\n\nclass DatabaseWrapper(PostGISDatabaseWrapper):\n    def prepare_database(self):\n        # This is the overwrite - we don't want to call the\n        # super() because of a faulty extension creation\n     pass\n"], [], [], [], [], ["System check identified no issues (5 silenced).\nTraceback (most recent call last):\nFile \"/app/.heroku/python/lib/python3.10/site-packages/django/db/backends/utils.py\", line 87, in _execute\nreturn self.cursor.execute(sql)\npsycopg2.errors.UndefinedTable: relation \"spatial_ref_sys\" does not exist\nThe above exception was the direct cause of the following exception:\nTraceback (most recent call last):\nFile \"/app/manage.py\", line 40, in\nmain()\nFile \"/app/manage.py\", line 36, in main\nexecute_from_command_line(sys.argv)\nFile \"/app/.heroku/python/lib/python3.10/site-packages/django/core/management/init.py\", line 446, in execute_from_command_line\nutility.execute()\nFile \"/app/.heroku/python/lib/python3.10/site-packages/django/core/management/init.py\", line 440, in execute\nself.fetch_command(subcommand).run_from_argv(self.argv)\nFile \"/app/.heroku/python/lib/python3.10/site-packages/django/core/management/base.py\", line 414, in run_from_argv\nself.execute(*args, **cmd_options)\nFile \"/app/.heroku/python/lib/python3.10/site-packages/django/core/management/base.py\", line 460, in execute\noutput = self.handle(*args, **options)\nFile \"/app/.heroku/python/lib/python3.10/site-packages/django/core/management/base.py\", line 98, in wrapped\nres = handle_func(*args, **kwargs)\nFile \"/app/.heroku/python/lib/python3.10/site-packages/django/core/management/commands/migrate.py\", line 106, in handle\nconnection.prepare_database()\nFile \"/app/.heroku/python/lib/python3.10/site-packages/psqlextra/backend/base.py\", line 32, in prepare_database\nsuper().prepare_database()\nFile \"/app/.heroku/python/lib/python3.10/site-packages/django/contrib/gis/db/backends/postgis/base.py\", line 26, in prepare_database\ncursor.execute(\"CREATE EXTENSION IF NOT EXISTS postgis\")\nFile \"/app/.heroku/python/lib/python3.10/site-packages/sentry_sdk/integrations/django/init.py\", line 544, in execute\nreturn real_execute(self, sql, params)\nFile \"/app/.heroku/python/lib/python3.10/site-packages/django/db/backends/utils.py\", line 67, in execute\nreturn self._execute_with_wrappers(\nFile \"/app/.heroku/python/lib/python3.10/site-packages/django/db/backends/utils.py\", line 80, in _execute_with_wrappers\nreturn executor(sql, params, many, context)\nFile \"/app/.heroku/python/lib/python3.10/site-packages/django_read_only/init.py\", line 74, in blocker\nreturn execute(sql, params, many, context)\nFile \"/app/.heroku/python/lib/python3.10/site-packages/django/db/backends/utils.py\", line 84, in _execute\nwith self.db.wrap_database_errors:\nFile \"/app/.heroku/python/lib/python3.10/site-packages/django/db/utils.py\", line 91, in exit\nraise dj_exc_value.with_traceback(traceback) from exc_value\nFile \"/app/.heroku/python/lib/python3.10/site-packages/django/db/backends/utils.py\", line 87, in _execute\nreturn self.cursor.execute(sql)\ndjango.db.utils.ProgrammingError: relation \"spatial_ref_sys\" does not exist\nSentry is attempting to send 2 pending error messages\nWaiting up to 2 seconds\nPress Ctrl-C to quit\n"], ["def replace_ending(sentence, old, new):\n# Check if the old string is at the end of the sentence \nif sentence.endswith(old):\n    # Using i as the slicing index, combine the part\n    # of the sentence up to the matched string at the \n    # end with the new string\n    i = sentence[:-len(old)]\n    new_sentence = i+new\n    return new_sentence\n\n# Return the original sentence if there is no match \nreturn sentence\n"], ["from dataclasses import dataclass\nimport inspect\n\n@dataclass\nclass Config:\n    var_1: str\n    var_2: str\n\n    @classmethod\n    def from_dict(cls, env):      \n        return cls(**{\n            k: v for k, v in env.items() \n            if k in inspect.signature(cls).parameters\n        })\n\n\n# usage:\nparams = {'var_1': 'a', 'var_2': 'b', 'var_3': 'c'}\nc = Config.from_dict(params)   # works without raising a TypeError \nprint(c)\n# prints: Config(var_1='a', var_2='b')\n"], ["C:\\Python --version\n", "Python 3.8.5\n"], ["list = [{key: str(dict[key]) for key in dict.keys()} for dict in list]\n"], ["import os\nos.environ['KMP_DUPLICATE_LIB_OK']='True'\n"], ["pip install git+https://github.com/ssuwani/pytube\n"], [], ["def set_diff_1d(t1, t2, assume_unique=False):\n    \"\"\"\n    Set difference of two 1D tensors.\n    Returns the unique values in t1 that are not in t2.\n\n    \"\"\"\n    if not assume_unique:\n        t1 = torch.unique(t1)\n        t2 = torch.unique(t2)\n    return t1[(t1[:, None] != t2).all(dim=1)]\n"], ["tf_dataset = get_dataset()    # returns a tf.data.Dataset() file\ntf.data.experimental.save(dataset=tf_dataset, path=\"path/to/desired/save/file_name\")\nwith open(\"path/to/desired/save/file_name\" + \".pickle\")), 'wb') as file:\n    pickle.dump(tf_dataset.element_spec, file)   # I need this for opening it later\n", "element_spec = pickle.load(\"path/to/desired/save/file_name\" + \".pickle\", 'rb'))\ntensor_data = tf.data.experimental.load(\"path/to/desired/save/file_name\", element_spec=element_spec)\n"], [], ["AttributeError: module 'datetime' has no attribute 'strptime'\n", "date_time_obj = datetime.datetime.strptime(str(date), '%Y-%m-%d %H:%M:%S') \n", "from datetime import datetime\n"], ["pip install -U git+https://github.com/Rapptz/discord.py\n", "pip3 install -U git+https://github.com/Rapptz/discord.py\n", "from discord_components import DiscordComponents, Button, ButtonStyle, InteractionType\n", "DiscordComponents(bot, change_discord_methods=True)\n", "await ctx.send(type=InteractionType.ChannelMessageWithSource, content=\"Message Here\", components=[Button(style=ButtonStyle.URL, label=\"Example Invite Button\", url=\"https://google.com\"), Button(style=ButtonStyle.blue, label=\"Default Button\", custom_id=\"button\")])\n", "@bot.event\nasync def on_button_click(interaction):\n    if interaction.component.label.startswith(\"Default Button\"):\n        await interaction.respond(type=InteractionType.ChannelMessageWithSource, content='Button Clicked')\n", "import discord\nfrom discord.ext import commands\nfrom discord_components import DiscordComponents, Button, ButtonStyle, InteractionType\n\nbot = commands.Bot(command_prefix=prefix, description=\"Desc\", help_command=None)\n\n@bot.event\nasync def on_ready():\n    DiscordComponents(bot, change_discord_methods=True)\n    await bot.change_presence(activity=discord.Game(name=f\"{prefix}help\"))\n    print(\"Bot has successfully logged in as: {}\".format(bot.user))\n    print(\"Bot ID: {}\\n\".format(bot.user.id))\n\n@bot.command()\nasync def button(ctx):\n    await ctx.send(type=InteractionType.ChannelMessageWithSource, content=\"Message Here\", components=[Button(style=ButtonStyle.URL, label=\"Example Invite Button\", url=\"https://google.com\"), Button(style=ButtonStyle.blue, label=\"Default Button\", custom_id=\"button\")])\n\nbot.run(\"token\")\n", "[btn 1][btn 2]\n[btn 3][btn 4]\n"], [], ["import torch\nfirst = torch.Tensor([1, 2, 3, 4, 5, 6])\nsecond = torch.Tensor([7, 3, 9, 1])\nintersection=first[(first.view(1, -1) == second.view(-1, 1)).any(dim=0)]\n", "diff=first[(first.view(1, -1) != second.view(-1, 1)).all(dim=0)]\n"], [], [], [], [], ["import numpy as np \nimport pandas as pd\ndata = pd.read_csv('./FileName.csv')\ndata.describe().loc['mean']\n"], [], ["# Examine the stack trace very carefully, you will see a line something like this:\nTypeError: self.c_map cannot be converted to a Python object for pickling\n", "# [Bugfix]. Add next line to initialize this again to eliminate pmap pickle error. Stacktrace is your friend!\nhdb = HivedbApi(base_dir=hivedb_base_dir, table_name=table_name, partition_type=PartitionType.HiveFilePerDate)\nhdb.write(df_trades)\n"], ["/opt/anaconda3/pkgs/visions-0.5.0-pyhd3eb1b0_0/site-packages/visions/dtypes/boolean.py\n"], [], [], [], [], [], ["pip uninstall keras-nightly\n"], [], ["conda update --all\n", "conda install -c conda-forge pandas-profiling\n"], ["def is_palindrome(input_string):\n    new_string = input_string.lower()\n    no_space = new_string.replace(\" \",\"\")\n\n    reverse_string =new_string.replace(\" \",\"\")[::-1]\n    if reverse_string==no_space:\n        return True\n    return False\n\nprint(is_palindrome(\"Never Odd or Even\")) # Should be True\nprint(is_palindrome(\"abc\")) # Should be False\nprint(is_palindrome(\"kayak\")) # Should be True\n"], ["OSError: [Errno 9] Bad file descriptor \n"], ["from keras_preprocessing.text import Tokenizer\nfrom keras_preprocessing.sequence import pad_sequences\n"], ["iteration = 0\namount = 0\nwhile True:\n    iteration++\n    number = int(input(\"Number: \"))\n    if number == 0:\n        break\n    amount += number\n    print(f\"Sum so far: {amount}\")\n    \nprint(f\"Numbers in total: {iteration-1}\")\n"], ["number_of_numbers=0\ntotal_sum=0\nwhile True:\n    number = int(input(\"Number: \"))\n    if number == 0:\n        break\n    number_of_numbers += 1\n    total_sum += number\n\nprint(\"Total number of numbers is: \", number_of_numbers)\nprint(\"Total sum is: \", total_sum)\n"], ["amount = 0\nnumber = 0\nwhile True:\n    amount += 1\n    number += int(input(\"Number: \"))\n    if number == 0:\n        break\n\nprint(f\"Numbers in total: {amount-1}\")\nprint(f\"Sum of the numbers : {number}\")\n"], [], ["# could it work like this as well? if not why? thanks :)\ndef first_and_last(message):\nwhile bool(message) == True:\n    first_letter = str(message[0])\n    last_letter = str(message[-1])\n    if first_letter == last_letter:\n        return True\n    else :\n        return False\n return True\n\n print(first_and_last(\"else\"))\n print(first_and_last(\"tree\"))\n print(first_and_last(\"\"))\n # Output (True, False, True)\n"], [], [" pip uninstall keras\n pip uninstall Tensorflow\n", " pip install tensorflow==2.6\n pip install keras==2.6\n"], ["pip uninstall tensorflow\npip uninstall keras\n", "pip install tensorflow==2.6.0\n"], ["df.select([col(col_name).alias('prefix' + col_name) for col_name in df])\n\n"], ["timestamp = Timestamp('2017-11-12 00:00:00')\n\nstr_timestamp = str(timestamp)\n"], ["pip install --upgrade tensorflow\n"], [], ["pip install --upgrade pip\n", "pip install numpy \n"], [], ["s = 'teststring'\n\nr = ' '.join([s[i:i+2] for i in range(len(s)-1)])\n\nprint(r)\n"], ["str1 = 'teststring'\nresult = []\nfor i in range(len(str1) - 1):\n    result.append(str1[i:i + 2])\n\nprint(result)\n", "['te', 'es', 'st', 'ts', 'st', 'tr', 'ri', 'in', 'ng']\n"], ["str1 = 'teststring'\ni=0\nwhile i<=len(str1)-2: \n    str2=str1[i:i+2]\n    i += 1\n    print(str2)\n"], ["for j in range(len(s) - 1):\n    print(s[j:j + 2])\n", "for c1, c2 in zip(s[:-1], s[1:]):\n    print(c1 + c2)\n"], [], ["pd.read_excel(r\"C:\\Users\\selman\\PycharmProjects\\selman_learning\\bisiklet_fiyatlari.xlsx\")\n"], [], ["def first_and_last(message):\n    if message == \"\" or message[0] == message[-1]:\n        return True\n    else:\n        return False\n\nprint(first_and_last(\"else\"))\nprint(first_and_last(\"tree\"))`enter code here`\nprint(first_and_last(\"\"))\n"], ["pip3 uninstall keras\npip3 install keras --upgrade\n"], ["def is_palindrome(input_string):\n    input_string = input_string.lower().replace(\" \", \"\") '''make the string have \n                                    lower letter remove the withspace'''\n    new_string = \"\"\n    reverse_string = \"\"\n    for n in range(len(input_string)):\n        new_string += input_string[n]\n        reverse_string += input_string[(len(input_string)-(1+n))] '''manually make string \n                                                from behind with indexing.'''\n    if new_string == reverse_string:\n        return True\n    return False\n"], [], ["pd.read_excel(\"./<file name>\")\n"], ["import pandas as pd\npath = 'absolute_path/records.xlsx' #eg. C:\\\\Projects\\\\readexcel\\\\file\\\\records.xlsx\ndf = pd.read_excel(path)\n"], ["with open(\"<path to your file>\", encoding = 'utf-8') as f:\n     pandas.read_excel(f)\n"], ["name:`INSTALLED_APPS = [\n    ...,\n    'app.budget',\n]`\n", "class BudgetConfig(AppConfig):\n    default_auto_field = 'django.db.models.BigAutoField'\n    name = 'app.budget'\n"], [], ["pd.to_datetime(1.547559e+09, unit='s', origin='unix') \n# Timestamp('2019-01-15 13:30:00')\n", "pd.to_datetime(['2019-01-15 13:30:00']).astype(int) / 10**9\n# Float64Index([1547559000.0], dtype='float64')\n", "# create test data\ndates = pd.to_datetime(['2019-01-15 13:30:00'])\n\n# calculate unix datetime\n(dates - pd.Timestamp(\"1970-01-01\")) // pd.Timedelta('1s')\n\n[out]:\nInt64Index([1547559000], dtype='int64')\n", "pd.Timestamp('2019-01-15 13:30:00').timestamp()\n# 1547559000.0\n", "pd.to_datetime(['2019-01-15 13:30:00']).map(pd.Timestamp.timestamp)\n# Float64Index([1547559000.0], dtype='float64')\n"], [], [], ["pip install --upgrade tensorflow\n"], [], ["# Runtime.txt\npython-3.8.5\n"], [], ["def sol(word, board):\n    rows = len(board)\n    cols = len(board[0])\n    coordinates = []\n    wordCnt = 0\n    co = []\n    result = []\n    def getWord(row, col, word, wordCnt, board):\n        if row < 0 or col < 0 or row > len(board)-1 or col > len(board[0])-1 or wordCnt > len(word) -1 or board[row][col] != word[wordCnt]:\n            return\n        result.append(word[wordCnt])\n        co.append((row, col))\n        getWord(row+1, col, word, wordCnt+1, board)\n        getWord(row, col+1, word, wordCnt+1, board)\n        return co, result\n\n    for row in range(rows):\n        for col in range(cols):\n            if board[row][col] == word[wordCnt]:\n                co, result = getWord(row, col, word, wordCnt, board)\n                if ''.join(result[-len(word):]) == word:\n                    print(co[-len(word):])\n\n                \nsol('cat', board)\n"], [], ["pip3 install jsonvice\n"], [], [], ["python -m pip install git+https://github.com/Zeecka/pytube@fix_1060\n"], ["python fixNvPe.py --input=C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\lib\\*.dll\n"], [], ["[1, 2, 9, 0]\n[2, 4, 4]\n[0]\n"], ["import numpy as np\nlst1 = [6, 9, 8] \nlst2 = [5, 9, 2]\nlst1_len = len(lst1)\nlst2_len = len(lst2)\nif lst1_len >= lst2_len:\n    lst2 = [0] * (lst1_len - lst2_len) + lst2\nelse:\n    lst1 = [0] * (lst2_len - lst1_len) + lst1\n\ncommon_len = len(lst1)\n\nlst1_val = sum(np.array(lst1) * np.array([10**(-x) for x in range(-common_len + 1, 1)]))\nlst2_val = sum(np.array(lst2) * np.array([10**(-x) for x in range(-common_len + 1, 1)]))\ntotal = lst1_val + lst2_val\ntotal_as_list = [int(x) for x in str(total)]\n", "print(total_as_list)\n[1, 2, 9, 0]\n"], [], ["t = int(input())\nfor z in range(t):\n    n = int(input()) \n    a = []\n    for y in range(n):\n        x = int(input())\n        a.append(x) \n\n    for i in range(n):\n        for j in range(i,n+1):\n            for k in range(i,j):\n                print(a[k], end=\" \")\n            print()\n"], ["a = input().split()\n\nfor i in range(len(a)):\n    for j in range(len(a)):\n        if j>=i:\n            print(*a[i:j+1])\n", "1\n1 2\n1 2 3\n2\n2 3\n3\n"], ["t = int(input())\nfor z in range(t):\n    n = int(input()) \n    a = list(map(int, input().split()))  \n\n    for i in range(n):\n        for j in range(i+1,n+1):\n            print(*a[i:j])\n", "1\n3\n1 2 3  # end of input\n1\n1 2\n1 2 3\n2\n2 3\n3\n"], [], [], [], ["def addNums(lst1, lst2, *args):\n    numsIters = [iter(num[::-1]) for num in [lst1, lst2] + list(args)]  # make the iterators for each list\n    carry, final = 0, []                                                # Initially carry is 0, 'final' will store the result\n    \n    while True:\n        nums = [next(num, None) for num in numsIters]                   # for every num in numIters, get the next element if exists, else None\n        if all(nxt is None for nxt in nums): break                      # If all numIters returned None, it means all numbers have exhausted, hence break from the loop\n        nums = [(0 if num is None else num) for num in nums]            # Convert all 'None' to '0'\n        digit = sum(nums) + carry                                       # Sum up all digits and carry\n        final.append(digit % 10)                                        # Insert the 'ones' digit of result into final list\n        carry = digit // 10                                             # get the 'tens' digit and update it to carry\n\n    if carry: final.append(carry)                                       # If carry is non-zero, insert it\n    return final[::-1]                                                  # return the fully generated final list\n\nprint(addNums([6, 9, 8], [5, 9, 2]))                                    # [1, 2, 9, 0]\nprint(addNums([7, 6, 9, 8, 8], [5, 9, 2], [3, 5, 1, 7, 4]))             # [1, 1, 2, 7, 5, 4]\n\n"], ["def list_sum(lst1, n, lst2, m, output):\ni, j, k, carry = n - 1, m - 1, max(n, m), 0\nwhile i >= 0 and j >= 0:\n    output[k] = (lst1[i] + lst2[j] + carry) % 10\n    carry = (lst1[i] + lst2[j] + carry) // 10\n    i = i - 1\n    j = j - 1\n    k = k - 1\nwhile i >= 0:\n    output[k] = (lst1[i] + carry) % 10\n    carry = (lst1[i] + carry) // 10\n    i = i - 1\n    k = k - 1\nwhile j >= 0:\n    output[k] = (lst2[j] + carry) % 10\n    carry = (lst2[j] + carry) // 10\n    j = j - 1\n    k = k - 1\noutput[0] = carry\nprint(output)\n", "outputSize = (1 + max(n, m))\noutput = outputSize * [0]\n", "list_sum(lst1, n, lst2, m, output)\n"], [], [], ["def list_sum(lst1, lst2):\n    out = []\n    for i, lst in enumerate([lst1, lst2]):\n        if len(lst) > 0:\n            out.append(int(''.join(str(x) for x in lst)))\n        else:\n            if i == 0:\n                return lst2\n            else:\n                return lst1\n    return [int(x) for x in str(out[0]+out[1])]\n\nlist_sum([6,9,8],[5,9,2])\n", "[1, 2, 9, 0]\n"], ["def get_sum_as_list(list1, list2):\n    first_int = int(''.join(map(str,list1)))\n    second_int = int(''.join(map(str,list2)))\n    result = [int(num) for num in str(first_int+second_int)]\n    return result\n"], [], ["python3 -m pip install git+https://github.com/pytube/pytube\n"], ["# check token expiration\nif expires is None:\n    raise credentials_exception\nif datetime.utcnow() > datetime.utcfromtimestamp(token_data.expires):\n    raise credentials_exception\nreturn user\n"], ["extended_arg = 0\n"], [], [], [], [], [], ["pip uninstall keras\n", "pip install keras==2.6.0\n"], [], [], [], ["cv2.imshow() \n", "import matplotlib.image as mpimg \nfrom matplotlib.pyplot import imshow\n%matplotlib inline\ntestim = mpimg.imread('butterfly.jpg')\nimshow(testim)\n", "from google.colab.patches import cv2_imshow\ncv2_imshow('butterfly.jpg')\n"], ["def print_keys(dic):\n    for key, value in dic.items():\n        print(key)\n        if isinstance(value, dict):\n            print_keys(value)\n", "print(life['animals'].keys()) # dict_keys(['cats', 'octopi', 'emus'])\n# or\nprint(*(key for key in life['animals'])) # cats octopi emus\n# or a normal loop like in the other answer.\n"], ["def replace_ending(sentence, old, new):\n    if old in sentence:\n        sentence = sentence[::-1]\n        index = sentence.index(old[::-1])\n        new_sentence = sentence[:index] + new[::-1] + sentence[(len(old)+index):]\n        return new_sentence[::-1]\n    return sentence\n"], ["else:\n    arg = None\n    extended_arg = 0 \nyield (i, op, arg)\n"], [], ["from object_detection.utils import config_util\nfrom object_detection import model_lib_v2\n\nPIPELINE_CONFIG_PATH = 'path_to_your_pipeline.config'\n\n# Load the pipeline config as a dictionary\npipeline_config_dict = config_util.get_configs_from_pipeline_file(PIPELINE_CONFIG_PATH)\n\n# OVERRIDE EXAMPLES\n# Example 1: Override the train tfrecord path\npipeline_config_dict['train_input_config'].tf_record_input_reader.input_path[0] = 'your/override/path/to/train.record'\n# Example 2: Override the eval tfrecord path\npipeline_config_dict['eval_input_config'].tf_record_input_reader.input_path[0] = 'your/override/path/to/test.record'\n\n# Convert the pipeline dict back to a protobuf object\npipeline_config = config_util.create_pipeline_proto_from_configs(pipeline_config_dict)\n\n# EXAMPLE USAGE:\n# Example 1: Run the object detection train loop with your overrides (has to be string representation)\nmodel_lib_v2.train_loop(config_override=str(pipeline_config))\n# Example 2: Save the pipeline config to disk\nconfig_util.save_pipeline_config(config, 'path/to/save/new/pipeline.config)\n"], [], ["42681 INFO: PyInstaller: 4.6\n42690 INFO: Python: 3.10.0\n"], ["from keras.preprocessing.image import ImageDataGenerator\n", "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"], [], [], ["<site-packages>/keras\n<site-packages/tensorflow/python/keras\n", "pip install keras==2.6.*\n"], ["def repeat(word, n, sep='&'):\n    return sep.join(word for _ in range(n))\n\nprint(repeat('Hallo', 3))\n", "hallo&hallo&hallo\n"], ["from collections import Counter\nn=int(input(\"Enter the number of products to be stored in a list : \"))\n\nlist1=[]\n\nfor i in range(n):\n    items=int(input(\"value for product \" + str(i+1) + \" : \"))\n    list1.append(items)\ndup_dict=Counter(list1)\ncount=0\nfor i in dup_dict.values():\n    if(i!=1):\n        count+=1\n\nprint(\"Count of duplicate elements in the list: \",count)\n"], ["list1 = [4, 4, 4, 1, 5]\n# ---\nfrom collections import Counter\n\ncounts = Counter(list1)  # > Counter({4: 3, 1: 1, 5: 1})\ntotal = sum(count>1 for count in counts.values())\n\nprint(total)  # -> 1\n"], ["n = int(input(\"Enter the number of products to be stored in a list : \"))  # \n\nI have entered 5\n\nlist1 = []\n\nfor i in range(n):\n    items = int(input(\"value for product \" + str(i + 1) + \" : \"))\n    list1.append(items)\n\ndup = {}\n\nfor a in list1:\n    if list1.count(a) > 1:\n        dup[a] = dup.get(a, 0)+1\n\nprint(\"Count of duplicate elements in the list: \", len(dup))\nprint(dup)\n", "Enter the number of products to be stored in a list : 5\nvalue for product 1 : 4\nvalue for product 2 : 4\nvalue for product 3 : 4\nvalue for product 4 : 2\nvalue for product 5 : 2\nCount of duplicate elements in the list:  2\n{4: 3, 2: 2}\n"], ["import numpy\n\nfor a in list1: \n    if list1.count(a)>1:\n        dup.append(a)\n\ndup_array = numpy.array(dup)\nunique, counts = numpy.unique(dup, return_counts=True)\ndict(zip(unique, counts))\n"], ["n=int(input(\"Enter the number of products to be stored in a list : \"))\n\nlist1=[]\n\nfor i in range(n):\n    item = int(input(\"value for product \" + str(i+1) + \" : \"))\n    list1.append(item)\n    \ndup = []\n\nfor a in list1:\n    if (list1.count(a) > 1) and (a not in dup):\n        dup.append(a)\n\nprint(\"Count of duplicate elements in the list: \", len(dup))\n\n"], ["for a in list1:\n    if list1.count(a)>1 and a not in dup:\n        dup.append(a)\n", "print(\"Count of duplicate elements in the list: \",len(dup))\n", "dup = set()\n"], [], ["word = 'mammoth'\ncharacter = 'm'\n\nfor x in range(0, len(word) - 2):\n    substr = word[x:x + 3]\n    if substr.startswith(character):\n        print(substr)\n", "mam\nmmo\nmot\n"], [], ["word = word = input(\"Please type in a word: \")\ncharacter = input(\"Please type in a character: \") \nindex = word.find(character)\nwhile index!=-1:\n    if len(word)>=index+3:\n        print(word[index:index+3])\n    index = word.find(character,index+1)\n"], ["import numpy as np \nimport pandas as pd\ndf =pd.DataFrame(np.random.rand(3,6))\n\nwith open(\"dump_from_v1.3.4.pickle\", \"wb\") as f: \n    pickle.dump(df, f) \n\nquit()\n", "import pickle\n\nwith open(\"dump_from_v1.3.4.pickle\", \"rb\") as f: \n    df = pickle.load(f) \n\n\n---------------------------------------------------------------------------\nAttributeError                            Traceback (most recent call last)\n<ipython-input-2-ff5c218eca92> in <module>\n      1 with open(\"dump_from_v1.3.4.pickle\", \"rb\") as f:\n----> 2     df = pickle.load(f)\n      3 \n\nAttributeError: Can't get attribute 'new_block' on <module 'pandas.core.internals.blocks' from '/opt/anaconda3/lib/python3.7/site-packages/pandas/core/internals/blocks.py'>\n"], [], ["from collections import UserDict\n\nclass FormData(UserDict):\n    def __init__(self, *args, **kwargs):\n        self.frozen = False\n        super().__init__(*args, **kwargs)\n        self.frozen = True\n        \n    def __setitem__(self, key, value):\n        if self.frozen and key not in self:\n            raise ValueError('Key %s is not in the dict. Available: %s' % (\n                key, self.keys()\n            ))\n        super().__setitem__(key, value)\n\ndef parse_form(content):\n    \"\"\"\n    Parse the first form in the html in content.\n    \"\"\"\n    \n    import lxml.html\n    tree = lxml.html.fromstring(content)\n    return FormData(tree.forms[0].fields)\n", "def test_foo_form(user_client):\n    url = reverse('foo')\n    response = user_client.get(url)\n    assert response.status_code == 200\n    data = parse_form(response.content)\n    response = user_client.post(url, data)\n    assert response.status_code == 302\n"], [], ["from keras.preprocessing.image import ImageDataGenerator\nfrom keras.preprocessing.image import img_to_array, load_img\nfrom keras import layers, models, optimizers\nfrom keras import backend as K\n", "from tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.preprocessing.image import img_to_array, load_img\nfrom tensorflow.keras import layers, models, optimizers\nfrom tensorflow.keras import backend as K\n"], [], [], [], [], ["import json\n\nclass RoundingFloat(float):\n    __repr__ = staticmethod(lambda x: format(x, '.2f'))\n\njson.encoder.c_make_encoder = None\nif hasattr(json.encoder, 'FLOAT_REPR'):\n    # Python 2\n    json.encoder.FLOAT_REPR = RoundingFloat.__repr__\nelse:\n    # Python 3\n    json.encoder.float = RoundingFloat\n\nprint(json.dumps({'number': 1.0 / 81}))\n"], [], [], [], ["def first_and_last(message):\n    if message == \"\":\n        return True\n    elif message[0] == message[-1]:\n        return True  \n    else:\n        return False\n\nprint(first_and_last(\"else\"))\nprint(first_and_last(\"tree\"))\nprint(first_and_last(\"\"))\n\noutput would be  below \n\nTrue\nFalse\nTrue\n"], ["def _register_wrapper_optimizer_cls(optimizer_cls, wrapper_optimizer_cls):\n  _REGISTERED_WRAPPER_OPTIMIZER_CLS[optimizer_cls] = wrapper_optimizer_cls\n"], [], ["python -m pip install --upgrade pytube\n"], ["company = models.ForeignKey(Company, on_delete=models.CASCADE, related_name='company', null=True)\n"], ["class TokenData(BaseModel):\n    username: Optional[str] = None\n    expires: Optional[datetime]\n", "@router.get('/user/me')\nasync def get_current_user(token: str = Depends(oauth2_scheme)):\n    # get the current user from auth token\n\n    # define credential exception\n    credentials_exception = HTTPException(\n        status_code=status.HTTP_401_UNAUTHORIZED,\n        detail=\"Could not validate credentials\",\n        headers={\"WWW-Authenticate\": \"Bearer\"},\n    )\n\n    try:\n        # decode token and extract username and expires data\n        payload = jwt.decode(token, SECRET_KEY, algorithms=[ALGORITHM])\n        username: str = payload.get(\"sub\")\n        expires = payload.get(\"exp\")\n    except JWTError:\n        raise credentials_exception\n\n    # validate username\n    if username is None:\n        raise credentials_exception\n    token_data = TokenData(username=username, expires=expires)\n    user = Users.search(where('name') == token_data.username)\n    if user is None:\n        raise credentials_exception\n\n    # check token expiration\n    if expires is None:\n        raise credentials_exception\n    if datetime.utcnow() > token_data.expires:\n        raise credentials_exception\n    return user\n"], ["pip3 uninstall keras\npip3 install keras --upgrade\n"], [], ["{'A': [{'grade': 'A', 'name': 'James'}, {'grade': 'A', 'name': 'Zelda'}], 'B': [{'grade': 'B', 'name': 'Tom'}]}\n"], ["import pandas as pd\ndf = pd.Dataframe(arr)    \nfor index, group in df.groupby('grade'):\n    print(group)\n"], ["arr2 = {}\nfor d in arr:\n    t = arr2.setdefault(d['grade'], [])\n    t.append(d)\n", ">>> arr2\n{'A': [{'grade': 'A', 'name': 'James'}, {'grade': 'A', 'name': 'Zelda'}],\n 'B': [{'grade': 'B', 'name': 'Tom'}]}\n"], ["import json\ngradeList = [\n    {\"grade\": 'A', \"name\": 'James'},\n    {\"grade\": 'B', \"name\": 'Tom'},\n    {\"grade\": 'A', \"name\": 'Zelda'}\n]\ngradeDict = {}\nfor d in gradeList:\n    gradeDict.setdefault(d[\"grade\"], []).append(d)\n\nprint(json.dumps(gradeDict, indent=4))\n", "{\n    \"A\": [\n        {\n            \"grade\": \"A\",\n            \"name\": \"James\"\n        },\n        {\n            \"grade\": \"A\",\n            \"name\": \"Zelda\"\n        }\n    ],\n    \"B\": [\n        {\n            \"grade\": \"B\",\n            \"name\": \"Tom\"\n        }\n    ]\n}\n"], ["pip install --upgrade tensorflow\npip install --upgrade tensorflow-gpu\n"], ["def repeat(word, n, delim):\n    str = ''\n    for i in range(n): # this will repeat the next line n times.\n        str += word + delim \n    return str[0:len(str) - len(delim)] # len(delim) will remove the last 'delim' from 'str'. \n", "print(repeat(string, n, delim))\n"], ["def myprint(word, n, delim):\n    ans = [word] * n \n    return delim.join(ans)\n    \nprint(myprint('cat',3,'petting'))\n", "catpettingcatpettingcat\n"], ["$ python3\nPython 3.6.9 (default, Jan 26 2021, 15:33:00) \n[GCC 8.4.0] on linux\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n>>> print('petting'.join([\"cat\"]*3))\ncatpettingcatpettingcat\n>>> \n"], ["def repeat(word, n, delim):\n    print(*n*[word], sep=delim)\n", "def repeat(word, n, delim):\n    print(delim.join(word for _ in range(n)))\n"], ["x = [True, False, True, False]\ny = [a, b, c, d]  # assuming that a, b, c and d are some kind of object\noutput = []\nfor i, k in enumerate(x):\n    if k:\n        output.append(x[i])\n"], ["# Instead of this:\nfrom keras.preprocessing import image\n\n# Do this:\nfrom tensorflow.keras.preprocessing import image\n"], [], ["await ctx.channel.send(\"Context\",components=[Button(style=ButtonStyle.blue, label=\"Test\")]) #Blue button with button label of \"Test\"\n    res = await self.client.wait_for(\"button_click\") #Wait for button to be clicked\n    await res.respond(type=InteractionType.ChannelMessageWithSource, content=f'Button Clicked') #Responds to the button click by printing out a message only user can see #In our case, its \"Button Clicked\"\n", "from discord_components import DiscordComponents, Button, ButtonStyle, InteractionType\n"], [], [], ["str = \"stay am stay am  delete am\"\n#  want to remove the last am\nstr = str[:str.rfind('am')]\nprint(str)\n"], ["@dataclass(init=False)\nclass Config:\n    VAR_NAME_1: str\n    VAR_NAME_2: str\n\n    def __init__(self, **kwargs):\n        names = set([f.name for f in dataclasses.fields(self)])\n        for k, v in kwargs.items():\n            if k in names:\n                setattr(self, k, v)\n", "field_names = set(f.name for f in dataclasses.fields(Config))\nc = Config(**{k:v for k,v in os.environ.items() if k in field_names})\n"], [], [], ["# Neah it does not, some debugging revealed:\n# Credit: (with corrections and debugging)\n# https://stackoverflow.com/questions/64687375/get-labels-from-dataset-when-using-tensorflow-image-dataset-from-directory\n# predictions = np.array([])\n\ntest_labels =  np.array([])\n# counter = 0\nfor x, y in test_unshuffled:\n#   predictions = np.argmax(model.predict(x), axis = -1)  #np.concatenate([predictions, np.argmax(model.predict(x), axis = -1)])\n#   print(f'prediction: {predictions}, size of {len(predictions)}')\n#   print(f'y label:    {y.numpy()}, size of {len(y.numpy())}') #labels = np.concatenate([labels, np.argmax(y.numpy(), axis=-1)])\n  test_labels = np.concatenate([test_labels, y.numpy()])\n#   counter += 1\n#   if counter > 1:\n#     break\n\n# with the final code:\ntest_predicted_labels = np.argmax(classes_predicted_unshuffled, axis=1)\ntest_predicted_labels.shape # sanity check\n\ntest_labels =  np.array([])\nfor x, y in test_unshuffled:\n  test_labels = np.concatenate([test_labels, y.numpy()])\ntest_labels.shape # sanity check better match test_predicted_labels\n"], ["Python 3.9.6 (default, Jun 29 2021, 10:19:25)\n[GCC 10.3.0]\n"], [], [], ["class MyModelPredict(object):\n    def __init__(self, model):\n        self._estimator_type = 'classifier'\n        \n    def predict(self, X):\n        return your_custom_prediction\n\nmodel = MyModelPredict()\nplot_confusion_matrix(model, X, y_true)\n"], [], ["match name: \n    case \"example_111\" | \"example_222\": \n        return f\"Hello {name}\" \n    case _: \n        return \"Bye\"\n", "def get_product_info(make, in_dollar): \n\n    match make:\n\n        case \"product_111\" if in_dollar: \n            return \"10000 $\"\n\n        case \"product_222\" if not in_dollar:\n            return \"10000*73 INR\"\n\n        case _: \n            return \"error\"\n"], ["#!/usr/bin/python3.8\n# GENERATED BY DEBIAN\n\nimport sys\n\n# Run the main entry point, similarly to how setuptools does it, but because\n# we didn't install the actual entry point from setup.py, don't use the\n# pkg_resources API.\nfrom pip import main\nif __name__ == '__main__':\n    sys.exit(main())\n"], [], ["import pandas as pd\ndf = pd.DataFrame(data=[[1,'a']],columns=['numeruc_col','string_col'])\n\nprint(df.columns[list(map(pd.api.types.is_numeric_dtype,df.dtypes))]) # one way\nprint(df.dtypes.map(pd.api.types.is_numeric_dtype)) # another way\n"], ["input_tensor = torch.randn(5, 8)\nprint(input_tensor)\nindices = torch.LongTensor(np.random.choice(5,2, replace=False)) \noutput_tensor = torch.index_select(input_tensor, 0, indices)\nprint(output_tensor)\n"], ["class AuthorManager(models.Manager):\n    def get_queryset(self):\n        return AuthorQuerySet(self.model, using=self._db)\n\n    def annotate_with_copies_sold(self):\n        return self.get_queryset().annotate_with_copies_sold()\n\nclass AuthorQuerySet(models.QuerySet):\n    def annotate_with_copies_sold(self):\n        return self.annotate(copies_sold=Sum('Book_Author__copies_sold'))\n\n\nclass Author(models.Model):\n    first_name = models.CharField(max_length=50)\n    last_name = models.CharField(max_length=50)\n    objects = AuthorManager()\n\n    class Meta:\n        verbose_name_plural = \"Author\" \n        verbose_name = 'Author'\n        ordering = ('first_name','last_name')\n\nclass Book(models.Model):\n    title = models.CharField(max_length=250, unique=True)\n    copies_sold = models.PositiveIntegerField(default=0)\n    author = models.ForeignKey(Author, on_delete=models.CASCADE, related_name='Book_Author')\n\n    class Meta:\n        verbose_name_plural = \"Book\" \n        verbose_name = 'Book'\n        ordering = ('title','copies_sold')\n\n\n\n\nfrom vehicles.models import Author, Book\ntry:\n    author  = Author.objects.get(first_name='Mark', last_name='Twain')\nexcept Author.DoesNotExist:\n    author  = Author.objects.create(first_name='Mark', last_name='Twain')\n\ntry:\n    book = Book.objects.get(author=author, title='Adventrure of Huckleberry Finn', copies_sold=7)\nexcept Book.DoesNotExist:\n    book = Book.objects.create(author=author, title='Adventrure of Huckleberry Finn', copies_sold=7)\n    pass\ntry:\n    book = Book.objects.get(author=author, title='Adventrure of Tomm Saywer', copies_sold=4)\nexcept Book.DoesNotExist:\n    book = Book.objects.create(author=author, title='Adventrure of Tomm Saywer', copies_sold=4)\n    pass\n\nauthor = Author.objects.annotate_with_copies_sold().first()\nprint(author.copies_sold)\n11\n\n1.Create AuthorManager, AuthorQuerySet classes from Author and Books\n2.Create Author, Book models \n3.Prepare Test Data and use model manager to filter the queryset\n"], ["import string \nx=string.ascii_lowercase\n   \nfor i in x:\n    for g in x:\n        print(i,g)\n"], ["function solution($a){\n    // write your code in PHP7.0\n    $binarian = 0;\n    foreach ($a as $val){\n        $binarian += pow(2, $val);\n    }\n\n    $b = [];\n    while($binarian > 0){\n        $el = intval(log($binarian, 2));\n        array_push($b, $el);\n        $binarian -= pow(2, $el);\n    }\n    \n    return $b;\n    \n}\n"], [], [], ["cd apps && django-admin startapp app_name\n"], [], [], ["tf.data.experimental.save(\n    ds, tf_data_path, compression='GZIP'\n)\nwith open(tf_data_path + '/element_spec', 'wb') as out_:  # also save the element_spec to disk for future loading\n    pickle.dump(ds.element_spec, out_)\n", "with open(tf_data_path + '/element_spec', 'rb') as in_:\n    es = pickle.load(in_)\n\nloaded = tf.data.experimental.load(\n    tf_data_path, es, compression='GZIP'\n)\n"], ["!pip3 uninstall keras-nightly\n!pip3 uninstall -y tensorflow\n!pip3 install keras==2.1.6\n!pip3 install tensorflow==1.15.0\n!pip3 install h5py==2.10.0\n"], [], [], [], ["!pip install tensorflow==1.13.0\n", "%tensorflow_version 1.x\n"], [], ["IC = type('IdentityClassifier', (), {\"predict\": lambda i : i, \"_estimator_type\": \"classifier\"})\nplot_confusion_matrix(IC, y_pred, y_test, normalize='true', values_format='.2%');\n"], ["import tensorflow as tf\ntf.keras.models.load_model(model_path)\n"], ["RUN apk update \\\n   && apk add --no-cache build-base\n"], ["list = [{'a':'p', 'b':2, 'c':'k'}, {'a':'e', 'b':'f', 'c':5}]\nlist = [{str(j): str(i) for i, j in enumerate(d)} for d in list]\n\nfor x in list:\n    print(\"the values of b is: \" + x['b'])\n", "for x in list:\n    print(f\"the values of b is: {x['b']}\")\n"], ["class StringDict(dict):\n    def __init__(self):\n        dict.__init__(self)\n        \n    def __getitem__(self, y):\n        value_to_string = str(dict.__getitem__(self, y))\n        return value_to_string\n    \n    def get(self, y):\n        value_to_string = str(dict.get(self, y))\n        return value_to_string\n    \n    \n\nexampleDict = StringDict()\n\nexampleDict[\"no_string\"] = 123\n\nprint(exampleDict[\"no_string\"])\n123\nprint(type(exampleDict[\"no_string\"]))\n<class 'str'>\n"], [], ["list = [{'a':'p', 'b':2, 'c':'k'},\n        {'a':'e', 'b':'f', 'c':5}]\n\nfor dicts in list:\n    for keys in dicts:\n        dicts[keys] = str(dicts[keys])\nprint(list)\n"], ["pd.Timestamp('2021-04-01').timestamp()\n\n[Out]:\n1617235200.0\n\npd.Timestamp('2021-04-01 00:02:35.234').timestamp()\n\n[Out]:\n1617235355.234\n"], ["def first_and_last(message):\n\nif message==\"\" or message[0]==message[-1]:\n\n    return True\n\nreturn False\n"], ["df.reset_index(drop=True, inplace=True)\n", "df = df.reset_index(drop=True)\n", "df = df.style.set_caption('Top 10 Fields of Research by Aggregated Funding Amount')\n"], [], ["sudo apt-get update\n", "sudo apt-get install python-pip (Python2)\nsudo apt-get install python3-pip (Python3)\n"], [], [], ["r = r.decode('utf-8', 'ignore')\n"], ["pip install --upgrade opencv-contrib-python\npip install --upgrade opencv-python\n"], [], ["df.style.set_table_attributes(\"style='display:inline'\").set_caption('Caption table')\n"], ["def replace_ending(sentence, old, new):\n# Check if the old string is at the end of the sentence \nif sentence.endswith(old):\n    # Using i as the slicing index, combine the part\n    # of the sentence up to the matched string at the \n    # end with the new string\n    i = len( sentence.split())\n    new_sentence = sentence[:-len(old)] + new \n    return new_sentence\n\n# Return the original sentence if there is no match \nreturn sentence\n"], ["RUN apk --update --no-cache add python3-dev libffi-dev gcc musl-dev make libevent-dev build-base\n"], [" uname -m # Display the host architecture\n #x86_64\n\n docker pull arm32v7/ubuntu # Get ARM docker image\n\n docker run --rm -t arm32v7/ubuntu uname -m\n standard_init_linux.go:211: exec user process caused \"exec format error\"\n", "sudo apt-get install qemu binfmt-support qemu-user-static # Install the qemu packages\ndocker run --rm --privileged multiarch/qemu-user-static --reset -p yes # This step will execute the registering scripts\n", "$ docker run --rm -t arm32v7/ubuntu uname -m\narmv7l\n"], [], ["import multiprocessing\nmultiprocessing.cpu_count()\n12  \n# I actually have 6 pysical cores, if you use this as base it will likely hog system\n\n\nimport psutil \npsutil.cpu_count(logical = False)\n6 #actual number of pysical cores\n\npsutil.cpu_count(logical = True)\n12 #logical cores (e.g. hyperthreading)\n"], ["import pandas as pd\ndate_1 = pd.to_datetime('2020-07-18 18:50:00')\nprint(date_1.value) \n"], [], [], ["import torch\n\nn = 4\nreplace = True # Can change\nchoices = torch.rand(4, 3)\nchoices_flat = choices.view(-1)\n\nif replace:\n    index = torch.randint(choices_flat.numel(), (n,))\nelse:\n    index = torch.randperm(choices_flat.numel())[:n]\n\nselect = choices_flat[index]\n"], ["python3 get-pip.py\nsudo apt install python3-pip\n"], ["import string\n\nfor firstchar in string.ascii_lowercase:\n    for secondchar in string.ascii_lowercase:\n        print(firstchar + secondchar)\n"], [], [" csv_writer.writerow(mylist)\n", " csv_writer = csv.writer(csv_file, delimiter=';')\n", "...\nwith open(file, \"w\", newline=\"\") as csv_file:\n    for row in mylist:\n        print(row, file=file)\n...\n", "...\nwith open(file, \"w\", newline=\"\") as csv_file:\n    csv_writer = csv.writer(csv_file, delimiter=';')\n    csv_writer.writerows([elt] for elt in mylist)\n    ...\n"], ["csv_writer.writerows((entry,) for entry in mylist)\n", "import csv with open('some.csv', newline='', encoding='utf-8') as f:\n    reader = csv.reader(f)\n    for row in reader:\n        print(row)\n"], [], [], ["import matplotlib.pyplot as plt\nfrom numpy import *\nepsilon=1e-8\n\ndef f(x):\n   if x<epsilon\n      return 0.5\n\n   return (1-sin(x)/tan(x))/x**2\n   #note: same as (1-cos(x))/x**2\n\nx=arange(0,6,0.01)\ny=vectorize(f)\nplt.plot(x,y(x))\nplt.show()\n"], ["pip install numpy\n", "from numpy import *\ndef f(x):     #these are all the same function using different identities  \n   a = (1-(sin(x)/tan(x)))/(x**2)\n   b = (1-(sin(2*x)/(2*sin(x))))/(x**2)\n   c = (1-((1-((tan(x/2))**2))/(1+(tan(x/2))**2)))/(x**2)\n   d = (sin(x)**2+cos(x)**2-cos(x))/(x**2)\n   e = (sin(x)**2+cos(x)**2-(sin(2*x)/(2*sin(x))))/(x**2)\n   return a, b, c, d, e\nprint(f(float128(1.2e-8)))\n", "(0.5003141275115400736, 0.49956120933620291774, 0.49993766842387149567, 0.49993766842387149567, 0.49956120933620291774)\n"], [], ["sin(x)/x * tan(x/2)/x\n"], [], [], [], ["class Codes:\n    SUCCESS = 200\n    NOT_FOUND = 404\n\ndef handle(retcode):\n    match retcode:\n        case Codes.SUCCESS:\n            print('success')\n        case Codes.NOT_FOUND:\n            print('not found')\n        case _:\n            print('unknown')\n"], ["from pymystem3 import Mystem\nmystem = Mystem()\n    \ndef preprocess_text(text):\n   ...\n   tokens = mystem.lemmatize(text)\n   ...\n   text = \" \".join(tokens)\n   return text\n\ndata_set = Parallel(n_jobs=-1)(delayed(preprocess_text)(article) for article in tqdm(articles))\n", "def preprocess_text(text):\n   ...\n   mystem = Mystem()\n   tokens = mystem.lemmatize(text)\n   ...\n   text = \" \".join(tokens)\n   return text\n"], ["E: Unable to locate package python-pip\n", "vi get-pip.py\n", "ESC then :wq => press Enter\n", "sudo python get-pip.py\n"], [], [], ["x = [True, False, True, False]\ny = [\"a\", \"b\", \"c\", \"d\"]\n\nprint([b for a, b in zip(x, y) if a])\n", ">>> from itertools import compress\n>>> x = [True, False, True, False]\n>>> y = [\"a\", \"b\", \"c\", \"d\"]\n>>> list(compress(y, x))\n['a', 'c']\n"], ["import re\nimport mechanize\n\nbr = mechanize.Browser()\nbr.open(\"http://www.example.com/\")\n# follow second link with element text matching regular expression\nresponse1 = br.follow_link(text_regex=r\"cheese\\s*shop\", nr=1)\nprint(br.title())\nprint(response1.geturl())\nprint(response1.info())  # headers\nprint(response1.read())  # body\n\nbr.select_form(name=\"order\")\n# Browser passes through unknown attributes (including methods)\n# to the selected HTMLForm.\nbr[\"cheeses\"] = [\"mozzarella\", \"caerphilly\"]  # (the method here is __setitem__)\n# Submit current form.  Browser calls .close() on the current response on\n# navigation, so this closes response1\nresponse2 = br.submit()\n"], ["python3.8 -m pip --version\n", "python3.8 -m pip install [package]\n"], ["df.describe()['FeatureName']['mean']\n"], ["def sublist(x):\n    count = 0\n    new = []\n    if 5 in x:\n        while(x[count] != 5):\n            new.append(x[count])\n            count += 1\n        return new\n        \n    else:\n        return x\n"], [], ["predictions = np.array([])\nlabels =  np.array([])\nfor x, y in test_ds:\n  predictions = np.concatenate([predictions, **np.argmax**(model.predict(x), axis = -1)])\n  labels = np.concatenate([labels, np.argmax(y.numpy(), axis=-1)])\n"], ["def first_and_last(message):\n    if not message:\n        return True\n    elif (message[0] == message[-1]):\n        return True\n    elif (message[0] != message[-1]):\n        return False\n\n\nprint(first_and_last(\"else\"))\nprint(first_and_last(\"tree\"))\nprint(first_and_last(\"\"))\n"], ["elems = driver.find_elements_by_css_selector(\".sc-eYdvao.kvdWiq [href]\")\nlinks = [elem.get_attribute('href') for elem in elems]\n", "elems = WebDriverWait(driver,10).until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, \".sc-eYdvao.kvdWiq [href]\")))\n"], ["from bs4 import BeautifulSoup\n\ndef selected_option(select):\n    option = select.find(\"option\", selected=True)\n    if option: \n        return option['value']\n\n# tag name => how to extract its value\ntags = {  \n    \"input\": lambda t: t['value'],\n    \"textarea\": lambda t: t.text,\n    \"select\": selected_option\n}\n\n\ndef parse_form(html):\n    soup = BeautifulSoup(html, 'html.parser')\n    form = soup.find(\"form\")\n    return {\n        e['name']: tags[e.name](e)\n        for e in form.find_all(tags.keys())\n    }\n", "{\n    \"foo\": \"bar\",\n    \"area\": \"long text\",\n    \"your-choice\": \"a\"\n}\n"], ["def parse_form(content):\n    import lxml.html\n    tree = lxml.html.fromstring(content)\n    return dict(tree.forms[0].fields)\n"], ["from bs4 import BeautifulSoup\n\n\ndef parse_form(content):\n    data = {}\n    html = BeautifulSoup(content, features=\"lxml\")\n    form = html.find('form', recursive=True)\n    fields = form.find_all(('input', 'select', 'textarea'))\n    for field in fields:\n        name = field.get('name')\n        if name:\n            if field.name == 'input':\n                value = field.get('value')\n            elif field.name == 'select':\n                try:\n                    value = field.find_all('option', selected=True)[0].get('value')\n                except:\n                    value = None\n            elif field.name == 'textarea':\n                value = field.text\n            else:\n                # checkbox ? radiobutton ? file ? \n                continue\n            data[name] = value\n    return data\n"], ["pip3 install cmake \npip3 install dlib\n"], [], [], [], ["import cv2\ncv2.__version__\n"], ["my_list = []\nn = int(input(\"Size of list: \"))\n\nfor i in range(n):\n    my_list.append(int(input(\"Enter value: \")))\n\nfiltered_list = list(filter(lambda x: x % 5 == 0, my_list))\n\nprint(filtered_list)\n"], ["my_list = []\nn = int(input(\"Size of list: \"))\n\nfor i in range(n):\n    my_list.append(int(input(\"Enter value: \")))\n\nmy_list2=my_list.copy() #create a copy of my_list\n\nfor i in my_list2: #loop through my_list2\n    if i % 5 != 0:\n        continue\n    else: \n        my_list.remove(i)\n\n\nprint(my_list)\n"], [], [], [], [], ["def is_palindrome(input_string):\n    new_string = \"\"\n    reverse_string = \"\"\n    \n    for word in input_string:\n        if word != \" \":\n            new_string = new_string.strip().lower() + word\n            reverse_string = word + reverse_string.strip().lower()\n    # Compare the strings\n    if new_string == reverse_string:\n        return True\n    return False\n\nprint(is_palindrome(\"Never Odd or Even\")) # Should be True\nprint(is_palindrome(\"abc\")) # Should be False\nprint(is_palindrome(\"kayak\")) # Should be True\n"], ["import xlwings as xw\nimport pandas as pd\n\nfilename = \"test.xlsx\"\ndf = pd.read_excel(filename, \"Town_names\")\n\n# Do your modifications of the worksheet here. For example, the following line \"df * 2\".\ndf = df * 2 \n\napp = xw.App(visible=False)\nwb = xw.Book(filename)\nws = wb.sheets[\"Town_names\"]\n\nws.clear()\nws[\"A1\"].options(pd.DataFrame, header=1, index=False, expand='table').value = df\n\n# If formatting of column names and index is needed as xlsxwriter does it, the following lines will do it.\nws[\"A1\"].expand(\"right\").api.Font.Bold = True\nws[\"A1\"].expand(\"down\").api.Font.Bold = True\nws[\"A1\"].expand(\"right\").api.Borders.Weight = 2\nws[\"A1\"].expand(\"down\").api.Borders.Weight = 2\n\nwb.save(filename)\napp.quit()\n"], [], ["def is_palindrome(input_string):\n\n    # We'll create two strings, to compare them\n    new_string = \"\"\n    reverse_string = \"\"\n    # Traverse througenter code hereh each letter of the input string\n    for letter in input_string.strip().lower():\n        # Add any non-blank letters to the \n        # end of one string, and to the front\n        # of the other string. \n        if letter!=\" \":\n            new_string = new_string+letter\n            reverse_string = letter+reverse_string\n    # Compare the strings\n    if new_string==reverse_string:\n        return True\n    return False\n", "print(is_palindrome(\"Never Odd or Even\")) # Should be True\n\nprint(is_palindrome(\"abc\")) # Should be False\n\nprint(is_palindrome(\"kayak\")) # Should be True\n"], ["import argparse\n\nimport tensorflow as tf\nfrom google.protobuf import text_format\nfrom object_detection.protos import pipeline_pb2\n\ndef parse_arguments():                                                                                                                                                                                                                                                \n    parser = argparse.ArgumentParser(description='')                                                                                                                                                                                                                  \n    parser.add_argument('pipeline')                                                                                                                                                                                                                                   \n    parser.add_argument('output')                                                                                                                                                                                                                                     \n    return parser.parse_args()                                                                                                                                                                                                                                        \n\n\ndef main():                                                                                                                                                                                                                                                           \n    args = parse_arguments()                                                                                                                                                                                                                                          \n    pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()                                                                                                                                                                                                          \n\n    with tf.io.gfile.GFile(args.pipeline, \"r\") as f:                                                                                                                                                                                                                     \n        proto_str = f.read()                                                                                                                                                                                                                                          \n        text_format.Merge(proto_str, pipeline_config)                                                                                                                                                                                                                 \n\n    pipeline_config.model.ssd.image_resizer.fixed_shape_resizer.height = 300                                                                                                                                                                                          \n    pipeline_config.model.ssd.image_resizer.fixed_shape_resizer.width = 300                                                                                                                                                                                           \n\n    config_text = text_format.MessageToString(pipeline_config) \n                                                                                                                                                                                                   \n    with tf.io.gfile.GFile(args.output, \"wb\") as f:                                                                                                                                                                                                                \n        f.write(config_text)                                                                                                                                                                                                                                          \n\nif __name__ == '__main__':                                                                                                                                                                                                                                            \n    main() \n"], ["testData = tf.keras.preprocessing.image_dataset_from_directory(\n    dataDirectory,\n    labels='inferred',\n    label_mode='categorical',\n    seed=324893,\n    image_size=(height,width),\n    batch_size=32)\n\n\npredictions = np.array([])\nlabels =  np.array([])\nfor x, y in testData:\n  predictions = np.concatenate([predictions, model.predict_classes(x)])\n  labels = np.concatenate([labels, np.argmax(y.numpy(), axis=-1)])\n\ntf.math.confusion_matrix(labels=labels, predictions=predictions).numpy()\n", "Found 4 files belonging to 2 classes.\narray([[2, 0],\n       [2, 0]], dtype=int32)\n"], [], ["pip install tensorflow-gpu==2.0.0\n", "I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_100.dll\n"], ["from django.db import models\nfrom django.db.models import Sum\nfrom django.db.models.functions import Coalesce\n\nclass AuthorManager(models.Manager):\n    def get_queryset(self):\n        return AuthorQuerySet(self.model, using=self._db)\n    \n    def annotate_with_copies_sold(self):\n        return self.get_queryset().annotate_with_copies_sold()\n\nclass AuthorQuerySet(models.QuerySet):\n    def annotate_with_copies_sold(self):\n        # Write your solution here\n        return self.annotate(copies_sold=Coalesce(Sum('books__copies_sold'), 0))\n\n\nclass Author(models.Model):\n    # Make sure this manager is available.\n    objects = AuthorManager()\n    # objects = models.Manager.from_queryset(AuthorQuerySet)()\n    first_name = models.CharField(max_length=30)\n    last_name = models.CharField(max_length=30)\n\n\nclass Book(models.Model):\n    title = models.CharField(max_length=30)\n    copies_sold = models.PositiveIntegerField()\n    author = models.ForeignKey(Author, on_delete=models.CASCADE, related_name='books')\n    enter code here\n"], [], [], ["for firstchar in range(97, 123):\n    for secondchar in range(97, 123):\n          print(chr(firstchar) + chr(secondchar))\n"], ["word_list = ['WELCOME']\ndouble_letters = []\nfor word in word_list:\n    for i,j in enumerate(word):\n        x = word[i:i+2]\n        if len(x) == 2:\n            double_letters.append(x)\nprint(double_letters)\n"], ["from string import ascii_lowercase as lowercase_letters\n\nfor first_letter in lowercase_letters:\n    for second_letter in lowercase_letters:\n        print(first_letter + second_letter)\n"], [], ["pip install tf-nightly-gpu\n", "I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudart64_110.dll\n"], [], ["curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py\npython3.8 get-pip.py\n"], [], ["def sublist(a):\n    i=0;\n    lst=[];\n    while(i<len(a) and a[i]!=5):\n        lst.append(a[i]);\n        i+=1;\n    return lst;\n"], ["from bisect import bisect_left\n\ndef find_words(board, words, x, y, prefix, path):\n    ' Find words that can be generated starting at position x, y '\n    \n    # Base case\n    # find if current word prefix is in list of words\n    found = bisect_left(words, prefix)  # can use binary search since words are sorted\n    if found >= len(words):\n        return\n   \n    if words[found] == prefix:\n        yield prefix, path              # Prefix in list of words\n\n    # Give up on path if what we found is not even a prefix\n    # (there is no point in going further)\n    if len(words[found]) < len(prefix) or words[found][:len(prefix)] != prefix:\n        return\n    \n    # Extend path by one lettter in boarde\n    # Since can only go right and down \n    # No need to worry about same cell occurring multiple times in a given path\n    for adj_x, adj_y in [(0, 1), (1, 0)]:\n        x_new, y_new = x + adj_x, y + adj_y\n        if x_new < len(board) and y_new < len(board[0]):\n            yield from find_words(board, words, x_new, y_new, \\\n                                  prefix + board[x_new][y_new], \\\n                                  path + [(x_new, y_new)])\n     \ndef check_all_starts(board, words):\n    ' find all possilble paths through board for generating words '\n    # check each starting point in board\n    for x in range(len(board)):\n        for y in range(len(board[0])):\n            yield from find_words(board, words, x, y, board[x][y], [(x, y)])\n   \ndef find_non_overlapping(choices, path):\n    ' Find set of choices with non-overlapping paths '\n    if not choices:\n        # Base case\n        yield path\n    else:\n        word, options = choices[0]\n\n        for option in options:\n            set_option = set(option)\n            \n            if any(set_option.intersection(p) for w, p in path):\n                # overlaps with path\n                continue\n            else:\n                yield from find_non_overlapping(choices[1:], path + [(word, option)])\n        \n    \ndef solve(board, words):\n    ' Solve for path through board to create words '\n    words.sort()\n    \n    # Get choice of paths for each word\n    choices = {}\n    for word, path in check_all_starts(board, words):\n        choices.setdefault(word, []).append(path)\n    \n    # Find non-intersecting paths (i.e. no two words should have a x, y in common)\n    if len(choices) == len(words):\n        return next(find_non_overlapping(list(choices.items()), []), None)\n    \n", "from pprint import pprint as pp\n\nwords = [ \"dog\", \"dogma\", \"cat\" ]\nboard = [\n            ['d', 'r', 'd', 'o', 'r', 's'],\n            ['o', 'b', 'i', 'g', 'n', 'c'],\n            ['g', 'f', 'n', 'm', 't', 'a'],\n            ['x', 's', 'i', 'a', 'n', 't']]\n\npp(solve(board, words))\n        \n", "Test 1\n[('dog', [(0, 0), (1, 0), (2, 0)]),\n ('dogma', [(0, 2), (0, 3), (1, 3), (2, 3), (3, 3)]),\n ('cat', [(1, 5), (2, 5), (3, 5)])]\n", "words = [\"by\",\"bat\"] \nboard = [ ['b', 'a', 't'], \n          ['y', 'x', 'b'], \n          ['x', 'x', 'y'], ] \n\npp(solve(board, words))\n", "Test 2\n[('bat', [(0, 0), (0, 1), (0, 2)]), \n ('by', [(1, 2), (2, 2)])]\n"], ["{\n    'd': [(0, 0), (0, 2)],\n    'r': [(0, 1), (0, 4)],\n    'o': [(0, 3), (1, 0)],\n    's': [(0, 5), (3, 1)],\n    'b': [(1, 1)],\n    'i': [(1, 2), (3, 2)],\n    'g': [(1, 3), (2, 0)],\n    'n': [(1, 4), (2, 2), (3, 4)],\n    'c': [(1, 5)],\n    'f': [(2, 1)],\n    'm': [(2, 3)],\n    't': [(2, 4), (3, 5)],\n    'a': [(2, 5), (3, 3)],\n    'x': [(3, 0)]\n}\n", "[\n    [\n         [(0, 0), (1, 0), (2, 0)], # dog\n         [(0, 2), (0, 3), (1, 3)]\n    ],\n    [\n         [(0, 2), (0, 3), (1, 3), (2, 3), (3, 3)] # dogma\n    ],\n    [\n         [(1, 5), (2, 5), (3, 5)] # cat\n    ]\n]\n", "[\n    [(0, 0), (1, 0), (2, 0)], # dog\n    [(0, 2), (0, 3), (1, 3), (2, 3), (3, 3)], # dogma\n    [(1, 5), (2, 5), (3, 5)] # cat\n]\n"], [], ["def findWords(grid, words):\n    # Regular old dfs through the grid, we only go right or down\n    def dfs(row, col, path, idx):\n        if idx == len(word):\n            if word in all_paths:\n                all_paths[word].append(list(path))\n            else:\n                all_paths[word] = [list(path)]\n        else:\n            if row + 1 < len(grid):\n                if grid[row+1][col] == word[idx]:\n                    path.append((row+1, col))\n                    dfs(row+1, col, path, idx+1)\n                    path.pop()\n            if col + 1 < len(grid[0]):\n                if grid[row][col+1] == word[idx]:\n                    path.append((row, col+1))\n                    dfs(row, col+1, path, idx+1)\n                    path.pop()\n\n    # For each word, find all possible paths through the grid to spell the word\n    # Each path is a collection of coordinates as is desired from the function\n    # Paths are indexed by word and stored in a list in a dictionary\n    all_paths = {}\n    for row in range(len(grid)):\n        for col in range(len(grid[0])):\n            for word in words:\n                if grid[row][col] == word[0]:\n                    dfs(row, col, [(row, col)], 1)\n\n    # Try all possible combinations of paths from each letter\n    def dfs2(idx):\n        if idx == len(words):\n            return True\n\n        word = words[idx]\n        for path in all_paths[word]:\n            for loc in path:\n                if loc in seen:\n                    return False\n            for loc in path:\n                seen.add(loc)\n            if dfs2(idx+1):\n                retlst.append(path)\n                return True\n            else:\n                for loc in path:\n                    seen.remove(loc)\n        return False\n\n    # Backtrack through possible combinations\n    seen = set([])\n    retlst = []\n    dfs2(0)\n    return retlst\n"], ["def is_palindrome(input_string):\n    # We'll create two strings, to compare them\n    new_string = input_string.replace(\" \", \"\")\n    new_string = new_string.lower()\n    reverse_string = new_string[::-1]\n    reverse_string = reverse_string.lower()\n    # Traverse through each letter of the input string\n    if new_string == reverse_string:\n        return True\n    return False\n\n\nprint(is_palindrome(\"Never Odd or Even\"))  # Should be True\nprint(is_palindrome(\"abc\"))  # Should be False\nprint(is_palindrome(\"kayak\"))  # Should be True\n"], [], ["Error: Could not import PILLOW_VERSION from PIL\nOS: Linux 18.0 (LUBUNTU)\nPython: 3.6\n", "pillow: 7.0.0-py36hb39fc2d_0 --> 6.1.0-py36h34e0f95_0\ncommand: conda install pillow=6.1\n"], ["def sublist(lst):\n\n\n    output_list = []\n    for i in lst:\n        while i==5:\n            return output_list\n        output_list.append(i)\n    return output_list\n"], ["sudo apt install python3.8\nsudo apt install python3.8-distutils\n\nwget https://bootstrap.pypa.io/get-pip.py\nsudo python3.8 get-pip.py\n"], [], ["conda create -n YOURENVNAME python=3.6 // 3.6> incompatible with keras\nconda activate YOURENVNAME\nconda install tensorflow-gpu\nconda install -c anaconda keras\nconda install -c anaconda scikit-learn\nconda install matplotlib\n", "2020-02-23 13:31:44.910213: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'cudart64_101.dll'; dlerror: cudart64_101.dll not found\n\n2020-02-23 13:31:44.925815: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll\n\n2020-02-23 13:31:44.941384: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_10.dll\n\n2020-02-23 13:31:44.947427: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_10.dll\n\n2020-02-23 13:31:44.965893: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_10.dll\n\n2020-02-23 13:31:44.982990: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_10.dll\n\n2020-02-23 13:31:44.990036: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'cudnn64_7.dll'; dlerror: cudnn64_7.dll not found\n"], [], ["<p class=\"sc-eYdvao kvdWiq\">\n    <a href=\"https://www.iproperty.com.my/property/setia-eco-park/sale-1653165/\">Shah Alam Setia Eco Park, Setia Eco Park</a>\n</p>\n", "print(driver.find_element_by_css_selector(\"p.sc-eYdvao.kvdWiq > a\").get_attribute('href'))\n", "print(driver.find_element_by_xpath(\"//p[@class='sc-eYdvao kvdWiq']/a\").get_attribute('href'))\n", "print([my_elem.get_attribute(\"href\") for my_elem in driver.find_elements_by_css_selector(\"p.sc-eYdvao.kvdWiq > a\")])\n", "print([my_elem.get_attribute(\"href\") for my_elem in driver.find_elements_by_xpath(\"//p[@class='sc-eYdvao kvdWiq']/a\")])\n", "print(WebDriverWait(driver, 10).until(EC.visibility_of_element_located((By.CSS_SELECTOR, \"p.sc-eYdvao.kvdWiq > a\"))).get_attribute('href'))\n", "print(WebDriverWait(driver, 10).until(EC.visibility_of_element_located((By.XPATH, \"//p[@class='sc-eYdvao kvdWiq']/a\"))).get_attribute('href'))\n", "print([my_elem.get_attribute(\"innerHTML\") for my_elem in WebDriverWait(driver, 20).until(EC.visibility_of_all_elements_located((By.CSS_SELECTOR, \"p.sc-eYdvao.kvdWiq > a\")))])\n", "print([my_elem.get_attribute(\"innerHTML\") for my_elem in WebDriverWait(driver, 20).until(EC.visibility_of_all_elements_located((By.XPATH, \"//p[@class='sc-eYdvao kvdWiq']/a\")))])\n", "from selenium.webdriver.support.ui import WebDriverWait     \nfrom selenium.webdriver.common.by import By     \nfrom selenium.webdriver.support import expected_conditions as EC\n"], [" >>> df\n       A      B\n0      1      1\n1    NaN      6\n2    NaN    NaN\n3      2      2\n4    NaN    NaN\n5      4      4\n6   some   some\n7  value  other\n", ">>> df.A.str.isnumeric()\n0     True\n1      NaN\n2      NaN\n3     True\n4      NaN\n5     True\n6    False\n7    False\nName: A, dtype: object\n\n# df.B.str.isnumeric()\n", ">>> df\n       A   B\n0      1   1\n1    NaN   6\n2    NaN  33\n3      2   2\n4    NaN  22\n5      4   4\n6   some  66\n7  value  11\n", ">>> df.apply(lambda x: x.str.isnumeric())\n       A     B\n0   True  True\n1    NaN  True\n2    NaN  True\n3   True  True\n4    NaN  True\n5   True  True\n6  False  True\n7  False  True\n", ">>> df\n   num  rating    name  age\n0    0    80.0  shakir   33\n1    1   -22.0   rafiq   37\n2    2   -10.0     dev   36\n3  num     1.0   suraj   30\n", ">>> df._get_numeric_data()\n   rating  age\n0    80.0   33\n1   -22.0   37\n2   -10.0   36\n3     1.0   30\n", ">>> df.select_dtypes(include=['int64','float64']) # choosing int & float\n   rating  age\n0    80.0   33\n1   -22.0   37\n2   -10.0   36\n3     1.0   30\n\n>>> df.select_dtypes(include=['int64'])  # choose int\n   age\n0   33\n1   37\n2   36\n3   30\n"], ["conda activate my_env_name\n"], ["import tensorflow as tf\ntf.config.experimental.list_physical_devices('GPU')\n"], [], [], [], ["$ pip uninstall pillow\n$ CC=\"cc -mavx2\" pip install -U --force-reinstall pillow-simd\n"], [], ["combined = torch.cat((t1, t2))\nuniques, counts = combined.unique(return_counts=True)\ndifference = uniques[counts == 1]\nintersection = uniques[counts > 1]\n"], [], ["    new_string = new_string+i\n    reverse_string = i+reverse_string\n", "# We'll create two strings, to compare them\n\ninput_string = input_string.lower()\nnew_string = \"\"\nreverse_string = \"\"\n# Traverse through each letter of the input string\nfor i in input_string:\n    # Add any non-blank letters to the \n    # end of one string, and to the front\n    # of the other string. \n    if i !=\" \":\n        new_string = new_string+i\n        reverse_string = i+reverse_string\n# Compare the strings\nif new_string == reverse_string:\n    return True\nreturn False\n\nprint(is_palindrome(\"Never Odd or Even\")) # Should be True\nprint(is_palindrome(\"abc\")) # Should be False\nprint(is_palindrome(\"kayak\")) # Should be True\n", " True \n False\n True\n"], ["def sublist(x):\n    accum = 0\n    sub = []\n    while accum < len(x):\n        if x[accum]== 5:\n            return sub\n        else:\n            sub.append(x[accum])\n        accum = accum +1\n    return sub\n\nx = [1, 3, 4, 5,6,7,8]\nprint(sublist(x))\n"], [], ["def is_palindrome(input_string):\n    # We'll create two strings, to compare them\n    new_string = \"\"\n    reverse_string = \"\"\n    # Traverse through each letter of the input string\n    for char in input_string:\n        # Add any non-blank letters to the \n        # end of one string, and to the front\n        # of the other string.\n        if char !=\" \":\n            new_string +=char.lower() \n\n            reverse_string =char.lower()+reverse_string\n\n    # Compare the strings\n    if new_string==reverse_string:\n        return True\n    return False\n\nprint(is_palindrome(\"Never Odd or Even\")) # Should be True\nprint(is_palindrome(\"abc\")) # Should be False\nprint(is_palindrome(\"kayak\")) # Should be True\n"], ["pictures[torch.randint(len(pictures), (10,))]  \n", "indices = torch.randperm(len(pictures))[:10]\n\npictures[indices]\n"], [], ["ls /bin/python*\n", "sudo apt-get install python3-pip\n"], [], [], ["import pandas as pd\nimport matplotlib.pyplot as plt\nfrom matplotlib.ticker import PercentFormatter\n\n\ndef _plot_pareto_by(df_, group_by, column):\n\n    df = df_.groupby(group_by)[column].sum().reset_index()\n    df = df.sort_values(by=column,ascending=False)\n\n    df[\"cumpercentage\"] = df[column].cumsum()/df[column].sum()*100\n\n\n    fig, ax = plt.subplots(figsize=(20,5))\n    ax.bar(df[group_by], df[column], color=\"C0\")\n    ax2 = ax.twinx()\n    ax2.plot(df[group_by], df[\"cumpercentage\"], color=\"C1\", marker=\"D\", ms=7)\n    ax2.yaxis.set_major_formatter(PercentFormatter())\n\n    ax.tick_params(axis=\"y\", colors=\"C0\")\n    ax2.tick_params(axis=\"y\", colors=\"C1\")\n\n    for tick in ax.get_xticklabels():\n        tick.set_rotation(45)\n    plt.show()\n"], ["if 'Authorization' in headers:\n    # If we get redirected to a new host, we should strip out any\n    # authentication headers.\n    original_parsed = urlparse(response.request.url)\n    redirect_parsed = urlparse(url)\n\n    if (original_parsed.hostname != redirect_parsed.hostname):\n        del headers['Authorization']\n", "from requests import Session\n\nclass NoRebuildAuthSession(Session):\n    def rebuild_auth(self, prepared_request, response):\n        \"\"\"\n        No code here means requests will always preserve the Authorization\n        header when redirected.\n        Be careful not to leak your credentials to untrusted hosts!\n        \"\"\"\n\nsession = NoRebuildAuthSession()\nresponse = session.post('https://myserver.com/endpoint', headers=headers, data=data)\n"], [], [], [], [], [], [], ["def replace_ending(sentence, old, new):\n    if sentence.endswith(old):\n        return sentence[:-len(old)] + new\n    return sentence\n"], [], [], [], ["def is_palindrome(input_string):\n    # We'll create two strings, to compare them\n    new_string = \"\"\n    reverse_string = \"\"\n    # Traverse through each letter of the input string\n    for word in input_string:\n        # Add any non-blank letters to the \n        # end of one string, and to the front\n        # of the other string. \n        word = word.lower()\n        if word != \" \":\n            new_string = new_string + word\n            reverse_string = word + reverse_string\n    # Compare the strings\n    if new_string == reverse_string:\n        return True\n    return False\n\nprint(is_palindrome(\"Never Odd or Even\")) # Should be True\nprint(is_palindrome(\"abc\")) # Should be False\nprint(is_palindrome(\"kayak\")) # Should be True\n"], ["y_pred = estimator.predict(X)\n    cm = confusion_matrix(y_true, y_pred, sample_weight=sample_weight,\n                          labels=labels, normalize=normalize)\n", "import seaborn as sns\n\ncm = confusion_matrix(y_true, y_pred)\nf = sns.heatmap(cm, annot=True)\n"], [], [], [], [], ["\nnum = [1, 2, 3, 17, 1, 3, 5, 4, 3, 7, 5, 6, 9]\nnew = []\ndef check_nums(x):\n    idx = 0\n    while idx < len(x) and x[idx] != 7:\n        print(idx)\n        new.append(x[idx])\n        idx += 1\n    print(idx)\n    return new\nprint(check_nums(num))\n\n"], ["tensor([ 1, 24])\ntensor([ 9, 12,  5])\n"], ["def is_palindrome(input_string):\n    # We'll create two strings, to compare them\n    new_string = \"\"\n    reverse_string = \"\"\n    # Traverse through each letter of the input string\n    for letter in input_string.strip():\n        # Add any non-blank letters to the \n        # end of one string, and to the front\n        # of the other string. \n        new_string = new_string+letter.replace(\" \",\"\")\n        reverse_string = letter.replace(\" \",\"\")+reverse_string\n    # Compare the strings\n    if new_string.lower() == reverse_string.lower():\n        return True\n    return False\n\nprint(is_palindrome(\"Never Odd or Even\")) # Should be True\nprint(is_palindrome(\"abc\")) # Should be False\nprint(is_palindrome(\"kayak\")) # Should be True\n"], ["def is_palindrome(input_string):\n    # We'll create two strings, to compare them\n    new_string = \"\"\n    reverse_string = \"\"\n    # Traverse through each letter of the input string\n    for letter in input_string.strip():\n        # Add any non-blank letters to the \n        # end of one string, and to the front\n        # of the other string. \n        if letter !=' ':\n            new_string = new_string+letter\n            reverse_string = letter+reverse_string\n    # Compare the strings\n    if new_string.lower() == reverse_string.lower():\n        return True\n    return False\n\nprint(is_palindrome(\"Never Odd or Even\")) # Should be True\nprint(is_palindrome(\"abc\")) # Should be False\nprint(is_palindrome(\"kayak\")) # Should be True\n"], [], ["bearer_token = str(base64.b64encode(access_token.encode()), \"utf8\")\nheaders = {'Content-Type': 'application/json', 'Authorization': 'Bearer {}'.format(bearer_token)}\n"], [], ["class MyAuth(requests.auth.AuthBase):\ndef __init__(self, bearer_token):\n    self.username = None\n    self.bearer_token = bearer_token\n\ndef __call__(self, r):\n    r.headers['Authorization'] = self.bearer_token\n    return r\n", "headers = {'Content-Type': 'application/json'}\n\ndata = '{\"FirstName\" : \"Jane\", \"LastName\" : \"Smith\"}'\n\nresponse = requests.post('https://myserver.com/endpoint', headers=headers, auth=MyAuth(bearer_token), data=data)\n"], [], [], [">>> from pyspark.sql.functions import *\n>>> df.show()\n+---+----+----+-------+\n| id|name| sal|Address|\n+---+----+----+-------+\n|  1| ABC|5000|     US|\n|  2| DEF|4000|     UK|\n|  3| GHI|3000|    JPN|\n|  4| JKL|4500|    CHN|\n+---+----+----+-------+\n\n>>> df1.show()\n+---+----+----+-------+\n| id|name| sal|Address|\n+---+----+----+-------+\n|  1| ABC|5000|     US|\n|  2| DEF|4000|    CAN|\n|  3| GHI|3500|    JPN|\n|  4|JKLM|4800|    CHN|\n+---+----+----+-------+\n\n>>> df2 = df.select([col(c).alias(\"x_\"+c) for c in df.columns])\n>>> df3 = df1.join(df2, col(\"id\") == col(\"x_id\"), \"left\")\n\n //udf declaration \n\n>>> def CheckMatch(Column,r):\n...     check=''\n...     ColList=Column.split(\",\")\n...     for cc in ColList:\n...             if(r[cc] != r[\"x_\" + cc]):\n...                     check=check + \",\" + cc\n...     return check.replace(',','',1).split(\",\")\n\n>>> CheckMatchUDF = udf(CheckMatch)\n\n//final column that required to select\n>>> finalCol = df1.columns\n>>> finalCol.insert(len(finalCol), \"column_names\")\n\n>>> df3.withColumn(\"column_names\", CheckMatchUDF(lit(','.join(df1.columns)),struct([df3[x] for x in df3.columns])))\n       .select(finalCol)\n       .show()\n+---+----+----+-------+------------+\n| id|name| sal|Address|column_names|\n+---+----+----+-------+------------+\n|  1| ABC|5000|     US|          []|\n|  2| DEF|4000|    CAN|   [Address]|\n|  3| GHI|3500|    JPN|       [sal]|\n|  4|JKLM|4800|    CHN| [name, sal]|\n+---+----+----+-------+------------+\n"], ["import pyspark.sql.functions as f\n\ndf1 = spark.read.option(\"header\", \"true\").csv(\"test1.csv\")\ndf2 = spark.read.option(\"header\", \"true\").csv(\"test2.csv\")\n\ncolumns = df1.columns\ndf3 = df1.alias(\"d1\").join(df2.alias(\"d2\"), f.col(\"d1.id\") == f.col(\"d2.id\"), \"left\")\n\nfor name in columns:\n    df3 = df3.withColumn(name + \"_temp\", f.when(f.col(\"d1.\" + name) != f.col(\"d2.\" + name), f.lit(name)))\n\n\ndf3.withColumn(\"column_names\", f.concat_ws(\",\", *map(lambda name: f.col(name + \"_temp\"), columns))).select(\"d1.*\", \"column_names\").show()\n", "val df1 = spark.read.option(\"header\", \"true\").csv(\"test1.csv\")\nval df2 = spark.read.option(\"header\", \"true\").csv(\"test2.csv\")\n\nval columns = df1.columns\nval df3 = df1.alias(\"d1\").join(df2.alias(\"d2\"), col(\"d1.id\") === col(\"d2.id\"), \"left\")\n\ncolumns.foldLeft(df3) {(df, name) => df.withColumn(name + \"_temp\", when(col(\"d1.\" + name) =!= col(\"d2.\" + name), lit(name)))}\n  .withColumn(\"column_names\", concat_ws(\",\", columns.map(name => col(name + \"_temp\")): _*))\n  .show(false)\n", "+---+----+----+-------+------------+\n|id |name|sal |Address|column_names|\n+---+----+----+-------+------------+\n|1  |ABC |5000|US     |            |\n|2  |DEF |4000|UK     |Address     |\n|3  |GHI |3000|JPN    |sal         |\n|4  |JKL |4500|CHN    |name,sal    |\n+---+----+----+-------+------------+\n"], ["df['col1'] = np.where(df['col1'] < df['col2'], df['col3'], df['col1'])\n"], ["df['col1'] = df.apply(lambda c: c['col3'] if c['col1'] < 2 else c['col1'], axis=1)\n"], ["df.loc[df[\"col1\"] < 2, \"col1\"] = df[\"col3\"]\n"], ["df['col1'] = df.apply(lambda x: x['col3'] if x['col1'] < x['col2'] else x['col1'], axis=1)\n"], [], ["if not message:\n", "def first_and_last(message):\n        if not message:\n            return True\n        if (message[0] == message[3]):\n            return True\n        elif (message[0] != message[3]):\n            return False\n\n\nprint(first_and_last(\"else\"))\nprint(first_and_last(\"tree\"))\nprint(first_and_last(\"\"))\n"], ["def first_and_last(message):\n    if not message:\n        return True\n    elif (message[0] == message[-1]):\n        return True\n    else:\n        return False\n\n\nprint(first_and_last(\"else\")) # Returns True\nprint(first_and_last(\"tree\")) # Returns False\nprint(first_and_last(\"\")) # Returns True\n"], ["def first_and_last(message):\nif not message:\n    return False\nelse: return True\n\n\nprint(first_and_last(\"else\")) #True\nprint(first_and_last(\"tree\")) #True\nprint(first_and_last(\"\")) #False\n"], ["def first_and_last(message):\n    if not message:\n        return True\n    return message[0] == message[-1]\n", "def first_and_last(message):\n    return not message or message[0] == message[-1]\n"], [], ["### read data from a Peaktech 1337 Oscilloscope (OWON)\nimport usb.core\nimport usb.util\n\ndev = usb.core.find(idVendor=0x5345, idProduct=0x1234)\n\nif dev is None:\n    raise ValueError('Device not found')\nelse:\n    print(dev)\n    dev.set_configuration()\n\ndef send(cmd):\n    # address taken from results of print(dev):   ENDPOINT 0x3: Bulk OUT\n    dev.write(3,cmd)\n    # address taken from results of print(dev):   ENDPOINT 0x81: Bulk IN\n    result = (dev.read(0x81,100000,1000))\n    return result\n\ndef get_id():\n    return send('*IDN?').tobytes().decode('utf-8')\n\ndef get_data(ch):\n    # first 4 bytes indicate the number of data bytes following\n    rawdata = send(':DATA:WAVE:SCREen:CH{}?'.format(ch))\n    data = []\n    for idx in range(4,len(rawdata),2):\n        # take 2 bytes and convert them to signed integer using \"little-endian\"\n        point = int().from_bytes([rawdata[idx], rawdata[idx+1]],'little',signed=True)\n        data.append(point/4096)  # data as 12 bit\n    return data\n\ndef get_header():\n    # first 4 bytes indicate the number of data bytes following\n    header = send(':DATA:WAVE:SCREen:HEAD?')\n    header = header[4:].tobytes().decode('utf-8')\n    return header\n\ndef save_data(ffname,data):\n    f = open(ffname,'w')\n    f.write('\\n'.join(map(str, data)))\n    f.close()\n\nprint(get_id())\nheader = get_header()\ndata = get_data(1)\nsave_data('Osci.dat',data)\n### end of code\n"], [], [], ["main.createOrReplaceTempView(\"table_name\")\n\nnew_cols_select = \", \".join([\"MAIN_COL.\" + col + \" as pre_\" + col for col in spark.sql(\"select MAIN_COL.* from table_name\").columns])\n\nnew_df = spark.sql(f\"select {new_cols_select} from table_name\")\n"], ["def read(self, endpoint, size_or_buffer, timeout = None):\n    r\"\"\"Read data from the endpoint.\n    This method is used to receive data from the device. The endpoint\n    parameter corresponds to the bEndpointAddress member whose endpoint\n    you want to communicate with. The size_or_buffer parameter either\n    tells how many bytes you want to read or supplies the buffer to\n    receive the data (it *must* be an object of the type array).\n    The timeout is specified in miliseconds.\n    If the size_or_buffer parameter is the number of bytes to read, the\n    method returns an array object with the data read. If the\n    size_or_buffer parameter is an array object, it returns the number\n    of bytes actually read.\n    \"\"\"\n"], ["import pip._internal.operations.freeze\n_ = pip._internal.operations.freeze.get_installed_distributions()\nprint(sorted([\"%s==%s\" % (i.key, i.version) for i in _])[:10])\n['absl-py==0.7.1',\n 'aiml==0.9.2',\n 'aio-utils==0.0.1',\n 'aiocache==0.10.1',\n 'aiocontextvars==0.2.2',\n 'aiocqhttp==0.6.7',\n 'aiodns==2.0.0',\n 'aiofiles==0.4.0',\n 'aiohttp-proxy==0.1.1',\n 'aiohttp==3.6.2']\n"], ["!pip freeze\n"], [], ["!pip list\n"], [], ["from django.db import models\nfrom django.db.models import Sum\nfrom django.db.models.functions import Coalesce\n\n\nclass AuthorManager(models.Manager):\n    def get_queryset(self):\n        return AuthorQuerySet(self.model, using=self._db)\n\n    def annotate_with_copies_sold(self):\n        return self.get_queryset().annotate_with_copies_sold()\n\n\nclass AuthorQuerySet(models.QuerySet):\n    def annotate_with_copies_sold(self):\n        return self.annotate(copies_sold=Sum('books__copies_sold'))\n\n\nclass Author(models.Model):\n    objects = AuthorManager()\n    first_name = models.CharField(max_length=30)\n    last_name = models.CharField(max_length=30)\n\n\nclass Book(models.Model):\n    title = models.CharField(max_length=30)\n    copies_sold = models.PositiveIntegerField()\n    author = models.ForeignKey(Author, on_delete=models.CASCADE, related_name='books')\n", "author_total_books = Author.objects.total_copies_sold().first()\n", "author_books = Author.objects.filter(id=2).total_copies_sold()\n", "Author.objects.annotate_with_copies_sold().get(id=2)\nauthor.copies_sold \n15\n"], ["val schema2 = new StructType()\n    .add(\"pre_a\",StringType)\n    .add(\"pre_b\",StringType)\n    .add(\"pre_c\",StringType) \n", "df.select(col(\"MAIN_COL\").cast(schema2)).show()\n"], ["class AuthorQueryset(models.QuerySet):\n    def total_copies_sold(self):\n        ...\n\nclass Author(models.Model):\n    objects = models.Manager.from_queryset(AuthorQueryset)()\n"], [], [], [], ["df['pareto'] = 100 *df.country.cumsum() / df.country.sum()\nfig, axes = plt.subplots()\nax1 = df.plot(use_index=True, y='country',  kind='bar', ax=axes)\nax2 = df.plot(use_index=True, y='pareto', marker='D', color=\"C1\", kind='line', ax=axes, secondary_y=True)\nax2.set_ylim([0,110])\n"], [], ["/usr/bin/sudo /bin/mkdir /Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.7/etc\n/usr/bin/sudo /bin/ln -s /etc/ssl/ /Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.7/etc/\n"], [], ["jupyter notebook --debug\n", "OMP: Error #15: Initializing libiomp5.dylib, but found libiomp5.dylib already initialized.\nOMP: Hint This means that multiple copies of the OpenMP runtime have been linked into the program. That is dangerous, since it can\ndegrade performance or cause incorrect results. The best thing to do\nis to ensure that only a single OpenMP runtime is linked into the\nprocess, e.g. by avoiding static linking of the OpenMP runtime in any\nlibrary. As an unsafe, unsupported, undocumented workaround you can\nset the environment variable KMP_DUPLICATE_LIB_OK=TRUE to allow the\nprogram to continue to execute, but that may cause crashes or silently\nproduce incorrect results. For more information, please see\nhttp://www.intel.com/software/products/support/.\n", "conda install nomkl\n"], ["class nouns:\n\n    def get_nouns(self, sentences):\n        start = time.time()\n        docs = nlp.pipe(sentences, n_threads=-1)\n        result = [ ' '.join([token.text for token in doc if token.tag_ in ['NN', 'NNP', 'NNS', 'NNPS']]) for doc in docs]\n        print('Time Elapsed {} ms'.format((time.time() - start) * 1000))\n        print(result)\n\n\nif __name__ == '__main__':\n    sentences = ['we went to the school yesterday',\n                 'The weather is really cold',\n                 'Can we catch the dog?',\n                 'How old are you John?',\n                 'I like diving and swimming',\n                 'Can the world become united?']\n    obj = nouns()\n    obj.get_nouns(sentences)\n"], [], [], [], [" replace this with database code in settings.py (use your db name,user,password)\n\n DATABASES = {\n     'default': {\n     'ENGINE': 'django.db.backends.postgresql',\n     'NAME': 'mydjangodb',\n     'USER': 'root',\n     'PASSWORD': 'CSGOroot',\n     'HOST': 'localhost'\n      }\n  }\n", "  python manage.py migrate\n  python manage.py makemigrations (your app name)\n  python manage.py migrate\n"], ["DATABASES = {\n'default': {\n    'ENGINE': 'django.db.backends.postgresql_psycopg2',\n    'NAME': 'postgres',\n    'USER': 'postgres',\n    'PASSWORD': 'postgres',\n    'HOST': '127.0.0.1',\n    'PORT': '5432',\n}\n"], ["df.loc[df.groupby('A')['B val'].idxmin()]\n"], ["import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\niris = sns.load_dataset(\"iris\")\ndf = pd.melt(iris, iris.columns[-1], iris.columns[:-1])\n\ng = sns.FacetGrid(df, col=\"variable\", hue=\"species\", col_wrap=2)\ng.map(sns.kdeplot, \"value\", shade=True)\n\nplt.show()\n"], ["plt.subplots(2, 2)\nfor i, col in enumerate(iris.columns[:4]):\n    plt.subplot(2, 2, i+1)\n    sns.kdeplot(iris.loc[iris['species'] == 'setosa', col], shade=True, label='setosa')\n    sns.kdeplot(iris.loc[iris['species'] == 'versicolor', col], shade=True, label='versicolor')\n    sns.kdeplot(iris.loc[iris['species'] == 'virginica', col], shade=True, label='virginica')\n    plt.xlabel('cm')\n    plt.title(col)\n    if i == 1:\n        plt.legend(loc='upper right')\n    else:\n        plt.legend().remove()\n\nplt.subplot_tool() # Opens a widget which allows adjusting plot aesthetics\n"], ["import numpy as np\nimport pandas as pd\nfrom sklearn.datasets import load_iris\nimport seaborn as sns\n\niris = load_iris()\niris = pd.DataFrame(data=np.c_[iris['data'], iris['target']],\n                    columns=iris['feature_names'] + ['target'])\n\n# Sort the dataframe by target\ntarget_0 = iris.loc[iris['target'] == 0]\ntarget_1 = iris.loc[iris['target'] == 1]\ntarget_2 = iris.loc[iris['target'] == 2]\n\nsns.distplot(target_0[['sepal length (cm)']], hist=False, rug=True)\nsns.distplot(target_1[['sepal length (cm)']], hist=False, rug=True)\nsns.distplot(target_2[['sepal length (cm)']], hist=False, rug=True)\n\nsns.plt.show()\n"], ["import seaborn as sns\nimport matplotlib.pyplot as plt\nsns.set(style=\"ticks\", color_codes=True)\niris = sns.load_dataset(\"iris\")\n\ndef hide_current_axis(*args, **kwds):\n    plt.gca().set_visible(False)\n\ng = sns.pairplot(iris, hue=\"species\", palette=\"husl\")\ng.map_upper(hide_current_axis)\ng.map_lower(hide_current_axis)\n"], [], [], [], [], ["from google.colab.patches import cv2_imshow\n", "!curl -o logo.png https://colab.research.google.com/img/colab_favicon_256px.png\nimport cv2\nimg = cv2.imread('logo.png', cv2.IMREAD_UNCHANGED)\ncv2_imshow(img)\n"], [], ["def shortest_equivalent_binarian(A): \n   s = set() \n   for a in A: \n       while a in s: # carry propagation\n           s.remove(a) \n           a += 1 \n       s.add(a) \n   return sorted(s, reverse=True)\n# reverse is not necessary for correctness, but gives the same B as in your example\n"], [], [], ["# find the binarian\nbinarian = sum(2**a for a in A)\n# find the powers of two that are present in A\n# We do this by making a list of which bits are True in the binarian.\n#   we check each bit, using len(bin()) to as an easy log2\n#   we only include powers of two that produce 1 when and'ed with the binarian\nB = [pwr for pwr in range(len(bin(binarian)) - 2) if (2**pwr & binarian)]\n"], ["while n:\n    n, d = divmod(n, 2)\n    print(d)\n", "if n == 0:\n    print(0)\nelif n < 0:\n    print('-')\n    n = -n\nwhile n:\n    n, d = divmod(n, 2)\n    print(d)\n"], ["def decimalToBinary(n): \n    return bin(n).replace(\"0b\",\"\") \n"], ["n = int(input('Input any Integer: '))\n\ndim = str(bin(n)).split('0b', 1)[1].strip()\n\nprint('\\n'.join([n for n in dim]))\n"], ["n=int(input(\"Enter a number\\n\"))\nres=\"\"\nwhile n >= 1:\n  res=res+str(n%2)\n  n //= 2\nprint(int(res[::-1])) \n", "Enter a number\n10\n1010\n", "Enter a number\n99\n1100011\n"], ["def int2bin( num ) :\n    result = []\n    while num :\n        result.append( str(num & 1) )\n        num >>= 1\n    return ''.join( result[::-1] )\n", ">>> int2bin(4)\n'100'\n"], ["n=int(input(\"enter a number\"))\n\nbinary = \"\"\nwhile n > 1:\n    rest = n % 2\n    n //= 2\n    print(\"rest: {}\".format(rest), \"step: {}\".format(n))\n    binary = str(rest) + binary  \nif(n>=1):\n  binary =\"1\" + binary  \n\nprint(binary)\n", "enter a number: <b>2045</b>    \n 1. rest: 1 step: 1022\n 2. rest: 0 step: 511\n 3. rest: 1 step: 255\n 4. rest: 1 step: 127\n 5. rest: 1 step: 63\n 6. rest: 1 step: 31\n 7. rest: 1 step: 15\n 8. rest: 1 step: 7\n 9. rest: 1 step: 3\n 10. rest: 1 step: 1\n\n 11111111101\n"], ["n=int(input(\"enter a number\\n\"))\n\nwhile n >= 1:    # Should be >= 1, not > 1.\n    print(n%2)\n    n //= 2\n    # Removed if else.\n", "0\n1\n1\n", "1\n1\n0\n"], ["wb = openpyxl.load_workbook(r'path/to/file.xlsx')\nws = wb.get_sheet_by_name('Town_names')\nws.delete_rows(0, 1000)\n\nwb.save(r'path/to/file.xlsx')\n\nwb = openpyxl.load_workbook(r'path/to/file.xlsx')\nactiveSheet = wb.get_sheet_by_name('Town_names')\n\nfor r in dataframe_to_rows(Town_namesDF, index=False, header=True):\n    activeSheet.append(r)\n\nfor cell in activeSheet['A'] + activeSheet[1]:\n    cell.style = 'Pandas'\n\nwb.save(r'path/to/file.xlsx')\n"], ["with pd.ExcelWriter('/path/to/file.xlsx',engine = \"openpyxl\",  mode='a') as writer:\n workBook = writer.book\n try:\n  workBook.remove(workBook['Town_names'])\n except:\n  print(\"worksheet doesn't exist\")\n finally:\n  df.to_excel(writer, sheet_name='Town_names')\n writer.save()\n"], ["Store_sheet1=pd.read_excel('path/to/file.xlsx',sheetname='Sheet1')\nStore_sheet2=pd.read_excel('path/to/file.xlsx',sheetname='Sheet2')\nStore_sheet3=pd.read_excel('path/to/file.xlsx',sheetname='Sheet3')\n\nwith pd.ExcelWriter(r'path/to/file.xlsx', engine='openpyxl', mode='a') as writer:\n    Town_namesDF.to_excel(writer,sheet_name='Town_names')\n    Store_sheet1.to_excel(writer,sheet_name='Sheet1')\n    Store_sheet2.to_excel(writer,sheet_name='Sheet2')\n    Store_sheet3.to_excel(writer,sheet_name='Sheet3')\nwriter.save()\nwriter.close()\n"], ["RUN chmod +x /app/helloworld.py\n", "#!/usr/bin/env python # whatever your defualt python to run the script\n"], [], [], ["import argparse\n\nimport tensorflow as tf\nfrom google.protobuf import text_format\nfrom object_detection.protos import pipeline_pb2\n\n\ndef parse_arguments():                                                                                                                                                                                                                                                \n    parser = argparse.ArgumentParser(description='')                                                                                                                                                                                                                  \n    parser.add_argument('pipeline')                                                                                                                                                                                                                                   \n    parser.add_argument('output')                                                                                                                                                                                                                                     \n    return parser.parse_args()                                                                                                                                                                                                                                        \n\n\ndef main():                                                                                                                                                                                                                                                           \n    args = parse_arguments()                                                                                                                                                                                                                                          \n    pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()                                                                                                                                                                                                          \n\n    with tf.gfile.GFile(args.pipeline, \"r\") as f:                                                                                                                                                                                                                     \n        proto_str = f.read()                                                                                                                                                                                                                                          \n        text_format.Merge(proto_str, pipeline_config)                                                                                                                                                                                                                 \n\n    pipeline_config.model.ssd.image_resizer.fixed_shape_resizer.height = 300                                                                                                                                                                                          \n    pipeline_config.model.ssd.image_resizer.fixed_shape_resizer.width = 300                                                                                                                                                                                           \n\n    config_text = text_format.MessageToString(pipeline_config)                                                                                                                                                                                                        \n    with tf.gfile.Open(args.output, \"wb\") as f:                                                                                                                                                                                                                       \n        f.write(config_text)                                                                                                                                                                                                                                          \n\n\nif __name__ == '__main__':                                                                                                                                                                                                                                            \n    main() \n", "TOOL_DIR=tool/tf-models/research\n\n(\n   cd $TOOL_DIR\n   protoc object_detection/protos/*.proto --python_out=.\n)\n\nexport PYTHONPATH=$PYTHONPATH:$TOOL_DIR:$TOOL_DIR/slim\n\npython3 edit_pipeline.py pipeline.config pipeline_new.config\n", "pipeline_config.train_input_reader.tf_record_input_reader.input_path[0] = '/tensorflow/models/data/train100.record'\n", "pipeline_config.eval_input_reader[0].label_map_path  = label_map_full_path\npipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[0] = val_record_path\n"], [], ["Jupyter Notebook 5.7.4\nPython 3.7.1 (default, Dec 10 2018, 22:54:23) \nIPython 7.2.0\n", "Jupyter Notebook 5.7.4\nPython 3.7.1 (default, Dec 10 2018, 22:54:23) \nIPython 7.2.0\n", "Jupyter Notebook 5.6.0\nPython 3.7.0 (default, Jun 28 2018, 08:04:48) [MSC v.1912 64 bit (AMD64)]\nIPython 6.5.0 -- An enhanced Interactive Python. Type '?' for help.\n", "Python 3.6.1 |Anaconda 4.4.0 (64-bit)|\nIPython 5.3.0\n", "Jupyter Notebook 4.3.1\nPython 2.7.13 |Anaconda 4.3.1 (64-bit)| \nIPython 5.1.0 \n"], ["df.style.set_caption(\"Hello World\")\n", "import matplotlib.pyplot as plt\nimport pandas as pd\n\nmy_frame = pd.DataFrame(data={'simulation1':[71,4.8,65,4.7],\n                              'simulation2':[71,4.8,69,4.7],\n                              'simulation3':[70,3.8,68,4.9],\n                              'experiment':[70.3,3.5,65,4.4]})\n#my_frame Display pandas table\n\nfig = plt.figure(figsize = (8, 2))\nax = fig.add_subplot(111)\n\nax.table(cellText = my_frame.values,\n          rowLabels = my_frame.index,\n          colLabels = my_frame.columns,\n          loc = \"center\"\n         )\nax.set_title(\"Top 10 Fields of Research by Aggregated Funding Amount\")\n\nax.axis(\"off\");\n"], ["df.style.set_caption('Top 10 Fields of Research by Aggregated Funding Amount')\n"], [], ["import logging\nfrom fastapi import FastAPI\n\nclass App:\n    \"\"\" Core application to test. \"\"\"\n\n    def __init__(self):\n        self.api = FastAPI()\n        # register endpoints\n        self.api.get(\"/\")(self.read_root)\n        self.api.on_event(\"shutdown\")(self.close)\n\n    async def close(self):\n        \"\"\" Gracefull shutdown. \"\"\"\n        logging.warning(\"Shutting down the app.\")\n\n    async def read_root(self):\n        \"\"\" Read the root. \"\"\"\n        return {\"Hello\": \"World\"}\n\n\"\"\" Testing part.\"\"\"\nfrom multiprocessing import Process\nimport asynctest\nimport asyncio\nimport aiohttp\nimport uvicorn\n\nclass TestApp(asynctest.TestCase):\n    \"\"\" Test the app class. \"\"\"\n\n    async def setUp(self):\n        \"\"\" Bring server up. \"\"\"\n        app = App()\n        self.proc = Process(target=uvicorn.run,\n                            args=(app.api,),\n                            kwargs={\n                                \"host\": \"127.0.0.1\",\n                                \"port\": 5000,\n                                \"log_level\": \"info\"},\n                            daemon=True)\n        self.proc.start()\n        await asyncio.sleep(0.1)  # time for the server to start\n\n    async def tearDown(self):\n        \"\"\" Shutdown the app. \"\"\"\n        self.proc.terminate()\n\n    async def test_read_root(self):\n        \"\"\" Fetch an endpoint from the app. \"\"\"\n        async with aiohttp.ClientSession() as session:\n            async with session.get(\"http://127.0.0.1:5000/\") as resp:\n                data = await resp.json()\n        self.assertEqual(data, {\"Hello\": \"World\"})\n"], [], ["return str(self.product)\n"], ["class ProductOrder(models.Model):\n    product = models.ForeignKey(Product, on_delete=models.CASCADE, null=True)\n    ordering = models.ForeignKey(Order, on_delete=models.CASCADE,blank=True,null=True)\n\n    def __str__(self):\n        return <b>str(</b>self.product<b>)</b>"], [], [">>> import pythonflow as pf\n>>> import math\n>>> with pf.Graph() as graph:\n...     pi = pf.constant(math.pi)\n...     length = pf.constant(1.0)\n...     radius = pf.constant(0.25)\n...     density = pf.constant(450)\n...     volume = length*pi*radius**2\n...     mass = volume*density\n... \n>>> graph(volume)\n0.19634954084936207\n>>> graph(mass)\n88.35729338221293\n>>> graph(volume, {length: graph(length)*2})\n0.39269908169872414\n>>> graph(mass, {length: graph(length)*2})\n176.71458676442586\n>>> \n"], ["b = {1:'a',\n     2:'b',\n     3:{4:'A',\n        5:'B'},\n     6:'c'}\n\nall_keys = list()\n\nfor key in b.keys():\n   if isinstance(b[key],dict):\n       all_keys.append(key)\n       all_keys.append(list(b[key].keys()))\n   else:\n       all_keys.append(key)\n", "Out[17]: [1, 2, 3, [4, 5], 6]\n"], ["for k in life.keys():\n    if type(life[k]) is dict:\n        for k1 in life[k].keys():\n            print(k1)\n"], ["for key in life[\"animals\"]:\n    print(key)\n"], ["$ /usr/bin/python3 -c 'import ssl; print(ssl.get_default_verify_paths())'\nDefaultVerifyPaths(cafile=None, capath=None, openssl_cafile_env='SSL_CERT_FILE', openssl_cafile='/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.7/etc/ssl/cert.pem', openssl_capath_env='SSL_CERT_DIR', openssl_capath='/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.7/etc/ssl/certs')\n", "$ sudo rsync -avzP /etc/ssl/ /Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.7/etc/ssl/\n"], ["from itertools import chain\nfrom math import pi\n\nclass Cylinder:\n\n    _dependencies = {\n        \"length\": [\"volume\"],\n        \"radius\": [\"volume\"],\n        \"volume\": [\"mass\"],\n        \"density\": [\"mass\"]\n    }\n    _dependent_vars = set(chain(*list(_dependencies.values())))\n\n    def __init__(self, radius, length, density):\n        self._radius = radius\n        self._length = length\n        self._density = density\n        self._volume = None\n        self._mass = None\n\n    def _reset_dependent_vars(self, name):\n        for var in self._dependencies[name]:\n            super().__setattr__(f\"_{var}\", None)\n            if var in self._dependencies:\n                self._reset_dependent_vars(var)\n\n    def __setattr__(self, name, value):\n        if name in self._dependent_vars:\n            raise AttributeError(\"Cannot set this value.\")\n        if name in self._dependencies:\n            self._reset_dependent_vars(name)\n            name = f\"_{name}\"\n        super().__setattr__(name, value)\n\n    @property\n    def volume(self):\n        if self._volume is None:\n            self._volume = self.length*pi*self.radius**2\n            print(\"Volume calculated\")\n        return self._volume\n\n    @property\n    def mass(self):\n        if self._mass is None:\n            self._mass = self.volume*self.density\n            print(\"Mass calculated\")\n        return self._mass\n\n    @property\n    def length(self):\n        return self._length\n\n    @property\n    def radius(self):\n        return self._radius\n\n    @property\n    def density(self):\n        return self._density\n"], ["from weakref import WeakKeyDictionary\n\nclass DependantAttribute:\n    \"\"\"Describes an attribute that is a fuction of other attributes.\n\n    Only recalculates if one of the values it relies on changes. \n    'interns' the value and the values used to calculate it.\n    This attribute must be set in the class's __init__\n\n    name - the name of this instance attribute\n    func - the function used to calculate the value\n    attributes - instance attribute names that this attribute relies on\n                 must match function parameter names\n    mapping - not implemented: {attribute_name: function_parameter_name}\n\n    \"\"\"\n    def __init__(self, name, func, attributes):\n        self.name = name\n        self.func = func\n        self.attributes = attributes\n        #self.mapping = None\n        self.data = WeakKeyDictionary()\n\n    def __get__(self, instance, owner):\n        values = self.data.get(instance)\n        if any(getattr(instance,attr) != values[attr]\n               for attr in self.attributes):\n            value = self.recalculate(instance)\n            setattr(instance,self.name, value) \n        return self.data.get(instance)['value']\n\n    def __set__(self, instance, value):\n        # store the new value and current attribute values\n        values = {attr:getattr(instance,attr) for attr in self.attributes}\n        # validate?! : value == self.recalculate(**values)\n        values['value'] = value\n        self.data[instance] = values\n\n    def recalculate(self, instance):\n            # calculating a new value relies on\n            # attribute_name == function_parameter_name\n            kwargs = {attr:getattr(instance,attr) for attr in self.attributes}\n            return self.func(**kwargs)\n", "from math import pi\n# define the functions outside the class\ndef volfnc(length, radius):\n    return length * pi * pow(radius,2)\ndef massfnc(volume, density):\n    return volume * density\n\nclass Cylinder:\n    volume = DependantAttribute('volume',volfnc, ('length','radius'))\n    mass = DependantAttribute('mass',massfnc, ('volume','density'))\n\n    def __init__(self, radius, length, density):\n\n        self.radius = radius\n        self.length = length\n        self.density = density\n\n        # the dependent attributes must be set in __init__\n        self.volume = volfnc(length,radius)\n        self.mass = massfnc(self.volume,density)\n\n\nc = Cylinder(1,1,1)\nd = Cylinder(1,2,1)\n", ">>> c.volume, c.mass\n(3.141592653589793, 3.141592653589793)\n>>> d.volume, d.mass\n(6.283185307179586, 12.566370614359172)\n>>> c.radius = 2\n>>> d.density = 3\n>>> c.volume, c.mass\n(12.566370614359172, 12.566370614359172)\n>>> d.volume, d.mass\n(6.283185307179586, 18.84955592153876)\n"], ["from math import pi\n\nclass Cylinder:\n    _independent = {\"length\", \"radius\", \"density\"}\n    _dependent = {\"volume\", \"mass\"}\n\n    def __init__(self, radius, length, density):\n        self._radius = radius\n        self._length = length\n        self._density = density\n        self._volume = None\n        self._mass = None\n\n    def __setattr__(self, name, value):\n        if name in self._independent:\n            name = f\"_{name}\"\n            for var in self._dependent:\n                super().__setattr__(f\"_{var}\", None)\n        if name in self._dependent:\n            print(\"Cannot set dependent variable!\")\n            return\n        super().__setattr__(name, value)\n\n    @property\n    def volume(self):\n        if self._volume is None:\n            self._volume = self.length*pi*self.radius**2\n            print(\"Volume calculated\")\n        return self._volume\n\n    @property\n    def mass(self):\n        if self._mass is None:\n            self._mass = self.volume*self.density\n            print(\"Mass calculated\")\n        return self._mass\n\n    @property\n    def length(self):\n        return self._length\n\n    @property\n    def radius(self):\n        return self._radius\n\n    @property\n    def density(self):\n        return self._density\n"], ["from __future__ import annotations\nfrom dataclasses import field, fields, dataclass\n\n@dataclass()\nclass Record:\n    name: str\n    address: str\n    zip: str = field(default=None)  # won't fail if dictionary doesn't have a zip key\n\n    @classmethod\n    def create_from_dict(cls, dict_) -> Record:\n        class_fields = {f.name for f in fields(cls)}\n        return Record(**{k: v for k, v in dict_.items() if k in class_fields})\n"], ["python manage.py startapp Your_App_Name ./apps/Your_Apps_Folder_Name/\n", "INSTALLED_APPS = [\n    ...,\n    'apps.Your_App_Name',\n]\n"], ["if os.name == nt:\n    from windows_support import Feature\nelse:\n    from linux_support import Feature\n", "if os.name == 'nt':\n    class Feature:\n        ...\nelse:\n    class Feature:\n        ...\n"], [], [], ["first class\nsecond class\n2\n3\n"], [], ["def ceil(n):\n    q, r = divmod(n, 1)\n    return int(q) + bool(r)\n"], ["rounded_up_x = int(-(-x // 1))\n"], ["def myCeil(x):\n    return int(x) + int((x>0) and (x - int(x)) > 0)\n", "print([myCeil(i) for i in [myCeil(i) for i in [-2, -1.1, -0.0, 0, 1, 1.2, 3]])\n#[-2, -1, 0, 0, 1, 2, 3]\n"], [], [], ["INSTALLED_APPS = [\n    ...,\n    'apps.budget',\n]\n"], ["INSTALLED_APPS = [\n'app.budget.apps.BudgetConfig',\n]\n"], [], ["def count_even(num):\n    s = str(num)\n    for c in s:\n        yield c in '02468'\n", "(c in '02468' for c in str(num))\n", "class Count:\n    def __init__(self, num):\n        self.str_num = iter(str(num))\n\n    def __iter__(self):\n        return self\n\n    def __next__(self):\n        c = next(self.str_num)\n        return c in '02468'\n", "import matplotlib.pyplot as plt\nfrom simple_benchmark import BenchmarkBuilder\n%matplotlib notebook\n\nbench = BenchmarkBuilder()\n\n@bench.add_function()\ndef iteration(it):\n    for i in it:\n        pass\n\n@bench.add_function()\ndef generator(it):\n    it = (item for item in it)\n    for i in it:\n        pass\n\n@bench.add_arguments()\ndef argument_provider():\n    for i in range(2, 15):\n        size = 2**i\n        yield size, [1 for _ in range(size)]\n\nplt.figure()\nresult = bench.run()\nresult.plot()\n", "import matplotlib.pyplot as plt\nfrom simple_benchmark import BenchmarkBuilder\n%matplotlib notebook\n\nbench = BenchmarkBuilder()\n\n@bench.add_function()\ndef generator_expression(it):\n    it = (item for item in it)\n    for i in it:\n        pass\n\n@bench.add_function()\ndef list_comprehension(it):\n    it = [item for item in it]\n    for i in it:\n        pass\n\n@bench.add_arguments('size')\ndef argument_provider():\n    for i in range(2, 15):\n        size = 2**i\n        yield size, list(range(size))\n\nplt.figure()\nresult = bench.run()\nresult.plot()\n", "import matplotlib.pyplot as plt\nfrom simple_benchmark import BenchmarkBuilder\n%matplotlib notebook\n\nbench = BenchmarkBuilder()\n\n@bench.add_function()\ndef my_sum(it):\n    sum_ = 0\n    for i in it:\n        sum_ += i\n    return sum_\n\nbench.add_function()(sum)\n\n@bench.add_arguments()\ndef argument_provider():\n    for i in range(2, 15):\n        size = 2**i\n        yield size, [1 for _ in range(size)]\n\nplt.figure()\nresult = bench.run()\nresult.plot()\n", "import matplotlib.pyplot as plt\nfrom simple_benchmark import BenchmarkBuilder\n%matplotlib notebook\n\nbench = BenchmarkBuilder()\n\n@bench.add_function()\ndef string_iteration(s):\n    # there is no \"a\" in the string, so this iterates over the whole string\n    return 'a' in s  \n\n@bench.add_function()\ndef python_iteration(s):\n    for c in s:\n        pass\n\n@bench.add_arguments('string length')\ndef argument_provider():\n    for i in range(2, 20):\n        size = 2**i\n        yield size, '1'*size\n\nplt.figure()\nresult = bench.run()\nresult.plot()\n", "%matplotlib notebook\n\nfrom simple_benchmark import BenchmarkBuilder\nimport matplotlib.pyplot as plt\nimport random\n\nbench1 = BenchmarkBuilder()\n\n@bench1.add_function()\ndef f1(x):\n    return sum(c in '02468' for c in str(x))\n\n@bench1.add_function()\ndef f2(x):\n    return sum([c in '02468' for c in str(x)])\n\n@bench1.add_function()\ndef f3(x):\n    return sum([True for c in str(x) if c in '02468'])    \n\n@bench1.add_function()\ndef f4(x):\n    return sum([1 for c in str(x) if c in '02468'])\n\n@bench1.add_function()\ndef explicit_loop(x):\n    count = 0\n    for c in str(x):\n        if c in '02468':\n            count += 1\n    return count\n\n@bench1.add_function()\ndef f5(x):\n    s = str(x)\n    return sum(s.count(c) for c in '02468')\n\nbench1.add_function()(str)\n\n@bench1.add_arguments(name='number length')\ndef arg_provider():\n    for i in range(2, 15):\n        size = 2 ** i\n        yield (2**i, int(''.join(str(random.randint(0, 9)) for _ in range(size))))\n\n\nbench2 = BenchmarkBuilder()\n\n@bench2.add_function()\ndef f1(x):\n    return sum(c in '02468' for c in x)\n\n@bench2.add_function()\ndef f2(x):\n    return sum([c in '02468' for c in x])\n\n@bench2.add_function()\ndef f3(x):\n    return sum([True for c in x if c in '02468'])    \n\n@bench2.add_function()\ndef f4(x):\n    return sum([1 for c in x if c in '02468'])\n\n@bench2.add_function()\ndef explicit_loop(x):\n    count = 0\n    for c in x:\n        if c in '02468':\n            count += 1\n    return count\n\n@bench2.add_function()\ndef f5(x):\n    return sum(x.count(c) for c in '02468')\n\n@bench2.add_arguments(name='number length')\ndef arg_provider():\n    for i in range(2, 15):\n        size = 2 ** i\n        yield (2**i, ''.join(str(random.randint(0, 9)) for _ in range(size)))\n\nf, (ax1, ax2) = plt.subplots(1, 2, sharey=True)\nb1 = bench1.run()\nb2 = bench2.run()\nb1.plot(ax=ax1)\nb2.plot(ax=ax2)\nax1.set_title('Number')\nax2.set_title('String')\n"], ["import timeit\n\nnum = ''.join(str(i % 10) for i in range(1, 10000001))\n\ndef count_simple_sum():\n    return sum(1 for c in num)\n\ndef count_simple_for():\n    count = 0\n    for c in num:\n        count += 1\n    return count\n\n\nprint('For Loop Sum:', timeit.timeit(count_simple_for, number=10))\nprint('Built-in Sum:', timeit.timeit(count_simple_sum, number=10))\n", "For Loop Sum: 2.8987821330083534\nBuilt-in Sum: 3.245505138998851\n", "  3 LOAD_CONST               1 (<code object <genexpr> at 0x10dcc8c90, file \"test.py\", line 14>)\n  6 LOAD_CONST               2 ('count2.<locals>.<genexpr>')\n"], ["  7           0 LOAD_CONST               1 (0)\n              3 STORE_FAST               0 (count)\n\n  8           6 SETUP_LOOP              42 (to 51)\n              9 LOAD_GLOBAL              0 (str)\n             12 LOAD_GLOBAL              1 (n)\n             15 CALL_FUNCTION            1 (1 positional, 0 keyword pair)\n             18 GET_ITER\n        >>   19 FOR_ITER                28 (to 50)\n             22 STORE_FAST               1 (c)\n\n  9          25 LOAD_FAST                1 (c)\n             28 LOAD_CONST               2 ('02468')\n             31 COMPARE_OP               6 (in)\n             34 POP_JUMP_IF_FALSE       19\n\n 10          37 LOAD_FAST                0 (count)\n             40 LOAD_CONST               3 (1)\n             43 INPLACE_ADD\n             44 STORE_FAST               0 (count)\n             47 JUMP_ABSOLUTE           19\n        >>   50 POP_BLOCK\n\n 11     >>   51 LOAD_FAST                0 (count)\n             54 RETURN_VALUE\n", "9 LOAD_GLOBAL              0 (str)\n...\n15 CALL_FUNCTION            1 (1 positional, 0 keyword pair)\n", " 14           0 LOAD_GLOBAL              0 (sum)\n              3 LOAD_CONST               1 (<code object <genexpr> at 0x10dcc8c90, file \"test.py\", line 14>)\n              6 LOAD_CONST               2 ('count2.<locals>.<genexpr>')\n              9 MAKE_FUNCTION            0\n             12 LOAD_GLOBAL              1 (str)\n             15 LOAD_GLOBAL              2 (n)\n             18 CALL_FUNCTION            1 (1 positional, 0 keyword pair)\n             21 GET_ITER\n             22 CALL_FUNCTION            1 (1 positional, 0 keyword pair)\n             25 CALL_FUNCTION            1 (1 positional, 0 keyword pair)\n             28 RETURN_VALUE\n"], ["string length: 502\ncount_even_digits_spyr03_list 0.04157966522\ncount_even_digits_spyr03_sum 0.05678154459\ncount_even_digits_spyr03_for 0.036128606150000006\ncount_even_digits_spyr03_count 0.010441866129999991\ncount_even_digits_spyr03_count_unrolled 0.009662931009999999\n"], ["pipeline_config.eval_input_reader[0].label_map_path  = label_map_full_path\npipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[0] = val_record_path\n"], ["date_time_obj = date.to_pydatetime()\n"], [], ["def sublist(x):\n    sub = []\n    x = (num for num in x)  # create a generator\n    num = next(x, 5)  \n    while num != 5:\n        sub.append(num)\n        num = next(x, 5)  # iterate\n    return sub\n\nx = [1, 3, 4, 5, 1, 2, 3]\nsublist(x)\n\n>>> [1, 3, 4]\n"], ["def sublist(x):\n    pass\n", "def sublist(x):\n    for num in x:\n        if num == 5:\n            # we need to stop; break out of the for loop\n            break\n        # output the next number\n        yield num\n", ">>> for num in sublist([3, 4, 2, 5, 6, 7]):\n...     print(num)\n3\n4\n2\n>>> \n", "from functools import wraps\nreturn_list = lambda f:wraps(f)(lambda *a,**k:list(f(*a,**k)))\n", "@return_list\ndef sublist(x):\n    for num in x:\n        if num == 5:\n            # we need to stop; break out of the for loop\n            break\n        # output the next number\n        yield num\n", ">>> print(sublist([3, 4, 2, 5, 6, 7]))\n[3, 4, 2]\n>>>\n"], ["def sublist(input_list):\n    output_list = []\n    index = 0\n    while index < len(input_list):\n        if input_list[index] != 5:\n            output_list.append(input_list[index])\n            index += 1\n        else:\n            break\n    return output_list\n"], [], [], [], [], [], ["t1 = torch.tensor([1, 9, 12, 5, 24], device = 'cuda')\nt2 = torch.tensor([1, 24], device = 'cuda')\nindices = torch.ones_like(t1, dtype = torch.uint8, device = 'cuda')\nfor elem in t2:\n    indices = indices & (t1 != elem)  \nintersection = t1[indices]  \n"], [], ["instr = \"abc123abc456abc7891\"\n\nsubstr = \"\"\nsub_list = []\nprev_digit = instr[0].isdigit()\n\nfor char in instr:\n    # if the character's digit-ness is different from the last one,\n    #    then \"tie off\" the current substring and start a new one.\n    this_digit = char.isdigit()\n    if this_digit != prev_digit:\n        sub_list.append(substr)\n        substr = \"\"\n        prev_digit = this_digit\n\n    substr += char\n\n# Add the last substr to the list\nsub_list.append(substr)\n\nprint(sub_list)\n", "['abc', '123', 'abc', '456', 'abc', '7891']\n"], ["def getn(w):\n   ans = []\n   section = ''\n\n   if w[0].isdigit():\n       last = 'digit'\n   else:\n       last = 'letter'\n\n   for char in w:\n       if char.isdigit():\n           if last == 'letter':\n               ans.append(section)\n               section = ''\n               last = 'digit'\n           section += char\n       else:\n           if last == 'digit':\n               ans.append(section)\n               section = ''\n               last = 'letter'\n           section += char\n   ans.append(section)\n\n   for index, section in enumerate(ans):\n       if section.isdigit():\n           ans[index] = section[::-1]\n   return ''.join(ans)\n\nstring = 'abc123abc456abc7891'\nprint(getn(string))\n"], ["from itertools import groupby\n\ndef getn(s):\n    sections = groupby(s, key=lambda char: char.isdigit())\n    result = []\n    for isdig, chars in sections:\n        if isdig:\n            result += list(reversed(list(chars)))\n        else:\n            result += list(chars)\n    return \"\".join(result)\n\ninput = \"abc123abc456abc7891\"\nprint(getn(input))\n"], ["//p[@class='sc-eYdvao kvdWiq']/a\n"], ["elems = driver.find_elements_by_xpath(\"//p[contains(@class, 'sc-eYdvao') and contains(@class='kvdWiq')]/a\")\nfor elem in elems:\n   print elem.get_attribute['href']\n"], ["# d = dict()\nclass Round7FloatEncoder(json.JSONEncoder): \n    def iterencode(self, obj): \n        if isinstance(obj, float): \n            yield format(obj, '.7f')\n\n\nwith open('test.json', 'w') as f:\n    json.dump(d, f, cls=Round7FloatEncoder)\n"], [], [], ["df.loc[df.groupby('A').B.idxmin()]\n\n   A  B   C\n2  1  2  10\n4  2  4   4\n", "df.loc[df.groupby('A').B.idxmin()].reset_index(drop=True)\n\n   A  B   C\n0  1  2  10\n1  2  4   4\n"], ["pd.to_numeric(df['column'], errors='coerce').notnull().all()\n", "df.apply(lambda s: pd.to_numeric(s, errors='coerce').notnull().all())\n", "df = pd.DataFrame({'col' : [1,2, 10, np.nan, 'a'], \n                   'col2': ['a', 10, 30, 40 ,50],\n                   'col3': [1,2,3,4,5.0]})\n", "col     False\ncol2    False\ncol3     True\ndtype: bool\n"], ["df.shape[1] == df.select_dtypes(include=np.number).shape[1]\n", "new_df = df.select_dtypes(include=np.number)\n"], ["df.select_dtypes(include=[\"float\", 'int'])\n", "df.select_dtypes(exclude=[\"float\", 'int'])\n"], ["from _ctypes import PyObj_FromPtr\nimport json\nimport re\n\n\nclass FloatWrapper(object):\n    \"\"\" Float value wrapper. \"\"\"\n    def __init__(self, value):\n        self.value = value\n\n\nclass MyEncoder(json.JSONEncoder):\n    FORMAT_SPEC = '@@{}@@'\n    regex = re.compile(FORMAT_SPEC.format(r'(\\d+)'))  # regex: r'@@(\\d+)@@'\n\n    def default(self, obj):\n        return (self.FORMAT_SPEC.format(id(obj)) if isinstance(obj, FloatWrapper)\n                else super(MyEncoder, self).default(obj))\n\n    def iterencode(self, obj, **kwargs):\n        for encoded in super(MyEncoder, self).iterencode(obj, **kwargs):\n            # Check for marked-up float values (FloatWrapper instances).\n            match = self.regex.search(encoded)\n            if match:  # Get FloatWrapper instance.\n                id = int(match.group(1))\n                float_wrapper = PyObj_FromPtr(id)\n                json_obj_repr = '%.7f' % float_wrapper.value  # Create alt repr.\n                encoded = encoded.replace(\n                            '\"{}\"'.format(self.FORMAT_SPEC.format(id)), json_obj_repr)\n            yield encoded\n\n\nd = dict()\nd['val'] = FloatWrapper(5.78686876876089075543)  # Must wrap float values.\nd['name'] = 'kjbkjbkj'\n\nwith open('float_test.json', 'w') as file:\n    json.dump(d, file, cls=MyEncoder, indent=4)\n", "def wrap_type(obj, kind, wrapper):\n    \"\"\" Recursively wrap instances of type kind in dictionary and list\n        objects.\n    \"\"\"\n    if isinstance(obj, dict):\n        new_dict = {}\n        for key, value in obj.items():\n            if not isinstance(value, (dict, list)):\n                new_dict[key] = wrapper(value) if isinstance(value, kind) else value\n            else:\n                new_dict[key] = wrap_type(value, kind, wrapper)\n        return new_dict\n\n    elif isinstance(obj, list):\n        new_list = []\n        for value in obj:\n            if not isinstance(value, (dict, list)):\n                new_list.append(wrapper(value) if isinstance(value, kind) else value)\n            else:\n                new_list.append(wrap_type(value, kind, wrapper))\n        return new_list\n\n    else:\n        return obj\n\n\nd = dict()\nd['val'] = 5.78686876876089075543\nd['name'] = 'kjbkjbkj'\n\nwith open('float_test.json', 'w') as file:\n    json.dump(wrap_type(d, float, FloatWrapper), file, cls=MyEncoder, indent=4)\n"], ["d = dict()\nd['val'] = 5.78686876876089075543\nd['name'] = 'kjbkjbkj'\nd[\"mylist\"] = [1.23456789, 12, 1.23, {\"foo\": \"a\", \"bar\": 9.87654321}]\nd[\"mydict\"] = {\"bar\": \"b\", \"foo\": 1.92837465}\n\n# dump the object to a string\nd_string = json.dumps(d, indent=4)\n\n# find numbers with 8 or more digits after the decimal point\npat = re.compile(r\"\\d+\\.\\d{8,}\")\ndef mround(match):\n    return \"{:.7f}\".format(float(match.group()))\n\n# write the modified string to a file\nwith open('test.json', 'w') as f:\n    f.write(re.sub(pat, mround, d_string))\n", "import json\n\nclass MyCustomEncoder(json.JSONEncoder):\n    def iterencode(self, obj):\n        if isinstance(obj, float):\n            yield format(obj, '.7f')\n        elif isinstance(obj, dict):\n            last_index = len(obj) - 1\n            yield '{'\n            i = 0\n            for key, value in obj.items():\n                yield '\"' + key + '\": '\n                for chunk in MyCustomEncoder.iterencode(self, value):\n                    yield chunk\n                if i != last_index:\n                    yield \", \"\n                i+=1\n            yield '}'\n        elif isinstance(obj, list):\n            last_index = len(obj) - 1\n            yield \"[\"\n            for i, o in enumerate(obj):\n                for chunk in MyCustomEncoder.iterencode(self, o):\n                    yield chunk\n                if i != last_index: \n                    yield \", \"\n            yield \"]\"\n        else:\n            for chunk in json.JSONEncoder.iterencode(self, obj):\n                yield chunk\n", "with open('test.json', 'w') as f:\n    json.dump(d, f, cls = MyCustomEncoder)\n", "{\"val\": 5.7868688, \"name\": \"kjbkjbkj\", \"mylist\": [1.2345679, 12, 1.2300000, {\"foo\": \"a\", \"bar\": 9.8765432}], \"mydict\": {\"bar\": \"b\", \"foo\": 1.9283747}}\n", "# write d using custom encoder\nwith open('test.json', 'w') as f:\n    json.dump(d, f, cls = MyCustomEncoder)\n\n# load output into new_d\nwith open('test.json', 'r') as f:\n    new_d = json.load(f)\n\n# write new_d out using default encoder\nwith open('test.json', 'w') as f:\n    json.dump(new_d, f, indent=4)\n"], ["import pandas as pd\n\ns = pd.Series([1, 2, 3, 4, 5])\ns.describe()['mean']\n# 3.0\n", "s.describe()[['mean', 'std']]\n# mean    3.000000\n# std     1.581139\n# dtype: float64\n"], ["df.describe(include='all').loc['mean']\n"], [], [" pip install https://pypi.python.org/packages/da/06/bd3e241c4eb0a662914b3b4875fc52dd176a9db0d4a2c915ac2ad8800e9e/dlib-19.7.0-cp36-cp36m-win_amd64.whl#md5=b7330a5b2d46420343fbed5df69e6a3f\n"], ["class Foo:\n    def __init__(self, private):\n        self.private = private\n\n    def __getattribute__(self, attr):\n        import inspect\n        frame = inspect.currentframe()\n        try:\n            back_self = frame.f_back.__self__\n            if not back_self == self: #is it inside the class?\n                ban = ('private', '__dict__') #all private vars, ban __dict__ for no loopholes\n                if attr in ban:\n                    msg = 'Foo object has no attribute {!r}'\n                    raise AttributeError(msg.format(attr))\n        finally:\n            del frame\n        return super().__getattribute__(attr)\n\n    def print_private(self):\n        print(self.private) #access in the class!\n\n\nfoo = Foo('hi')\nfoo.print_private() #output: hi\nfoo.private #makes an error\n"], ["def privateNS():\n\n    class MyObject(object):\n        __slots__ = ['private'] # name doesn't matter\n\n        def __new__(cls, value): # only sets inst.private on new instance creation\n            inst = object.__new__(cls)\n\n            setprivate(inst, value)\n\n            return inst\n\n        # __init__ is not needed, and can't be used here to set inst.private\n\n        def showprivate(inst):\n            return getprivate(inst)\n\n    dsc = MyObject.private # get descriptor\n    getprivate = dsc.__get__\n    setprivate = dsc.__set__\n    del MyObject.private # revoke normal access\n\n    return MyObject\n\nMyObject = privateNS()\ndel privateNS\n\ninst = MyObject( 20 )\nprint( inst.showprivate() ) # 20\n", ">>> inst.showprivate.__closure__[0].cell_contents\n<method-wrapper '__get__' of member_descriptor object at 0x00E588A0>\n", ">>> inst.showprivate.__closure__[0].cell_contents.__self__.__set__( inst, 30 )\n>>> inst.showprivate()\n30\n"], ["print('''Student Number: {}\\\n        \\nStudent Course: {}\\\n        \\nYear Level: {}\\\n        \\nStudent Name: {}\\\n        \\nAddress: {}\\\n        \\nBirthdate: {}\\\n        \\nFather\\'s Name: {}\\\n        \\nMother\\'s Name: {}'''.format(*i))\n"], ["print(\"                 Main Menu                 \")\nprint(\"[1] Input   Student Records\")\nprint(\"[2] Display Student Records\")\nmain_choice=int(input(\"Choice: \"))\nStud_list=[]\nk=[]\nchoice1='y'\nif main_choice==1:\n    while choice1=='y' or choice1=='Y':\n        Stud_number=int(input(\"Student Number: \"))\n\n        Stud_Course=input(\"Student Course: \")\n\n        Year_Level=int(input(\"Year Level: \"))\n\n        Stud_Name=input(\"Student Name:\")\n\n        Address=input(\"Address: \")\n\n        Birthday=int(input(\"Birthdate: \"))\n\n        Father_Name=input(\"Father's Name: \")\n\n        Mother_Name=input(\"Mother's Name: \")\n\n        Stud_list.append([Stud_number,Stud_Course,Year_Level,Stud_Name,Address,Birthday,Father_Name,Mother_Name])\n\n        choice1=input(\"Input another? [Y]/[N]: \")\nif main_choice==2:\n    if not Stud_list:\n        print(\"List is empty\")\n    else:\n        for i in  Stud_list : \n            print(\"\"\"\n            Student Number: {}\n               Student Course: {}\n               Year Level: {}\n               Student Name: {}\n               Address: {}\n               Birthdate: {}\n               Father's Name: {}\n               Mother's Name: {}\"\"\".format(i[0], i[1], i[2], i[3], i[4], i[5], i[6], i[7]))\n"], ["for i in Stud_list: \n    print(\"Student Number:\",i[0])\n    print(\"Student Course:\", i [1])\n    print(\"Year Level:\",i[2])\n    print(\"Student Name:\",i[3])\n    print(\"Address: \",i[4])\n    print(\"Birthdate: \",i[5])\n    print(\"Father's Name: \",i[6])\n    print(\"Mother's Name: \",i[7])\n    print()\n"], ["l = [123456, 'Course', 1, 'Name', 'Here', Birth, 'HIM', 'HER']\nprint(\"\"\"Student Number: {}\\n\n       Student Course: {}\\n\n       Year Level: {}\\n\n       Student Name: {}\\n\n       Address: {}\\n\n       Birthdate: {}\\n\n       Father's Name: {}\\n\n       Mother's Name: {}\\n\"\"\".format(l[0], l[1], l[2], l[3], l[4], l[5], l[6], l[7]))\n"], ["class Foo:\n    def __init__(self):\n        private = 'bar'\n        def print_private():\n            print(private)\n        self.print_private = print_private\n\nfoo = Foo()\nfoo.print_private()  # works\nfoo.private  # kaboom\n"], ["class Private:\n    def __init__(self, attribute):\n        self.attribute = attribute\n\n    def __get__(self, obj, type=None):\n        raise AttributeError(\"'{}' object has no attribute '{}'\".format(obj, self.attribute))\n\n    def __set__(self, obj, value):\n        obj.__dict__[self.attribute] = value\n\nclass YourClass:\n    private = Private('private')\n\n    def __init__(self):\n        self.private = 10\n        print(self.private)  # Raise AttributeError\n"], ["import pandas as pd\nimport matplotlib.pyplot as plt\nfrom matplotlib.ticker import PercentFormatter\n\ndf = pd.DataFrame({'country': [177.0, 7.0, 4.0, 2.0, 2.0, 1.0, 1.0, 1.0]})\ndf.index = ['USA', 'Canada', 'Russia', 'UK', 'Belgium', 'Mexico', 'Germany', 'Denmark']\ndf = df.sort_values(by='country',ascending=False)\ndf[\"cumpercentage\"] = df[\"country\"].cumsum()/df[\"country\"].sum()*100\n\n\nfig, ax = plt.subplots()\nax.bar(df.index, df[\"country\"], color=\"C0\")\nax2 = ax.twinx()\nax2.plot(df.index, df[\"cumpercentage\"], color=\"C1\", marker=\"D\", ms=7)\nax2.yaxis.set_major_formatter(PercentFormatter())\n\nax.tick_params(axis=\"y\", colors=\"C0\")\nax2.tick_params(axis=\"y\", colors=\"C1\")\nplt.show()\n"], ["x = [True, False, True, False]\ny = ['a', 'b', 'c', 'd']\n\nprint([item for keep, item in zip(x, y) if keep])\n", "import numpy as np\n\nx = [True, False, True, False]\ny = ['a', 'b', 'c', 'd']\n\nprint(list(np.array(y)[x]))\n", "x = [True, False, True, False]\ny = ['a', 'b', 'c', 'd']\n\ntemp = []\n\nfor index in range(len(y)):\n    if x[index]:\n        temp.append(y[index])\n\nprint(temp)\n"], ["import numpy as np\n>>> x = [True, False, True, False]\n>>> y = ['a', 'b', 'c', 'd']\n>>> np.array(y)[x]\narray(['a', 'c'], dtype='<U1')\n", ">>> [i for idx, i in enumerate(y) if x[idx]]\n['a', 'c']\n"]]