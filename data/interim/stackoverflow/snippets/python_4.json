[["cv.CascadeClassifier(cv.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n", "pip install opencv-contrib-python\n"], ["cv.CascadeClassifier(cv.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n"], ["camera = cv.VideoCapture(camera_port, cv.CAP_DSHOW) # Added cv.CAP_DSHOW\nreturn_value, image = camera.read()\ncv.imwrite(\"image.png\", image)\ncamera.release()\ncv.destroyAllWindows() # Handles the releasing of the camera accordingly\n"], [], ["captureDevice = cv.VideoCapture(0, cv.CAP_DSHOW)\n"], ["camera = cv.VideoCapture(camera_port, cv.CAP_DSHOW)\n\ncv.destroyAllWindows()\n"], ["camera.release()\ncv2.destroyAllWindows()\n"], [], ["def cartesian_product_basic(left, right):\n    return (\n       left.assign(key=1).merge(right.assign(key=1), on='key').drop('key', 1))\n\ncartesian_product_basic(left, right)\n", "left.merge(right, how=\"cross\") # implements the technique above\n", "  col1_x  col2_x col1_y  col2_y\n0      A       1      X      20\n1      A       1      Y      30\n2      A       1      Z      50\n3      B       2      X      20\n4      B       2      Y      30\n5      B       2      Z      50\n6      C       3      X      20\n7      C       3      Y      30\n8      C       3      Z      50\n", "def cartesian_product(*arrays):\n    la = len(arrays)\n    dtype = np.result_type(*arrays)\n    arr = np.empty([len(a) for a in arrays] + [la], dtype=dtype)\n    for i, a in enumerate(np.ix_(*arrays)):\n        arr[...,i] = a\n    return arr.reshape(-1, la)  \n", "def cartesian_product_generalized(left, right):\n    la, lb = len(left), len(right)\n    idx = cartesian_product(np.ogrid[:la], np.ogrid[:lb])\n    return pd.DataFrame(\n        np.column_stack([left.values[idx[:,0]], right.values[idx[:,1]]]))\n\ncartesian_product_generalized(left, right)\n\n   0  1  2   3\n0  A  1  X  20\n1  A  1  Y  30\n2  A  1  Z  50\n3  B  2  X  20\n4  B  2  Y  30\n5  B  2  Z  50\n6  C  3  X  20\n7  C  3  Y  30\n8  C  3  Z  50\n\nnp.array_equal(cartesian_product_generalized(left, right),\n               cartesian_product_basic(left, right))\nTrue\n", "left2 = left.copy()\nleft2.index = ['s1', 's2', 's1']\n\nright2 = right.copy()\nright2.index = ['x', 'y', 'y']\n    \n\nleft2\n   col1  col2\ns1    A     1\ns2    B     2\ns1    C     3\n\nright2\n  col1  col2\nx    X    20\ny    Y    30\ny    Z    50\n\nnp.array_equal(cartesian_product_generalized(left, right),\n               cartesian_product_basic(left2, right2))\nTrue\n", "def cartesian_product_multi(*dfs):\n    idx = cartesian_product(*[np.ogrid[:len(df)] for df in dfs])\n    return pd.DataFrame(\n        np.column_stack([df.values[idx[:,i]] for i,df in enumerate(dfs)]))\n\ncartesian_product_multi(*[left, right, left]).head()\n\n   0  1  2   3  4  5\n0  A  1  X  20  A  1\n1  A  1  X  20  B  2\n2  A  1  X  20  C  3\n3  A  1  X  20  D  4\n4  A  1  Y  30  A  1\n", "def cartesian_product_simplified(left, right):\n    la, lb = len(left), len(right)\n    ia2, ib2 = np.broadcast_arrays(*np.ogrid[:la,:lb])\n\n    return pd.DataFrame(\n        np.column_stack([left.values[ia2.ravel()], right.values[ib2.ravel()]]))\n\nnp.array_equal(cartesian_product_simplified(left, right),\n               cartesian_product_basic(left2, right2))\nTrue\n", "from timeit import timeit\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nres = pd.DataFrame(\n       index=['cartesian_product_basic', 'cartesian_product_generalized', \n              'cartesian_product_multi', 'cartesian_product_simplified'],\n       columns=[1, 10, 50, 100, 200, 300, 400, 500, 600, 800, 1000, 2000],\n       dtype=float\n)\n\nfor f in res.index: \n    for c in res.columns:\n        # print(f,c)\n        left2 = pd.concat([left] * c, ignore_index=True)\n        right2 = pd.concat([right] * c, ignore_index=True)\n        stmt = '{}(left2, right2)'.format(f)\n        setp = 'from __main__ import left2, right2, {}'.format(f)\n        res.at[f, c] = timeit(stmt, setp, number=5)\n\nax = res.div(res.min()).T.plot(loglog=True) \nax.set_xlabel(\"N\"); \nax.set_ylabel(\"time (relative)\");\n\nplt.show()\n"], ["    # this is where the magic begins! (overload the '/' operator)\n    def __truediv__(self, key): \n        try:\n            return self._make_child((key,))\n        except TypeError:\n            return NotImplemented\n\n\n    def _make_child(self, args):\n        drv, root, parts = self._parse_args(args)\n        drv, root, parts = self._flavour.join_parsed_parts(\n            self._drv, self._root, self._parts, drv, root, parts)\n        return self._from_parsed_parts(drv, root, parts)\n\n\n    @classmethod\n    def _from_parsed_parts(cls, drv, root, parts):\n        self = object.__new__(cls)\n        self._drv = drv\n        self._root = root\n        self._parts = parts\n        return self  # finally return 'self', which is a Path object.\n"], ["sed 's/==.*$//' requirements.txt\n", "asgiref\nbeautifulsoup4\ncertifi\nchardet\nClick\nDjango\nidna\npytz\nrequests\nsix\nsoupsieve\nsqlparse\nurllib3\n", "sed 's/==.*$//' requirements.txt | xargs pip install\n"], [], [], ["df1 = df.filter(regex='TP|VR|TV')\n#i couldn't figure out to split by \n#word\\number without creating an additional whitespace split.\ndf1.columns = df1.columns\\\n     .str.replace('(\\d+)', r' \\1' ,regex=True).str.split(' ',expand=True)\n\n#or more succinctly.\ndf1.columns = pd.MultiIndex.from_frame(df1.columns.str.extract('(\\D+)(\\d+)'))   \n\nprint(df1)\n\n  TP              VR              TV\n   1    2     3    1     2     3   1   2   3\n0  0  700  2100  300  1159  2877  30  30  47\n", "df1.stack(1).rename(columns={'TP': 'Price', 'VR': 'Net', 'TV': 'Range'})\n    \n     Price  Range   Net\n0 1      0     30   300\n  2    700     30  1159\n  3   2100     47  2877\n"], ["df = pd.DataFrame({'TP1':[0], 'TP2':[700], 'TP3':[2100], 'VR1':[300], 'VR2':[1159], 'VR3':[2877], 'TV1':[30], 'TV2':[30], 'TV3':[47]})\n\npd.wide_to_long(df.reset_index(), [\"TP\", \"VR\", \"TV\"], i=\"index\", j=\"Nr\").droplevel('index').rename(columns={'TP': 'Price', 'VR': 'Net', 'TV': 'Range'})\n", "    Price   Net  Range\nNr                    \n1       0   300     30\n2     700  1159     30\n3    2100  2877     47\n"], [], ["pd.wide_to_long(df, stubnames=['TP', 'VR', 'TV'], i='Num', j='ID')\n", "out = (pd\n .wide_to_long(df, stubnames=['TP', 'VR', 'TV'], i='Num', j='ID')\n .reset_index('ID')\n .drop(columns=['TR', 'TR-Tag'])\n .rename(columns={'TP': 'Price', 'VR': 'Net', 'TV': 'Range'})\n )\n", "       ID  Price   Net  Range\nNum                          \nAA-24   1      0   300     30\nAA-24   2    700  1159     30\nAA-24   3   2100  2877     47\n", "out = (pd\n .wide_to_long(df.set_axis(df.columns.str.replace(r'\\(USD\\)$', '', regex=True),\n                           axis=1),\n               stubnames=['TP', 'VReal', 'TiV'], i='Num', j='ID')\n .reset_index('ID')\n .drop(columns=['TR', 'TR-Tag'])\n .rename(columns={'TP': 'Price', 'VReal': 'Net', 'TiV': 'Range'})\n )\n", "       ID  Price   Net  Range\nNum                          \nAA-24   1      0   300     30\nAA-24   2    700  1159     30\nAA-24   3   2100  2877     47\n"], ["#install venv \npython3 -m venv venv\n\n#activate venv\nsource venv/bin/activate\n\n#on Windows (cmd.exe)\nvenv\\Scripts\\activate.bat\n\n#on Windows (PowerShell)\nvenv\\Scripts\\Activate.ps1\n\n#install requests in virtual environment\npip install request\n", "python3 -m pip install requests\n", "pip3 show requests \n", "python3 -m pip show requests \n"], [], ["txt = \"apple_banana_cherry_orange\"\n# setting the maxsplit parameter to 1, will return a list with 2 elements!\nx = txt.split(\"_\", 1)\nprint(x[-1])\n"], ["input_string = \"blah_end\"\ndelimiter = '_'\n\nif delimiter in input_string:\n     result = input_string.split(\"_\", 1)[1] # The \",1\" says only split once\nelse:\n     # Do whatever here. If you want  a space, \" \" to be a delimiter too you can try that.\n     result = input_string\n"], [], ["sp = string.split('_')\nresult = '_'.join(sp[1:]) if len(sp) > 1 else sp[0]\n"], [], ["function subLength(word, character) {\n  const regexString = `[${character}]`;\n  const regex = new RegExp(regexString, 'g');\n  const found = word.match(regex);\n  \n  if (found.length !== 2) {\n    return 0;\n  } \n  \n  first = word.indexOf(character);\n  second = word.lastIndexOf(character);\n  \n  return second - first + 1;\n};\n\nsubLength('Saturday', 'a'); // returns 6\n"], ["def calculator():\n    # Get dog age\n    age = input(\"Input dog years: \")\n    try:\n    # Cast to float\n        d_age = float(age)\n        if (d_age> 5):\n            human_age = (d_age-5)*7+5*7.2\n            print(\"The given dog age\",str(d_age),\"is\", str(human_age), \"in human years\")\n        elif (d_age>4):\n                human_age = d_age*7.2\n                print(\"The given dog age\",str(d_age),\"is\",str(human_age),\"in human years\")\n        elif (d_age>3):\n                human_age = d_age*8\n                print(\"The given dog age\",str(d_age),\"is\",str(human_age),\"in human years\")\n        elif (d_age>2):\n                human_age = d_age*9.3\n                print(\"The given dog age\",str(d_age),\"is\",round(human_age,2),\"in human years\")\n        elif (d_age>1):\n                human_age = d_age*12\n                print(\"The given dog age\",str(d_age),\"is\",str(human_age),\"in human years\")\n        elif (d_age>0):\n                human_age = d_age*15\n                print(\"The given dog age\",str(d_age),\"is\",str(human_age),\"in human years\")\n        elif (d_age<0 or d_age==0):\n                print(d_age, \"is a negative number or zero. Age can not be that.\")\n    except:\n        print(age, \"is an invalid age.\")\n        print(traceback.format_exc())\n        \ncalculator()\n"], ["for sum_row, sum_col in zip(map(sum, matrix), map(sum, zip(*matrix))):\n    print(sum_row, sum_col)\n\n\n"], [], [], [], ["pip install requests\n"], ["df= df.withColumn('month_date', trunc('date', 'month'))\n", "date           month_date \n2019-05-28     2019-05-01\n", "df= df.withColumn(\"week_end\", next_day(\"date\", \"SUN\")).withColumn(\"week_start_date\", date_sub(\"week_end\", 6))\n"], [], ["# A 2D plot of the SPEED variable, assigning the coordinate values,\n# and plot the verticies of each point\nds.SPEED.plot(x='longitude', y='latitude')\nplt.scatter(ds.longitude, ds.latitude)\n\n# I want to find the speed at a certain lat/lon point.\nlat = 21.22\nlon = -122.68\n\n# First, find the index of the grid point nearest a specific lat/lon.   \nabslat = np.abs(ds.latitude-lat)\nabslon = np.abs(ds.longitude-lon)\nc = np.maximum(abslon, abslat)\n\n([xloc], [yloc]) = np.where(c == np.min(c))\n\n# Now I can use that index location to get the values at the x/y diminsion\npoint_ds = ds.sel(x=xloc, y=yloc)\n\n# Plot requested lat/lon point blue\nplt.scatter(lon, lat, color='b')\nplt.text(lon, lat, 'requested')\n\n# Plot nearest point in the array red\nplt.scatter(point_ds.longitude, point_ds.latitude, color='r')\nplt.text(point_ds.longitude, point_ds.latitude, 'nearest')\n\nplt.title('speed at nearest point: %s' % point_ds.SPEED.data)\n"], ["DG = nx.DiGraph([(1,2), (2,4), (3,4), (4,5), (4,6), (6,7)])\n[sorted(generation) for generation in nx.topological_generations(DG)]\n", "[[1, 3], [2], [4], [5, 6], [7]]\n"], [], [], ["def anti_vowel(text):\n    all_vowels = [\"A\", \"E\", \"U\", \"I\", \"O\", \"a\", \"e\", \"o\", \"u\", \"i\"]\n    listed_text = []\n    for letter in text:\n        listed_text.append(letter)\n    for vowel in all_vowels:\n        while vowel in listed_text:\n            listed_text.remove(vowel)\n    return \"\".join(listed_text)\n    \nprint(anti_vowel(\"Hey look Words!\"))\n", "Hy lk Wrds!\n"], ["if base< num :\n   calc += f\" + {num}\"\n"], ["numbers = [5,6,7,8,8]\nmaxlist = [num for num in numbers if True not in [True for i in numbers if i > num]]\n"], ["import pandas as pd\n", "def calc_grade(age):\n        if 50 < age < 200:\n            return 'Grandpa'\n        elif 30 <= age <=50:\n            return 'Mature'\n        elif 20 <= age < 30:\n            return 'Young'\n        elif 10 <= age < 20:\n            return 'Kid'\n        elif age < 10:\n            return 'Baby'\n\n%timeit df['elderly'] = df['age'].map(calc_grade)\n", "bins = [0, 10, 20, 30, 50, 200] #200 year Vampires are people I guess...you could change to a date you belieave plausible.\nlabels = ['Baby','Kid','Young', 'Mature','Grandpa']\n\n%timeit df['elderly'] = pd.cut(x=df.age, bins=bins, labels=labels , include_lowest=True, right=False, ordered=False)\n"], [], ["class Solution:\n    def letterCombinations(self, digits: str) -> List[str]:\n        phoneKeypad = {'2':'abc', '3':'def','4':'ghi', '5':'jkl', '6':'mno', '7':'pqrs','8':'tuv', '9':'wxyz'}\n        if digits == \"\":\n            return []\n        numbers = list(phone_map[digits[0]])\n        for digit in digits[1:]:\n            numbers = [old+new for old in numbers for new in list(phoneKeypad[digit])]\n        return numbers\n"], ["1. App Key === API Key === Consumer API Key === Consumer Key === Customer Key === oauth_consumer_key\n2. App Key Secret === API Secret Key === Consumer Secret === Consumer Key === Customer Key === oauth_consumer_secret\n3. Callback URL === oauth_callback\n \n", "1. Request Token === oauth_token\n2. Request Token Secret === oauth_token_secret\n3. oauth_verifier\n \n", "1. Access token === Token === resulting oauth_token\n2. Access token secret === Token Secret === resulting oauth_token_secret\n", "api_key = \"hgrthgy2374RTYFTY\"  # CONSUMER_KEY\napi_secret_key = \"hGDR2Gyr6534tjkht\"  # CONSUMER_SECRET\naccess_token = \"HYTHTYH65TYhtfhfgkt34\"  # ACCESS_TOKEN\naccess_token_secret = \"ged5654tHFG\"  # ACCESS_TOKEN_SECRET\n\nauth = tweepy.OAuthHandler(api_key, api_secret_key)\nauth.set_access_token(access_token, access_token_secret)\napi = tweepy.API(auth)  \n", "bearer_token = \"ABDsdfj56nhiugd5tkggred\"  # BEARER_TOKEN\nauth = tweepy.Client(bearer_token)\napi = tweepy.API(auth)\n", "auth = tweepy.AppAuthHandler(consumer_key, consumer_secret)\napi = tweepy.API(auth)\n"], ["import asyncio\n\nasync def example():\n    p1 = await asyncio.create_subprocess_exec(\"sleep\", \"1\")\n    p2 = await asyncio.create_subprocess_exec(\"sleep\", \"2\")\n    p1_run = asyncio.create_task(p1.wait())\n    p2_run = asyncio.create_task(p2.wait())\n    pending = [p1_run, p2_run]\n    while pending:\n        done, pending = await asyncio.wait(pending, return_when=asyncio.FIRST_COMPLETED)\n        if p1_run in done:\n            print(\"p1 finished, with status: \", p1.returncode)\n        if p2_run in done:\n            print(\"p2 finished, with status: \", p2.returncode)\n\nasyncio.get_event_loop().run_until_complete(example())\n", "async def wait_and_return_original(proc: asyncio.subprocess):\n    await proc.wait()\n    return proc\n\nasync def example2():\n    p1 = await asyncio.create_subprocess_exec(\"sleep\", \"1\")\n    p2 = await asyncio.create_subprocess_exec(\"sleep\", \"2\")\n    \n    for p in asyncio.as_completed([wait_and_return_original(p) for p in [p1, p2]]):\n        p_completed = await p   # NOTE: for-loop iteration variable doesn't decide which task is first completed until here!\n        if p_completed is p1:\n            print(\"p1 finished, with status: \", p1.returncode)\n        if p_completed is p2:\n            print(\"p2 finished, with status: \", p2.returncode)\n\nasyncio.get_event_loop().run_until_complete(example2())\n"], ["import cv2\nfrom google.colab.patches import cv2_imshow\nimport time\n\ncap = cv2.VideoCapture('video.mp4')\n\nwhile cap.isOpened():\n#while True:\n  ok, frame = cap.read()\n\n  if not ok:\n    break\n\n  if ok:\n    #edit your video size here, to adjust the performance\n    largura=frame.shape[1] \n    altura=frame.shape[0]\n    lamenor=int(frame.shape[1]/5)\n    altmenor=int(frame.shape[0]/5)\n    frame = cv2.resize(frame, (lamenor,altmenor))\n\n    # as you read\n    clear_output(wait=True)\n    cv2_imshow(frame)\n    #delay time to update frame\n    time.sleep(1.1)\n\n  if cv2.waitKey(1100) & 0xFF == ord('q'):\n    break\n\ncap.release()\ncv2.destroyAllWindows()\n", "cap = cv2.VideoCapture('video.mp4')\n", "#0 = webcam position in your webcams\ncap = cv2.VideoCapture(0)\n#or cap = cv2.VideoCapture(0, cv2.CAP_DSHOW)\n", "frame2 = cv2.flip(frame, 1)\n\n# as you read\nclear_output(wait=True)\ncv2_imshow(frame)\ncv2_imshow(frame2)\n"], ["with pd.ExcelWriter('target.xlsx', mode='a') as writer:  \n    df.to_excel(writer, sheet_name='sheet_1')\n"], [" def isPermutationOfPalindrome(phrase): #solution in O(l) where l is the length of phrase\n        phrase = phrase.lower()\n        odd_chars = []\n        for rec in phrase:\n            if rec!=' ':\n                if rec not in odd_chars:\n                    odd_chars.append(rec)\n                else:\n                    odd_chars.remove(rec)\n        if(len(odd_chars)<=1):\n            return True\n        return False\n    \n    print(isPermutationOfPalindrome(\"Tact Coa\"))\n", "  t  -->  odd_chars =  ['t']\n  a  -->  odd_chars =  ['t', 'a']\n  c  -->  odd_chars =  ['t', 'a', 'c']\n  t  -->  odd_chars =  ['a', 'c']\n  c  -->  odd_chars =  ['a']\n  o  -->  odd_chars =  ['a', 'o']\n  a  -->  odd_chars =  ['o']\n    \n    Result:\n        True\n"], ["    a_string = 'word 1 tab \\t double quote \\\\\" last words'\n    print(f'a_string={a_string}')\n    print(f'{a_string=}')\n", "    a_string=word 1 tab      double quote \\\" last words\n    a_string='word 1 tab \\t double quote \\\\\" last words\n"], [], [], ["celery_app = Celery()\n...\ncelery_app.conf.update(result_extended=True)\n", "task = AsyncResult(task_id, app=celery_app)\ntask.name\n"], [], ["mat = [[1, 2, 3, 5],\n     [5, 6, 7, 1],\n     [9, 10, 11, 8],\n     [4, 7, 4, 3]]\n \ndef rotate_matrix(a):\n    b = []\n    i = len(a)-1\n    while i>=0:\n        if len(a) == len(a[-1]):\n            for j in range(0, len(a)):\n                print(j)\n                if (len(b) < (j+1)):\n                    b.append([a[i][j]])\n                    print(b)\n                else:\n                    b[j].append(a[i][j])\n                    print(b)\n            i -= 1\n        else:\n            for j in range(0, len(a)+1):\n                print(j)\n                if (len(b) < (j+1)):\n                    b.append([a[i][j]])\n                    print(b)\n                else:\n                    b[j].append(a[i][j])\n                    print(b)\n            i -= 1\n    return b\n    \nprint(rotate_matrix(mat))\n"], [], ["import time\nstart_time = time.time()\n...\nelapsed_time = time.time() - start_time\ndays = 0\nif elapsed_time >= 86400:\n    days = int(elapsed_time / 86400)\nelapsed = time.strftime(\"%H:%M:%S\", time.gmtime(time.time() - start_time))\nif days == 0:\n    print(f\"Took: {elapsed}\")\nelse:\n    print(f\"Took: {days}:{eplased}\")\n\n  \n"], ["control_dict = {}\nfuture = executor.submit(my_func, chunk))\ncontrol_dict[id(future)] = chunk\n"], ["#vending machine\ndef CountMoneyAndIssueDrink():\n    \n    total_coins = 0\n    coke_price = 10\n    change = 0\n    \n    while True:\n        insertedcoins = int(input(\"Insert coins:\"))\n        total_coins += insertedcoins\n        print(total_coins ,\" total coins inserted\")\n        \n        if total_coins <= 0:\n            print(\"Insert some coins\")\n            CountMoneyAndIssueDrink()\n            return\n        elif(total_coins > coke_price):\n            change = total_coins - coke_price\n            print(\"enjoy coke!!, here is the change:\", change)\n            break\n        elif(total_coins == coke_price):\n            print(\"enjoy coke!!\")\n            break\n\n\nif __name__ == \"__main__\":\n    CountMoneyAndIssueDrink()\n"], ["maths,A,123 \n", "df = pd.read_csv(csv_filename, names=(\"subject\", \"grade\", \"studentid\"))\n"], [], ["def repeatedString(s, n):\n    \n    totalNumber = 0 // setting total of a's to 0\n\n    // using count function to find the total number of a's in the substring\n    totalNumber = s.count('a')\n\n    // finding how many number of times the substring fits in \"n\" and multiplying that by the number of a's we found earlier\n    totalNumber = n//len(s) * totalNumber \n\n    // if there is a remainder, we loop through the remainder string and add the number of \"a's\" found in that substring to the total\n    for i in s[:n%len(s)]:\n        if(i == \"a\"):\n            totalNumber +=1\n        \n    return totalNumber\n"], [], ["[cfati@cfati-5510-0:/cygdrive/e/Work/Dev/StackOverflow/q055271912]> ~/sopr.sh\n### Set shorter prompt to better fit when pasted in StackOverflow (or other) pages ###\n\n[064bit prompt]> ls\ncode00.py  code01.py\n[064bit prompt]>\n[064bit prompt]> cat code00.py\nprint(\"This is:\", __file__)\n\n[064bit prompt]> python3 -c \"import os, subprocess;subprocess.Popen(os.path.join(os.getcwd(), \\\"code00.py\\\")).communicate()\"\nTraceback (most recent call last):\n  File \"<string>\", line 1, in <module>\n  File \"/usr/lib/python3.6/subprocess.py\", line 709, in __init__\n    restore_signals, start_new_session)\n  File \"/usr/lib/python3.6/subprocess.py\", line 1344, in _execute_child\n    raise child_exception_type(errno_num, err_msg, err_filename)\nOSError: [Errno 8] Exec format error: '/cygdrive/e/Work/Dev/StackOverflow/q055271912/code00.py'\n[064bit prompt]>\n[064bit prompt]> cat code01.py\n#!/usr/bin/env python3\n\nprint(\"This is:\", __file__)\n\n[064bit prompt]> python3 -c \"import os, subprocess;subprocess.Popen(os.path.join(os.getcwd(), \\\"code01.py\\\")).communicate()\"\nThis is: /cygdrive/e/Work/Dev/StackOverflow/q055271912/code01.py\n"], [], [], ["0, 1, 2\n1, 2, 0\n2, 0, 1\n0, 1, 2\n1, 2, 0\n2, 0, 1\n...\n"], [], [], ["from dataclasses import dataclass\nimport re\nfrom enum import Enum\n\n\nclass Descriptor:\n    def __init__(self, type, validators=(), **kwargs):\n        self.type = type\n        self.default = kwargs.get(\"default\")\n        self.validators = validators\n        self.kwargs = kwargs\n\n    def __set_name__(self, owner, name):\n        self.name = name\n\n    def __get__(self, instance, owner):\n        if not instance:\n            return self\n        # return instance.__dict__[self.name]\n        return instance.__dict__.get(self.name, self.default)\n\n    def __delete__(self, instance):\n        del instance.__dict__[self.name]\n\n    def __set__(self, instance, value):\n        if isinstance(value, Descriptor):\n            value = self.default\n        else:\n            if not isinstance(value, self.type):\n                raise TypeError(\n                    f\"{self.name!r} VALUES MUST BE TYPE {self.type!r} NOT {type(value)}!\"\n                )\n            switch = {\n                \"POSITIVE\": self.val_positive,\n                \"BETWEEN\": self.val_between_values,\n                \"MAXMINZISE\": self.val_between_sizes,\n                \"SIZE\": self.val_size,\n                \"EMAIL\": self.val_email,\n                \"NUMBER\": self.val_number,\n                \"ONEOF\": self.val_one_of,\n            }\n            for validator in self.validators:\n                if validator in switch:\n                    switch[validator](value)\n        instance.__dict__[self.name] = value\n\n    def val_positive(self, value: int | float):\n        if value <= 0:\n            raise ValueError(f\"VALUE IS NOT VALID FOR {self.name!r} MUST BE POSITIVE\")\n\n    def val_between_values(self, value: int | float):\n        maxval = self.kwargs.get(\"maxval\")\n        if maxval is not None:\n            if not isinstance(maxval, int) or isinstance(maxval, float):\n                raise TypeError(\n                    f\"MAX VALUE MUST BE TYPE INTEGER OR FLOAT NOT {type(value)}!\"\n                )\n            if value > maxval:\n                raise ValueError(\n                    f\"VALUE IS NOT VALID FOR {self.name!r} MUST BE GREATER THAN {maxval}\"\n                )\n        minval = self.kwargs.get(\"minval\")\n        if minval is not None:\n            if not isinstance(minval, int) or isinstance(maxval, float):\n                raise TypeError(\n                    f\"MIN VALUE MUST BE TYPE INTEGER OR FLOAT NOT {type(value)}!\"\n                )\n            if value < minval:\n                raise ValueError(\n                    f\"VALUE IS NOT VALID FOR {self.name!r} MUST BE LESS THAN {minval}\"\n                )\n\n    def val_between_sizes(self, value: int):\n        maxsize = self.kwargs.get(\"maxsize\")\n        if maxsize is not None:\n            if not isinstance(maxsize, int):\n                raise TypeError(f\"MAX VALUE MUST BE TYPE INTEGER NOT {type(value)}!\")\n            if len(value) > maxsize:\n                raise ValueError(\n                    f\"VALUE IS NOT VALID FOR {self.name!r} MUST BE GREATER THAN {maxsize}\"\n                )\n        minsize = self.kwargs.get(\"minsize\")\n        if minsize is not None:\n            if not isinstance(minsize, int):\n                raise TypeError(f\"MIN VALUE MUST BE TYPE INTEGER NOT {type(value)}!\")\n            if len(value) < minsize:\n                raise ValueError(\n                    f\"VALUE IS NOT VALID FOR {self.name!r} MUST BE LESS THAN {minsize}\"\n                )\n\n    def val_size(self, value: str):\n        length = self.kwargs.get(\"size\")\n        if length is None:\n            raise ValueError(\"LEN NOT DEFINED\")\n        if len(value) > length:\n            raise ValueError(\n                f\"VALUE IS NOT VALID FOR {self.name!r} THE LIMIT OF CHACRTERS IS {length}\"\n            )\n\n    def val_email(self, value: str):\n        regex = r\"\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b\"\n        if not re.fullmatch(regex, value):\n            raise ValueError(\"MAIL NOT VALID\")\n\n    def val_number(self, value: str):\n        regex = \"[0-9]+\"\n        if not re.match(regex, value):\n            raise ValueError(\"STRING NUMBER NOT VALID\")\n\n    def val_one_of(self, value: str):\n        posible_values = self.kwargs.get(\"posible_values\")\n        if posible_values is None:\n            raise ValueError(\"POSIBLE VALUES NOT DEFINED\")\n        if not issubclass(posible_values, Enum):\n            raise TypeError(f\"POSIBLE VALUES MUST BE TYPE ENUM NOT {type(value)}!\")\n        values = [e.value for e in posible_values]\n        if value not in values:\n            raise ValueError(\n                f\"VALUE IS NOT VALID FOR {self.name!r} IS NOT PRESENT IN ARRAY {posible_values}\"\n            )\n@dataclass\nclass Person():\n   personid: str = Descriptor((str), [\"SIZE\"], size=8)\n"], [">>> d = deque([0,1,2])\n>>> for _ in range(10):\n...     print(*d)\n...     d.rotate(-1)  # negative -> rotate to the left\n...\n0 1 2\n1 2 0\n2 0 1\n0 1 2\n1 2 0\n2 0 1\n0 1 2\n1 2 0\n2 0 1\n0 1 2\n"], ["cycles = [a[i:]+a[:i] for i, _ in enumerate(a)]\nwhile True:\n    for c in cycles: print(c)\n", "from itertools import count\nn = len(a)\nfor i in count():\n    j = i%n\n    print(a[j:]+a[:j])\n"], [], ["a = [ 0, 1, 2 ]\ni = 0\nl = len(a)\nwhile True:\n  out = []\n  for j in range(i, i+l):\n    out.append(a[j%l])\n  print(out)\n  i=(i+1)%l\n", "[0, 1, 2]\n[1, 2, 0]\n[2, 0, 1]\n[0, 1, 2]\n[1, 2, 0]\n[2, 0, 1]\n"], [], [], [], ["class MyInline(django.contrib.admin.TabularInline):\n\n    def formfield_for_dbfield(self, *args, **kwargs):\n        formfield = super().formfield_for_dbfield(*args, **kwargs)\n        if formfield:\n            formfield.widget.can_delete_related = False\n            formfield.widget.can_change_related = False\n            formfield.widget.can_add_related = False\n            formfield.widget.can_view_related = False\n\n        return formfield\n"], [], ["today = datetime.date.today()\nprevious_year = today.year -1\ntoday_last_year = today.replace(year = previous_year)\n"], ["{% load static %}\n<link rel\"stylesheet\" href = \"{% static 'style.css' %}\">\n"], [], [], ["def cycle(colors,n):\n   return [colors[(n + i) % len(colors)] for i in range(len(colors))]\n", "[cycle(colors,j) for j in range(len(colors))]\n"], [], [], [], [], ["def elderly_function(age):\n if age < 10:\n  return 'baby'\n if age < 20:\n  return 'kid'\n if age < 30\n  return 'young'\n if age < 50:\n  return 'mature'\n if age >= 50:\n  return 'grandpa'\n\ndf[\"elderly\"] = df[\"age\"].map(lambda x: elderly_function(x))\n# Works with apply as well:\ndf[\"elderly\"] = df[\"age\"].apply(lambda x: elderly_function(x))\n"], ["dataclassWith(Y(x=2, z=5), y=3)      # > Y(x=3, y=3, z=5)\ndataclassWith(Y(x=2, z=5), X, x=99)  # > X(z=5, x=99)  # There is no z\n", "MISSING = object()\ndef dataclassWith(other, clz=None, **kw):\n    if clz is None: clz = other.__class__\n\n    k = other.__dict__.copy()\n    k.update(kw)\n    return clz(**{k:v for k,v in k.items()\n                  if getattr(clz, k, MISSING) is not MISSING})\n\n\nclass TestDataclassUtil(unittest.TestCase):\n    def test_dataclassWith(self):\n        @dataclasses.dataclass\n        class X():\n            x:int = 1\n            z:int = 99\n\n        @dataclasses.dataclass\n        class Y(X):\n            y:int = 2\n\n        r = dataclassWith(Y(x=2), y=3)\n        self.assertTrue(isinstance(r, Y))\n        self.assertTrue(r.x==2)\n        self.assertTrue(r.y==3)\n        self.assertTrue(r.z==99)\n\n        r = dataclassWith(Y(x=2), X, z=100)\n        self.assertTrue(isinstance(r, X))\n        self.assertTrue(r.x==2)\n        self.assertTrue(r.z==100)\n"], ["pypy3\npypy3-pip\nipypy3\nbuild-essential\npypy-dev\npypy3-dev\n"], ["my_list_of_dicts = [s.to_dict() for s in li]\nmy_df = pd.Dataframe(my_list_of_dicts)\n"], ["def divisibleSumPairs(n, k, ar):\n   \n    import itertools\n    \n    return len([x for x in itertools.combinations(ar,r=2) if (x[0]+x[1])%k==0])\n"], ["if __name__ == '__main__':\n    app.run_server(host='0.0.0.0', port=8007, debug=False)\n"], ["list1 = [\"1\",\"2\",\"4\",\"5\",\"3\"]\n\nfor index,value in enumerate(list1):\n    if value in [\"3\"] : # this condiation can be (value in [\"3\",\"2\"])\n        list1.pop(index)\n        break\nprint(list1)\n"], ["print(i, type(i))\n", "for i, element in enumerate(list):\n"], [], ["cdo remapbil,target_grid infile.nc ofile.nc\n"], [], [], ["0 < a < b < c\n", "p(x,y,z) = 1 - mu(x,y,y)/mu_max\n", "mu(x,y,z) = ((acy)^2 + (abz)^2 + (bcx)^2)^0.5\n", "mu_max = bc\n", "import numpy as np\nnp.random.seed(42)\n\n# Function to generate a random point on a uniform sphere\n# (relying on https://stackoverflow.com/a/33977530/8565438)\n\ndef randompoint(ndim=3):\n    vec = np.random.randn(ndim,1)\n    vec /= np.linalg.norm(vec, axis=0)\n    return vec\n\n# Give the length of each axis (example values):\n\na, b, c = 1, 2, 4\n\n# Function to scale up generated points using the function `f` mentioned above:\n\nf = lambda x,y,z : np.multiply(np.array([a,b,c]),np.array([x,y,z]))\n\n# Keep the point with probability `mu(x,y,z)/mu_max`, ie\n\ndef keep(x, y, z, a=a, b=b, c=c):\n    mu_xyz = ((a * c * y) ** 2 + (a * b * z) ** 2 + (b * c * x) ** 2) ** 0.5\n    return mu_xyz / (b * c) > np.random.uniform(low=0.0, high=1.0)\n\n# Generate points until we have, let's say, 1000 points:\n\nn = 1000\npoints = []\nwhile len(points) < n:\n    [x], [y], [z] = randompoint()\n    if keep(x, y, z):\n        points.append(f(x, y, z))\n", "for p in points:\n    pscaled = np.multiply(p,np.array([1/a,1/b,1/c]))\n    assert np.allclose(np.sum(np.dot(pscaled,pscaled)),1)\n", "import matplotlib.pyplot as plt\nfig = plt.figure()\nax = fig.add_subplot(projection=\"3d\")\npoints = np.array(points)\nax.scatter(points[:, 0], points[:, 1], points[:, 2])\n# set aspect ratio for the axes using https://stackoverflow.com/a/64453375/8565438\nax.set_box_aspect((np.ptp(points[:, 0]), np.ptp(points[:, 1]), np.ptp(points[:, 2])))\nplt.show()\n"], [], ["from decouple import config\n\nif __name__ == \"__main__\":\n    if config(\"ENV\") == \"DEV\":\n        app.run(debug=True, port=8080)\n    else:\n        app.run(debug=False, port=8080)\n"], ["for train_i, test_i in kf.split(X):\n    print(\"TRAIN:\", train_i, \"TEST:\", test_i)\n    X_train, X_test = X.iloc[train_i], X.iloc[test_i]\n    y_train, y_test = y.iloc[train_i], y.iloc[test_i]\n"], [], ["string_list = input().split(\" \")\nnum_list = []\nnew_list = []\nfor each_word in string_list:\n    num = ''\n    new_word = ''\n    for each_char in enumerate(each_word):\n        index, character = each_char\n        if (character.isdigit()) :\n            num += character\n        elif(character.isdigit() == False and num != ''): \n            num_list += [int(num)]\n            num = ''\n            new_word += \"{}\" + character \n        else:\n            new_word += character\n\n    if (each_word.isdigit() or num != ''):\n        num_list += [int(num)]\n        new_word += \"{}\"\n    if new_word != '':\n        new_list += [new_word]\n    if each_word == \"\":\n        new_list += [\"\"]\n\n\nnum_list = sorted(num_list, reverse= True)\nprint(\" \".join(new_list).format(*num_list))\n"], ["from typing import Any, List\nfrom typing_extensions import Final\n\nNO_SKIP_OPTION: Final[str] = \"--no-skip\"\n\ndef pytest_addoption(parser):\n    parser.addoption(NO_SKIP_OPTION, action=\"store_true\", default=False, help=\"also run skipped tests\")\n\ndef pytest_collection_modifyitems(config,\n                                  items: List[Any]):\n    if config.getoption(NO_SKIP_OPTION):\n        for test in items:\n            test.own_markers = [marker for marker in test.own_markers if marker.name not in ('skip', 'skipif')]\n"], [], ["with torch.no_grad():\n   graph_x = some_list_of_numbers\n   graph_y = some_list_of_tensors\n\n   plt.plot(graph_x, graph_y)\n   plt.show()\n"], ["app.run_server(host=\"127.0.0.1\", port=\"8050\")\n"], ["my_list = [f\"Unnamed: {i}\" for i in range(16, 60)]\n\n# Output\n['Unnamed: 16', 'Unnamed: 17', 'Unnamed: 18', 'Unnamed: 19', ...]\n"], ["torch.load(file)\n", "result = torch.from_numpy(np.load(file))\n"], [], ["from concurrent.futures import ThreadPoolExecutor, as_completed\n\ndef add_one(number, n):\n    return number + 1 + n\n\ndef process():\n    all_numbers = []\n    for i in range(0, 10):\n        all_numbers.append(i)\n\n    threads = []\n    all_results = []\n    with ThreadPoolExecutor(max_workers=10) as executor:\n        for number in all_numbers:\n            threads.append(executor.submit(add_one, number))\n\n        for index, task in enumerate(threads):\n            result = task.result()\n            #print(result)\n            all_results.append(result)\n\n    for index, result in enumerate(all_results):\n        print(result)\n\nprocess()\n"], [], ["    -abs(n)\n"], [], [], [], ["list(map(lambda x: f'Unnamed: {x}', range(16, 60)))\n"], ["prefix = \"Unnamed: \"\nlst = [prefix + str(i) for i in range(16,25)]\nprint(lst)\n", "['Unnamed: 16', 'Unnamed: 17', 'Unnamed: 18', 'Unnamed: 19', 'Unnamed: 20', 'Unnamed: 21', 'Unnamed: 22', 'Unnamed: 23', 'Unnamed: 24']\n"], [], ["ls /usr/bin/python*\n# /usr/bin/python2    /usr/bin/python3    /usr/bin/python2.7  /usr/bin/python3.6\n\npython3 -V\n# Python 3.6.8\n", "which aws\n# ~/.local/bin/aws\n\nvi ~/.local/bin/aws\n#!/usr/bin/python3\n", "$ aws\n# usage: aws [options] <command> <subcommand> [<subcommand> ...] [parameters]\n"], ["from itertools import zip_longest\n''.join(''.join(x) for x in zip_longest(abc,qwe,fillvalue =''))\n"], [], ["async def foo():\n   r = asynkit.eager(get_remote_data(url))\n   s = await do_other_stuff()\n   return compute(s, await r)\n"], ["from itertools import zip_longest\nabc = 'Hello World'\nqwe = 'abc 123'\n''.join(i+j for i, j in zip_longest(abc, qwe, fillvalue=''))\n", "'Haeblcl o1 2W3orld'\n"], [], ["abc = 'Hello World'\nqwe = 'abc 123'\nmin_len = min(len(abc), len(qwe))\nprint(\"\".join(a+q for a,q in zip(abc, qwe)) + abc[min_len:] + qwe[min_len:])\n"], [], ["def repeatedString(s, n):\n    count = 0\n    for index, i in enumerate(s*n):\n        if index >= n:\n            return count\n        if(i == 'a'):\n            count += 1\n    # empty string\n    return count\n"], ["a = int(input(\"Please enter the first value: \"))\nb = int(input(\"Please enter the second value: \"))\nc = int(input(\"Please enter the third value: \"))\nlst = []\nlst.append(a)\nlst.append(b)\nlst.append(c)\nprint(sorted(lst))\n"], ["$ ./tone.py ~/pics/girl.jpg x.jpg +10 +10 0\n"], ["try:\n   money=int(input())\n\n   if money <10000:\n       print('you are poor '+name)\n   elif money >= 10000 and money<100000:\n       print('you are neither poor nor rich '+ name)\n   elif money >=100000:\n       print('you are rich ')\n\nExcept:\n   print(\"Please enter valid data\")\n"], [">>> import numpy as np\n>>> p[(np.array(p) > 18).argmax():]\n[20, 13, 29, 3, 39]\n", "p = np.hstack([np.random.randint(0,15,10000),np.random.randint(-20,30,10000)])\n"], ["fig.legend([ax.get_ylabel(), ax2.get_ylabel()], loc='upper right')\n"], ["def repeatedString(s, n):\n\n#finding quotient and remainder of division\n\nstr1=len(s)\nremainder=0\nif 1<=str1<=100 and 1<=n<=10**12:\n    quotient= n//str1 \n    a_s = s.count(\"a\")\n    \n    if a_s==0:\n        return 0\n    else:\n        remainder=s[:n%str1].count('a')\n        return quotient*a_s + remainder\n"], ["magick girl_on_chair.jpg \\\n-colorspace LAB -separate \\\n\\( -clone 0 -fx \"u<0.15?u+0.15:u\" \\) \\\n-swap 0,3 +delete \\\n-set colorspace LAB -combine -colorspace sRGB \\\ngirl_on_chair_proc2.jpg\n\nmagick girl_on_chair.jpg \\\n-colorspace YCBCR -separate \\\n\\( -clone 0 -fx \"u<0.15?u+0.15:u\" \\) \\\n-swap 0,3 +delete \\\n-set colorspace YCBCR -combine -colorspace sRGB \\\ngirl_on_chair_proc3.jpg\n\nmagick girl_on_chair.jpg \\\n-colorspace HSV -separate \\\n\\( -clone 2 -fx \"u<0.15?u+0.15:u\" \\) \\\n+swap +delete \\\n-set colorspace HSV -combine -colorspace sRGB \\\ngirl_on_chair_proc4.jpg\n", "import cv2\nimport numpy as np\n\n# read image\nimg = cv2.imread(\"girl_on_chair.jpg\")\n\n# convert to LAB and extract L  channel\nLAB = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\nL,A,B = cv2.split(LAB)\n\n# process L channel\nL_proc = np.where(L<40, cv2.add(L,40), L)\n\n# recombine L_proc with A and B\nLAB_new = cv2.merge([L_proc, A, B])\n\n# convert back to BGR\nresult = cv2.cvtColor(LAB_new, cv2.COLOR_LAB2BGR)\n\n# save result\ncv2.imwrite('girl_on_chair_brighten2.jpg', result)\n\ncv2.imshow('img', img)\ncv2.imshow('L', L)\ncv2.imshow('L_proc', L_proc)\ncv2.imshow('result', result)\ncv2.waitKey(0)\ncv2.destroyAllWindows()\n"], ["magick girl_on_chair.jpg \\\n\\( -clone 0 -colorspace LAB -channel 0 -separate +channel \\\n-auto-threshold triangle -negate +write thresh.png \\) \\\n\\( -clone 0 -evaluate multiply 4 \\) \\\n+swap -compose over -composite \\\ngirl_on_chair_processed.jpg\n", "import cv2\nimport numpy as np\n\n# read image\nimg = cv2.imread(\"girl_on_chair.jpg\")\n\n# convert to LAB and extract L  channel\nLAB = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\nL = LAB[:,:,0]\n\n# threshold L channel with triangle method\nvalue, thresh = cv2.threshold(L, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_TRIANGLE)\nprint(value)\n\n# threshold with adjusted value\nvalue = value + 10\nthresh = cv2.threshold(L, value, 255, cv2.THRESH_BINARY)[1]\n\n# invert threshold and make 3 channels\nthresh = 255 - thresh\nthresh = cv2.merge([thresh, thresh, thresh])\n\ngain = 3\nblue = cv2.multiply(img[:,:,0], gain)\ngreen = cv2.multiply(img[:,:,1], gain)\nred = cv2.multiply(img[:,:,2], gain)\nimg_bright = cv2.merge([blue, green, red])\n\n# blend original and brightened using thresh as mask\nresult = np.where(thresh==255, img_bright, img)\n\n# save result\ncv2.imwrite('girl_on_chair_thresh.jpg', thresh)\ncv2.imwrite('girl_on_chair_brighten.jpg', result)\n\ncv2.imshow('img', img)\ncv2.imshow('L', L)\ncv2.imshow('thresh', thresh)\ncv2.imshow('img_bright', img_bright)\ncv2.imshow('result', result)\ncv2.waitKey(0)\ncv2.destroyAllWindows()\n"], ["import cv2\n\ndef lighten(img, value=30):\n    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n    v = hsv[..., 2]\n    v[:] = cv2.add(v, value)\n    return cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n\nimg = cv2.imread(\"image.jpg\")\ngray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\nmask = cv2.threshold(gray, 175, 255, cv2.THRESH_BINARY)[1] == 0\nimg[mask] = lighten(img)[mask]\ncv2.imshow(\"result\", img)\ncv2.waitKey(0)\n"], ["import matplotlib.pyplot as plt\nimport numpy as np\n\n# Generate some straight-line data\nxdata = np.arange(0,256)\n# And the new mapping\nydata = xdata + 30*(255-xdata)/255\n\n# Plot\nplt.plot(xdata,xdata,'.k')\nplt.plot(xdata,ydata,'g^')\nplt.title('Adjustment of V')\nplt.xlabel('Input V')\nplt.ylabel('Output V')\nplt.grid(True)\nplt.show()\n"], ["Path(Path(__file__).parent,\".env\")\n"], [], [], ["item_no = [0,5,6,2,6,5,6,7,8,1,2,8]\nmax_no = 0\nlist = []\nfor no in item_no:\n    if no==max_no:\n         list.append(no)  #append the list with the new number\n    elif no > max_no:\n       max_no = no\n       list=[no]         # reset the list with new highest number\nprint(list)--->output[8,8]\n"], [], ["coke_price = 50\npayment = coke_price\n\n\ndef main():\n    global coke_price\n    global payment\n\n    while True:\n        money_input = int(input(\"Enter one coin at a time: \").strip())\n        payment = payment - money_input\n\n        if payment < 0:\n            print(\"Change Owed =\", -payment)\n            return\n        elif payment == 0:\n            print(\"No Change Owed, Here's a coke \", payment)\n            return\n        else:\n            print(\"Amount Due =\", payment)\n\nmain()\n"], ["def main():\ntotal_insert = 0 # this variable will keep track of the total insert\ncoke = 50\nwhile True: # use while True to create a loop that keeps on running.\n    insert = int(input(\"Insert one coin at a time: \").strip())\n    total_insert += insert\n    if total_insert < coke:\n        print(\"Amount due: \", coke-total_insert)\n    if total_insert == coke:\n        print(\"Here is a nice coke!\")\n        break\n    if total_insert > coke:\n        print(\"Here is a nice coke and money:\", total_insert-coke) # get the extra money\n        break\nmain()\n"], ["def main():\n    total = 0\n    while True:\n        total += int(input(\"Insert one coin at a time: \").strip())\n        coke = 50\n        print(total)\n        if total > coke:\n            print(\"Change Owed =\", total - coke)\n            return\n        elif total == coke:\n            print(\"No Change Owed, Here's a coke \")\n            return\n        else:\n            print(\"Amount Due =\", coke-total)\n\n\nmain()\n"], ["class SignUpForm(UserCreationForm):\n    email = forms.EmailField(required=True)\n\n    class Meta:\n        model = User\n        model._meta.get_field('email')._unique = True\n        fields = (\"username\", \"email\", \"password1\", \"password2\")\n"], ["    for i in row:\n        if i in words:\n            words[i] += 1\n        else:\n             words[i] = 1\n"], ["#get user's input on dog_age\ndog_age = input(\"Enter your dog's age in years\")\ntry:\n    #cast to a float\n    d_age = float(dog_age)\n    #convert dog age to human age\n    #ensure input is not negative\n    if (d_age > 0):\n        if (d_age <=1):\n            h_age = d_age *15\n        elif (d_age <=2):\n            h_age = d_age *12\n        elif (d_age <=3):\n            h_age = d_age*9.3\n        elif (d_age <=4):\n            h_age = d_age*8\n        elif (d_age <=5):\n            h_age = d_age*7.2\n        else:\n            h_age = 36 + (d_age - 5) *7    \n        human_age = round(h_age,2)\n        #print instruction for valid input\n        print('The given dog age', dog_age,'is', str(human_age),'in human years')\n    else: \n        print('Age cannot be a negative number.')\nexcept ValueError:\n    print(dog_age,'is invalid.')\n"], [], ["> python -m pip install --upgrade pip\n", "$ pip install --upgrade pip\n", "$ pip install --upgrade pip\n"], [], ["from collections import Counter\n\ndef perm_palindrome(string_input):\n\n    count_dict = Counter(string_input)\n    odd_count = 0\n\n    for values in count_dict.values():\n        if values % 2 != 0:\n            odd_count += 1\n            if odd_count > 1:\n                return False\n    else:\n        return True\n\n\nstring_value = \"aabb\"\noutput = perm_palindrome(string_input=string_value)\nprint(\"Answer of permutation palindrome if {} is :::: {}\".format(string_value, output))\n"], [], ["import asyncio\n\n\nasync def startit(thing):\n    t = asyncio.create_task(thing)\n    # what we really need to do here is:\n    # Insert t into runnable queue, just before asyncio.current_task(), and switch to it.\n    # Only, it is not possible since event loops are just about scheduling callbacks\n    await asyncio.sleep(0)\n    return t\n\n\nasync def fa():\n    print('fa start')\n    gb = await startit(fb())\n    # send off a hTTP request and wait for it\n    print ('fa doing blocking thing')\n    await asyncio.sleep(0.1)\n    print ('fa waiting for gb')\n    await gb\n    print ('fa stopping')\n    return 'a'\n\nasync def fb():\n    print('fb start')\n    # send off another http request and wait for it\n    await asyncio.sleep(0.1)\n    print('fb stop')\n    return 'b'\n\n\nasync def main():\n    \n    print('main start')\n    ga = await startit(fa())\n    print(\"main waiting for a\")\n    await ga\n    print('main done')\n\nasyncio.run(main())\n", "main start\nfa start\nmain waiting for a\nfb start\nfa doing blocking thing\nfb stop\nfa waiting for gb\nfa stopping\nmain done\n", "main start\nfa start\nfb start\nfa doing blocking thing\nmain waiting for a\nfb stop\nfa waiting for gb\nfa stopping\nmain done\n"], ["def positive_validator(name, value):\n    if value <= 0:\n        raise ValueError(f\"values for {name!r}  have to be positive\")\n\nclass MyAttr:\n    def __init__(self, typ, validators=(), default=None):\n        if not isinstance(typ, type):\n            if isinstance(typ, tuple) and all([isinstance(t,type) for t in typ]):\n                pass\n            else:\n                raise TypeError(f\"'typ' must be a {type(type)!r} or {type(tuple())!r}` of {type(type)!r}\")\n        else:\n            typ=(typ,)\n        self.type = typ\n        self.name = f\"MyAttr_{self.type!r}\"\n        self.validators = validators\n        self.default=default\n        if self.default is not None or type(None) in typ:\n            self.__validate__(self.default)\n        \n    def __set_name__(self, owner, name):\n        self.name = name\n    \n    def __get__(self, instance, owner):\n        if not instance: return self\n        return instance.__dict__[self.name]\n\n    def __delete__(self, instance):\n        del instance.__dict__[self.name]\n        \n    def __validate__(self, value):\n        for validator in self.validators:\n            validator(self.name, value)\n            \n    def __set__(self, instance, value):\n        if value == self:\n            value = self.default\n        if not isinstance(value, self.type):\n            raise TypeError(f\"{self.name!r} values must be of type {self.type!r}\")\n\n        instance.__dict__[self.name] = value\n        \n\n\n#And now\n\n@dataclass\nclass Person:\n    name: str = MyAttr(str,[]) # required attribute, must be a str, cannot be none\n    age: float = MyAttr((int, float), [positive_validator,],2) # optional attribute, must be an int >0, defaults to 2\n    posessions: Union[list, type(None)] = MyAttr((list, type(None)),[]) # optional attribute in which None is default\n"], [], ["pip install cdo \n", "from cdo import Cdo\ncdo=Cdo()\ncdo.remapbil(\"target_grid\",input=\"in.nc\",output=\"out.nc\")\n", "gridtype=lonlat\nxfirst=X   (here X is the longitude of the left hand point)\nxinc=0.083\nxsize=NX   (here put the number of points in domain)\nyfirst=Y\nyinc=0.083\nysize=NY\n"], [], [], ["import nctoolkit as nc\ndata = nc.open_data(infile)\ndata.to_latlon(lon = [lon_min,lon_max],lat=[lat_min,lat_max], res =[0.083, 0.083])\n"], [], ["mementum = ['One-Year', \n        'Six-Month',\n        'Three-Month',\n        'One-Month'\n        ]\nfor period in mementum:\nhq_df[f'{period} Price Return'] = hq_df[f'{period} Price Return'].astype(float).fillna(0.0)\nfor row in hq_df.index:\n   for period in mementum:\n       hq_df.loc[row, f'{period} Return Percentile'] = stats.percentileofscore(hq_df[f'{period} Price Return'] , hq_df.loc[row, f'{period} Price Return'] )\n"], ["del /S /F /Q .\\dist\\*\ndel /S /F /Q .\\build\\*\n\npyinstaller -F -y --clean^\n    --hidden-import=\"pkg_resources.py2_warn\"^\n    --hidden-import=h5py ^\n    code_to_package.py -n NameOFApp\n"], ["{'a': (int, Ellipsis),\n 'b': {'c': (str, 'hi'), 'd': {'e': (bool, True), 'f': (float, 0.5)}},\n 'g': (str, 'hello'),\n 'h': (int, 123),\n 'i': (str, Ellipsis),\n 'k': (int, Ellipsis)}\n", "{'title': 'Demo_Pydantic_Nested_Model',\n 'type': 'object',\n 'properties': {'a': {'title': 'A', 'type': 'integer'},\n  'b': {'title': 'B',\n   'default': {'c': 'hi', 'd': {'e': True, 'f': 0.5}},\n   'allOf': [{'$ref': '#/definitions/Demo_Pydantic_Nested_Model_b'}]},\n  'g': {'title': 'G', 'default': 'hello', 'type': 'string'},\n  'h': {'title': 'H', 'default': 123, 'type': 'integer'},\n  'i': {'title': 'I', 'type': 'string'},\n  'k': {'title': 'K', 'type': 'integer'}},\n 'required': ['a', 'i', 'k'],\n 'definitions': {'Demo_Pydantic_Nested_Model_b_d': {'title': 'Demo_Pydantic_Nested_Model_b_d',\n   'type': 'object',\n   'properties': {'e': {'title': 'E', 'default': True, 'type': 'boolean'},\n    'f': {'title': 'F', 'default': 0.5, 'type': 'number'}}},\n  'Demo_Pydantic_Nested_Model_b': {'title': 'Demo_Pydantic_Nested_Model_b',\n   'type': 'object',\n   'properties': {'c': {'title': 'C', 'default': 'hi', 'type': 'string'},\n    'd': {'title': 'D',\n     'default': {'e': True, 'f': 0.5},\n     'allOf': [{'$ref': '#/definitions/Demo_Pydantic_Nested_Model_b_d'}]}}}}}\n"], ["-n \n", ">>> timeit.timeit(\"x = -abs(y)\", setup=\"y = 42\", number=5000)\n0.0005687898956239223\n>>> timeit.timeit(\"x = -y\", setup=\"y = 42\", number=5000)\n0.0002599889412522316\n"], [], ["out = next((p[i:] for i, item in enumerate(p) if item > 18), [])\n", "[20, 13, 29, 3, 39]\n", "import perfplot\nimport numpy as np\nimport pandas as pd\nimport random\nfrom itertools import dropwhile\n\ndef it_dropwhile(p):\n    return list(dropwhile(lambda x: x <= 18, p))\n\ndef walrus(p):\n    exceeded = False\n    return [x for x in p if (exceeded := exceeded or x > 18)]\n\ndef explicit_loop(p):\n    for i, x in enumerate(p):\n        if x > 18:\n            output = p[i:]\n            break\n    else:\n        output = []\n    return output\n\ndef genexpr_next(p):\n    return next((p[i:] for i, item in enumerate(p) if item > 18), [])\n\ndef np_argmax(p):\n    return p[(np.array(p) > 18).argmax():]\n\ndef pd_idxmax(p):\n    s = pd.Series(p)\n    return s[s.gt(18).idxmax():]\n\ndef list_index(p):\n    for x in p:\n        if x > 18:\n            return p[p.index(x):]\n    return []\n\ndef lazy_iter(p):\n    it = iter(p)\n    for x in it:\n        if x > 18:\n            return [x, *it]\n    return []\n\nperfplot.show(\n    setup=lambda n: random.choices(range(0, 15), k=10*n) + random.choices(range(-20,30), k=10*n),\n    kernels=[it_dropwhile, walrus, explicit_loop, genexpr_next, np_argmax, pd_idxmax, list_index, lazy_iter],\n    labels=['it_dropwhile','walrus','explicit_loop','genexpr_next','np_argmax','pd_idxmax', 'list_index', 'lazy_iter'],\n    n_range=[2 ** k for k in range(18)],\n    equality_check=np.allclose,\n    xlabel='~n/20'\n)\n", "def list_index(p):\n    for x in p:\n        if x > 18:\n            return p[np.where(p==x)[0][0]:]\n    return []\n\nperfplot.show(\n    setup=lambda n: np.hstack([np.random.randint(0,15,10*n), np.random.randint(-20,30,10*n)]),\n    kernels=[it_dropwhile, walrus, explicit_loop, genexpr_next, np_argmax, pd_idxmax, list_index, lazy_iter],\n    labels=['it_dropwhile','walrus','explicit_loop','genexpr_next','np_argmax','pd_idxmax', 'list_index', 'lazy_iter'],\n    n_range=[2 ** k for k in range(18)],\n    equality_check=np.allclose,\n    xlabel='~n/20'\n)\n"], ["def start_over_18(p):\n    for x in p:\n        if x > 18:\n            return p[p.index(x):]\n    return []\n", "def start_over_18(p):\n    it = iter(p)\n    for x in it:\n        if x > 18:\n            return [x, *it]\n    return []\n"], ["public static int getCharBetween(String s, char c){\n        if(s.equals(null) ||s.length()==0){\n            return -1;\n        }\n        char[] ch=s.toCharArray();\n        List<Integer> list= new ArrayList<>();\n        for(char cha:ch){\n            if(cha==c){\n                list.add(s.indexOf(cha));\n                s=s.substring(s.indexOf(cha)+1, s.length()-1);\n                if(list.size()==2){\n                    break;\n                }\n            }\n        }\n        if(list.size()==0){\n            return -1;\n        }\n        return (list.get(1)-list.get(0))-1;\n}\n"], [], [], ["import pandas as pd\ndf = pd.DataFrame([4,9,10,4,20,13,29,3,39])\ndf = df[df[0].gt(18).idxmax():]\nprint(df)\n", "    0\n4  20\n5  13\n6  29\n7   3\n8  39\n"], ["L = {'2':\"abc\",'3':\"def\",'4':\"ghi\",'5':\"jkl\",\n     '6':\"mno\",'7':\"pqrs\",'8':\"tuv\",'9':\"wxyz\"}\nclass Solution:\n    def letterCombinations(self, digits: str) -> List[str]:\n        if not digits:\n            # always validate the input\n            return []\n        res=[]\n        def dfs(i,cur):\n            if len(cur)==len(digits):\n                res.append(cur)\n                return\n            for letter in L[digits[i]]:\n                dfs(i+1,cur+letter)\n        dfs(0,\"\")\n        return res\n"], ["#Installing specific packages.\n!pip install -q dash==1.19.0\n!pip install -q jupyter_dash==0.3.0\n\n#Importing the libraries.\nfrom jupyter_dash import JupyterDash\nimport dash_html_components as html\nimport dash_core_components as dcc\nimport plotly.graph_objs as go\nimport plotly.express as px\nimport dash\nfrom dash.dependencies import Input, Output\nexternal_stylesheets = ['https://codepen.io/chriddyp/pen/bWLwgP.css']\n\napp = JupyterDash(__name__,external_stylesheets = external_stylesheets) #\n\napp.layout= html.Div([html.H1(\"Hello world!!!\"),\n                  html.Div(\"This is the first paragraph\"),\n                 html.H1(\"Welcome back\"),\n                 html.Div(\"This is the second paragraph\"),\n                  html.Div(id=\"no_show\",style= {'display':'none'}),\n                 dcc.Graph(id = \"graph\",figure = go.Figure())],\n                style = {\"text-align\":\"center\"})\n\napp.css.config.serve_locally = True\napp.scripts.config.serve_locally = True\n\nif __name__ =='__main__':\n    app.run_server(mode=\"external\")\n"], [], [], ["app = JupyterDash(__name__)\napp.run_server(mode=external,port=8050)\n", "app=dash.Dash(__name__)\napp.run_server()\n"], [], ["import os\nos.environ[\"KAGGLE_CONFIG_DIR\"] = \"/path_to_your_kaggle.json_file\"\n"], ["def get_formset(self, request, obj=None, **kwargs):\n     formset = super().get_formset(request, obj, **kwargs)\n     field = formset.form.base_fields[\"your_foreign_key_field\"]\n     field.widget.can_add_related = False\n     field.widget.can_change_related = False\n     field.widget.can_delete_related = False\n     return formset\n\n"], ["list_of_dict = [{'a': 1, 'b': 2, 'c': 3}, {'a': 3, 'b': 5}, {'k': 5, 'j': 5}, {'a': 3, 'k': 5, 'd': 4}, {'a': 3}]\n\n# prepare a list/set of all the keys from all the dictionaries\n\n# method 1: use sum \nall_keys = sum([[a for a in x.keys()] for x in list_of_dict], [])\n\n# method 2: use itertools \nimport itertools\nall_keys = list(itertools.chain.from_iterable(list_of_dict))\n\n# method 3: use union of the set\nall_keys = set().union(*list_of_dict)\n\nprint(all_keys)\n# ['a', 'b', 'c', 'a', 'b', 'k', 'j', 'a', 'k', 'd', 'a']\n\n# convert the list to set to remove duplicates \nall_keys = set(all_keys)\nprint(all_keys)\n# {'a', 'k', 'c', 'd', 'b', 'j'}\n\n# now merge the dictionary\nmerged = {k: [d.get(k) for d in list_of_dict if k in d] for k in all_keys}\nprint(merged)\n# {'a': [1, 3, 3, 3], 'k': [5, 5], 'c': [3], 'd': [4], 'b': [2, 5], 'j': [5]}\n", "all_keys = set().union(*list_of_dict)\nmerged = {k: [d.get(k) for d in list_of_dict if k in d] for k in all_keys}\n\nprint(merged)\n# {'a': [1, 3, 3, 3], 'k': [5, 5], 'c': [3], 'd': [4], 'b': [2, 5], 'j': [5]}\n"], [], ["list_of_dict = [{'a': 1, 'b': 2, 'c': 3}, {'a': 3, 'b': 5}, {'k': 5, 'j': 5}, {'a': 3, 'k': 5, 'd': 4}, {'a': 3}]\n\noutput = {\n    k: [d[k] for d in list_of_dict if k in d]\n    for k in set().union(*list_of_dict)\n}\nprint(output)\n{'d': [4], 'k': [5, 5], 'a': [1, 3, 3, 3], 'j': [5], 'c': [3], 'b': [2, 5]}\n"], ["from collections import defaultdict\n\nres = defaultdict(list)\n\nfor d in list_of_dict:\n    for k, v in d.items():\n        res[k].append(v)\n", "defaultdict(list,\n            {'a': [1, 3, 3, 3],\n             'b': [2, 5],\n             'c': [3],\n             'k': [5, 5],\n             'j': [5],\n             'd': [4]})\n"], ["ou = {}\nfor d in list_of_dict:\n    for key, value in d.items():\n        output.setdefault(key, []).append(value)\n"], ["name = [1, 2, 0, 1, 5, 3, 0, 8, 2, 9]\nlen1=len(name)\nfor i in range(len1): #iteration from 1st value\n   for j in range(i+1,len1): #iteration from i+1 \n       if  name[i] < name[j]: #this is ascending order (*the < changed to > then ascending order)\n           name[i],name[j]=name[j],name[i] #swapping logic in python\nprint (name)\n"], ["   n = int(input(\"Enter the total numbers: \"))\n   arr = list(map(int, input(\"Enter the numbers: \").split()))\n\n   max_val = max(arr)\n\n   lst = [x for x in arr if x!=max_val]\n   second_max = max(lst) \n   \n   print(second_max)\n"], ["s = 'aba'\nn = 10\n    \ncount = 0\ninters = s * n\n\n# Here you need to slice(inters) not (s) because s only hold 'aba'\n# And not n+1 it's take 11 values only n\nreals = inters[0:n]\n  for i in reals:\n    if (i == 'a'):\n      count += 1\n    \nprint(count)\n"], ["limit = int(input(\"Limit:\"))\nbase = 0\nnum = 1\nnum_total = 0\nmsg = \"\"\nwhile base < limit:\n    msg = msg + str(num) + \"+\"\n    base += num\n    num += 1\nmsg =  msg[:-1] + \"=\" + str(limit) \nprint(msg)\n", "1+2+3+4+5+6=21\n"], [], ["sum = 0\nlong_output = []\n\nfor i in range(limit + 1):\n  sum += i\n  long_output.append(str(i))\n\nprint(\"The consecutive sum: {} = {}\".format(' + '.join(long_output), sum))\n"], ["limit = int(input(\"Limit:\"))\n\nn = int(((1 + 8 * limit) ** 0.5 - 1) / 2)\n\nformula = \" + \".join(map(str, range(1, n + 1)))\ntotal  = n * (n + 1) // 2\nprint(f\"The consecutive sum: {formula} = {total}\")\n"], ["from IPython.display import HTML\nfrom base64 import b64encode\n\nvideo_path = '/content/drive/MyDrive/Data_proc/ball.mp4'\n\nmp4 = open(video_path, \"rb\").read()\ndata_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\nHTML(f\"\"\"\n<video width=400 controls><source src=\"{data_url}\" type=\"video/mp4\">\n</video>\"\"\")\n"], [], [], [], [], ["np.load(path, allow_pickle=True)\n"], [], ["import tweepy\n\nclient = tweepy.Client(bearer_token=\"add_your_Bearer_Token\")\n\n# Replace with your own search query\n#replace place_country with the code of your country of interest or remove.\nquery = 'COVID19 place_country:GB'\n\n# Starting time period YYYY-MM-DDTHH:MM:SSZ (max period back is March 2006)\nstart_time = '2018-01-01T00:00:00Z'\n\n# Ending time period YYYY-MM-DDTHH:MM:SSZ\nend_time = '2018-08-03T00:00:00Z'\n\n#I'm getting the geo location of the tweet as well as the location of the user and setting the number of tweets returned to 10 (minimum) - Max is 100\n\ntweets = client.search_all_tweets(query=query, tweet_fields=['context_annotations', 'created_at', 'geo'], place_fields=['place_type', 'geo'], user_fields=['location'], expansions='author_id,geo.place_id', start_time=start_time, end_time=end_time, max_results=10)\n\n# Get list of places and users\nplaces = {p[\"id\"]: p for p in tweets.includes['places']}\nusers = {u[\"id\"]: u for u in tweets.includes['users']}\n\n#loop through the tweets to get the tweet ID, Date, Text, Author ID, User Location and Tweet Location\nfor tweet in tweets.data:\n    print(tweet.id)\n    print(tweet.created_at)\n    print(tweet.text)\n    print(tweet.author_id)\n    if users[tweet.author_id]:\n        user = users[tweet.author_id]\n        print(user.location) #note that users can add whatever they want as location\n    if places[tweet.geo['place_id']]:\n        place = places[tweet.geo['place_id']]\n        print(place.full_name)\n        print(\"================\")\n"], ["left['dummy'] = 'a'\nright['dummy'] = 'a'\n\ncartesian = left.merge(right, how='inner', on='dummy')\n\ndel cartesian['dummy']\n"], [">>> import dataclasses\n>>> @dataclasses.dataclass\n... class Dummy:\n...     foo: int\n...     bar: int\n... \n>>> dummy = Dummy(1, 2)\n>>> dummy_copy = dataclasses.replace(dummy)\n>>> dummy_copy.foo = 5\n>>> dummy\nDummy(foo=1, bar=2)\n>>> dummy_copy\nDummy(foo=5, bar=2)\n"], [], ["class SignUpForm(UserCreationForm):\n    email = forms.EmailField(max_length=254, help_text='Required. Inform a valid email address.')\n\n    class Meta:\n        model = User\n        fields = ('username', 'email', 'password1', 'password2', )\n\n    def clean(self):\n        cleaned_data = super().clean()\n        email = cleaned_data.get('email')\n\n        if User.objects.filter(email=email).exists():\n            msg = 'A user with that email already exists.'\n            self.add_error('email', msg)           \n    \n        return self.cleaned_data\n"], ["list1 = list(arr)\n    \n    \nnew_set = set(list1)\n    \n    \nnew_list = list(new_set)\nnew_list.sort()\n    \n    \nnew_list.pop(-1)\n    \nprint(new_list[-1])\n"], [], [], [], ["\nfilename = input()\nwords = []\nnew_words = []\nwith open(filename, 'r') as csvfile:\n    reader = csv.reader(csvfile, delimiter = ',')\n    for row in reader:\n        for word in row:\n            words.append(word)\n        for word in words:\n            freq = words.count(word)\n            if word not in new_words:\n                new_words.append(word)\n                print(word, freq)\n         \n\n"], ["import csv\nwith open('input1.csv', 'r') as wordsfile:\nwords_reader = csv.reader(wordsfile)\nfor row in words_reader:\n    list_of_words = set(row)\n    for word in list_of_words:\n        count = row.count(word)\n        print(word, count)\n", "row = row.split()\nlist_of_words = set(row)\n"], [], [], ["python -m pip install -U pip --user //In Windows \npip install -U pip --user //Linux, and MacOS\n"], ["return [s[i%len(s)] for i in range(n)].count('a')\n"], [], [], ["from concurrent.futures import ThreadPoolExecutor, as_completed\n\n\ndef add_one(number, index):\n    return number + 1, index\n\n\ndef process():\n    all_numbers = []\n    for i in range(0, 10):\n        all_numbers.append(i)\n\n    threads = []\n    all_results = []\n    with ThreadPoolExecutor(max_workers=10) as executor:\n        for index, number in enumerate(all_numbers):\n            threads.append(executor.submit(add_one, number, index))\n        for task in as_completed(threads):\n            result, index = task.result()\n            all_results.append([result, index])\n        all_results = sorted(all_results, key=lambda x: x[-1])\n\n    for index, result in enumerate(all_results):\n        print(result[0])\n\n\nprocess()\n"], [], [], [], [], [], [], ["figure, axis = pyplot.subplots(nrows=1,ncols=2, figsize=(15, 6), tight_layout=True)\n\naxis[0].legend(title='Country', title_fontsize = 12) #this line\naxis[0].pie(x=piechart_result['value_eur'],labels=piechart_result['short_name'])\n\naxis[1].pie(x=piechart_result['value_eur'],labels=piechart_result['short_name')\n\npyplot.show()\n", "figure, axis = pyplot.subplots(nrows=1,ncols=2, figsize=(15, 6), tight_layout=True)\n\naxis[0].pie(x=piechart_result['value_eur'],labels=piechart_result['short_name'])\naxis[0].legend(title='Country', title_fontsize = 12) # this line \n\naxis[1].pie(x=piechart_result['value_eur'],labels=piechart_result['short_name')\n\npyplot.show()\n"], [], [], [], ["def calculator():\n    age = input(\"Input dog years: \")\n    try:\n        d_age = float(age)\n        ageDict = {1: 15, 2: 12, 3: 9.3, 4: 8, 5: 7.2}\n        if d_age in ageDict:\n            print(round(d_age*ageDict[d_age],2))\n        else:\n            print(round(5*7.2+(d_age - 5)*7,2))\n    except ValueError:\n        print(age,\"is an invalid age\")\n\ncalculator()\n"], [], ["def calculator():\n\n    # Get dog age\n    age = input(\"Input dog years: \")\n\n    try:\n        # Cast to float\n        d_age = float(age)\n        # If user enters negative number, print message\n        if(d_age < 0):\n            print(\"Age can not be a negative number\", age)\n        # Otherwise, calculate dog's age in human years\n        elif(d_age == 1):\n            d_age = 15\n        elif(d_age == 2):\n            d_age == 2 * 12\n        elif(d_age == 3):\n            d_age == 3 * 9.3\n        elif(d_age == 4):\n            d_age = 4 * 8\n        elif(d_age == 5):\n            d_age = 3 * 7.2\n        else:\n            d_age = 5 * 7.2 + (age - 5) * 7\n        print(\"\\n \\t \\'The given dog age\", age, \"is\", d_age, \"human years.\")\n    except ValueError:\n            print(age, \"is an invalid age\")\n\ncalculator()\n"], ["pip install https://github.com/johnteslade/python-netfilterqueue/archive/refs/heads/update-cython-code.zip\n"], [], ["if __name__ == '__main__':\n    app.run_server(host='localhost',port=8005)\n"], ["py -3.8 -m venv env \n", "py -3.9 -m venv env\n"], ["plt.hist([x01, x02,x03], color=[\"lightcoral\",\"lightskyblue\",\"slategrey\"], stacked=True, \n             label=['Supressed','Active','Resolved'])\nplt.legend()\n", "plt.hist([x01])\nplt.legend()\n"], ["import re\ndef reposition(s):\n   return re.sub('\\d+', '{}', s).format(*sorted(map(int, re.findall('\\d+', s)), reverse=True))\n\nvals = ['I am 5 years and 11 months old', 'I am 28 years 9 months 11 weeks and 55 days old']\nresult = [reposition(i) for i in vals]\n", "['I am 11 years and 5 months old', 'I am 55 years 28 months 11 weeks and 9 days old']\n"], ["string = \"I am 28 years 9 months 11 weeks and 55 days old\"\n\nnumbers = [int(substring) for substring in string.split() if substring.isdigit()]\nsorted_numbers = iter(sorted(numbers, reverse=True))\noutput =  \" \".join([substring if not substring.isdigit() else str(next(sorted_numbers)) for substring in string.split()])\n\nprint(output)\n\n# I am 55 years 28 months 11 weeks and 9 days old\n"], ["\"Try 1 or 423 or 849 things.\"\n", "def sortNumbers(text):\n    # replace all non-digit characters by space, split result\n    numbers = ''.join(t if t.isdigit() else ' ' for t in text).split()\n\n    # order descending by integer value\n    numbers.sort(key=lambda x:-int(x))  \n\n    # replace all found numbers - do not mess with the original string with \n    # respect to splitting, spaces or anything else - multiple spaces\n    # might get reduced to 1 space if you \"split()\" it.\n    for n in numbers:\n        text = text.replace(n, \"{}\")\n\n    return text.format(*numbers)  # put the sorted numbers back into the string\n\nfor text in [\"I am 5 years and 11 months old\",\n            \"I am 28 years 9 months 11 weeks and 55 days old\",\n            \"What is 5 less then 45?\",\n            \"At 49th Street it is 500.\", \"It is $23 and 45.\"]:\n\n    print(sortNumbers(text))\n", "I am 11 years and 5 months old\nI am 55 years 28 months 11 weeks and 9 days old\nWhat is 45 less then 5?\nAt 500th Street it is 49.\nIt is $45 and 23.\n"], ["def RearrangeNumbers(source):\n    tmp0=source.split()\n    int_l=[]\n    for j,i in enumerate(tmp0):\n      try:\n        tmp0[j]=int(i)\n        int_l.append(int(i))\n      except ValueError:\n        pass\n    int_l.sort()\n    for j,i in enumerate(tmp0):\n      if isinstance(i,int):\n        tmp0[j]=str(int_l[0])\n        int_l.pop(0)\n    return ' '.join(tmp0)\n\nprint(RearrangeNumbers(input()))\n", "I am 28 years 9 months 11 weeks and 55 days old\nI am 9 years 11 months 28 weeks and 55 days old\n"], ["import re\ninp = 'I am 28 years 9 months 11 weeks and 55 days old'\nnumbers = tuple(sorted(map(int, re.findall(r'([\\d]+)', inp)), reverse=True)) # find all numbers, converts each number to int, sort them and convert to tuple\ninpPlaceholders = re.sub(r'([\\d]+)', '%s', inp) # replace all numbers in the string to %s placeholders\nprint(inpPlaceholders % numbers) # rebuild the string, using %s string formatting\n", "I am 55 years 28 months 11 weeks and 9 days old\n"], [], ["hqm_dataframe.fillna(0,inplace=True)\n"], ["a=np.array([[1, 2, 3], [4, 5, 6]])\n# Object array\nb={'data':'somet',\n   'data_2':'defin'}\n#Save arrays into file\nnp.savez('/content/123.npz', a=a, b=b)\n#Load file into data variable\ndata = np.load('/content/123.npz')\nprint(data['b'])\n", "data = np.load('/content/123.npz',allow_pickle=True)\n"], ["from django.db.models.signals import post_save, pre_save\nfrom django.dispatch import  receiver\nfrom django.contrib.auth.models import User\nfrom django.forms import ValidationError\n\n@receiver(pre_save, sender=User)\ndef check_email(sender, instance, **kwargs):\n    email = instance.email\n    if sender.objects.filter(email=email).exclude(username=instance.username).exists():\n        raise ValidationError('Email Already Exists')\n"], ["left.merge(right, how='cross')\n", "import itertools\nl=list(itertools.product(left.values.tolist(),right.values.tolist()))\npd.DataFrame(list(map(lambda x : sum(x,[]),l)))\n   0  1  2   3\n0  A  1  X  20\n1  A  1  Y  30\n2  A  1  Z  50\n3  B  2  X  20\n4  B  2  Y  30\n5  B  2  Z  50\n6  C  3  X  20\n7  C  3  Y  30\n8  C  3  Z  50\n"], ["python -m uvicorn main:app --reload\n"], [], [], [], [], ["def find_sum(s, lst):\n    indices = {x: i for i, x in enumerate(lst)}\n    for i, x in enumerate(lst):\n        target = s - x\n        if x <= target and target in indices and i != indices[target]:\n            yield x, target  # <- I also simplified this\n", ">>> lst = [2, 4, 5, 6, 7, 8]\n>>> list(find_sum(12, lst))  # <- Note the `list()` here.\n[(4, 8), (5, 7)]\n", "def find_sum(s, lst):\n    targets = set(lst)\n    for x in targets:\n        target = s - x\n        if x < target and target in targets:\n            yield x, target\n"], ["def find_sum(s, lst):\n    s.sort()\n    good_pairs = []\n    indices = {x: i for i, x in enumerate(lst[:len(lst)//2])}\n    # print(indices)\n    for i, x in enumerate(lst):\n        target = s - x\n        if target in indices:\n            good_pairs.append((lst[i], lst[indices[target]]))\n\n    return good_pairs\n\nlst = [2, 4, 5, 6, 7, 8]\nprint(find_sum(12, lst)) \n"], ["import itertools\n\ndef find_sum(s, lst):\n    return [x for x in itertools.combinations(lst, r=2) if x[0] + x[1] == s]\n\nlst = [2, 4, 5, 6, 7, 8]\nprint(find_sum(12, lst))\n", "[(4, 8), (5, 7)]\n"], ["    python -m pip install autopep8\n"], ["import cartopy.crs as ccrs\n\n# Projection may vary\nprojection = ccrs.LambertConformal(central_longitude=-97.5,\n                             central_latitude=38.5,\n                             standard_parallels=[38.5])\ntransform = np.vectorize(lambda x, y: projection.transform_point(x, y, ccrs.PlateCarree()))\n\n# The grid should be aligned such that the projection x and y are the same\n# at every y and x index respectively\ngrid_y = ds.isel(x=0)\ngrid_x = ds.isel(y=0)\n\n_, proj_y = transform(grid_y.longitude, grid_y.latitude)\nproj_x, _ = transform(grid_x.longitude, grid_x.latitude)\n\n# ds.sel only works on the dimensions, so we can't just add\n# proj_x and proj_y as additional coordinate variables\nds[\"x\"] = proj_x\nds[\"y\"] = proj_y\n\ndesired_x, desired_y = transform(-122.68, 21.2)\nnearest_point = ds.sel(x=desired_x, y=desired_y, method=\"nearest\")\n\nprint(nearest_point.SPEED)\n", "<xarray.DataArray 'SPEED' ()>\narray(10.934007)\nCoordinates:\n    latitude   float64 21.14\n    longitude  float64 -122.7\n    x          float64 -2.701e+06\n    y          float64 -1.581e+06\n"], ["final_df = pd.DataFrame(columns = my_columns)\n\nfor symbol_string in symbol_strings:\n    batch_api_call_url = f'https://sandbox.iexapis.com/stable/stock/market/batch?symbols={symbol_string}&types=price,stats&token={IEX_CLOUD_API_TOKEN}'\n    data = requests.get(batch_api_call_url).json()\n#    print(symbol_string.split(','))\n#    print(data['AAPL']['stats'])\n    for symbol in symbol_string.split(','):\n        final_df = final_df.append(\n            pd.Series(\n                [\n                    symbol,\n                    data[symbol]['price'],\n                    data[symbol]['stats']['year1ChangePercent'],\n                    np.nan\n                ],\n                index = my_columns\n            ),\n            ignore_index=True\n        )\n", "hqm_df = pd.DataFrame(columns = hqm_columns)\n\nfor symbol_string in symbol_strings:\n    batch_api_call_url = f'https://sandbox.iexapis.com/stable/stock/market/batch?symbols={symbol_string}&types=price,stats&token={IEX_CLOUD_API_TOKEN}'\n    data = requests.get(batch_api_call_url).json()\n    for symbol in symbol_string.split(','):\n        hqm_df = hqm_df.append(\n            pd.Series(\n                [\n                    symbol,\n                    data[symbol]['price'],\n                    np.nan,\n                    data[symbol]['stats']['year1ChangePercent'],\n                    np.nan,\n                    data[symbol]['stats']['month6ChangePercent'],\n                    np.nan,\n                    data[symbol]['stats']['month3ChangePercent'],\n                    np.nan,\n                    data[symbol]['stats']['month1ChangePercent'],\n                    np.nan\n                ],\n                index = hqm_columns\n            ),\n            ignore_index=True\n        )\n", "hqm_df['One-Year Price Return'] = hqm_df['One-Year Price Return'].astype('float')\nhqm_df['Six-Month Price Return'] = hqm_df['Six-Month Price Return'].astype('float')\nhqm_df['Three-Month Price Return'] = hqm_df['Three-Month Price Return'].astype('float')\nhqm_df['One-Month Price Return'] = hqm_df['One-Month Price Return'].astype('float')\n"], ["df = df.reset_index()\ndf['week_date'] = pd.to_datetime(\n    df['Year'].astype(str) + df['Week_Number'].astype(str) + \"1\",\n    format='%G%V%w'\n)\ndf = df.set_index(['Year', 'Week_Number'])\n"], ["df['week_date-Week']=pd.to_datetime(df['Week_Number'].astype(str)+df['Year'].astype(str).add('-1') ,format='%V%G-%u')\n"], ["pd.to_datetime(pd.Series(['27-07-2020'])).dt.strftime('%V')\n"], ["import datetime\n\ndf = df.reset_index()\n\ndf['week_date']=(df[['Year','Week_Number']].astype(str)\n                 .apply(lambda x:datetime.datetime.strptime('-W'.join(x) + '-1', \"%Y-W%W-%w\"),1))\n\ndf = df.set_index(['Year', 'Week_Number'])\n"], ["{...,\n\"python.pythonPath\": \"C:\\\\Users\\\\<user>\\\\miniconda3\\\\envs\\\\py39\\\\python.exe\",\n\"python.condaPath\": \"C:\\\\Users\\\\<user>\\\\miniconda3\\\\Scripts\\\\conda.exe\",\n\"terminal.integrated.cwd\": \"D:\\\\my_VSCode_storage\\\\py39_env\\\\my_project_folder\",\n\"terminal.integrated.defaultProfile.windows\": \"PowerShell\",\n\"terminal.integrated.profiles.windows\": {\n    \"PowerShell\": {\n        \"source\": \"PowerShell\",\n        \"icon\": \"terminal-powershell\",\n        \"python.terminal.executeInFileDir\": true,\n        \"args\":[\"-NoLogo\",\n                \"-ExecutionPolicy\",\n                \"Bypass\",\n                \"-NoExit\",\n                \"-Command\",\n                \"& C:\\\\Users\\\\<user>\\\\miniconda3\\\\shell\\\\condabin\\\\conda-hook.ps1\",\n                \";conda activate 'C:\\\\Users\\\\<user>\\\\miniconda3'\"\n                ]\n     },\n   \n     ...}\n"], [], ["import pathlib\nmain_dir = 'my_main_dir'\nsub_dir = 'sub_dir'\nfname = 'filename.tsv'\nfilepath = pathlib.PurePath(main_dir, sub_dir, fname)\n"], ["# pip install konfuzio_sdk\n# in working directory\n# konfuzio_sdk init\n\nfrom konfuzio_sdk.api import get_results_from_segmentation\n\nresult = get_results_from_segmentation(doc_id=1111, project_id=111) \n"], ["auth = tweepy.AppAuthHandler(consumer_key, consumer_secret)\napi = tweepy.API(auth)\nfor tweet in tweepy.Cursor(api.search, q='cool').items(3):\n    print(tweet.text)\n"], ["asgiref\nbeautifulsoup4\ncertifi\nchardet\nClick\nDjango\nidna\npytz\nrequests\nsix\nsoupsieve\nsqlparse\nurllib3\n"], [], [], ["yourList = [7,7,76,4,54,4,5,234,5,56,7,234,34,234,234]\n\nyourList.sort()\nind = yourList.index(max(yourList))\nfor i in range(ind,ind+(len(yourList)-ind)):\n    print(yourList[i])\n\n\n", "lis = [1,2,3,12,12,1,12,3,4,5,6,12, 12]\ncount = lis.count(max(lis))\nloop = [print(max(lis), end=\" \") for i in range(count)]\n"], ["from concurrent.futures import ThreadPoolExecutor, as_completed\nimport time\nimport itertools\n\ndef add_one(number, n):\n    return number + 1 + n\n\ndef process():\n    all_numbers = list(range(0, 10))\n\n    with ThreadPoolExecutor(max_workers=10) as executor:\n        \n        for result in executor.map(add_one, all_numbers, itertools.repeat(2)):\n            print(result)\n\nprocess()\n", "3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n"], ["from concurrent.futures import ThreadPoolExecutor, as_completed\n\ndef add_one(number):\n    return number + 1\n\ndef process():\n    all_numbers = []\n    for i in range(0, 10):\n        all_numbers.append(i)\n\n    all_results = []\n    with ThreadPoolExecutor(max_workers=10) as executor:\n        for i in executor.map(add_one, all_numbers):\n            print(i)\n            all_results.append(i)\n\n    for index, result in enumerate(all_results):\n        print(result)\n\nprocess()\n", "from concurrent.futures import ThreadPoolExecutor, as_completed\n\ndef add_one(args):\n    return args[0] + 1 + args[1]\n\ndef process():\n    all_numbers = []\n    for i in range(0, 10):\n        all_numbers.append([i, 2])\n\n    all_results = []\n    with ThreadPoolExecutor(max_workers=10) as executor:\n        for i in executor.map(add_one, all_numbers):\n            print(i)\n            all_results.append(i)\n\n    for index, result in enumerate(all_results):\n        print(result)\n\nprocess()\n"], [], [], ["sudo apt install libnfnetlink-dev libnetfilter-queue-dev\n", "pip3 install nfqp3\n"], [], [], ["import copy\ndef rotateImage(a):\n out = copy.deepcopy(a)\n x = 0;\n y = 0;\n for i in a:\n  l = len(i)\n  for j in i:\n   out[y][x+l-1] = j\n   y += 1\n   if(y == l):\n    y=0\n  x -= 1\n return(out)\n"], ["[path to python installation folder]/python.exe -m venv env\n"], [], [], ["{% load staticfiles %}\n{% load static from staticfiles %}\n{% load admin_static %}\n", "{% load static %}\n"], ["hqm_dataframe.replace([None], 0, inplace = True)\n"], ["String palindromePermutation(String s){\n\n      Set<Character> set=new HashSet<Character>();\n     \n      for(int i=0; i<s.length(); ++i){\n        if (!set.contains(s.charAt(i)))\n            set.add(s.charAt(i));\n        else \n            set.remove(s.charAt(i));\n    }\n    if(set.size() > 1){\n      return \"NO\";\n    }\n     return \"YES\";\n\n  }\n"], ["from django.contrib.auth.models import AbstractUser\n\n\nclass CustomUser(AbstractUser):\n    email = models.EmailField(unique=True)\n", "from django.core.exceptions import ValidationError\n\n\nclass YourForm(UserCreationForm):\n\n    def clean(self):\n       email = self.cleaned_data.get('email')\n       if User.objects.filter(email=email).exists():\n            raise ValidationError(\"Email exists\")\n       return self.cleaned_data\n", "user = models.ForeignKey(settings.AUTH_USER_MODEL, on_delete=models.DO_NOTHING)\n"], [], ["auth = tweepy.AppAuthHandler(consumer_key, consumer_secret)\napi = tweepy.API(auth)\n", "auth.set_access_token(key, secret)\n"], [], ["final_losses.append(loss)\n", "plt.plot(range(epochs), final_loss)\nplt.ylabel('RMSE Loss')\nplt.xlabel('Epoch');\n", "Type(range(epochs)), type(final_losses)\n", "fi_los = [fl.item() for fl in final_losses ]\nplt.plot(range(epochs), fi_los)\nplt.ylabel('RMSE Loss')\nplt.xlabel('Epoch');\n"], [], ["def repeatedString(s, n):\n    # Get the length of input string\n    strlen = len(s)\n    a_repeat = 0\n    # Get the total count of a repeated character from the input string\n    for i in range(0,strlen):\n        if s[i] == 'a':\n            a_repeat = a_repeat + 1\n    # Get the multiplier to make sure that desired input string length achieved\n    str_multiplier = int(n // strlen) \n    # Get the repeated count if new string is been created\n    result = a_repeat*str_multiplier\n    new_str = s[:int( n % strlen )]\n    # for odd length of string, get the remaining characters and find repated characters count and add up it to final count\n    for i in range(0, len(new_str)):\n        if new_str[i] == 'a':\n            result += 1\n    return result\n"], ["def repeatedString(s, n):\n    target = 'a'\n    target_count = 0\n\n    # how many times does the string need to be repeated: (n // len(s) * s) + s[:(n % len(s))] \n    quotient = n // len(s)\n    remainder = n % len(s)\n\n    for char in s:  # how many times target appears in 1 instance of the substring\n        if char == target:\n            target_count += 1\n        \n    # how many times the target appears in many instances of the substring provided\n    target_count = target_count * quotient\n\n    for char in s[:remainder]:  # count the remaining targets in the truncated substring\n        if char == target:\n            target_count += 1\n\n    return target_count\n"], ["import numpy as np\nimport matplotlib.pyplot as plt\nimport re\n\ntxt_lines = txt.split('\\n')\nmax_line_index = max([len(line) for line in txt_lines])\npadded_txt_lines = [line + \" \" * (max_line_index - len(line)) for line in txt_lines] # pad short lines with spaces\nspace_idx_counters = np.zeros(max_line_index)\n\nfor idx, line in enumerate(padded_txt_lines):\n    if line.find(\"-----------------------Page\") >= 0: # reached end of page\n        break\n    space_idxs = [pos for pos, char in enumerate(line) if char == \" \"]\n    space_idx_counters[space_idxs] += 1\n\npadded_txt_lines = padded_txt_lines[:idx] #remove end page line\n\n# plot histogram of spaces in each character column\nplt.bar(list(range(len(space_idx_counters))), space_idx_counters)\nplt.title(\"Number of spaces in each column over all lines\")\nplt.show()\n\n# find the separator column idx\nseparator_idx = np.argmax(space_idx_counters)\nprint(f\"separator index: {separator_idx}\")\nleft_lines = []\nright_lines = []\n\n# separate two columns of text\nfor line in padded_txt_lines:\n    left_lines.append(line[:separator_idx])\n    right_lines.append(line[separator_idx:])\n\n# join each bulk into one stream of text, remove redundant spaces\nlhs = ' '.join(left_lines)\nlhs = re.sub(\"\\s{4,}\", \" \", lhs)\nrhs = ' '.join(right_lines)\nrhs = re.sub(\"\\s{4,}\", \" \", rhs)\n\nprint(\"************ Left Hand Side ************\")\nprint(lhs)\nprint(\"************ Right Hand Side ************\")\nprint(rhs)\n"], [], [], [], ["#forms.py\nfrom django.core.exceptions import ValidationError\nfrom django.contrib.auth.models import User\nfrom django.contrib.auth.form import UserCreationForm\nfrom some_app.validators import validate_email\n\ndef validate_email(value):\n    if User.objects.filter(email = value).exists():\n        raise ValidationError((f\"{value} is taken.\"),params = {'value':value})\n\nclass UserRegistrationForm(UserCreationForm):\n        email = forms.EmailField(validators = [validate_email])\n        \n        class Meta:\n            model = User\n        fields = ['username', 'email', 'password1', 'password2']    \n    \n"], ["minmax_scale(arr, feature_range=(0,1))\n", "normalized = (value - arr.min()) / (arr.max() - arr.min()) # Illustration\n"], [], ["python3 -m pip install autopep8\n"], ["with torch.no_grad():\n    (your code)\n"], ["import pandas as pd \nfrom tqdm import tqdm\n\nchunk_size = 50000\nchunks = [x for x in range(0, df.shape[0], chunk_size)]\n\nfor i in range(0, len(chunks) - 1):\n    print(chunks[i], chunks[i + 1] - 1)\n0 49999\n50000 99999\n100000 149999\n150000 199999\n200000 249990\n.........................\n\n\n\npivot_df = pd.DataFrame()\n\nfor i in tqdm(range(0, len(chunks) - 1)):\n    chunk_df = df.iloc[ chunks[i]:chunks[i + 1] - 1]\n    interactions = (chunk_df.groupby([user_col, item_col])[rating_col]\n      .sum()\n      .unstack()\n      .reset_index()\n      .fillna(0)\n      .set_index(user_col)\n    )\n    print (interactions.shape)\n    pivot_df = pivot_df.append(interactions, sort=False) \n", "from scipy import sparse\nimport numpy as np\nsparse_matrix = sparse.csr_matrix(df_new.to_numpy())\n"], [], [], ["from keras.datasets import imdb\n", "from tensorflow.keras.datasets import imdb\n\ntop_words = 10000\n((x_train, y_train), (x_test, y_test)) = imdb.load_data(num_words=top_words, seed=21)\n"], [], ["fig = plt.figure()\nax = fig.add_subplot(111)\nax.spines['left'].set_position('zero')\nax.spines['right'].set_color('none')\nax.spines['bottom'].set_position('zero')\nax.spines['top'].set_color('none')\nplt.axis([-5,5,-5,5])\nax.xaxis.set_ticks_position('bottom')\nax.yaxis.set_ticks_position('left')\nplt.grid()\nplt.arrow(0,0, 3,1, head_width=0.2, color='r', length_includes_head=True, label='u')\nplt.arrow(0,0, 1,3, head_width=0.2, color='r', length_includes_head=True, label='v')\nplt.arrow(0,0, 4,4, head_width=0.2, color='r', length_includes_head=True, label='u+v')\nax.legend()\n"], [], ["df = df.reset_index(drop=True)\n", "df.reset_index(drop=True, inplace=True)\n"], [], ["%load_ext tensorboard\n", "%load_ext tensorboard.notebook\n%tensorboard --logdir {logs_base_dir}\n"], ["export PATH=/Users/user_name/Library/Python/3.7/bin/:$PATH\n"], ["@dataclass\nclass Marker:\n    a: float\n    b: float = 1.0\n\nmarker_a = Marker(0.5)\n\nmarker_b = Marker(**marker_a.__dict__)\n\nmarker_b\n\n# Marker(a=0.5, b=1.0)\n", "marker_a = Marker(1.0, 2.0)\nmarker_b = Marker(11.0, 12.0)\n\nmarker_b.__dict__ = marker_a.__dict__.copy()\n\n# result: Marker(a=1.0, b=2.0)\n"], [], ["pyenv uninstall 2.7.18\npyenv install 2.7.18\n"], ["try:\n    money=int(input())\n\n    if money <10000:\n        print('you are poor '+name)\n    elif money >= 10000 and money<100000:\n        print('you are neither poor nor rich '+ name)\n    elif money >=100000:\n        print('you are rich ')\n\nexcept:\n    print(\"Input is not a valid number\")\n"], ["import sys\n\nclass A:\n    def __init__(self, x):\n        self.x = x\n\n    def __del__(self):\n        print(f'A x={self.x} being destructed.')\n\n\na1 = A(1)\na2 = A(2)\na1 = None\n# a1 is now destroyed\ninput('A(1) should have been destroyed by now ...')\na_list = [a2]\na_list.append(A(3))\na_list = None # A(3) should now be destroyed\ninput('A(3) should have been destroyed by now ...')\na4 = A(4)\nsys.exit(0) # a2 and a4 may or may not be garbage collected\n", "A x=1 being destructed.\nA(1) should have been destroyed by now ...\nA x=3 being destructed.\nA(3) should have been destroyed by now ...\nA x=2 being destructed.\nA x=4 being destructed.\n", "class A:\n    def __init__(self, x):\n        self.x = x\n        self.cleanup_done = False\n \n    def close(self):\n        print(f'A x={self.x} being cleaned up.')\n        self.cleanup_done = True\n \n \n    def __del__(self):\n        if not self.cleanup_done:\n            self.close()\n \n \nclass B:\n    def __init__(self, x):\n        self.a = A(x)\n \n    def foo(self):\n        print(\"I am doing some work\")\n \n \ndef bar():\n    b = B(9)\n    b.foo()\n \ndef other_function():\n    pass\n \nif __name__ == '__main__':\n    bar()\n    other_function()\n"], ["while True: # Infinite loop\n    try:\n        money = int(input()) # Try to convert the input into a number\n        break                # Break out of the infinite loop if the conversion is successful\n    except ValueError:       # Do this instead if the try block causes a ValueError\n        print(\"Sorry, that is not an integer. Please try again.\")\n\nif money < 10000:\n    print('you are poor ' + name)\nelif money >= 10000 and money < 100000:\n    print('you are neither poor nor rich ' + name)\nelif money >= 100000:\n    print('you are rich ' + name)\n"], ["try:\n    money=int(input())\n    \n    if money <10000:\n       print('you are poor '+name)\n    elif money >= 10000 and money<100000:\n       print('you are neither poor nor rich '+ name)\n    elif money >=100000:\n       print('you are rich ')\n    else:\n       print('wrong value')\nexcept ValueError:\n    print(\"not an integer\")\n"], ["try:\nmoney=int(input())\n", "except:\nprint('You should enter an integer!')\n"], ["while True: # Infinite loop\n    try:\n        money = int(input()) # Try to convert the input into a number\n        break                # Break out of the infinite loop if the conversion is successful\n    except ValueError:       # Do this instead if the try block causes a ValueError\n        print(\"Sorry, that is not an integer. Please try again.\")\n\nif money < 10000:\n    print('you are poor ' + name)\nelif money >= 10000 and money < 100000:\n    print('you are neither poor nor rich ' + name)\nelif money >= 100000:\n    print('you are rich ' + name)\n"], ["try:\n    money=int(input())\n\n    if money <10000:\n       print('you are poor '+ name)\n    elif money >= 10000 and money<100000:\n       print('you are neither poor nor rich '+ name)\n    elif money >=100000:\n       print('you are rich ')\nexcept:\n    print(\"error\")\n"], ["try:\n    money=int(input())\nexcept ValueError:\n    print(\"That is not an integer!\")\n"], [], [], ["a = float(input(\"Enter a: \"))\nb = float(input(\"Enter b: \"))\nif a > b:\n    a = a + b\n    b = a - b\n    a = a - b\nc = float(input(\"Enter c: \"))\nif b > c:\n    b = b + c\n    c = b - c\n    b = b - c\n    if a > b:\n        a = a + b\n        b = a - b\n        a = a - b\nprint (a, \"<\", b, \"<\", c)\n", "a = float(input(\"Enter a: \"))\nb = float(input(\"Enter b: \"))\nif a > b:\n    a, b = b, a\nc = float(input(\"Enter c: \"))\nif b > c:\n    b, c = c, b\n    if a > b:\n        a, b = b, a\nprint (a, \"<\", b, \"<\", c)\n"], ["a = float(input(\"Enter a: \"))\nb = float(input(\"Enter b: \"))\nc = float(input(\"Enter c: \"))\n\nif a > b:\n    a,b = b,a\nif a > c:\n    a,c = c,a\nif b > c:\n    b,c = c,b\n    \nprint (a, \"<\", b, \"<\", c)\n"], ["a=[int(input(\"First Number: \")),int(input(\"Second Number: \")),int(input(\"Third Number: \"))]\nfor x in range (0,len(a)):\n    for i in range (0,(len(a))-1):\n        if a[i]>a[i+1]:\n            a[i],a[i+1] = a[i+1],a[i]\nprint (\"Little to Bigger Sort:\",a)\n"], ["for i in range(len(num)):\n    for j in range(i+1, len(num)):\n        if(num[i] > num[j]):\n            temp = num[i]\n            num[i] = num[j]\n            num[j] = temp\nprint(num)\n\n"], [], ["File \"/usr/lib/python3/dist-packages/numpy/lib/npyio.py\", line 260, in __getitem__\n", "self.allow_pickle = True\n"], [], ["pip install pep8   \npip install --upgrade autopep8\n", "\"python.formatting.provider\": \"autopep8\"\n"], ["final_df.fillna(value=0, inplace=True)\n"], ["import tensorflow\nprint(tensorflow.__version__)\n", "np.load(somepath, allow_pickle=True)\n"], ["pedestrainsClassifier = cv2.CascadeClassifier(\"hogcascade_pedestrians.xml\")\n", "pedestrainsClassifier = cv2.CascadeClassifier(f\"{cv2.data.haarcascades}hogcascade_pedestrians.xml\")\n", "pedestrainsClassifier = cv2.CascadeClassifier(cv2.data.haarcascades +\"hogcascade_pedestrians.xml\")\n"], ["for row in hqm_dataframe.index:\n    for time_period in time_periods:\n    \n        change_col = f'{time_period} Price Return'\n        percentile_col = f'{time_period} Return Percentile'\n        if hqm_dataframe.loc[row, change_col] == None:\n            hqm_dataframe.loc[row, change_col] = 0.0\n", "for row in hqm_dataframe.index:\n    for time_period in time_periods:\n    \n        change_col = f'{time_period} Price Return'\n        percentile_col = f'{time_period} Return Percentile'\n\n        hqm_dataframe.loc[row, percentile_col] = score(hqm_dataframe[change_col], hqm_dataframe.loc[row, change_col])\n"], ["hqm_columns = [\n    'Ticker',\n    'Price',\n    'Number of Shares to Buy',\n    'One-Year Price Return',\n    'One-Year Return Percentile',\n    'Six-Month Price Return',\n    'Six-Month Return Percentile',\n    'Three-Month Price Return',\n    'Three-Month Return Percentile',\n    'One-Month Price Return',\n    'One-Month Return Percentile'\n]\n\nhqm_dataframe = pd.DataFrame(columns=hqm_columns)\nconvert_none = lambda x : 0 if x is None else x\n\nfor symbol_string in symbol_strings:\n    batch_api_call_url = f'https://sandbox.iexapis.com/stable/stock/market/batch?symbols={symbol_string}&types=price,stats&token={IEX_CLOUD_API_TOKEN}'\n    data = requests.get(batch_api_call_url).json()\n    \n    for symbol in symbol_string.split(','):\n        hqm_dataframe = hqm_dataframe.append(\n            pd.Series(\n                [\n                    symbol,\n                    data[symbol]['price'],\n                    'N/A',\n                    convert_none(data[symbol]['stats']['year1ChangePercent']),\n                    'N/A',\n                    convert_none(data[symbol]['stats']['month6ChangePercent']),\n                    'N/A',\n                    convert_none(data[symbol]['stats']['month3ChangePercent']),\n                    'N/A',\n                    convert_none(data[symbol]['stats']['month1ChangePercent']),\n                    'N/A'\n                ],\n                index = hqm_columns\n            ),\n            ignore_index=True\n        )\n"], ["time_periods = [\n                'One-Year',\n                'Six-Month',\n                'Three-Month',\n                'One-Month'\n                ]\n\nfor row in hqm_dataframe.index:\n    for time_period in time_periods:\n        if hqm_dataframe.loc[row, f'{time_period} Price Return'] == None:\n            hqm_dataframe.loc[row, f'{time_period} Price Return'] = 0\n"], [], ["# Reinstall awscli using your latest/current Python installation\nbrew reinstall awscli\n\n# Overwrite the existing /usr/local/bin/aws with the new installation\nbrew link --overwrite awscli\n"], ["class MyAdmin(django.contrib.admin.ModelAdmin):\n\n    def formfield_for_dbfield(self, *args, **kwargs):\n        formfield = super().formfield_for_dbfield(*args, **kwargs)\n\n        formfield.widget.can_delete_related = False\n        formfield.widget.can_change_related = False\n        # formfield.widget.can_add_related = False  # can change this, too\n        # formfield.widget.can_view_related = False  # can change this, too\n\n        return formfield\n"], [], ["$ sudo apt-get install libpython3.5-dev\n$ pip3 install regex --no-use-wheel\n", "# install the apt-file package in case you don't have it\n$ sudo apt-get install apt-file\n\n# populate/refresh the local apt-file package data\n$ sudo apt-file update\n\n# search for /Python.h.  Since it's a C header file,\n# I also grep for /include to limit the results.\n$ sudo apt-file search /Python.h | grep /include\nlibpython2.7-dbg: /usr/include/python2.7_d/Python.h\nlibpython2.7-dev: /usr/include/python2.7/Python.h\nlibpython3.5-dbg: /usr/include/python3.5dm/Python.h\nlibpython3.5-dev: /usr/include/python3.5m/Python.h\npypy-dev: /usr/lib/pypy/include/Python.h\n"], [], [], [], ["$ brew uninstall python@2\nUninstalling /usr/local/Cellar/python@2/2.7.15_1... (4,169 files, 76.0MB)\n", "$ pyenv versions\n  system\n* 2.7.12 (set by /Users/admin/.python-version)\n  3.4.5\n  3.7.7\n\n$ pyenv local system\n$ pyenv global system\n"], ["def sublength(string, char):\n    try:\n        start = string.index(char)\n        end = string.index(char, start+1)\n    except: return 'No two instances'\n    else: return end +2\n"], ["def f(s, c):\n    s = s.lower()\n    if s.count(c) != 2:\n        return 0\n    return s.index(c, mn+1)-s.index(c)+1\n    \n\nf('Saturday', 'a')\n"], ["import re\n\ndef substring_length(string, char):\n    match = re.search(f'{char}.+{char}', string)\n    match_length = len(match.group(0)) if match else 0\n    return match_length\n", "# Returns the expected results when there are two target characters\nprint(substring_length('Saturday', 'a'))\n6\n\n# Returns 0 when there aren't at least two target characters\nprint(substring_length('Saturday', 'z'))\n0\n\n# When there are more than two target characters, calculate the length from the start matching character to the last matching character\nprint(substring_length('Researcher', 'e'))\n8\n"], ["def sublength(string, char):\nnew_string = ''\nfound = False\nfor i in string:\n    if i == char:\n        if not found:\n            new_string += i\n            found = True\n        else:\n            new_string += i\n            found = False\n            break\n    elif found:\n        new_string += i\nif found:\n    new_string = \"\"\nreturn len(new_string)\n", "import re\nif re.search(\"a.*?a\", \"Saturday\"):\n    print(len(re.search(\"a.*?a\", \"Saturday\").group(0)))\nelse:\n    print(\"Nope\")\n"], ["try:\n    print(string[string.index(char)+1:].index(char)+2)\nexcept:\n    print(char ,'is not present twice in ', string)\n", "pos = string[string.find(char)+1:].find(char)+2\nif pos == 1 :\n    print(char ,'is not present twice in ', string)\nelse:\n    print(\"Are present at a distance of\",pos)\n"], ["def __init__(self, *args, **kwargs):\n    super().__init__(*args, **kwargs)\n    self.fields['xxx'].widget.can_delete_related = False\n"], ["chunk_size = 5000\nchunks = [x for x in range(0, df.shape[0], chunk_size)]\n\nfor i in range(0, len(chunks) - 1):\n    print(chunks[i], chunks[i + 1] - 1)\n\n0 4999\n5000 9999\n10000 14999\n15000 19999\n20000 24999\n25000 29999\n30000 34999\n35000 39999\n40000 44999\n45000 49999\n50000 54999\n55000 59999\n60000 64999\n65000 69999\n70000 74999\n75000 79999\n..continue..\n", "df_new = pd.concat([df.iloc[ chunks[i]:chunks[i + 1] - 1 ].pivot(index='user_id', columns='item', values='views') for i in range(0, len(chunks) - 1)])\n", "from scipy import sparse\nspr = sparse.coo_matrix(df_new.to_numpy())\n"], ["result = AsyncResult(task_id)\nresult.name = 'project.tasks.my_task'\nresult.args = [2, 3]\nresult.kwargs = {'a': 'b'}\n"], [], ["ln -s /usr/local/opt/openssl/lib/libcrypto.1.1.dylib /usr/local/lib\nln -s /usr/local/opt/openssl/lib/libssl.1.1.dylib /usr/local/lib\n"], [" X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n\n y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n"], ["pip install pipwin\npipwin install pyaudio\n"], [], [], ["app.run_server(host='0.0.0.0', debug=True)\n", "app.run_server(host='0.0.0.0', port=8050, debug=True)\n"], [], ["brew uninstall awscli\n", "brew install awscli\n"], ["def negativeNumber(x):\n    neg = x * (-1)\n    return neg\n"], ["import random\narray1 = []\narrayLength = 25\nfor i in range(arrayLength):\n   array1.append((random.randint(0, arrayLength)*-1))\n"], ["arrayLength = 25\narray1 = [-random.randint(0, arrayLength) for _ in arrayLength]\n"], ["@dataclass\nclass Person:\n    name: str\n    age: float\n\n    def __setattr__(self, name, value):\n        if name == 'age':\n            assert value > 0, f\"value of {name} can't be negative: {value}\"\n        self.__dict__[name] = value\n"], [], ["import dataclasses\n\nmarker_a = Marker(1.0, 2.0)\nmarker_b = Marker(**dataclasses.asdict(marker_a))\n"], ["from django.contrib.auth.models import User\n\nUser._meta.get_field('email')._unique = True\nSETTINGS.PY\nAUTHENTICATION_BACKENDS = [\n     'django.contrib.auth.backends.ModelBackend'\n]\n"], [], ["classifier = CascadeClassifier('haarcascade_frontalface_default.xml')\n", "SystemError: <class 'cv2.CascadeClassifier'> returned a result with an error set\n"], [], ["result = AsyncResult(task_id, app=celery_app)\nresult.task_name #tasks.add\n"], ["app = Celery(\"myapp\")  # add your parameters here\ntask_id = \"6dc5f968-3554-49c9-9e00-df8aaf9e7eb5\"\naresult = app.AsyncResult(task_id)\ntask_name = aresult.name\ntask_args = aresult.args\nprint(task_name, task_args)\n", "# Since the expected way does not work we need to use the inspect API:\ninsp = app.control.inspect()\ntask_ids = [task_id]\ninspect_result = insp.query_task(*task_ids)\n# print(inspect_result)\nfor node_name in inspect_result:\n    val = inspect_result[node_name]\n    if val:\n        # we found node that executes the task\n        arr = val[task_id]\n        state = arr[0]\n        meta = arr[1]\n        task_name = meta[\"name\"]\n        task_args = meta[\"args\"]\n        print(task_name, task_args)\n"], [" from tensorflow.keras.datasets import imdb\n", " from keras.datasets import imdb\n"], [], [], ["def __del__(self):\n  # body of destructor\n", "    # Python program to illustrate destructor \n    class Employee: \n      \n        # Initializing \n        def __init__(self): \n            print('Employee created.') \n      \n        # Deleting (Calling destructor) \n        def __del__(self): \n            print('Destructor called, Employee deleted.') \n      \n    obj = Employee() \n    del obj \n\n#Output\n#Employee created.\n#Destructor called, Employee deleted.\n", "# Python program to illustrate destructor \n  \nclass Employee: \n  \n    # Initializing  \n    def __init__(self): \n        print('Employee created') \n  \n    # Calling destructor \n    def __del__(self): \n        print(\"Destructor called\") \n  \ndef Create_obj(): \n    print('Making Object...') \n    obj = Employee() \n    print('function end...') \n    return obj \n  \nprint('Calling Create_obj() function...') \nobj = Create_obj() \nprint('Program End...') \n\n#Output:\n#Calling Create_obj() function...\n#Making Object...\n", "# Python program to illustrate destructor \n  \nclass A: \n    def __init__(self, bb): \n        self.b = bb \n  \nclass B: \n    def __init__(self): \n        self.a = A(self) \n    def __del__(self): \n        print(\"die\") \n  \ndef fun(): \n    b = B() \n  \nfun() \n\n#Output:\n#die\n"], [], [], ["def __del__(self):\n    self.my_func()\n", "class Employee: \n  \n    def __init__(self, name): \n        self.name = name\n        print('Employee created.') \n    \n    def get_name(self):\n        return self.name\n\n    def close(self):\n        print(\"Object closed\")\n\n    # destructor\n    def __del__(self):\n        self.close()\n  \nobj = Employee('John')\n\nprint(obj.get_name())\n\n# lets try deleting the object!\nobj.__del__() # you don't need to run this\n\nprint(\"Program ends\")\n\nprint(obj.get_name())\n", "> Employee created.\n> John \n> Object closed \n> Program ends  \n> John \n> Object closed\n"], [], ["def repeatedString(s, n):\n    if len(s)==1 and s=='a':\n        return n\n    cnt_a=0\n    for i in s:\n        if i == 'a':\n            cnt_a+=1\n    if cnt_a % 2 == 0:\n        no_a = (cnt_a/len(s)) * n\n        return math.ceil(no_a)\n    else:\n        no_a = (cnt_a/len(s)) * n\n        return math.floor(no_a)\n"], ["import sys\nsys.path\n", "sys.path.append('/Users/**your_user_name**/anaconda3/lib/python3.7/site-packages')\n"], ["print(datetime.datetime.now())\n2020-08-20 22:57:28.061648\n \ndef lastweeknumberoflastyear():\n    return datetime.date(datetime.datetime.now().year-1, 12, 28).isocalendar()[1]\n\nprint(datetime.datetime.now() - datetime.timedelta(weeks=lastweeknumberoflastyear()))\n2019-08-22 22:57:28.061785\n"], ["print(datetime.datetime.now())\n2020-08-20 17:56:56.397626\n\nprint(datetime.datetime.now() - datetime.timedelta(weeks=52))\n2019-08-22 17:56:56.397626\n"], ["from datetime import datetime\nx = datetime.now()\nlast_year = datetime(x.year-1,x.month,x.day,x.hour,x.minute,x.second,x.microsecond)\n"], ["now = datetime.datetime.now()\nlast_year = now.replace(now.year - 1)\n", "now = datetime.datetime.now()\nlast_year = now - datetime.timedelta(days=365)\n"], ["pip install tensorflow-gpu==2.2.0\n", "pip install https://storage.googleapis.com/tensorflow/windows/gpu/tensorflow_gpu-2.2.0-cp37-cp37m-win_amd64.whl\n"], ["pip3 install setuptools --upgrade\n"], [], ["@echo off\nset FLASK_ENV=development\nset FLASK_APP=run.py\nflask run\n"], ["import pandas as pd\nimport dash\nfrom dash.dependencies import Input, Output\nimport dash_core_components as dcc\nimport dash_html_components as html\nimport dash_table\nimport base64\nimport io\n\napp = dash.Dash()\n\n# app.scripts.config.serve_locally = True\n# app.css.config.serve_locally = True\n\nDF_GAPMINDER = pd.read_csv('https://raw.githubusercontent.com/plotly/datasets/master/gapminderDataFiveYear.csv'\n)\nDF_GAPMINDER = DF_GAPMINDER[DF_GAPMINDER['year'] == 2007]\nDF_GAPMINDER.loc[0:20]\n\nDF_SIMPLE = pd.DataFrame({\n    'x': ['A', 'B', 'C', 'D', 'E', 'F'],\n    'y': [4, 3, 1, 2, 3, 6],\n    'z': ['a', 'b', 'c', 'a', 'b', 'c']\n})\n\n\ndataframes = {'DF_GAPMINDER': DF_GAPMINDER,\n              'DF_SIMPLE': DF_SIMPLE}\n\n\ndef get_data_object(user_selection):\n    \"\"\"\n    For user selections, return the relevant in-memory data frame.\n    \"\"\"\n    return dataframes[user_selection]\n\n\napp.layout = html.Div([\n    html.H4('DataTable'),\n    html.Label('Report type:', style={'font-weight': 'bold'}),\n    dcc.Dropdown(\n        id='field-dropdown',\n        options=[{'label': df, 'value': df} for df in dataframes],\n        value='DF_GAPMINDER',\n        clearable=False\n    ),\n    \n    dash_table.DataTable(id='table')\n])\n\n\n@app.callback([Output(component_id='table', component_property='data'), \n             Output(component_id='table', component_property='columns')],\n            [Input('field-dropdown', 'value')])\ndef update_table(user_selection):\n    \"\"\"\n    For user selections, return the relevant table\n    \"\"\"\n    \n    df = get_data_object(user_selection)\n    columns = [{'name': col, 'id': col} for col in df.columns]\n    data = df.to_dict(orient='records')\n    return data, columns\n\n\napp.run_server()\n"], [], [], ["# use pip with python3\n$ python3 -m pip install fish\n"], [], [], ["pip TensorFlow\n\nvirtualenv --system-site-packages -p python3 ./venv\n", "pip install --upgrade pip\n\npip list  # show packages installed within the virtual environment\nthis command for quit \ndeactivate  # don't exit until you're done using TensorFlow\nwe finish by installing tensor \n\npip install --upgrade tensorflow\n", "python3 --version\npip3 --version\nvirtualenv --version\n", "sudo apt update\n\nsudo apt install python3-dev python3-pip\n\nsudo pip3 install -U virtualenv  # system-wide install\n", "pip3 install --user --upgrade tensorflow  # install in $HOME\n"], ["# Use `df.to_numpy() instead of `df.values` mentioned in the docs.\nnew_df = pd.DataFrame(np.vstack([df.columns, df.to_numpy()]),\n                      columns = [f'Q1.{i+1}' for i in range(df.shape[1])])\n\n  Q1.1 Q1.2 Q1.3 Q1.4 Q1.5\n0    a    b    c    d    e\n1    1    2    2    2    2\n2    2    3    3    3    3\n3    3    4    4    4    4\n4    4    5    5    5    5\n5    5    6    6    6    6\n6    6    7    7    7    7\n", "             # np.r_[[df.columns], df.to_numpy()]\npd.DataFrame(np.r_['0,2', df.columns, df.to_numpy()], \n             columns = [f'Q1.{i+1}' for i in range(df.shape[1])])\n\n  Q1.1 Q1.2 Q1.3 Q1.4 Q1.5\n0    a    b    c    d    e\n1    1    2    2    2    2\n2    2    3    3    3    3\n3    3    4    4    4    4\n4    4    5    5    5    5\n5    5    6    6    6    6\n6    6    7    7    7    7\n", "np.concatenate([[df.columns], df.values],axis=0)\n", "pd.DataFrame(np.vstack([df.columns, df.to_numpy()])).add_prefix('Q1.')\n\n  Q1.0 Q1.1 Q1.2 Q1.3 Q1.4\n0    a    b    c    d    e\n1    1    2    2    2    2\n2    2    3    3    3    3\n3    3    4    4    4    4\n4    4    5    5    5    5\n5    5    6    6    6    6\n6    6    7    7    7    7\n", "large_df = pd.DataFrame(np.random.randint(0,9,(1_000_000,5)),\n                        columns = ['a', 'b', 'c', 'd', 'e'])\n        a  b  c  d  e\n0       3  8  0  8  5\n1       7  4  0  0  7\n2       5  1  2  6  1\n3       8  0  5  5  6\n4       0  2  3  1  8\n...    .. .. .. .. ..\n999995  1  7  3  8  7\n999996  5  2  5  1  6\n999997  7  4  4  3  5\n999998  3  5  2  2  7\n999999  6  7  0  8  0\n\n[1000000 rows x 5 columns]\n"], ["new_df = (df.T.reset_index().T.reset_index(drop=True)\n            .set_axis([f'Q1.{i+1}' for i in range(df.shape[1])], axis=1))\nprint(new_df)\n", "  Q1.1 Q1.2 Q1.3 Q1.4 Q1.5\n0    a    b    c    d    e\n1    1    2    2    2    2\n2    2    3    3    3    3\n3    3    4    4    4    4\n4    4    5    5    5    5\n5    5    6    6    6    6\n6    6    7    7    7    7\n"], ["import pandas as pd\n\ndf = pd.DataFrame({'a': [1, 2, 3, 4, 5, 6],\n                   'b': [2, 3, 4, 5, 6, 7],\n                   'c': [2, 3, 4, 5, 6, 7],\n                   'd': [2, 3, 4, 5, 6, 7],\n                   'e': [2, 3, 4, 5, 6, 7]})\n\ndf.loc[-1] = df.columns.values\ndf.sort_index(inplace=True)\ndf.reset_index(drop=True, inplace=True)\n\ndf.rename(columns=\n    {\"a\": \"Q1.1\", \"b\": \"Q1.2\", \"c\": \"Q1.3\", \"d\": \"Q1.4\", \"e\": \"Q1.5\"}, \n    inplace=True)\n", "  Q1.1 Q1.2 Q1.3 Q1.4 Q1.5\n0    a    b    c    d    e\n1    1    2    2    2    2\n2    2    3    3    3    3\n3    3    4    4    4    4\n4    4    5    5    5    5\n5    5    6    6    6    6\n6    6    7    7    7    7\n"], ["data={\"A\":[4,3,4],\"B\":[5,2,7],\"C\":[3,5,9],\"D\":[6,3,0]}\n\ndf=pd.DataFrame(data)\n\ndf.loc[-1]=df.columns\ndf.index = df.index + 1  # shifting index\ndf.sort_index(inplace=True)\ndf.columns=[\"Q1.1\",\"Q1.2\",\"Q1.3\",\"Q1.4\"]\n", "  Q1.1 Q1.2 Q1.3 Q1.4\n0    A    B    C    D\n1    4    5    3    6\n2    3    2    5    3\n3    4    7    9    0\n"], ["df = pd.DataFrame({'a': [1,2,3,4,5,6],\n                  'b': [2,3,4,5,6,7],\n                  'c': [2,3,4,5,6,7],\n                  'd': [2,3,4,5,6,7],\n                  'e': [2,3,4,5,6,7]})\ndf.loc[-1,:] = df.columns\ndf.index += 1\ndf.sort_index(inplace = True)\ndf.columns=['Q1.1','Q1.2','Q1.3','Q1.4','Q1.5']\n", "  Q1.1 Q1.2 Q1.3 Q1.4 Q1.5\n0    a    b    c    d    e\n1    1    2    2    2    2\n2    2    3    3    3    3\n3    3    4    4    4    4\n4    4    5    5    5    5\n5    5    6    6    6    6\n6    6    7    7    7    7\n"], [], [], ["from subprocess import Popen\nfrom time import sleep\n\nps = [\n    Popen(['sleep', t])\n    for t in ('3', '5', '2')\n]\n\nwhile True:\n    exit_codes = [p.poll() for p in ps]\n    print(exit_codes)\n    if any(ec is not None for ec in exit_codes):\n        break\n    else:\n        sleep(1)\n", "[None, None, None]\n[None, None, None]\n[None, None, 0]\n"], ["import subprocess\nimport psutil\n\na = subprocess.Popen(['/bin/sleep', \"2\"])\n\nb = subprocess.Popen(['/bin/sleep', \"4\"])\n\nprocs_list = [psutil.Process(a.pid), psutil.Process(b.pid)]\n\ndef on_terminate(proc):\n     print(\"process {} terminated\".format(proc))\n\n# waits for multiple processes to terminate\ngone, alive = psutil.wait_procs(procs_list, timeout=3, callback=on_terminate)\n", "while True: \n    gone, alive = psutil.wait_procs(procs_list, timeout=3, callback=on_terminate) \n    if len(gone)>0: \n        break\n"], ["app.run_server(debug=True)\n", "app.run_server(debug=False)\n"], ["python3\npython3-pip\nipython3\nbuild-essential\npython-dev\npython3-dev\n", "sudo apt-get install python3 python3-pip ipython3 build-essential python-dev python3-dev\n"], ["class YourModelAdmin(admin.ModelAdmin):\n    ...\n    def get_form(self, request, obj=None, **kwargs):\n        form = super(YourModelAdmin, self).get_form(request, obj, **kwargs)\n        field = form.base_fields[\"your_foreign_key_field\"]\n        field.widget.can_add_related = False\n        field.widget.can_change_related = False\n        field.widget.can_delete_related = False\n        return form\n"], ["from torch.autograd import Variable\n\ntype(y)  # <class 'torch.Tensor'>\n\ny = Variable(y, requires_grad=True)\ny = y.detach().numpy()\n\ntype(y)  #<class 'numpy.ndarray'>\n"], ["def repeatedString(s,n):\n    i = 0\n    c = 0\n    for i in s:\n        if i == 'a':\n            c += 1\n\n    q = int(n / len(s)) #Finding the quotient \n    r = int(n % len(s)) #Finding the remainder\n    if r == 0: \n        c *= q \n\n    else:\n        x = 0\n        for i in range(r):\n            if s[i] == 'a':\n                x += 1\n        c = c*q + x\n\n    return int(c)\n\ns = input()\nn = int(input())\nprint(repeatedString(s,n))\n"], ["!pip install tensorflow==2.2-rc3\n"], [], ["from datetime import datetime as dt\n\nstart = dt.fromtimestamp(1588432670)\nend = dt.now()\nelapsed=end-start\nprint(\"Took: %02d:%02d:%02d:%02d\" % (elapsed.days, elapsed.seconds // 3600, elapsed.seconds // 60 % 60, elapsed.seconds % 60))\n", "Took: 33:00:21:49\n"], [], ["from datetime import datetime\nstart_time = datetime.now()\n\n# some code\n\nelapsed = datetime.now() - start_time)\nprint(f\"Took: {elapsed}\")\n", "from datetime import datetime\nd1 = datetime(2013,9,1,5,5,4)\nd2 = datetime(2013,1,13,3,2,1)\nresult1 = d1-d2\nprint ('{} between {} and {}'.format(result1, d1, d2))\n", "231 days, 2:03:03 between 2013-09-01 05:05:04 and 2013-01-13 03:02:01\n"], ["pickle.load(path)\n", "np.load(path, allow_pickle=True)\n"], [], ["pd.concat(li, axis=1).T\n"], ["def repeatedString(s, n):\n    if len(s)==1 and s==\"a\":\n        return n\n    count=s.count(\"a\") \n    x,y=divmod(n,len(s))\n    count=count*x\n    str=s[:y]\n    return count+str.count(\"a\")\n"], ["s = input().strip()\nn = int(input())\nprint(s[:n%len(s)].count('a')+(s.count('a')*(n//len(s))))\n"], [], [], ["import cf\nimport numpy\n\nf = cf.example_field(2) # Use cf.read to read your own data\n\nprint('Source field:')\nprint(f)\n\n# Define the output grid\nlat = cf.DimensionCoordinate(\n           data=cf.Data(numpy.arange(-90, 90.01, 0.083), 'degreesN'))\nlon = cf.DimensionCoordinate(\n          data=cf.Data(numpy.arange(0, 360, 0.083), 'degreesE'))\n\n# Regrid the field\ng = f.regrids({'latitude': lat, 'longitude': lon}, method='linear')\n\nprint('\\nRegridded field:')\nprint(g)\n", "Source field:\nField: air_potential_temperature (ncvar%air_potential_temperature)\n------------------------------------------------------------------\nData            : air_potential_temperature(time(36), latitude(5), longitude(8)) K\nCell methods    : area: mean\nDimension coords: time(36) = [1959-12-16 12:00:00, ..., 1962-11-16 00:00:00]\n                : latitude(5) = [-75.0, ..., 75.0] degrees_north\n                : longitude(8) = [22.5, ..., 337.5] degrees_east\n                : air_pressure(1) = [850.0] hPa\n\nRegridded field:\nField: air_potential_temperature (ncvar%air_potential_temperature)\n------------------------------------------------------------------\nData            : air_potential_temperature(time(36), latitude(2169), longitude(4338)) K\nCell methods    : area: mean\nDimension coords: time(36) = [1959-12-16 12:00:00, ..., 1962-11-16 00:00:00]\n                : latitude(2169) = [-90.0, ..., 89.94399999999655] degreesN\n                : longitude(4338) = [0.0, ..., 359.971] degreesE\n                : air_pressure(1) = [850.0] hPa\n\n"], [], ["ERROR: Command errored out with exit status 1: /usr/bin/python3 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-a7ojseph/regex/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-a7ojseph/regex/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /tmp/pip-record-bodowot9/install-record.txt --single-version-externally-managed --compile --install-headers /usr/local/include/python3.7/regex Check the logs for full command output.\n"], ["da_input = open_dataarray(\n    'input.nc') # the file the data will be loaded from\nregrid_axis = np.arange(-90, 90, 0.125) # new coordinates\nda_output = da_input.interp(lat=regrid_axis) # specify calculation\nda_ouput.to_netcdf('output.nc') # save direct to file\n"], [], ["    import numpy as np\n    def random_point_ellipsoid(a,b,c):\n        u = np.random.rand()\n        v = np.random.rand()\n        theta = u * 2.0 * np.pi\n        phi = np.arccos(2.0 * v - 1.0)\n        sinTheta = np.sin(theta);\n        cosTheta = np.cos(theta);\n        sinPhi = np.sin(phi);\n        cosPhi = np.cos(phi);\n        rx = a * sinPhi * cosTheta;\n        ry = b * sinPhi * sinTheta;\n        rz = c * cosPhi;\n        return rx, ry, rz\n"], [], ["!pip install pandas==0.21\nimport pandas as pd\nuser_by_movie = user_items.groupby(['user_id', 'movie_id'])['rating'].max().unstack()\n!pip install pandas\n"], [], ["pip install --upgrade 'setuptools<45.0.0'\n"], [], [], [], ["import pandas as pd\nold_df = pd.read_excel('target.xlsx')  \nframes = [old_df, new_df]\nresult = pd.concat(frames)\nresult.to_excel(\"target.xlsx\", sheet_name=\"sheet_1\", index=False)\n"], ["from openpyxl import load_workbook\nwriter = pandas.ExcelWriter('target.xlsx', engine='openpyxl') \nwriter.book = load_workbook('target.xlsx')\nwriter.sheets = dict((ws.title, ws) for ws in book.worksheets)\ndf.to_excel(excel_writer=writer, sheet_name=\"sheet_1\")\nwriter.save()\n"], ["import pandas as pd\n\n# Open the existing excel file with all sheets\ndf_dict = pd.read_excel('target.xlsx',sheet_name=None)\n\nwith pd.ExcelWriter(fp) as writer:\n\n     # Save the original sheets\n     for sheet in df_dict:\n          df[sheet].to_excel(writer, sheet_name=sheet)\n\n     # If the new sheet name doesn't exist, append it\n     if 'sheet_1' not in df_dict:\n          df.to_excel(writer, sheet_name='sheet_1')\n"], [], [], ["new_df = target_df.append(df)\n\n"], ["import pandas as pd\nimport numpy as np\nimport xlsxwriter\n\nworkbook = xlsxwriter.Workbook('arrays.xlsx')\nworksheet = workbook.add_worksheet() # a created excel sheet\n\narray = pd.read_csv('array.csv')\narray = array.tolist()\n\nrow = 0\n\nfor col, data in enumerate(array):\n    worksheet.write_column(row, col, data)\n\nworkbook.close()\n"], ["$ ls /usr/local/Cellar/openssl\n", "1.0.2t\n", "$ brew switch openssl 1.0.2t\n", "Cleaning /usr/local/Cellar/openssl/1.0.2t\nOpt link created for /usr/local/Cellar/openssl/1.0.2t\n", "(my-venv) $ python -c \"import hashlib;m=hashlib.md5();print(m.hexdigest())\"\n", "d41d8cd98f00b204e9800998ecf8427e\n"], ["(Path(__file__).parent).joinpath('.env')\n"], ["env_path = Path(__file__).parent / \".env\"\n"], [], [], [], ["#!/usr/bin/env python\n\nfrom os import path as environ\n\nimport click\n\nfrom flask import Flask\nfrom flask.cli import FlaskGroup\n\ndef create_app():\n    app = Flask(__name__)\n    ...\n    return app\n\n\n@click.group(cls=FlaskGroup, create_app=create_app)\n@click.option('-e', '--env', default=\"development\")\ndef manager(env):\n    environ[\"FLASK_ENV\"] = env\n\n\nif __name__ == \"__main__\":\n    manager()\n"], [], ["li_df = pd.DataFrame(li).T\n"], ["@app.callback(\n    [Output(component_id='tweet_table', component_property='data'),\n     Output(component_id='tweet_table', component_property='columns')\n    [Input(component_id='screenNames_submit_button', component_property='n_clicks_timestamp')],\n    [State(component_id='ScreenName_Input', component_property='value')]\n)\ndef display_tweets(submit_button, screen_names):\n    tweets = old_tweets(screen_names)\n    columns = [{'name': col, 'id': col} for col in tweets.columns]\n    data = tweets.to_dict(orient='records')\n    return data, columns\n"], [], [], ["> $ export FLASK_ENV=development \n> $ flask run (On Windows, use set instead of export.)\n"], ["from functools import partial\n\ndef reorder_from_idx(idx, a):\n    return a[idx:] + a[:idx]\n\ndef cyclic_perm(a):\n    return [partial(reorder_from_idx, i) for i in range(len(a))]\n\n\na = [1, 2, 3, 4, 5, 6]\nresult = cyclic_perm(a)\nprint(result)\n#[functools.partial(<function reorder_from_idx at 0x00000298D92189D8>, 0),\n# functools.partial(<function reorder_from_idx at 0x00000298D92189D8>, 1),\n# functools.partial(<function reorder_from_idx at 0x00000298D92189D8>, 2),\n# functools.partial(<function reorder_from_idx at 0x00000298D92189D8>, 3),\n# functools.partial(<function reorder_from_idx at 0x00000298D92189D8>, 4),\n# functools.partial(<function reorder_from_idx at 0x00000298D92189D8>, 5)]\nresult[3](a)\n#[4, 5, 6, 1, 2, 3]\n"], ["   public static int getNumberChar(char temp){\n    int a = Character.getNumericValue('a');\n    int z = Character.getNumericValue('z');\n    int val = Character.getNumericValue(temp);\n    if(val >= a && val <= z){\n     //   System.out.println(\"val = \" + (val - a));\n        return val - a;\n    }\n    return -1;\n}\n\n\npublic static int[] frequencyForEachCharInString(String str){\n    int[] frequencyChar = new int[getNumberChar('z')-getNumberChar('a') +1 ];\n    for (char c: str.toCharArray()) {\n        if(getNumberChar(c) != -1){\n          //  System.out.println(\"c = \" + getNumberChar(c));\n            frequencyChar[getNumberChar(c)]++;\n        }\n    }\n    return frequencyChar;\n}\npublic static boolean checkIfMaxOneOdd(int[] arr){\n    boolean isMaxOddOneOnly = false;\n    for (int index: arr) {\n        if(index % 2 == 1){\n            if(isMaxOddOneOnly){\n                return false;\n            } // that's mean i found more than one's odd in array ...\n            isMaxOddOneOnly =true;\n        }\n    }\n    return true;\n}\n\n\npublic static boolean palindromePermutation(String str){\n    int[] arr  = frequencyForEachCharInString(str);\n    return checkIfMaxOneOdd(arr);\n\n}\n"], [], ["df_stack=pd.DataFrame([[1.0, 2016.0, 'NonResidential', 'Hotel', 98101.0, 'DOWNTOWN',\n        47.6122, -122.33799, 1927.0, 57.85220900338872,\n        59.91269863912585],\n       [1.0, 2016.0, 'NonResidential', 'Hotel', 98101.0, 'DOWNTOWN',\n        47.61317, -122.33393, 1996.0, 55.82342114189166,\n        56.86951201265458],\n       [3.0, 2016.0, 'NonResidential', 'Hotel', 98101.0, 'DOWNTOWN',\n        47.61393, -122.3381, 1969.0, 76.68191235628086,\n        77.37931271575705],\n       [5.0, 2016.0, 'NonResidential', 'Hotel', 98101.0, 'DOWNTOWN',\n        47.61412, -122.33664, 1926.0, 68.53505428597694,\n        71.00764283155655],\n       [8.0, 2016.0, 'NonResidential', 'Hotel', 98121.0, 'DOWNTOWN',\n        47.61375, -122.34047, 1980.0, 67.01346098859122,\n        68.34485815906346]], columns=['OSEBuildingID', 'DataYear', 'BuildingType', \n                                      'PrimaryPropertyType', \n 'ZipCode', 'Neighborhood', 'Latitude', 'Longitude', 'YearBuilt', \n 'SourceEUI(KWm2)', 'SourceEUIWN(KWm2)' ])\ndf_stack[['OSEBuildingID', 'DataYear', 'BuildingType', 'PrimaryPropertyType', \n          'ZipCode', 'Neighborhood', 'Latitude', 'Longitude', 'YearBuilt', \n          'SourceEUI(KWm2)', 'SourceEUIWN(KWm2)']].groupby('OSEBuildingID').max()\n"], ["i_str =  '12345555555678'\nb = sorted(i_str)\nfor i in range(len(b)-1):\n    if b[i] == b[i+1]:\n        i_str = i_str.replace(b[i],'')\n"], ["inp = '1345552225555678'\n\ncounts = {};\n\nfor ch in inp:\n    if ch in counts:\n        counts[ch] = counts[ch] + 1\n    else:\n        counts[ch] = 1\n\nresult = '';\n\nfor ch in inp:\n    if counts[ch] == 1:\n        result = result + ch\n\nprint result\n"], ["input_str = 'ahuadvzudnioqdazvyduazdazdui'\nfor c in input_str:\n    if input_str.count(c)==1:\n        print(c)\n", "input_str = '12345555555678'\n[x for x in input_str if input_str.count(x) == 1]\n", "input_str = '12345555555678'\n[x for x in set(input_str) if input_str.count(x) == 1]\n"], ["from collections import Counter\n\ninp = '12345555555678'\nc = Counter(inp)\noutput = ''.join(k for k, v in c.items() if v == 1)  # -> 1234678\n", "c = {}\nfor char in inp:\n    c[char] = c.get(char, 0) + 1\n"], ["df.drop(index=list1,labels=None, axis=0, inplace=True,columns=None, level=None, errors='raise')\n"], [], ["KeyError: \"None of [Int64Index([26], dtype='int64')] are in the [index]\"\n", "df.to_csv('Step1.csv',index=False)\ndf = pd.read_csv('Step1.csv')\n"], [], ["def rotate_matrix(a):\n    b = []\n    i = len(a)-1\n    while i>=0:\n        for j in range(0, len(a)):\n            if (len(b) < (j+1)):\n                b.append([a[i][j]])\n            else:\n                b[j].append(a[i][j])\n        i -= 1\n    return b\n"], ["def chunks(collection_size, n_cores=mp.cpu_count()):\n    \"\"\" Return chunks of tuples \"\"\"\n\n\n    batch_size = round(collection_size/n_cores)\n    rest = collection_size%batch_size \n    cumulative = 0\n    for i in range(n_cores):\n        cumulative += batch_size\n        if i == n_cores-1:\n            yield (batch_size*i,cumulative+rest)\n        else:\n           yield (batch_size*i,cumulative)\n\n\ndef parallel_read(skipses,host=HOST, port=PORT):\n\n\n    print('Starting process on range of {} to {}'.format(skipses[0],skipses[1]))\n    client = MongoClient(host,port)\n    db = client[DB_NAME]\n    collection = db[COLLECTION_NAME]\n\n    cursor = collection.find({},{ '_id': False } )\n    _df = pd.DataFrame(list(cursor[skipses[0]:skipses[1]]))\n    return _df\n\n\n\ndef read_mongo(colc_size,_workers=mp.cpu_count()):\n    temp_df = pd.DataFrame()\n    pool = mp.Pool(processes=_workers)\n    results = [pool.apply_async(parallel_read, args=(chunk,))  for chunk in chunks(colc_size,n_cores=_workers)]\n    output = [p.get() for p in results]\n    temp_df = pd.concat(output)\n    return temp_df\n\n\ntime_0 = time()\ndf = read_mongo(get_collection_size())\nprint(\"Reading database with  {} processes took {}\".format(mp.cpu_count(),time()-time_0))\n\n\n\nStarting process on range of 0 to 53866\nStarting process on range of 323196 to 377062\nStarting process on range of 430928 to 484794\nStarting process on range of 538660 to 592526\nStarting process on range of 377062 to 430928\nStarting process on range of 700258 to 754124\nStarting process on range of 53866 to 107732\nStarting process on range of 484794 to 538660\nStarting process on range of 592526 to 646392\nStarting process on range of 646392 to 700258\nStarting process on range of 215464 to 269330\nStarting process on range of 754124 to 807990\nStarting process on range of 807990 to 915714\nStarting process on range of 107732 to 161598\nStarting process on range of 161598 to 215464\nStarting process on range of 269330 to 323196\n", "def iterator2dataframes(iterator, chunk_size: int):\n  \"\"\"Turn an iterator into multiple small pandas.DataFrame\n\n  This is a balance between memory and efficiency\n  \"\"\"\n  records = []\n  frames = []\n  for i, record in enumerate(iterator):\n    records.append(record)\n    if i % chunk_size == chunk_size - 1:\n      frames.append(pd.DataFrame(records))\n      records = []\n  if records:\n    frames.append(pd.DataFrame(records))\n  return pd.concat(frames)\n\ntime_0 = time()\ncursor = collection.find()\nchunk_size = 1000\ndf = iterator2dataframes(cursor, chunk_size)\nprint(\"Reading database with chunksize = {} took {}\".format(chunk_size,time()-time_0))\n", "time_0 = time()\ncursor = collection.find()\nchunk_size = 10000\ndf = iterator2dataframes(cursor, chunk_size)\nprint(\"Reading database with chunksize = {} took {}\".format(chunk_size,time()-time_0))\n"], ["def batched(cursor, batch_size):\n    batch = []\n    for doc in cursor:\n        batch.append(doc)\n        if batch and not len(batch) % batch_size:\n            yield batch\n            batch = []\n\n    if batch:   # last documents\n        yield batch\n\ndf = pd.DataFrame()\nfor batch in batched(cursor, 10000):\n    df = df.append(batch, ignore_index=True)\n", "%%time\n\ndf = pd.DataFrame(list(db.test.find().limit(300000)))\n", "%%time\n\ndf = pd.DataFrame()\nfor batch in batched(db.test.find().limit(300000), 10000):\n    df = df.append(batch, ignore_index=True)\n", "%%time\n\ndf = pd.DataFrame()\nfor batch in batched(db.test.find().limit(300000), 1000):\n    df = df.append(batch, ignore_index=True)\n", "%%time\n\ndf = pd.DataFrame()\nfor batch in batched(db.test.find().limit(300000), 100000):\n    df = df.append(batch, ignore_index=True)\n"], ["def iterator2dataframes(iterator, chunk_size: int):\n  \"\"\"Turn an iterator into multiple small pandas.DataFrame\n\n  This is a balance between memory and efficiency\n  \"\"\"\n  records = []\n  frames = []\n  for i, record in enumerate(iterator):\n    records.append(record)\n    if i % chunk_size == chunk_size - 1:\n      frames.append(pd.DataFrame(records))\n      records = []\n  if records:\n    frames.append(pd.DataFrame(records))\n  return pd.concat(frames)\n\nclient = MongoClient(host,port)\ncollection = client[db_name][collection_name]\ncursor = collection.find()\n\ndf = iterator2dataframes(cursor, 1000)\n"], ["client = MongoClient(host,port)\ncollection = client[db_name][collection_name]\nmaxrows=905679\n        for i in range(0, maxrows, 100000):\n            df2 = df2.iloc[0:0]\n            if (i+100000<maxrows):\n                cursor = collection.find()[i:i+100000]\n            else:\n                cursor = collection.find()[i:maxrows]\n            df2= pd.DataFrame(list(cursor))\n            df.append(df2, ignore_index=True)\n\n\n\n\n"], [], ["import pymongo\nimport pandas as pd\n\ndb = pymongo.MongoClient()['mydatabase']\ndb.mycollection.drop()\noperations = []\n\nfor i in range(900000):\n    operations.append(pymongo.InsertOne({'a': i}))\n\ndb.mycollection.bulk_write(operations, ordered=False)\ncursor = db.mycollection.find({})\ndf = pd.DataFrame(list(cursor))\nprint(df.count())\n"], ["def show_excitement():\n    str = \"I am super excited for this course!\"\n    return  (str + \" \")* 5\n\nprint show_excitement()\n"], [], [], [], [], ["with open(\"requirements.txt\") as myFile:\n  pkgs = myFile.read()\n  pkgs = pkgs.splitlines()\n\n  for pkg in pkgs:\n      print(pkg.split('==')[0])\n"], [], ["%load_ext tensorboard.notebook\n%tensorboard --logdir {logs_base_dir}\n"], ["def show_excitement(stri,n): \n    if(n==1):\n        return stri\n    else:\n        return show_excitement(stri,n-1)+\" \"+stri\nprint(show_excitement(\"I am super excited for this course!\",5))\n"], ["from google.colab.patches import cv2_imshow\nimport cv2\n\n# Download sample video\n!curl -o sample.mp4 https://www.sample-videos.com/video123/mp4/720/big_buck_bunny_720p_1mb.mp4\n\ncap = cv2.VideoCapture('sample.mp4')\nwhile cap.isOpened():\n    ret, image = cap.read()\n\n    if not ret:\n      break\n\n    cv2_imshow(image) # Note cv2_imshow, not cv2.imshow\n\n    cv2.waitKey(1) & 0xff\n\ncv2.destroyAllWindows()\ncap.release()\n"], [], ["f\"some_var={some_var}\"\n", "f\"{some_var=}\"\n", ">>> print(f\"{foo=}\")\nfoo=42\n>>>\n"], ["user = 'eric_idle'\nmember_since = date(1975, 7, 31)\nf'{user=} {member_since=}'\n\"user='eric_idle' member_since=datetime.date(1975, 7, 31)\"\n", ">>> delta = date.today() - member_since\n>>> f'{user=!s}  {delta.days=:,d}'\n'user=eric_idle  delta.days=16,075'\n", ">>> print(f'{theta=}  {cos(radians(theta))=:.3f}')\ntheta=30  cos(radians(theta))=0.866\n"], ["\"something={executed something}\"\n"], ["from google.colab.patches import cv2_imshow\ncv2_imshow(img)\n"], ["from IPython.display import clear_output, Image\nimport base64\n\ndef arrayShow (imageArray):\n    ret, png = cv2.imencode('.png', imageArray)\n    encoded = base64.b64encode(png)\n    return Image(data=encoded.decode('ascii'))\n\nvideo_capture = cv2.VideoCapture(VIDEO_SOURCE)\nwhile video_capture.isOpened():\n    success, frame = video_capture.read()\n\n    clear_output(wait=True)\n    img = arrayShow(frame)\n    display(img)\n\n    if cv2.waitKey(1) & 0xFF == ord('q'):\n        break\n"], ["scaled_inputs_all.iloc[shuffled_indices].values \n"], ["with np.load(path) as f:\n", "from keras.datasets import imdb\n(train_text, train_labels), (test_text, test_labels) = imdb.load_data(num_words=10000)\n"], [], ["arr1 = plt.arrow(0,0, 3,1, head_width=0.2, color='r', length_includes_head=True)\narr2 = plt.arrow(0,0, 1,3, head_width=0.2, color='g', length_includes_head=True)\narr3 = plt.arrow(0,0, 4,4, head_width=0.2, color='b', length_includes_head=True)\n\nplt.xlim(0,5)\nplt.ylim(0,5)\n\nplt.legend([arr1, arr2, arr3], ['u','v','u+v'])\n"], ["brew unlink openssl\n", "brew reinstall python@2\n"], ["pip install --user Werkzeug==0.16\n"], ["def any_palindrome(myString):\n    alpha_chars_only = [x for x in myString.lower() if x.isalpha()]\n    counts = Counter(alpha_chars_only)\n    number_of_odd = sum(1 for letter, cnt in counts.items() if cnt%2)\n    return number_of_odd <= 1\n", "number_of_odd = sum(cnt%2 for cnt in counts.values())\n", "return sum(cnt%2 for cnt in counts.values()) <= 1\n", "counts = Counter(x for x in myString.lower() if x.isalpha())\n", "return sum(cnt%2 for cnt in \n                 Counter(x for x in myString.lower()\n                          if x.isalpha()).values()) <= 1\n"], ["def show_excitement():\n\n    return (\"I am super excited for this course!\" + \" \")*5\n\nprint(show_excitement())\n"], ["from collections import Counter\n\ndef permutationPalindrome(string):\n    counterObject = Counter(char for char in string.lower() if char.isalpha())\n    no_of_odd = 0\n    for value in counterObject.values():\n        if value % 2 != 0:\n            no_of_odd += 1\n        if(no_of_odd > 1):\n            return False\n    return True\n"], [], [], [], ["from dir1.task11.task11 import *\nfrom dir1.task12.task12 import *\nfrom dir2.task21.task21 import *\nfrom dir2.task22.task22 import *\nfrom Helpers.FileHelper.ReadHelper import *\n\nclass Master:\n#Do your task work here\n    pass\n"], ["   # cli argument #1 is the task module to execute\n   import sys  \n   task_to_execute = sys.argv[1]\n\n   from Helpers.FileHelper.ReadHelper import *\n   exec(open(task_to_execute).read())\n", "   $> python -m root.dir1.task11.task11\n"], ["import sys\nsys.path.append('/full/path/to/Helpers/FilesHelper/')\n\nfrom ReadHelper import *\n"], [], ["import numpy as np\nimport xarray\nimport matplotlib.pyplot as plt\nfrom scipy.interpolate import griddata\n\nlats = np.array([[21.138, 21.14499, 21.15197, 21.15894, 21.16591],\n                 [21.16287, 21.16986, 21.17684, 21.18382, 21.19079],\n                 [21.18775, 21.19474, 21.20172, 21.2087, 21.21568],\n                 [21.21262, 21.21962, 21.22661, 21.23359, 21.24056],\n                 [21.2375, 21.2445, 21.25149, 21.25848, 21.26545]])\n\nlons = np.array([[-122.72, -122.69333, -122.66666, -122.63999, -122.61331],\n                 [-122.7275, -122.70082, -122.67415, -122.64746, -122.62078],\n                 [-122.735, -122.70832, -122.68163, -122.65494, -122.62825],\n                 [-122.7425, -122.71582, -122.68912, -122.66243, -122.63573],\n                 [-122.75001, -122.72332, -122.69662, -122.66992, -122.64321]])\n\nspeed = np.array([[10.934007, 10.941321, 10.991583, 11.063932, 11.159435],\n                  [10.98778, 10.975482, 10.990983, 11.042522, 11.131154],\n                  [11.013505, 11.001573, 10.997754, 11.03566, 11.123781],\n                  [11.011163, 11.000227, 11.010223, 11.049, 11.1449],\n                  [11.015698, 11.026604, 11.030653, 11.076904, 11.201464]])\n\nds = xarray.Dataset({'SPEED': (('i', 'j'), speed)},\n                    coords={'latitude': (('i', 'j'), lats),\n                            'longitude': (('i', 'j'), lons)},\n                    attrs={'variable': 'Wind Speed'})\n\nlat_min = float(np.min(ds.latitude))\nlat_max = float(np.max(ds.latitude))\nlon_min = float(np.min(ds.longitude))\nlon_max = float(np.max(ds.longitude))\nmargin = 0.02\n\nfig, ((ax1, ax2)) = plt.subplots(nrows=1, ncols=2, figsize=(12, 5))\n\nax1.set_xlim(lat_min - margin, lat_max + margin)\nax1.set_ylim(lon_min - margin, lon_max + margin)\nax1.axis('equal')\nds.SPEED.plot(ax=ax1, x='latitude', y='longitude', cmap=plt.cm.jet)\nax1.scatter(ds.latitude, ds.longitude, color='black')\n\n# find nearest_point for a requested lat/ lon\nlat_requested = 21.22\nlon_requested = -122.68\n\nd_lat = ds.latitude - lat_requested\nd_lon = ds.longitude - lon_requested\nr2_requested = d_lat**2 + d_lon**2\ni_j_loc = np.where(r2_requested == np.min(r2_requested))\n\nnearest_point = ds.sel(i=i_j_loc[0], j=i_j_loc[1])\n\n# Plot nearest point in the array red# Plot nearest point in the array red\nax1.scatter(lat_requested, lon_requested, color='green')\nax1.text(lat_requested, lon_requested, 'requested')\nax1.scatter(nearest_point.latitude, nearest_point.longitude, color='red')\nax1.text(nearest_point.latitude, nearest_point.longitude, 'nearest')\nax1.set_title(f'speed at nearest point: {float(nearest_point.SPEED.data):.2f}')\n\n# define grid from the dataset\nnum_points = 100\nlats_i = np.linspace(lat_min, lat_max, num_points)\nlons_i = np.linspace(lon_min, lon_max, num_points)\n\n# grid and contour the data.\nspeed_i = griddata((ds.latitude.values.flatten(), ds.longitude.values.flatten()),\n                   ds.SPEED.values.flatten(),\n                   (lats_i[None, :], lons_i[:, None]), method='cubic')\n\nax2.set_xlim(lat_min - margin, lat_max + margin)\nax2.set_ylim(lon_min - margin, lon_max + margin)\nax2.axis('equal')\nax2.set_title(f'griddata test {num_points} points')\n\nax2.contour(lats_i, lons_i, speed_i, 15, linewidths=0.5, colors='k')\ncontour = ax2.contourf(lats_i, lons_i, speed_i, 15, cmap=plt.cm.jet)\nplt.colorbar(contour, ax=ax2)\n\n# plot data points and labels\nax2.scatter(ds.latitude, ds.longitude, marker='o', c='b', s=5)\n\nfor i, (lat, lon) in enumerate(zip(ds.latitude.values.flatten(),\n                                   ds.longitude.values.flatten())):\n    text_label = f'{ds.SPEED.values.flatten()[i]:0.2f}'\n    ax2.text(lat, lon, text_label)\n\n# Plot nearest point in the array red\nax2.scatter(lat_requested, lon_requested, color='green')\nax2.text(lat_requested, lon_requested, 'requested')\nax2.scatter(nearest_point.latitude, nearest_point.longitude, color='red')\n\nplt.subplots_adjust(wspace=0.2)\nplt.show()\n"], ["import numpy as np\nimport pandas as pd\nimport xarray\nimport matplotlib.pyplot as plt\nfrom scipy.interpolate import griddata\n\nlats = np.array([21.138, 21.14499, 21.15197, 21.15894, 21.16591,\n                 21.16287, 21.16986, 21.17684, 21.18382, 21.19079,\n                 21.18775, 21.19474, 21.20172, 21.2087, 21.21568,\n                 21.21262, 21.21962, 21.22661, 21.23359, 21.24056,\n                 21.2375, 21.2445, 21.25149, 21.25848, 21.26545])\n\nlons = np.array([-122.72, -122.69333, -122.66666, -122.63999, -122.61331,\n                 -122.7275, -122.70082, -122.67415, -122.64746, -122.62078,\n                 -122.735, -122.70832, -122.68163, -122.65494, -122.62825,\n                 -122.7425, -122.71582, -122.68912, -122.66243, -122.63573,\n                 -122.75001, -122.72332, -122.69662, -122.66992, -122.64321])\n\nspeed = np.array([10.934007, 10.941321, 10.991583, 11.063932, 11.159435,\n                  10.98778, 10.975482, 10.990983, 11.042522, 11.131154,\n                  11.013505, 11.001573, 10.997754, 11.03566, 11.123781,\n                  11.011163, 11.000227, 11.010223, 11.049, 11.1449,\n                  11.015698, 11.026604, 11.030653, 11.076904, 11.201464])\n\nfig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(12, 5))\n\nidx = pd.MultiIndex.from_arrays(arrays=[lons, lats], names=[\"lon\", \"lat\"])\ns = pd.Series(data=speed, index=idx)\nda = xarray.DataArray.from_series(s)\nprint(da)\nda.plot(ax=ax1)\n\nprint('-'*80)\nprint(da.sel(lat=21.2, lon=-122.68, method='nearest'))\n\n# define grid.\nnum_points = 100\nlats_i = np.linspace(np.min(lats), np.max(lats), num_points)\nlons_i = np.linspace(np.min(lons), np.max(lons), num_points)\n\n# grid the data.\nspeed_i = griddata((lats, lons), speed,\n                   (lats_i[None, :], lons_i[:, None]), method='cubic')\n\n# contour the gridded data\nax2.contour(lats_i, lons_i, speed_i, 15, linewidths=0.5, colors='k')\ncontour = ax2.contourf(lats_i, lons_i, speed_i, 15, cmap=plt.cm.jet)\nplt.colorbar(contour, ax=ax2)\n\n# plot data points.\nfor i, (lat, lon) in enumerate(zip(lats, lons)):\n    label = f'{speed[i]:0.2f}'\n    ax2.annotate(label, (lat, lon))\n\nax2.scatter(lats, lons, marker='o', c='b', s=5)\n\nax2.set_title(f'griddata test {num_points} points')\n\nplt.subplots_adjust(wspace=0.2)\nplt.show()\n\n", "<xarray.DataArray (lat: 25, lon: 25)>\narray([[      nan,       nan,       nan,       nan,       nan, 10.934007,\n              nan,       nan,       nan,       nan,       nan,       nan,\n              nan,       nan,       nan,       nan,       nan,       nan,\n              nan,       nan,       nan,       nan,       nan,       nan,\n              nan],\n       [      nan,       nan,       nan,       nan,       nan,       nan,\n              nan,       nan,       nan,       nan, 10.941321,       nan,\n              nan,       nan,       nan,       nan,       nan,       nan,\n              nan,       nan,       nan,       nan,       nan,       nan,\n              nan],\n       [      nan,       nan,       nan,       nan,       nan,       nan,\n              nan,       nan,       nan,       nan,       nan,       nan,\n              nan,       nan,       nan, 10.991583,       nan,       nan,\n              nan,       nan,       nan,       nan,       nan,       nan,\n              nan],\n       [      nan,       nan,       nan,       nan,       nan,       nan,\n              nan,       nan,       nan,       nan,       nan,       nan,\n              nan,       nan,       nan,       nan,       nan,       nan,\n              nan,       nan, 11.063932,       nan,       nan,       nan,\n              nan],\n       [      nan,       nan,       nan, 10.98778 ,       nan,       nan,\n              nan,       nan,       nan,       nan,       nan,       nan,\n              nan,       nan,       nan,       nan,       nan,       nan,\n              nan,       nan,       nan,       nan,       nan,       nan,\n              nan],\n       [      nan,       nan,       nan,       nan,       nan,       nan,\n              nan,       nan,       nan,       nan,       nan,       nan,\n              nan,       nan,       nan,       nan,       nan,       nan,\n              nan,       nan,       nan,       nan,       nan,       nan,\n        11.159435],\n       [      nan,       nan,       nan,       nan,       nan,       nan,\n              nan,       nan, 10.975482,       nan,       nan,       nan,\n              nan,       nan,       nan,       nan,       nan,       nan,\n              nan,       nan,       nan,       nan,       nan,       nan,\n              nan],\n       [      nan,       nan,       nan,       nan,       nan,       nan,\n              nan,       nan,       nan,       nan,       nan,       nan,\n              nan, 10.990983,       nan,       nan,       nan,       nan,\n              nan,       nan,       nan,       nan,       nan,       nan,\n              nan],\n       [      nan,       nan,       nan,       nan,       nan,       nan,\n              nan,       nan,       nan,       nan,       nan,       nan,\n              nan,       nan,       nan,       nan,       nan,       nan,\n        11.042522,       nan,       nan,       nan,       nan,       nan,\n              nan],\n       [      nan,       nan, 11.013505,       nan,       nan,       nan,\n              nan,       nan,       nan,       nan,       nan,       nan,\n              nan,       nan,       nan,       nan,       nan,       nan,\n              nan,       nan,       nan,       nan,       nan,       nan,\n              nan],\n       [      nan,       nan,       nan,       nan,       nan,       nan,\n              nan,       nan,       nan,       nan,       nan,       nan,\n              nan,       nan,       nan,       nan,       nan,       nan,\n              nan,       nan,       nan,       nan,       nan, 11.131154,\n              nan],\n       [      nan,       nan,       nan,       nan,       nan,       nan,\n              nan, 11.001573,       nan,       nan,       nan,       nan,\n              nan,       nan,       nan,       nan,       nan,       nan,\n              nan,       nan,       nan,       nan,       nan,       nan,\n              nan],\n       [      nan,       nan,       nan,       nan,       nan,       nan,\n              nan,       nan,       nan,       nan,       nan,       nan,\n        10.997754,       nan,       nan,       nan,       nan,       nan,\n              nan,       nan,       nan,       nan,       nan,       nan,\n              nan],\n       [      nan,       nan,       nan,       nan,       nan,       nan,\n              nan,       nan,       nan,       nan,       nan,       nan,\n              nan,       nan,       nan,       nan,       nan, 11.03566 ,\n              nan,       nan,       nan,       nan,       nan,       nan,\n              nan],\n       [      nan, 11.011163,       nan,       nan,       nan,       nan,\n              nan,       nan,       nan,       nan,       nan,       nan,\n              nan,       nan,       nan,       nan,       nan,       nan,\n              nan,       nan,       nan,       nan,       nan,       nan,\n              nan],\n       [      nan,       nan,       nan,       nan,       nan,       nan,\n              nan,       nan,       nan,       nan,       nan,       nan,\n              nan,       nan,       nan,       nan,       nan,       nan,\n              nan,       nan,       nan,       nan, 11.123781,       nan,\n              nan],\n       [      nan,       nan,       nan,       nan,       nan,       nan,\n        11.000227,       nan,       nan,       nan,       nan,       nan,\n              nan,       nan,       nan,       nan,       nan,       nan,\n              nan,       nan,       nan,       nan,       nan,       nan,\n              nan],\n       [      nan,       nan,       nan,       nan,       nan,       nan,\n              nan,       nan,       nan,       nan,       nan, 11.010223,\n              nan,       nan,       nan,       nan,       nan,       nan,\n              nan,       nan,       nan,       nan,       nan,       nan,\n              nan],\n       [      nan,       nan,       nan,       nan,       nan,       nan,\n              nan,       nan,       nan,       nan,       nan,       nan,\n              nan,       nan,       nan,       nan, 11.049   ,       nan,\n              nan,       nan,       nan,       nan,       nan,       nan,\n              nan],\n       [11.015698,       nan,       nan,       nan,       nan,       nan,\n              nan,       nan,       nan,       nan,       nan,       nan,\n              nan,       nan,       nan,       nan,       nan,       nan,\n              nan,       nan,       nan,       nan,       nan,       nan,\n              nan],\n       [      nan,       nan,       nan,       nan,       nan,       nan,\n              nan,       nan,       nan,       nan,       nan,       nan,\n              nan,       nan,       nan,       nan,       nan,       nan,\n              nan,       nan,       nan, 11.1449  ,       nan,       nan,\n              nan],\n       [      nan,       nan,       nan,       nan, 11.026604,       nan,\n              nan,       nan,       nan,       nan,       nan,       nan,\n              nan,       nan,       nan,       nan,       nan,       nan,\n              nan,       nan,       nan,       nan,       nan,       nan,\n              nan],\n       [      nan,       nan,       nan,       nan,       nan,       nan,\n              nan,       nan,       nan, 11.030653,       nan,       nan,\n              nan,       nan,       nan,       nan,       nan,       nan,\n              nan,       nan,       nan,       nan,       nan,       nan,\n              nan],\n       [      nan,       nan,       nan,       nan,       nan,       nan,\n              nan,       nan,       nan,       nan,       nan,       nan,\n              nan,       nan, 11.076904,       nan,       nan,       nan,\n              nan,       nan,       nan,       nan,       nan,       nan,\n              nan],\n       [      nan,       nan,       nan,       nan,       nan,       nan,\n              nan,       nan,       nan,       nan,       nan,       nan,\n              nan,       nan,       nan,       nan,       nan,       nan,\n              nan, 11.201464,       nan,       nan,       nan,       nan,\n              nan]])\nCoordinates:\n  * lat      (lat) float64 21.14 21.14 21.15 21.16 ... 21.24 21.25 21.26 21.27\n  * lon      (lon) float64 -122.8 -122.7 -122.7 -122.7 ... -122.6 -122.6 -122.6\n--------------------------------------------------------------------------------\n<xarray.DataArray ()>\narray(10.997754)\nCoordinates:\n    lat      float64 21.2\n    lon      float64 -122.7\n"], [], ["import numpy as np\nfrom functools import partial\n\n# save np.load\nnp_load_old = partial(np.load)\n\n# modify the default parameters of np.load\nnp.load = lambda *a,**k: np_load_old(*a, allow_pickle=True, **k)\n\n# call load_data with allow_pickle implicitly set to true\n(train_data, train_labels), (test_data, test_labels) = \nimdb.load_data(num_words=10000)\n\n# restore np.load for future normal usage\nnp.load = np_load_old\n"], ["pd.DataFrame(li)\n"], [], [], ["%load_ext tensorboard\n"], ["import sys\nsys.path\n", "sys.executable\n"], ["from dataclasses import fields\n\nmarker_a = Marker(5)\nmarker_b = Marker(0, 99)\n\nfor field in fields(Marker):\n    setattr(marker_b, field.name, getattr(marker_a, field.name))\n\nprint(marker_b)  # Marker(a=5, b=1.0)\n"], ["counter = 10\ndef GetInput():\n    names = []\n    percentage = []\n    for i in range(counter):\n        names.append(input(\"Please enter the student's name: \"))\n        valid = False\n        while not(valid):      \n            try:\n                percent = int(input(\"Please enter the student's score between 0 and 100%: \"))\n                if percent >= 0 and percent <= 100:\n                    percentage.append(percent)\n                    valid = True\n                    break\n                else:\n                    continue\n            except ValueError:\n                print(\"\\nEnter valid marks!!!\")\n                continue\n            valid = True\n\n    return names, percentage\n\nstudents, marks = GetInput()\n\n", "\ndef GetInput():\n    records = dict()\n    for i in range(counter):\n        name = input(\"Please enter the student's name: \")\n        valid = False\n        while not(valid):      \n            try:\n                percent = int(input(\"Please enter the student's score between 0 and 100%: \"))\n                if percent >= 0 and percent <= 100:\n                    #percentage.append(percent)\n                    valid = True\n                    break\n                else:\n                    continue\n            except ValueError:\n                print(\"\\nEnter valid marks!!!\")\n                continue\n            valid = True\n        records[name] = percent\n    return records\n\nrecord = GetInput()\n"], [], ["def GetInput():\n    names = {}  # Needs to declare your dict\n    percentages = {}  # Needs to declare your dict\n    for counter in range(0, 3):\n        names[counter] = input(\"Please enter the student's name: \")\n\n        valid = False\n        while valid == False:\n            percentages[counter] = int(input(\"Please enter the student's score %: \"))\n            if percentages[counter] < 0 or percentages[counter] > 100:\n                print(\"Please enter a valid % [0-100]\")\n            else:\n                valid = True\n    return names, percentages  # Return outside of for loop.\n\nname, mark = GetInput()\nprint(name)\nprint(mark)\n", ">>> python3 test.py \nPlease enter the student's name: bob\nPlease enter the student's score %: 20\nPlease enter the student's name: ann\nPlease enter the student's score %: 30\nPlease enter the student's name: joe\nPlease enter the student's score %: 40\n{0: 'bob', 1: 'ann', 2: 'joe'}\n{0: 20, 1: 30, 2: 40}\n", "def GetInput():\n    students = {}\n    for _ in range(0, 3):\n        student_name = input(\"Please enter the student's name: \")\n        valid = False\n        while not valid:\n            student_percentages = int(input(\"Please enter the student's score %: \"))\n            if student_percentages < 0 or student_percentages > 100:\n                print(\"Please enter a valid % [0-100]\")\n                continue\n            valid = True\n            students[student_name] = student_percentages\n    return students\n\n\nstudents = GetInput()\nprint(students)\n", ">>> python3 test.py \nPlease enter the student's name: ann\nPlease enter the student's score %: 20\nPlease enter the student's name: bob\nPlease enter the student's score %: 30\nPlease enter the student's name: joe\nPlease enter the student's score %: 40\n{'ann': 20, 'bob': 30, 'joe': 40}\n"], ["#function to ask user to input name and score\ndef GetInput():\n    names=[]\n    percentages=[]\n    for counter in range(0,3):\n        names.append(input(\"Please enter the student's name: \"))\n\n        valid = False\n        while valid == False:\n            percentages.append(int(input(\"Please enter the student's score %: \")))\n            if percentages[counter] < 0 or percentages[counter] > 100:\n                print(\"Please enter a valid % [0-100]\")\n            else:\n                valid = True\n    return names, percentages\n\nname, mark = GetInput()\nprint(name,mark)\n"], ["def GetInput():\n    names={}\n    percentages={}\n    for counter in range(0,10):\n        names[counter] = input(\"Please enter the student's name: \")\n\n        valid = False\n        while valid == False:\n            percentages[counter] = int(input(\"Please enter the student's score %: \"))\n            if percentages[counter] < 0 or percentages[counter] > 100:\n                print(\"Please enter a valid % [0-100]\")\n            else:\n                valid = True\n    return names, percentages\n\nname, mark = GetInput()\n"], [], [], [], ["FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n", "np.load = lambda *a,**k: np_load_old(*a, allow_pickle=True, **k)\n"], [], ["cols = pd.read_csv('Path\\\\to\\\\file\\\\atp_matches_2016.csv', nrows=1).columns\ndf = pd.read_csv('Path\\\\to\\\\file\\\\atp_matches_2016.csv', usecols=cols)\n", "df.head()\n\n  tourney_id tourney_name surface  draw_size tourney_level    ...     l_1stWon  l_2ndWon  l_SvGms  l_bpSaved l_bpFaced\n0  2016-M020     Brisbane    Hard       32.0             A    ...         25.0      14.0     10.0        3.0       5.0\n1  2016-M020     Brisbane    Hard       32.0             A    ...         18.0       9.0      8.0        2.0       6.0\n2  2016-M020     Brisbane    Hard       32.0             A    ...         41.0      16.0     12.0        2.0       2.0\n3  2016-M020     Brisbane    Hard       32.0             A    ...         46.0      21.0     16.0        8.0      11.0\n4  2016-M020     Brisbane    Hard       32.0             A    ...         41.0      27.0     15.0        7.0       8.0\n\n[5 rows x 49 columns]\n"], ["rows = pd.read_csv('path/to/atp_matches_2016.csv', skiprows=[0], header = None)\n# skip header line\nrows = rows.dropna(axis=1, how='all')\n# drop columns that only have NaNs\n\nrows.columns = pd.read_csv('path/to/atp_matches_2016.csv', nrows=0).columns\nprint(rows.head(5))\n", "  tourney_id tourney_name surface  draw_size tourney_level  tourney_date  \\\n0  2016-M020     Brisbane    Hard       32.0             A    20160104.0   \n1  2016-M020     Brisbane    Hard       32.0             A    20160104.0   \n2  2016-M020     Brisbane    Hard       32.0             A    20160104.0   \n3  2016-M020     Brisbane    Hard       32.0             A    20160104.0   \n4  2016-M020     Brisbane    Hard       32.0             A    20160104.0 \n\n\n\n   match_num  winner_id  winner_seed winner_entry  ... w_bpFaced l_ace  l_df  \\\n0      300.0   105683.0          4.0          NaN  ...       1.0   7.0   3.0   \n1      299.0   103819.0          1.0          NaN  ...       1.0   2.0   4.0   \n2      298.0   105683.0          4.0          NaN  ...       4.0  10.0   3.0   \n3      297.0   103819.0          1.0          NaN  ...       1.0   8.0   2.0   \n4      296.0   106233.0          8.0          NaN  ...       2.0  11.0   2.0   \n\n  l_svpt  l_1stIn  l_1stWon  l_2ndWon  l_SvGms  l_bpSaved l_bpFaced  \n0   61.0     34.0      25.0      14.0     10.0        3.0       5.0  \n1   55.0     31.0      18.0       9.0      8.0        2.0       6.0  \n2   84.0     54.0      41.0      16.0     12.0        2.0       2.0  \n3  104.0     62.0      46.0      21.0     16.0        8.0      11.0  \n4   98.0     52.0      41.0      27.0     15.0        7.0       8.0  \n"], ["df_2016 = pd.read_csv(\"Path/to/file/atp_matches_2016.csv\", keep_default_na=False)\n"], ["import csv\nwith open('Path/to/file/atp_matches_2016.csv') as csvfile:\n     reader = csv.DictReader(csvfile)\n\n"], ["for i in list1\n", "for elem in list1:\n    if elem in ['3']: ...\n", "if elem in list1:\n    list1.remove(elem)\n"], ["list1=[\"1\",\"2\",\"4\",\"5\",\"3\"]\n\nfor i in range(len(list1)):\n    if list1[i]== \"3\":\n        list1.pop(i)\n        break\nprint(list1)\n"], [], ["        np_load_old = np.load\n        np.load = lambda *a: np_load_old(*a, allow_pickle=True)\n        (x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=None, test_split=0.2)\n        np.load = np_load_old\n"], ["!mkdir ~/.kaggle\n!touch ~/.kaggle/kaggle.json\n\napi_token = {\"username\":\"username\",\"key\":\"api-key\"}\n\nimport json\n\nwith open('/root/.kaggle/kaggle.json', 'w') as file:\n    json.dump(api_token, file)\n\n!chmod 600 ~/.kaggle/kaggle.json\n", "!kaggle datasets download -d datamunge/sign-language-mnist\n"], ["np_load_old = np.load\n\n# modify the default parameters of np.load\nnp.load = lambda *a,**k: np_load_old(*a, allow_pickle=True, **k)\n"], [], ["import torch\n\ntensor1 = torch.tensor([1.0,2.0],requires_grad=True)\n\nprint(tensor1)\nprint(type(tensor1))\n\ntensor1 = tensor1.numpy()\n\nprint(tensor1)\nprint(type(tensor1))\n", "tensor([1., 2.], requires_grad=True)\n<class 'torch.Tensor'>\nTraceback (most recent call last):\n  File \"/home/badScript.py\", line 8, in <module>\n    tensor1 = tensor1.numpy()\nRuntimeError: Can't call numpy() on Variable that requires grad. Use var.detach().numpy() instead.\n\nProcess finished with exit code 1\n", "import torch\n\ntensor1 = torch.tensor([1.0,2.0],requires_grad=True)\n\nprint(tensor1)\nprint(type(tensor1))\n\ntensor1 = tensor1.detach().numpy()\n\nprint(tensor1)\nprint(type(tensor1))\n", "tensor([1., 2.], requires_grad=True)\n<class 'torch.Tensor'>\n[1. 2.]\n<class 'numpy.ndarray'>\n\nProcess finished with exit code 0\n"], ["     dt_col_param = []\n\n     for col in output_df.columns:\n            dt_col_param.append({\"name\": str(col), \"id\": str(col)})\n\n    dash_table.DataTable(\n            columns=dt_col_param,\n            data=output_df.to_dict('records')\n        )\n"], [], ["def is_palindrome(s):\n    odd_counter = 0\n    for letter in s:\n        if s.count(letter) % 2 != 0:\n            odd_counter += 1\n\n    if odd_counter > 1:\n        return False\n    return True\n"], ["!mv .kaggle /root/\n"], ["def topological_sort_grouped(G):\n    indegree_map = {v: d for v, d in G.in_degree() if d > 0}\n    zero_indegree = [v for v, d in G.in_degree() if d == 0]\n    while zero_indegree:\n        yield zero_indegree\n        new_zero_indegree = []\n        for v in zero_indegree:\n            for _, child in G.edges(v):\n                indegree_map[child] -= 1\n                if not indegree_map[child]:\n                    new_zero_indegree.append(child)\n        zero_indegree = new_zero_indegree\n", "In [21]: list(nx.topological_sort(G))\nOut[21]: [3, 1, 2, 4, 6, 7, 5]\n\nIn [22]: list(topological_sort_grouped(G))\nOut[22]: [[1, 3], [2], [4], [5, 6], [7]]\n"], ["# adapted from https://gist.github.com/kachayev/5910538\nfrom collections import deque\nGRAY, BLACK = 0, 1\n\n\ndef topological(graph):\n    order, enter, state = deque(), set(graph), {}\n\n    dot = \"digraph X {\\r\\n\"\n    for item in graph.keys():\n        dep = graph[item]\n        for d in dep:\n            dot += item + \" -> \" + str(d) + '\\r\\n'\n    dot += \"}\"\n    print(dot)\n\n    def dfs(node):\n        state[node] = GRAY\n        for k in graph.get(node, ()):\n            sk = state.get(k, None)\n            if sk == GRAY:\n                raise ValueError(\"cycle\")\n            if sk == BLACK:\n                continue\n            enter.discard(k)\n            dfs(k)\n        #order.appendleft(node)  # show highest to lowest\n        order.append(node)  # show lowest to highest\n        state[node] = BLACK\n    while enter:\n        dfs(enter.pop())\n    return order\n\n\ndef main():\n    graph = {\n        '1': ['2'],\n        '2': ['4'],\n        '3': ['4'],\n        '4': ['5', '6'],\n        '6': ['7'],\n    }\n    try:\n        print(topological(graph))\n    except ValueError:\n        print(\"Cycle!\")\n\n\nif __name__ == \"__main__\":\n    main()\n", "deque(['5', '7', '6', '4', '2', '1', '3'])\n"], ["def process_cursor(G, passed, node_id):\n    if set(G.predecessors(node_id)).issubset(passed):\n        return True, list(G.successors(node_id))\n    return False, None\n\n\ndef get_all_roots(G: nx.DiGraph):\n    for node_id in G.nodes:\n        if not any(G.predecessors(node_id)):\n            yield node_id\n\n\ndef order_components(G: nx.DiGraph):\n    nodes_amount = len(G.nodes)\n    cursors = set(get_all_roots(G))\n    passed = []\n    iterations = 0\n    while len(passed) != nodes_amount:\n        iterations += 1\n        if iterations > nodes_amount:\n            raise ValueError(\"Could not create sequence of graph.\")\n        step = []\n        next_cursors = []\n        step_passed = []\n        for node_id in cursors:\n            can_process, tmp_cursors = process_cursor(G, passed, node_id)\n            if can_process:\n                next_cursors.extend(tmp_cursors)\n                step_passed.append(node_id)\n                node_data = G.nodes[node_id]\n                step.append(node_id)\n        cursors = set(next_cursors)\n        passed.extend(step_passed)\n        if step:\n            yield step\n    yield append\n"], ["    def load_data(.......):\n    .......................................\n    .......................................\n    - with np.load(path) as f:\n    + with np.load(path,allow_pickle=True) as f:\n"], [], ["np.load(training_image_names_array,allow_pickle=True)\n"], [], ["old = np.load\nnp.load = lambda *a,**k: old(*a,**k,allow_pickle=True)\n\nfrom keras.datasets import reuters\n(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=10000)\n\nnp.load = old\ndel(old)\n"], ["async def do_stuff():\n    ioBoundTask = do_iobound_work_async() # created a coroutine\n    ioBoundResult = await ioBoundTask     # start the coroutine\n    cpuBoundResult = do_cpu_intensive_calc()\n    print(f\"The result is {cpuBoundResult + ioBoundResult}\")\n", "def do_stuff():\n    # create a generator based coroutine\n    # cannot mix syntax of asyncio\n    ioBoundTask = do_iobound_work_async()\n    ioBoundResult = yield from ioBoundTask\n    # whatever\n", "async def do_cpu_intensive_calc():\n    print(\"Do smart calc...\")\n    await asyncio.sleep(2)\n    print(\"Calc finished.\")\n    return 2\n\n# 2.5s\nasync def do_stuff():\n    task1 = asyncio.create_task(do_iobound_work_async())\n    task2 = asyncio.create_task(do_cpu_intensive_calc())\n\n    ioBoundResult = await task1\n    cpuBoundResult = await task2\n    print(f\"The result is {cpuBoundResult + ioBoundResult}\")\n"], [], ["if __name__ == \"__main__\":\n    connexion_app.run(host=\"0.0.0.0\", port=constants.API_PORT, debug=True)\n"], ["import functools as ft\n\nimport more_itertools as mit\n\n\niterable = range(6, 10)\n", "def composed_shifts(n):\n    \"\"\"Return a function of `n` circular shifts.\"\"\"\n    def f(x):    \n        return ft.partial(mit.circular_shifts(x).__getitem__, n)()\n    return f\n", "composed_shifts(1)                                         # 1\n# <function __main__.composed_shifts.<locals>.f(x)>\n\ncomposed_shifts(1)(iterable)                               # 2\n# (7, 8, 9, 6)\n\ncomposed_shifts(3)(iterable)\n# (9, 6, 7, 8)\n", "mit.circular_shifts(iterable))\n", "[(6, 7, 8, 9),                                             # 0 shifts\n (7, 8, 9, 6),                                             # 1   \" \n (8, 9, 6, 7),                                             # 2   \" \n (9, 6, 7, 8)]                                             # 3   \"\n"], ["@dataclass\nclass MyClass:\n   def setname(self, value):\n       if not isinstance(value, str):\n           raise TypeError(...)\n       self.__dict__[\"name\"] = value\n   def getname(self):\n       return self.__dict__.get(\"name\")\n   name: str = property(getname, setname)\n   # optionally, you can delete the getter and setter from the class body:\n   del setname, getname\n", "def positive_validator(name, value):\n    if value <= 0:\n        raise ValueError(f\"values for {name!r}  have to be positive\")\n\nclass MyAttr:\n     def __init__(self, type, validators=()):\n          self.type = type\n          self.validators = validators\n\n     def __set_name__(self, owner, name):\n          self.name = name\n\n     def __get__(self, instance, owner):\n          if not instance: return self\n          return instance.__dict__[self.name]\n\n     def __delete__(self, instance):\n          del instance.__dict__[self.name]\n\n     def __set__(self, instance, value):\n          if not isinstance(value, self.type):\n                raise TypeError(f\"{self.name!r} values must be of type {self.type!r}\")\n          for validator in self.validators:\n               validator(self.name, value)\n          instance.__dict__[self.name] = value\n\n#And now\n\n@dataclass\nclass Person:\n    name: str = MyAttr(str)\n    age: float = MyAttr((int, float), [positive_validator,])\n"], ["input_list = [1, 2, 3, 4, 5, 6]\n\n\ndef cyclic_perm(a):\n    n = len(a)\n    result = []\n    for j in range(n):\n        def f(l, k=j):\n            return list(map(lambda i: l[i - k], range(n)))\n        result.append(f)\n    return result\n\n\nfor op in cyclic_perm(input_list):\n    print(op(input_list))\n\n"], ["def cyclic_perm(a):\n    n = len(a)\n    b = [[a[i - j] for i in range(n)] for j in range(n)]\n    return b\n\ndef cyclic_perm_func(a):\n    n = len(a)\n    def wrapper(a, n, j):\n        def cyc():\n            return [a[i - j] for i in range(n)]\n        return cyc\n    b = [wrapper(a, n, j) for j in range(n)]\n    return b\n\na = [1, 2, 3, 4,5,6]\nprint(cyclic_perm(a))  # Your original function\nf = cyclic_perm_func(a) # f is now a list of functions\nprint([g() for g in f])  # Let's call each in turn\n", "[[1, 2, 3, 4, 5, 6], [6, 1, 2, 3, 4, 5], [5, 6, 1, 2, 3, 4], [4, 5, 6, 1, 2, 3], [3, 4, 5, 6, 1, 2], [2, 3, 4, 5, 6, 1]]\n[[1, 2, 3, 4, 5, 6], [6, 1, 2, 3, 4, 5], [5, 6, 1, 2, 3, 4], [4, 5, 6, 1, 2, 3], [3, 4, 5, 6, 1, 2], [2, 3, 4, 5, 6, 1]]\n"], ["def show_excitement(str,n):\n    if(n==0):\n        print('\\n') # last bit of code that runs in the function, no return\n    else:\n        print(str, end=' ')\n        return show_excitement(str, n-1)\n\nstr=\"I am super excited for this course!\"\nshow_excitement(str, 5) # returns None but prints to console\n\n# result - note there will be space on end printed that you can't see\n# I am super excited for this course! I am super excited for this course! I am super excited for this course! I am super excited for this course! I am super excited for this course!\n", "def show_excitement(str, n, str_built=''):\n    if(n==0):\n        return str_built.strip() # clear last ' '\n    else:\n        str_built += str + ' ' # can be changed to '\\n' if needed on new line\n        return show_excitement(str, n-1, str_built)\n\n\nstr=\"I am super excited for this course!\"\nshow_excitement(str, 5) # string object\n# 'I am super excited for this course! I am super excited for this course! I am super excited for this course! I am super excited for this course! I am super excited for this course!'\nprint(show_excitement(str, 5))\n# I am super excited for this course! I am super excited for this course! I am super excited for this course! I am super excited for this course! I am super excited for this course!\n", "def show_excitement(str, n, sep=\" \"):\n    return sep.join([str] * n)\n"], ["def show_excitement(str, n):\n    global return_str\n    return_str += str\n    if n == 0:\n        return return_str\n    else:\n        show_excitement(str, n - 1)\n\n\nreturn_str = \"\"\nstr = \"I am super excited for this course!\"\nshow_excitement(str, 5)\nprint(return_str)\n"], ["def show_excitement(str,n):\n    global result\n    if(n==0):\n        return result.strip()\n    else:\n        result=result+\" \"+str\n        return show_excitement(str,n-1)\n\n\nresult = \"\"\nstr=\"I am super excited for this course!\"\nprint show_excitement(str,5)\n"], ["def show_excitement(str,n):\n        print(str)\n        if(n!=1):\n            show_excitement(str,n-1)\n\nstr=\"I am super excited for this course!\"\nshow_excitement(str,5)\n"], ["def show_excitement(str,n):\n    print str*n\n\nstr=\" I am super excited for this course!\"\n\nshow_excitement(str,5)\n"], ["def show_excitement(str,n):\n    if(n==0):\n        return str\n    else:\n        #return the str N times\n        return str*n\n\n\nstr=\"I am super excited for this course!\"\n\nprint show_excitement(str,5)\n"], ["\" \".join([\"hello\"] * 5)\n"], ["item_no = [5, 6, 7, 8, 8]\n#compute once - use many times\nmax_item = max(item_no)\nprint(item_no.count(max_item) * [max_item])\n", "[8, 8]\n"], ["!pip install tf-nightly\n"], ["def pytest_collection_modifyitems(items):\n    for item in items:\n        for node in reversed(item.listchain()):\n            node.own_markers = [m for m in node.own_markers if m.name not in ('skip', 'skipif')]\n", "@pytest.hookimpl(tryfirst=True)\ndef pytest_runtest_setup(item):\n    mark = item.get_closest_marker(name='myskip')\n    if mark:\n        condition = next(iter(mark.args), True)\n        reason = mark.kwargs.get('reason', 'custom skipping mechanism')\n        item.add_marker(pytest.mark.skipif(not os.getenv('PYTEST_RUN_FORCE_SKIPS', False) and condition, reason=reason), append=False)\n", "@pytest.mark.myskip\ndef test_skip():\n    assert True\n\n\n@pytest.mark.myskip(1 == 1, reason='my skip')\ndef test_skipif():\n    assert True\n", "$ PYTEST_RUN_FORCE_SKIPS=1 pytest -v\n...\ntest_spam.py::test_skip PASSED\ntest_spam.py::test_skipif PASSED\n...\n"], ["import pytest\n\nold_skipif = pytest.mark.skipif\n\ndef custom_skipif(*args, **kwargs):\n    return old_skipif(False, reason='disabling skipif')\n\npytest.mark.skipif = custom_skipif\n"], ["import pytest\nfrom _pytest.mark.evaluate import MarkEvaluator\n\ndef pytest_addoption(parser):\n    parser.addoption(\n        \"--no-skips\", action=\"store_true\", default=False, help=\"disable custom_skip marks\"\n    )\n\n@hookimpl(tryfirst=True)\ndef pytest_runtest_setup(item):\n    if item.config.getoption('--no-skips'):\n        return\n\n    # Check if skip or skipif are specified as pytest marks\n    item._skipped_by_mark = False\n    eval_skipif = MarkEvaluator(item, \"custom_skipif\")\n    if eval_skipif.istrue():\n        item._skipped_by_mark = True\n        pytest.skip(eval_skipif.getexplanation())\n\n    for skip_info in item.iter_markers(name=\"custom_skip\"):\n        item._skipped_by_mark = True\n        if \"reason\" in skip_info.kwargs:\n            pytest.skip(skip_info.kwargs[\"reason\"])\n        elif skip_info.args:\n            pytest.skip(skip_info.args[0])\n        else:\n            pytest.skip(\"unconditional skip\")\n\n    item._evalxfail = MarkEvaluator(item, \"xfail\")\n    check_xfail_no_run(item)\n"], ["-  with np.load(path) as f:\n+  with np.load(path, allow_pickle=True) as f:\n"], [], ["!pip install numpy==1.16.1\nimport numpy as np\n"], [], [], ["threads = []   #array for threads\n\n t = Thread(...)\n threads.append(t) #add all threads\n\n # Start all threads\n for x in threads:\n     x.start()\n\n # Wait for all of them to finish\n for x in threads:\n     x.join()\n"], ["\ncamera_port = 0\n#camera = cv2.VideoCapture(camera_port)\ncamera = cv2.VideoCapture(camera_port,cv2.CAP_DSHOW)\n# Check if the webcam is opened correctly\nif not camera.isOpened():\n    raise IOError(\"Cannot open webcam\")\n\nreturn_value, image = camera.read()\nprint(\"We take a picture of you, check the folder\")\ncv2.imwrite(\"image.png\", image)\n\ncamera.release() # Error is here\ncv2.destroyAllWindows()\n"], [], ["data = [6,6,6,6,6,6,6,6,6,5]\nsb = set(data) # remove duplicate elements\nsb.remove(max(sb)) # remove the max element\nprint(max(sb)) # print the new max\n", "5\n", "data = [6,6,6,6,6,6,6,6,6,5]\ndata = list(set(data))\n", ">>> data\n[5, 6]\n"], [], ["    if arr[0] >= arr[1]:\n    first_max = arr[0]\n    second_max = arr[1]\nelse:\n    first_max = arr[1]\n    second_max = arr[0]\n"], ["scaled_inputs_all.iloc[shuffled_indices]\n"], ["import pandas as pd\ninput_df = pd.DataFrame(data={'1': [1,2,3,4,5]\n                          ,'2': [1,2,3,4,5]\n                          ,'3': [1,2,3,4,5]\n                          ,'4': [1,2,3,4,5]\n                          ,'5': [1,2,3,4,5]})\n", "li = []\nli.append(input_df.iloc[0])\nli.append(input_df.iloc[4])\nnew_df = pd.DataFrame(li)\n", "new_df = input_df.iloc[0].append(input_df.iloc[4])\n"], ["from string import ascii_letters\nfrom collections import Counter\ns = \"Mr. owl ate my Metal worm\"\n\ndef is_permutation_palindrome(s):\n return len([i for i in Counter(c.lower() for c in s if c in ascii_letters).values() if i&1]) < 2\n\nprint(is_permutation_palindrome(s))\n", "s = \"Mr. owl ate my Metal worm\"\ndef is_permutation_palindrome(s):\n    counts = {}\n    for c in s.lower():\n        if c.isalpha():\n            if c in counts:\n                counts[c] += 1\n            else:\n                counts[c] = 1\n\n    odd_counts = [count for count in counts.values() if count % 2 == 1]\n    return len(odd_counts) < 2\n"], ["myString = \"Mr. owl ate my Metal worm\"\nalpha_chars_only = [x for x in myString.lower() if x.isalpha()]\nprint(alpha_chars_only)\n#['m', 'r', 'o', 'w', 'l', 'a', 't', 'e', 'm', 'y', 'm', 'e', 't', 'a', 'l', 'w', 'o', 'r', 'm']\n", "from collections import Counter \ncounts = Counter(alpha_chars_only)\nprint(counts)\n#Counter({'m': 4, 'a': 2, 'e': 2, 'l': 2, 'o': 2, 'r': 2, 't': 2, 'w': 2, 'y': 1})\n", "number_of_odd = sum(1 for letter, cnt in counts.items() if cnt%2)\nprint(number_of_odd)\n#1\n", "def any_palindrome(myString):\n    alpha_chars_only = [x for x in myString.lower() if x.isalpha()]\n    counts = Counter(alpha_chars_only)\n    number_of_odd = sum(1 for letter, cnt in counts.items() if cnt%2)\n    return number_of_odd <= 1\n\nprint(any_palindrome(mystring))\n#True\n"], [], ["def maxs(iterable):\n    max = None\n    count = 0\n    for index, value in enumerate(iterable):\n        if index == 0 or value >= max:\n            if value != max:\n                count = 0\n            max = value\n            count += 1\n    return count * [max]\n\n\nprint (maxs([5, 6, 7, 8, 8]))   # [8, 8]\nprint (maxs([3, 2, 4, 5, 1, 2, 4, 5, 2, 5, 0])) # [5, 5, 5]\nprint (maxs([])) # []\n"], ["item_no = [5, 6, 7, 8, 8]\n\nmax_no = max(item_no)\nhighest = [max_no for _ in range(item_no.count(max_no))]\nprint(highest)  # -> [8, 8]\n", "item_no = [5, 6, 7, 8, 8]\nmax_no = 0  # Note 1 \nfor i in item_no:\n    if i > max_no:\n        max_no = i\n        high = [i]\n    elif i == max_no:\n        high.append(i)\n"], ["numbers = [5, 6, 7, 8, 8]\nmaxnumbers = [i for i in numbers if i==max(numbers)]\nprint(*maxnumbers,sep=',')\n", "8,8\n", "numbers = [5, 6, 7, 8, 8]\nbiggest = max(numbers)\npositions = [inx for inx,i in enumerate(numbers) if i==biggest]\nprint(*positions,sep=',')\n", "3,4\n"], ["item_no = [5, 6, 7, 8, 8]\ncounter = item_no.count(max(item_no))      # 2\nprint([max(item_no) for x in range(counter)])   \n", "[8, 8]\n"], ["num = [8, 9, 4, 1, 2, 3]\n\ndef con(rng, pos=0):\n    if pos < len(rng):\n        if (pos > 0 and rng[pos]-1 == rng[pos-1]) or (pos < len(rng) -1 and rng[pos]+1 == rng[pos+1]):\n            print(\"con\", rng[pos])\n        con(rng, pos+1)\n\ncon(num)\n"], ["num = [8, 9, 4, 1, 2, 3]\n\nfor i in range(len(num)-1):  # not using -1 will cause index error\n    if num[i] + 1 == num[i + 1]:\n        if i == 0 or (i - 1 >= 0 and num[i - 1] != num[i] - 1):\n            print('Con', num[i])\n        print('Con', num[i + 1])\n", "num = [8, 9, 4, 1, 2, 3, 4, 4, 8, 9, 1, 2, 3, 0, 1, 5, 6, 1]\n\nfor i in range(len(num)-1):  # not using -1 will cause index error\n    if num[i] + 1 == num[i + 1]:\n        if i == 0 or (i - 1 >= 0 and num[i - 1] != num[i] - 1):\n            print('Con', num[i])\n        print('Con', num[i + 1])\n"], ["num=[8,9,4,1,2,3]\n\nfor i in range(len(num)):\n    if (\n        (  # check for the next number\n            i + 1 != len (num) and  # don't check the end of the list\n            num[i]+1==num[i+1] \n        ) or (  # check for the previous number\n            i != 0 and  # don't check before the list\n            num [i-1] == num [i] - 1\n        )\n    ): print('Con',num[i])\n"], ["num=[8,9,4,1,2,3]\n\nassert(len(num) > 1)\nfor i, n in enumerate(num):\n    if i != 0:\n        if n == num[i-1] + 1:\n            print(\"Con\", n)\n            continue\n    if i != len(num) - 1:\n        if n == num[i+1] - 1:\n            print(\"Con\", n)\n\n"], ["dash_table.DataTable(\n    id='table',\n    columns=[\n    {'name': 'Column 1', 'id': 'column1'},\n    {'name': 'Column 2', 'id': 'column2'},\n    {'name': 'Column 3', 'id': 'column3'},\n    {'name': 'Column 4', 'id': 'column4'},\n    {'name': 'Column 5', 'id': 'column5'}]\n)\n"], ["dash_table.DataTable(id='tweet_table')\n", "dash_table.DataTable(id='tweet_table', rows=[{}])\n"], ["from flask import Flask\nfrom config import Config\n\napp = Flask(__name__)\napp.config.from_object(Config)\n", "import os\n\nclass Config:\n    SECRET_KEY = os.environ.get('SECRET_KEY', 'default sekret')\n"], ["from flask import Flask\n\napp = Flask(__name__)\napp.config.from_pyfile('flask.cfg', silent=True)\n\n@app.route('/')\ndef home():\n    return 'Hello World'\n", "TESTING=False\nDEBUG=True\n", "from app import app\n\nif __name__ == '__main__':\n    app.run(host='127.0.0.1', port=5000)\n", "from flask import Flask\nimport os\n\ndef get_app_base_path():\n    return os.path.dirname(os.path.realpath(__file__))\n\n\ndef get_instance_folder_path():\n    return os.path.join(get_app_base_path(), \n                        'instance')\n\napp = Flask(__name__,\n            instance_path=get_instance_folder_path(),\n            instance_relative_config=True)\n\napp.config.from_pyfile('flask.cfg', silent=True)\n\n@app.route('/')\ndef home():\n    return 'Hello World'\n"], ["FLASK_APP=app.py (or whatever you named it)\nFLASK_ENV=development (or production)\n"], ["setx OPENCV_VIDEOIO_PRIORITY_MSMF 0\n"], ["def a(digits):\n    \"\"\"\n    :type digits: str\n    :rtype: List[str]\n    \"\"\"\n\n    letters = {'2':'abc', '3':'def','4':'ghi', '5':'jkl', '6':'mno', '7':'pqrs','8':'tuv', '9':'wxyz'}\n\n    def backtrack(digits, path, res):\n        if digits == '':\n            res.append(path)\n            return\n        if len(digits) == 1:\n            for letter in letters[digits[0]]:\n                path += letter\n                backtrack(digits[1:], path, res)\n                path = path[:-1]\n        else:\n            for n in range(len(digits)-1):\n                for letter in letters[digits[n]]:\n                    path += letter\n                    backtrack(digits[1:], path, res)\n                    path = path[:-1]\n\n    res = []\n    backtrack(digits, '', res)\n    return res\n"], ["def letterCombinations(digits):\n    \"\"\"\n    :type digits: str\n    :rtype: List[str]\n    \"\"\"\n\n    letters = {'2':'abc', '3':'def','4':'ghi', '5':'jkl', '6':'mno', '7':'pqrs','8':'tuv', '9':'wxyz'}\n\n    def backtrack(digits, path, res):\n        if digits == '':\n            res.append(path)\n            return\n        for letter in letters[digits[0]]:\n\n            # note that you can replace this section with \n            # backtrack(digits[1:], path + letter, res)\n\n            path += letter\n            backtrack(digits[1:], path, res)\n            path = path[:-1]\n\n\n    res = []\n    backtrack(digits, '', res)\n    return res\n\nletterCombinations('23')\n", "['ad', 'ae', 'af', 'bd', 'be', 'bf', 'cd', 'ce', 'cf']\n", "import itertools\nletters = {'2':'abc', '3':'def','4':'ghi', '5':'jkl', '6':'mno', '7':'pqrs','8':'tuv', '9':'wxyz'}\n\ndef letterCombinations(digits):\n    return [\"\".join(combo) for combo in itertools.product(*[letters[d] for d in digits])]\n\nprint(letterCombinations('23'))\n", "['ad', 'ae', 'af', 'bd', 'be', 'bf', 'cd', 'ce', 'cf']\n"], ["if digits is empty\n    path is a solution\nelse\n    for each letter in current digit\n        stick the letter on the front of\n           the letter combos for the rest of the input\n", "def backtrack(digits, path, res):\n    if len(digits) == 0:\n        res.append(path)\n    else:\n        for letter in letters[digits[0]]:\n            backtrack(digits[1:], letter + path, res)\n"], ["In [34]: def get_prod(number_list):\n...:     let_list = [nums[i] for i in number_list]\n...:     r = [[]]\n...:     for p in let_list:\n...:         r = [x + [y] for x in r for y in p]\n...:     return [''.join(i) for i in r]\n...:\n...:\n\nIn [35]: get_prod(['2', '3', '4'])\nOut[35]:\n['adg',\n 'adh',\n 'adi',\n 'aeg', ...\n"], [], [], ["sudo pip install --default-timeout=120 pandas\n", "export PIP_DEFAULT_TIMEOUT=120\n"], ["mat = [[1, 2, 3], [4,5,6,], [7,8,9]]\nnp.rot90(mat, k=1, axes=(1,0))\n", "array([[7, 4, 1],\n   [8, 5, 2],\n   [9, 6, 3]])\n", "new_matrix = matrix\n", "import copy\n\ndef rotate_clock(matrix):\n    new_matrix = copy.deepcopy(matrix)\n", "def rotate_clock(matrix):\n    new_matrix = [row[:] for row in matrix]\n"], ["import numpy as np\nA=np.array([[1, 2, 3, 33], [4, 5, 6, 66], [7, 8, 9, 99]])\nA\narray([[ 1,  2,  3, 33],\n       [ 4,  5,  6, 66],\n       [ 7,  8,  9, 99]])\n\nrotated_A=np.zeros((len(A[0]),len(A)))\nfor i in range(len(A)):\n    for j in range(len(A[0])):\n        rotated_A[j][len(A)-1-i]=A[i][j]\nrotated_A\narray([[  7.,   4.,   1.],\n       [  8.,   5.,   2.],\n       [  9.,   6.,   3.],\n       [ 99.,  66.,  33.]])\n"], ["import numpy as np\n\na = [[1, 2, 3],\n     [4, 5, 6],\n     [7, 8, 9]]\na_rot = np.rot90(a, k=3).tolist()\nfor row in a_rot:\n  print(row)\n", "[7, 4, 1]\n[8, 5, 2]\n[9, 6, 3]\n"], ["matrix = [[1, 2, 3],\n          [4, 5, 6],\n          [7, 8, 9]]\n\nrotated = [list(reversed(col)) for col in zip(*matrix)]\n\nfor row in rotated:\n    print(*row)\n", "7 4 1\n8 5 2\n9 6 3\n", "rotated = [list(reversed(col)) for col in zip(*matrix)]\n", "rotated = []\nfor col in zip(*matrix):\n    rotated.append(list(reversed(col)))\n"], [], ["def sum_rows(matrix):\n  return [sum(row) for row in matrix]\n", "def sum_cols(matrix):\n  return sum_rows(map(list, zip(*matrix)))\n", "def sum_cols_alt(matrix):\n  return [ sum(row[i] for row in matrix) for i, _ in enumerate(matrix) ]\n"], ["s = 0\nfor row in matrix:\n    s += row[0]\n", "s = sum([row[0] for row in matrix])\n"], ["colsum = sum(row[0] for row in matrix)\n"], ["sum([matrix[i][0] for i in range(len(matrix[0]))])\n"], ["m = pd.concat([pd.concat([left]*len(right)).sort_index().reset_index(drop=True),\n       pd.concat([right]*len(left)).reset_index(drop=True) ], 1)\n\n    col1  col2 col1  col2\n0     A     1    X    20\n1     A     1    Y    30\n2     A     1    Z    50\n3     B     2    X    20\n4     B     2    Y    30\n5     B     2    Z    50\n6     C     3    X    20\n7     C     3    Y    30\n8     C     3    Z    50\n"], ["class MyUser(AbstractBaseUser):\n    email = models.EmailField(\n        verbose_name='email address',\n        max_length=255,\n        unique=True,\n    )\n    date_of_birth = models.DateField()\n    is_active = models.BooleanField(default=True)\n    is_admin = models.BooleanField(default=False)\n"]]