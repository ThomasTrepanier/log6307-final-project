[[], ["import pandas as pd\nimport random\n\nimport xgboost\nimport shap\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\n\nfoo = pd.DataFrame({'id':[1,2,3,4,5,6,7,8,9,10],\n               'var1':random.sample(range(1, 100), 10),\n               'var2':random.sample(range(1, 100), 10),\n               'var3':random.sample(range(1, 100), 10),\n               'class': ['a','a','a','a','a','b','b','c','c','c']})\n\ncl_cols = foo.filter(regex='var').columns\nX_train, X_test, y_train, y_test = train_test_split(foo[cl_cols],\n                                                    foo[['class']],\n                                                    test_size=0.33, \n                                                    random_state=42)\n\nlabel_encoder = LabelEncoder()\ny_train_encoded = label_encoder.fit_transform(y_train.values.ravel())\ny_test_encoded = label_encoder.transform(y_test.values.ravel())\n\nmodel = xgboost.XGBClassifier(objective=\"multi:softprob\", \n                              num_class=len(label_encoder.classes_))\nmodel.fit(X_train, y_train_encoded)\n\nexplainer = shap.TreeExplainer(model)\nshap_values = explainer.shap_values(X_test)\nclasses = label_encoder.inverse_transform(range(\n                            len(label_encoder.classes_)))\nshap.summary_plot(shap_values, X_test, class_names=classes)\n"], [], [], [">>> \"123AbC\".isalnum()\nTrue\n>>> \"1&A\".isalnum()\nFalse\n", ">>> all(c.isnumeric() or c.isalpha() for c in \"123AbC\")\nTrue\n>>> all(c.isnumeric() or c.isalpha() for c in \"1&A\")\nFalse\n", ">>> re.fullmatch(\"\\w\", \"123AbC\", re.A)\nTrue\n>>> re.fullmatch(\"\\w\", \"1&A\", re.A)\nFalse\n"], ["pip install Django==3.2.19\n"], ["array = [1,2,3,4,5]\nfiltered_array = [x for x in array if x > 3]\n"], ["import pandas as pd\n\nnew_row = pd.DataFrame({\"sex\": \"male\", \"age\": 40, \"survived\": False, \"name\": \"Alex\"}, index=[0])\n\n(df_dict\n  .assign(name=['Alice', 'Bob', 'Charlie'])\n  .drop(\"pclass\", axis=1)\n  .pipe(lambda df_: pd.concat([df_, new_row], ignore_index = True))\n)\n", "import pandas as pd\n\ndef append_row(df1, d):\n    df2 = pd.DataFrame(d, index=[0])\n    return pd.concat([df1, df2], ignore_index = True)\n\ndf = pd.DataFrame(columns=['a', 'b'])\n(df\n    .pipe(append_row, {'a': 1, 'b': 2 })\n)\n"], ["html = '<pre>' + my_string '</pre>'\n\n<pre>\nHis this \n\nis \n\na sample\n\nString\n</pre>\n"], ["r'a\\.[a-zA-Z]\\s*&&\\s*\\([a-z]\\s*=\\s*a\\.get\\(\"n\"\\)\\)\\s*&&\\s*'\nr'\\([a-z]\\s*=\\s*([a-zA-Z0-9$]{2,3})(\\[\\d+\\])?\\([a-z]\\)'\n", "nfunc=re.escape(function_match.group(1))),\n"], ["import pytest\nfrom collections.abc import Mapping\nfrom _pytest.python_api import ApproxMapping\n\n\ndef my_approx(expected, rel=None, abs=None, nan_ok=False):\n    if isinstance(expected, Mapping):\n        return ApproxNestedMapping(expected, rel, abs, nan_ok)\n    return pytest.approx(expected, rel, abs, nan_ok)\n\n\nclass ApproxNestedMapping(ApproxMapping):\n    def _yield_comparisons(self, actual):\n        for k in self.expected.keys():\n            if isinstance(actual[k], type(self.expected)):\n                gen = ApproxNestedMapping(\n                    self.expected[k], rel=self.rel, abs=self.abs, nan_ok=self.nan_ok\n                )._yield_comparisons(actual[k])\n                for el in gen:\n                    yield el\n            else:\n                yield actual[k], self.expected[k]\n\n    def _check_type(self):\n        for key, value in self.expected.items():\n            if not isinstance(value, type(self.expected)):\n                super()._check_type()\n", "def test_nested():\n    assert {'foo': {'bar': 0.30000001}} == my_approx({'foo': {'bar': 0.30000002}})\n"], [], ["import statsmodels\nstatsmodels.__file__\n"], ["def url(regex, view, kwargs=None, name=None):\n    return re_path(regex, view, kwargs, name)\n"], [], ["def split_check(bill, people, tax = 0.09, tip = 0.15):\n", "def split_check(bill, people, tax = 0.09, tip = 0.15):\n    tax = bill * tax\n    tip = bill * tip\n    return(bill + tax + tip) / people\n"], [], [], ["import shapely.plotting\nfrom shapely.geometry import Polygon\n\npolygon1 = Polygon([(0, 5), (1, 1), (3, 0)])\n\nshapely.plotting.plot_polygon(polygon1)\n"], [], ["# Build Python packages through an intermediate stage based on ubuntu.\nFROM ubuntu:20.04 as builder\nRUN apt-get update -y\nARG DEBIAN_FRONTEND=noninteractives\n\n# Install system dependencies required to install a few python packages\n# These could be different based on the python package you want to install\nRUN apt-get install wget -y\nRUN apt-get install libtool build-essential autoconf automake pkg-config libtool-bin -y\nRUN apt-get update && apt-get install -y cmake python3-dev\n\n# In my case, I need the python packages `fb-re2` & `zeromq`\nRUN apt-get install -y libre2-dev\n# Install system dependency for `libzmq`\nWORKDIR /zeromq\nRUN wget -O zeromq-4.3.2.tar.gz https://github.com/zeromq/libzmq/releases/download/v4.3.2/zeromq-4.3.2.tar.gz &&\\\n    tar -xzf zeromq-4.3.2.tar.gz\nWORKDIR /zeromq/zeromq-4.3.2\nRUN ./autogen.sh && ./configure && make && make install\n\n\n# Update package lists and install necessary dependencies\nRUN apt-get update && apt-get install -y \\\n    software-properties-common \\\n    && add-apt-repository ppa:deadsnakes/ppa\n\n# Install Python 3.7 and pip\nRUN apt-get update && apt-get install -y \\\n    python3.7 \\\n    python3.7-dev \\\n    python3-pip \\\n    && rm -rf /var/lib/apt/lists/*\n\n# Set python3.7 as the default python\nRUN ln -s /usr/bin/python3.7 /usr/bin/python\nRUN apt-get update && apt-get install python3.7-distutils -y\nRUN apt-get install locate tcpdump -y\nRUN python -m pip install --no-binary=:all: pyzmq==18.0.2\nRUN python -m pip install fb-re2\n\n# Install a couple of other python libraries\nRUN python -m pip install --no-binary=:all: psutil==5.6.7\nRUN python -m pip install --no-binary=:all: netifaces==0.11.0\n\n### Final image build ###\n# Build the base image for python based applications like a webserver.\nFROM python:3.7.16-slim-buster\n\n### From the intermediate build stage, copy the generated outputs to our final python image\nCOPY --from=builder /usr/local/lib/libzmq* /usr/local/lib\nCOPY --from=builder /usr/local/lib/python3.7/dist-packages/zmq/ /usr/local/lib/python3.7/site-packages/zmq\nCOPY --from=builder /usr/local/lib/python3.7/dist-packages/pyzmq-18.0.2.egg-info/ /usr/local/lib/python3.7/site-packages/pyzmq-18.0.2.egg-info\n\nCOPY --from=builder /usr/local/lib/python3.7/dist-packages/psutil/ /usr/local/lib/python3.7/site-packages/psutil\nCOPY --from=builder /usr/local/lib/python3.7/dist-packages/netifaces* /usr/local/lib/python3.7/site-packages/\n\nRUN apt-get update && apt-get install -y libre2-dev\nCOPY --from=builder /usr/local/lib/python3.7/dist-packages/*re2* /usr/local/lib/python3.7/site-packages/\nCOPY --from=builder /usr/local/lib/python3.7/dist-packages/fb_re2-1.0.7.dist-info/ /usr/local/lib/python3.7/site-packages/fb_re2-1.0.7.dist-info\n## END of copying from intermediate ubuntu stage\n\nWORKDIR /my/work/dir/\nCOPY requirements.txt .\n\n# Install other python packages through requirements.txt\n# It will disregard any package installation failure\n# Logs can later be found in `/var/log/python_package_installation.log` inside the container\nRUN set -e && cat requirements.txt | xargs -n 1 pip install > /var/log/python_package_installation.log 2>&1 || true\n\nEXPOSE 18000\n# Let's run a simple python server, so that we can go to the\n# container's shell and debug ourselves\nCMD python3 -m http.server\n\n"], [], ["zoneinfo._common.ZoneInfoNotFoundError: 'No time zone found with key UTC+8'\n", "#settings.py\nTIME_ZONE = 'UTC+8'\n", "#settings.py\nTIME_ZONE = 'Asia/ShangHai'\n"], ["data = yaml.full_load(f) # around line 1391\n", "data = yaml.safeload(f)  # quoting from Salim Tekin\n                                     \n"], ["try:\n    ssh.connect(ip, **args)\nexcept paramiko.ssh_exception.AuthenticationException:\n    ssh.connect(ip, \n                disabled_algorithms=dict(keys=['rsa-sha2-256', 'rsa-sha2-512'],\n                                         pubkeys=[\"rsa-sha2-512\",\"rsa-sha2-256\"]), \n                **args)\n"], ["import tempfile\nfrom fastapi import FileResponse\n\n\nclass TempFileResponse(FileResponse):\n    def __init__(self, prefix, **params) -> None:\n        self.temp_file = tempfile.NamedTemporaryFile(prefix=prefix)\n        super().__init__(path=self.temp_file.name, **params)\n\n    def __del__(self):\n        # This will delete the file\n        self.temp_file.close()\n\n\n@router.get(\"/produce-data\", response_class=FileResponse)\nasync def produce() -> FileResponse:\n    file_name = \"some_file_data.txt\"\n    logger.info(f\"Downloading data as {file_name}\")\n    response_file = TempFileResponse(prefix=\"some_file_\", filename=file_name)\n    with open(response_file.temp_file.name, \"w\") as f:\n        f.write(\"Hello, world!\")\n    return response_file\n"], ["from aiogram import Bot, Dispatcher, executor, types\n\nAPI_TOKEN = 'API'\n\nbot = Bot(token=API_TOKEN)\ndp = Dispatcher(bot)\n\n@dp.message_handler()\nasync def echo(message: types.Message):\n  await message.answer(message.text)\n\nasync def notify_message(dp: Dispatcher) # THIS FUNCTION\n  print('Hello World')\n\nif __name__ == '__main__':\n   executor.start_polling(dp, skip_updates=True, on_startup=notify_message)\n", "from aiogram import Bot, Dispatcher, executor, types\n\nAPI_TOKEN = 'API'\n\nbot = Bot(token=API_TOKEN)\ndp = Dispatcher(bot)\n\n@dp.message_handler()\nasync def echo(message: types.Message):\n  await message.answer(message.text)\n\nasync def notify_message() # THIS FUNCTION\n  # await print('Hello World')\n  print('Hello, world') # you shouldn't await the print fucntion, because it isn't async.\n\nif __name__ == '__main__':\n   await notifty_message()\n   executor.start_polling(dp, skip_updates=True)\n", "from aiogram import Bot, Dispatcher, executor, types\n\nAPI_TOKEN = 'API'\n\nbot = Bot(token=API_TOKEN)\ndp = Dispatcher(bot)\n\n@dp.message_handler()\nasync def echo(message: types.Message):\n  await message.answer(message.text)\n\ndef notify_message() # THIS FUNCTION\n  print('Hello, world')\n\nif __name__ == '__main__':\n   notifty_message()\n   executor.start_polling(dp, skip_updates=True)\n"], [], ["def flatten_model(modules):\n    def flatten_list(_2d_list):\n        flat_list = []\n        # Iterate through the outer list\n        for element in _2d_list:\n            if type(element) is list:\n                # If the element is of type list, iterate through the sublist\n                for item in element:\n                    flat_list.append(item)\n            else:\n                flat_list.append(element)\n        return flat_list\n\n    ret = []\n    try:\n        for _, n in modules:\n            ret.append(flatten_model(n))\n    except:\n        try:\n            if str(modules._modules.items()) == \"odict_items([])\":\n                ret.append(modules)\n            else:\n                for _, n in modules._modules.items():\n                    ret.append(flatten_model(n))\n        except:\n            ret.append(modules)\n    return flatten_list(ret)\n"], ["from azure.storage.blob import BlobClient\n\nblob_client = BlobClient.from_connection_string(\n        conn_str='my_conn_str',\n        container_name='my_container_name',\n        blob_name='my_blob_name')\n\nwith open(\"./SampleSource.txt\", \"rb\") as data:\n    blob.upload_blob(data)\n"], [], ["Build Failed\nError: PythonPipBuilder:ResolveDependencies - pip executable not found in your python environment at ..\\Python310\\python.EXE\n"], [], ["num1 = int(input())\nnum2 = int(input())\nnum3 = int(input())\n\nsmallest_num = min(num1, num2, num3)\nif (num1 < num2):\n    if (num1 < num3):\n        smallest_num = num1\nelif (num2 < num1):\n    if (num2 < num3):\n        smallest_num = num2\nelif (num3 < num2):\n    if (num3 < num1):\n        smallest_num = num3\n\nprint(smallest_num)\n"], ["pip3 upip3 uninstall virtualenvninstall virtualenv\nsudo pip3 uninstall virtualenv\nsudo apt purge python3-virtualenv\n"], ["import re\n\ncontent = '\\r\\n\\r\\n\\r\\n\\r\\n\\r\\ntest'\ncontent = re.sub(r'(\\r\\n)+', r'\\r\\n', content)  # '\\r\\ntest'\n"], ["pygame.draw.rect(your surface name, color, (x, y, length, width))\n"], ["import yfinance as yf\n\ndef current_price(instrument):\n    data = yf.Ticker(instrument).history(period=\"1d\", interval=\"1m\")\n    return data[\"Close\"].iloc[-1]\n\nprint(current_price(\"TSLA\"))\n"], ["$ snap install powershell\n$ pwsh\nps> install-module exchangeonlinemanagement\nps> Connect-ExchangeOnline\nps> New-ServicePrincipal -AppId <appid> -ObjectId <objid>\nps> Add-MailboxPermission -Identity <email@domain> -User <ObjectId> -AccessRights FullAccess`\nps> exit\n$\n"], ["new_df.fillna(\"Others\",inplace=True,axis = 1)\n\nnew_df = pd.get_dummies(new_df, columns=cat_col)\n\ncol_to_drop = [col for col in new_df.columns.tolist() if col.__contains__(\"Others\")]\n\nnew_df.drop(col_to_drop, axis=1,inplace=True)\n", "cat_col = data.dtypes[data.dtypes == 'O'].index.tolist() #to get the list of categorical variables\n\nnew_df = pd.get_dummies(new_df, columns=cat_col, drop_first=True,dummy_na=True)\n"], ["from itertools import count\n\nunique = count()\n\nq.put((priority, next(unique), item))\n", "from functools import total_ordering\n\n@total_ordering\nclass PrioritizedItem:\n    def __init__(self, priority, item):\n        self.priority = priority\n        self.item = item\n\n    def __eq__(self, other):\n        if not isinstance(other, __class__):\n            return NotImplemented\n        return self.priority == other.priority\n\n    def __lt__(self, other):\n        if not isinstance(other, __class__):\n            return NotImplemented\n        return self.priority < other.priority\n"], ["apt install -y software-properties-common\nadd-apt-repository ppa:deadsnakes/ppa\napt install python3.10\n", "root@XXX:/home/XXX# python\npython            python2           python2.7         python2.7-config  python2-config    python3           python3.10        python3.8         python3.8-config  python3-config    python3-wsdump    python-config     \n\nroot@XXX:/home/XXX# python3.10\nPython 3.10.12 (main, Jun  7 2023, 12:45:35) [GCC 9.4.0] on linux\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n>>> exit\nUse exit() or Ctrl-D (i.e. EOF) to exit\n>>> \n", "root@XXX:/home/XXX# update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.10 1\n", "root@XXX:/home/XXX# update-alternatives --config python3\nThere are 2 choices for the alternative python3 (providing /usr/bin/python3).\n\n  Selection    Path                 Priority   Status\n------------------------------------------------------------\n* 0            /usr/bin/python3.8    1         auto mode\n  1            /usr/bin/python3.10   1         manual mode\n  2            /usr/bin/python3.8    1         manual mode\n\nPress <enter> to keep the current choice[*], or type selection number: 1\nupdate-alternatives: using /usr/bin/python3.10 to provide /usr/bin/python3 (python3) in manual mode\n", "root@XXX:/home/XXX# update-alternatives --config python3\nThere are 2 choices for the alternative python3 (providing /usr/bin/python3).\n\n  Selection    Path                 Priority   Status\n------------------------------------------------------------\n  0            /usr/bin/python3.10   1         auto mode\n* 1            /usr/bin/python3.10   1         manual mode\n  2            /usr/bin/python3.8    1         manual mode\n\nPress <enter> to keep the current choice[*], or type selection number: \n", "root@XXX:/home/XXX# python3 --version\nPython 3.10.12\n", "root@XXX:/home/XXX# apt-get install -y python3-pip\n", "root@XXX:/home/XXX# apt-get install -y python3.10-venv\n"], ["def preProcesser(board: chess.Board):\n    chess_dict = {\n            1 : [1,0,0,0,0,0],\n            2 : [0,1,0,0,0,0],\n            3 : [0,0,1,0,0,0],\n            4 : [0,0,0,1,0,0],\n            5 : [0,0,0,0,1,0],\n            6 : [0,0,0,0,0,1],\n            0 : [0,0,0,0,0,0]\n        }\n    return torch.from_numpy(np.array([np.array(chess_dict[(board.piece_type_at(sq) if board.piece_type_at(sq) else 0)])*(-1 if board.color_at(sq)==False else 1) for sq in chess.SQUARES]).astype(np.float16).reshape(-1))\n"], [], ["pip install -r requirements.txt\n"], ["import re\n\ntable = 'table1'\n\ntable = re.sub(r'\\d+', '', table)\n"], ["{\n    \"jupyter.interactiveWindow.textEditor.executeSelection.\": true\n}\n\n", "\"python.dataScience.sendSelectionToInteractiveWindow\": false\n"], [], [], ["conda install -c conda-forge nbformat\n", "pip install --upgrade nbformat\n\n"], ["from dataclasses import dataclass\n\n@dataclass\nclass XY:\n    \"2d point\"\n    x: float or int\n    y: float or int\n\npoints = [XY(1, 2), XY(3, 4), XY(5, 6), XY(7, 8)]\ndata_dict = dict(zip(('x', 'y'), zip(*(vars(p).values() for p in points))))\n\nprint(data_dict)\n", "{'x': (1, 3, 5, 7), 'y': (2, 4, 6, 8)}\n"], ["(a - a[..., [0]]).sum(-1) == 0\n"], ["apt install pkg-config\n"], ["import en_core_web_sm\nnlp = en_core_web_sm.load()\n\ndoc = nlp(text)\nxxxxxxx\n"], [], ["import pandas as pd\n\n\ndef my_append(self, x, ignore_index=False):\n    if ignore_index:\n        return pd.concat([self, x])\n    else:\n        return pd.concat([self, x]).reset_index(drop=True)\n\n\nif not hasattr(pd.DataFrame, \"append\"):\n    setattr(pd.DataFrame, \"append\", my_append)\n\n"], [], [], ["XY = namedtuple('XY', ['x', 'y'])\n", "points = [XY(1,2), XY(3,4), XY(5,6), XY(7,8)]\nxs, ys = zip(*points)\n# (1, 3, 5, 7)\n# (2, 4, 6, 8)\n", "def idataclass(**kwargs):     \n    def deco(cls):\n        cls = dataclass(cls, **kwargs)\n        cls.__iter__  = lambda s: (getattr(s, field.name) for field  in fields(s))\n        return cls\n    return deco\n\n \n@idataclass()\nclass XY:\n    x: float | int\n    y: float | int\n"], [], ["pattern = r\"[\\w]+[aeiou]{3,}[a-z]+\"\n"], ["(base) C:\\>cd /d d:\n(base) D:\\>jupyter notebook\n"], ["df.iloc[:, 1:] = df.iloc[:, 1:].apply(pd.to_numeric)\n", "df[df.columns[1:]] = df[df.columns[1:]].apply(pd.to_numeric)\n", "df[df.columns[1:]] = df[df.columns[1:]].astype(float)\n"], [], [], ["from operator import attrgetter\nfrom dataclasses import dataclass\n\n@dataclass\nclass XY:\n    \"2d point\"\n    x: float | int\n    y: float | int\n\npoints = [XY(1,2), XY(3,4), XY(5,6), XY(7,8)]\nxs, ys = map(list, zip(*map(attrgetter('x', 'y'), points)))\n"], [], ["def pt2iter(pt):\n    yield pt.x\n    yield pt.y\n\nxs, ys = zip(*map(pt2iter, points))\n", "def pt2iter(pt):\n    return pt.x, pt.y\n"], ["from dataclasses import dataclass, astuple\n\n@dataclass\nclass XY:\n    \"2d point\"\n    x: float | int\n    y: float | int\n    def __iter__(self):\n        return iter(astuple(self))\n\npoints = [XY(1,2), XY(3,4), XY(5,6), XY(7,8)]\nxs, ys = zip(*points)\n", "xs, ys = zip(*map(astuple, points))\n"], [], ["(1, 3, 5, 7)\n(2, 4, 6, 8)\n"], ["import boto3\n\nfileCount = 0\n\n# One-liner\nfileCount = sum([page['KeyCount'] for page in boto3.client('s3').get_paginator('list_objects_v2').paginate(Bucket=bucket,Prefix=File)])\n\n# More readable\ns3 = boto3.client('s3')\ns3p = s3.get_paginator('list_objects_v2')\ns3i = s3p.paginate(Bucket=bucket,Prefix=File)\nfileCount = sum(KeyCount for KeyCount in s3i.search('KeyCount'))\n# Or\nfor KeyCount in s3i.search('KeyCount'):\n  fileCount += KeyCount\n\n"], ["pip install torch\n", "%pip install torch\n"], [], ["if(raw_code == \"\"):\n    return \"\"\n", "if(raw_code == \"\"):\n    return []\n", "if(match != None):\n    code_lines_list = find_object_from_startpoint(js, match.span()[1]).split('\\n')\n    joined_lines = \"\".join(code_lines_list)\n    # Prepend function definition (e.g. `Dea=function(a)`)\n    return match.group(0) + joined_lines\nelse:\n    return \"\"\n"], ["camera.set(cv2.CAP_PROP_FOURCC, cv2.VideoWriter.fourcc('M', 'J', 'P', 'G'))\n"], [], ["'blas=*=accelerate'\n"], ["def longest(numbers):\nmy_max, count_ = 1, 1\nstart_idx, end_idx = 0, 0\nfor i in range(len(numbers)-1):\n    # if difference between number and his follower is 1,they are in sequence\n    if numbers[i+1]-numbers[i] ==1:\n        count_ = count_+1\n    else:\n        if count_ > my_max :\n            my_max = count_\n            end_idx = i\n            start_idx = i+1 - my_max\n        # Reset counter\n        count_ = 1\nif count_ > my_max:\n    my_max = count_\n    end_idx = i+1\n    start_idx = i+2-my_max\nreturn (start_idx,end_idx,my_max)\n"], [], [], [], [], [], ["pip install pandas\n"], [], [], [], [], ["function_patterns = [\n    # https://github.com/ytdl-org/youtube-dl/issues/29326#issuecomment-865985377\n    # https://github.com/yt-dlp/yt-dlp/commit/48416bc4a8f1d5ff07d5977659cb8ece7640dcd8\n    # var Bpa = [iha];\n    # ...\n    # a.C && (b = a.get(\"n\")) && (b = Bpa[0](b), a.set(\"n\", b),\n    # Bpa.length || iha(\"\")) }};\n    # In the above case, `iha` is the relevant function name\n    r'a\\.[a-zA-Z]\\s*&&\\s*\\([a-z]\\s*=\\s*a\\.get\\(\"n\"\\)\\)\\s*&&.*?\\|\\|\\s*([a-z]+)',\n    r'\\([a-z]\\s*=\\s*([a-zA-Z0-9$]+)(\\[\\d+\\])?\\([a-z]\\)', ]\n"], ["def BracketMatcher(strParam: str) -> bool:\n  pairs = {'(':')', '[':']', '{':'}'}\n  stack = []\n  for c in strParam:\n    if c in '([{':\n      stack.append(c)\n    elif c in ')]}':\n      if not stack or c != pairs[stack[-1]]:\n        return False\n      stack.pop()\n  return len(stack) == 0\n"], [], ["df.iloc[-1, 0]\n"], ["/opt/random/nonstandard/whoa/pip\n/usr/local/bin/pip\n/usr/bin/pip\n", "/opt/random/nonstandard/whoa/pip --version\n"], ["pattern = \"^[a-zA-Z0-9-+_.@]*\\.+[^@/]*$\"\n"], ["from django.conf import settings\nimport authentication\nfrom .room import Room\n\nclass Section(models.Model):\n    ...\n    boss = models.ForeignKey(settings.AUTH_USER_MODEL, on_delete=models.SET(authentication.models.get_sential), ...)\n    surrogate = models.ForeignKey(settings.AUTH_USER_MODEL, on_delete=models.SET(get_sentinel), ...)\n    room = models.ForeignKey(Room, on_delete=models.SET_NULL, ...)\n    is_subordinate_to = models.ForeignKey('self', on_delete=models.SET_NULL, ...)\n"], ["error: invalid version number in 'MACOSX_DEPLOYMENT_TARGET='\n", "export MACOSX_DEPLOYMENT_TARGET=11\n"], [], [">>> name = \"Fred\"\n>>> f\"He said his name is {name}.\"\n\"He said his name is Fred.\"\n\n>>> name = \"Fred\"\n>>> f\"He said his name is {name!r}.\"\n\"He said his name is Fred.\"\n\n>>> f\"He said his name is {repr(name)}.\" # repr() is equivalent to !r\n\"He said his name is Fred.\"\n\n>>> width = 10\n>>> precision = 4\n>>> value = decimal.Decimal(\"12.34567\")\n>>> f\"result: {value:{width}.{precision}}\" # nested fields\nresult: 12.35\n\n>>> today = datetime(year=2023, month=1, day=27)\n>>> f\"{today:%B %d, %Y}\" # using date format specifier\nJanuary 27, 2023\n\n>>> number = 1024\n>>> f\"{number:#0x}\" # using integer format specifier\n0x400\n"], ["from selenium import webdriver\nfrom selenium.common import NoSuchElementException, TimeoutException\nfrom selenium.webdriver.support.wait import WebDriverWait\nfrom selenium.webdriver.support import expected_conditions as EC\nfrom selenium.webdriver.common.keys import Keys\nfrom time import sleep\n\n# I used Chrome but you can used any browser\n \n# ---- Optional - add options to keep the webpage open ----\noptions = webdriver.ChromeOptions()\noptions.add_experimental_option(\"detach\", True)\n\ndriver = webdriver.Chrome(options=options)\n", "try:\n     notification_off = WebDriverWait(driver, 20).until(EC.presence_of_element_located(('xpath', '//*[@id=\"mount_0_0_LP\"]/div/div/div[3]/div/div/div[1]/div/div[2]/div/div/div/div/div[2]/div/div/div[3]/button[2]')))\nexcept TimeoutException:\n    print(\"no such element found\")\nelse:\n    click_anywhere.click()\n\n", "sleep(20)\ntry:\n     not_off = driver.find_element('name', 'Not Now')\nexcept NoSuchElementException:\n     print('No such element found')\nelse:\n      not_off.click()\n", "sleep(5)\ntry:\n    notification_off = driver.find_elements('css selector', 'button')\nexcept NoSuchElementException:\n    print(\"notification element not found\")\nelse:\n    # dictionary comprehension\n    not_off = [item for item in notification_off if item.text == \"Not Now\"]\n    not_off[0].click()\n"], [], [], ["pip3 install pip==21.0.1 poetry==1.1.8 poetry-core==1.0.4\n", "poetry cache clear --all .\n"], [], ["def summer_69(nums):\n    total = 0\n    ignore_section = False\n\n    for num in nums:\n        if num == 6:\n            ignore_section = True\n        elif num == 9:\n            ignore_section = False\n        elif not ignore_section:\n            total += num\n\n    return total\n"], [" dataset, dataset_info = tfds.load('malaria', with_info=True, as_supervised=True,shuffle_files=True,split[\"train\"],data_dir=\"you_dir\\tensorflow_datasets\\\\\")\n", "  for i, (image, label) in enumerate(train_dataset.take(16)):\n        ax = plt.subplot(4, 4, i+1)\n        plt.imshow(image)\n        plt.title(dataset_info.features['label'].int2str(label))\n        plt.axis('off')\n\nplt.show()\n"], ["opencv-python-headless                  4.7.0.72\n"], ["def min_refills(distance, tank, stops):\n    stop_list = []\n    stops.append(distance) # append the destination to the stop list\n    # write your code here\n    if distance <= tank: # if the travel distance <= distance travelled in one full tank\n        return 0\n    else:\n        start = 0\n        prev = 0\n        for stop in stops:\n            \n            if stop - start < tank:     # if refueling stop is closer to the starting point than the car can travel in one full tank\n                prev = stop     # move prev pointer to the refueling stop\n            elif (stop - start == tank) and (stop != distance):     # don't consider destination as a refueling stop\n                start = stop    # move the starting point to the current gas stop\n                stop_list.append(stop)      # add the refueling stop to the stop list\n                prev = stop     # move the prev pointer to the stop\n            elif stop - start > tank:\n                start = prev    # move the starting point to the prev gas stop\n                if stop - start > tank:     # if next refuleing stop is farther than the dist. car can go in one full tank\n                    return -1\n                stop_list.append(prev)      # add the refueling stop to the list\n                prev = stop     # move the prev pointer the stop\n\n    return len(stop_list)\n"], ["string = \"11234\"\nstring_asList = list(string)       #converts sting into list\n\nstring_asList[0] = \"I\"             #replace element at [O] index\nstring = ''.join(string_asList)    #converts list back to string\n\nprint(string)\n"], [], ["import os\nfrom shutil import move\nfrom glob import iglob\nfrom pathlib import Path\nfrom concurrent.futures import ThreadPoolExecutor\n\n\n# The .py file has to be on the same directory as the folders containing the files!\nroot = Path(__file__).parent\n\n# Using threading in case the operation becomes I/O bound (many files)\nwith ThreadPoolExecutor() as executor:\n    for file in iglob(str(root / \"**\" / \"*\")):\n        file = Path(file)\n\n        # The new filename is the name of the directory, and the suffix(es) of the original file\n        new_filename = f\"{file.parent.name}{''.join(file.suffixes)}\"\n\n        # Move AND rename simultaneosly\n        executor.submit(move, file, root / new_filename)\n\n        # Delete directory because it is empty, and has no utility; ommit this line if not True\n        executor.submit(os.rmdir, file.parent)\n", "import os\nfrom shutil import move\nfrom glob import iglob\nfrom pathlib import Path\nfrom concurrent.futures import ThreadPoolExecutor\n\n\nRENAME_ONLY = True\n\n\n# The .py file has to be on the same directory as the folders containing the files!\nroot = Path(__file__).parent\n\n# Using threading in case the operation becomes I/O bound\nwith ThreadPoolExecutor() as executor:\n    for file in iglob(str(root / \"**\" / \"*\")):\n        file = Path(file)\n\n        # The new filename is the name of the directory, and the suffix(es) of the original file\n        new_filename = f\"{file.parent.name}{''.join(file.suffixes)}\"\n\n        if RENAME_ONLY:\n            executor.submit(os.rename, file, file.parent / new_filename)\n        else:\n            # Move AND rename simultaneosly\n            executor.submit(move, file, root / new_filename)\n\n            # Delete directory because it is empty, and has no utility; ommit this line if not True\n            executor.submit(os.rmdir, file.parent)\n"], ["apk fetch python3 py3-pip libbz2 libexpat libffi gdbm mpdecimal libpanelw readline \\\n    sqlite-libs py3-setuptools libgcc libstdc++ py3-packaging py3-parsing\n", "ENV PYTHONUNBUFFERED=1\nCOPY ./*.apk .\n\nRUN apk add --allow-untrusted --no-network libgcc* libstdc++* gdbm* libbz2* \\\n    libexpat* libffi* libpanel* mpdecimal* \\\n    readline* sqlite* \\\n    python3-3.11.4-r0.apk py3-parsing* py3-packaging* py3-setuptools* py3-pip-23.1.2-r0.apk && \\\n    rm *.apk && \\\n    ln -sf python3 /usr/bin/python\n"], ["import boto3\n\ndef count_objects_in_s3_folder(bucket_name, folder_name):\n    # Create an S3 client\n    s3 = boto3.client('s3')\n\n    # Specify the bucket and prefix (folder) within the bucket\n    bucket = {'Bucket': bucket_name}\n    prefix = folder_name + '/'\n\n    # Initialize the object count\n    object_count = 0\n\n    # Use the list_objects_v2 API to retrieve the objects in the folder\n    paginator = s3.get_paginator('list_objects_v2')\n    response_iterator = paginator.paginate(Bucket=bucket_name, Prefix=prefix)\n\n    # Iterate through the paginated responses\n    for response in response_iterator:\n        if 'Contents' in response:\n            object_count += len(response['Contents'])\n\n    print(f\"Number of objects in folder '{folder_name}': {object_count}\")\n\n# Provide the S3 bucket name and folder name to count objects in\nbucket_name = 'your_bucket_name'\nfolder_name = 'your_folder_name'\n\ncount_objects_in_s3_folder(bucket_name, folder_name)\n"], [], [], [], [], ["fig.update_xaxes(\n    rangebreaks=[dict(values=pd.date_range(start=\"2023-05-28\",end=\"2023-06-09\"))] # hide dates with no values\n)\n"], ["    <RCC>\n      <qresource prefix=\"/\">\n        <file>icons/myicon.png</file>\n      </qresource>\n    </RCC>\n", "    sed 's/:\\/icons\\//icons:/g' pyuic6_output_file.py > patched_file.py\n", "    QtCore.QDir.setSearchPaths(\"icons\", [os.path.join(os.path.dirname(__file__), 'icons')])\n"], ["// Step 1: Define the enums\nService = Enum('Service', ['Plumbing', 'Electrical', 'Carpentry', 'Special'])\nPlumbing = Enum('Plumbing', ['REGULAR', 'EXPRESS'])\nElectrical = Enum('Electrical', ['REGULAR', 'REWIRING', 'NEWSOCKETS'])\nCarpentry = Enum('Carpentry', ['REPAIR', 'NEW'])\nSpecial = Enum('Special', ['DEEPCLEAN', 'TOILETS'])\n\n    \n// step 2, define a dict to keep a track of your enums\nenumlist = {\n    'Plumbing' : Plumbing,\n    'Electrical' : Electrical,\n    'Carpentry' : Carpentry,\n    'Special' : Special\n}\n\n\n// step 3 : functions to convert an enum to and from string   \ndef str_to_enum(namestring):\n    try:\n        if namestring.split(\".\", 2)[0] not in enumlist:\n            return None\n        return enumlist[namestring.split(\".\", 2)[0]][namestring.split(\".\", 2)[1]]\n    except KeyError as e:\n        return None\n        \ndef enum_to_tr(value):\n    if not isinstance(value, Enum):\n        return None\n    return str(value)\n\n// step 4, a function to check if the enum named has the key needed\n\ndef is_in(enumname, keystr):   \n    supposedEnum = f'{enumname}.{keystr}'\n    \n    if str_to_enum(supposedEnum) is None:\n        return False\n    return True\n"], ["import timeit\nfrom enum import Enum, EnumMeta\nfrom random import randint\n\n\nclass MetaEnum(EnumMeta):\n    def __contains__(cls, item):\n        try:\n            cls(item)\n        except ValueError:\n            return False\n        return True    \n\n\nclass BaseEnum(Enum, metaclass=MetaEnum):\n    pass\n\n\nclass Action(BaseEnum):\n    A = 1\n    B = 2\n    C = 3\n    D = 4\n    \n    def is_action(obj):\n        try:\n            Action(obj)\n        except ValueError:\n            return False\n        return True\n\nrepeat, N = 100, 10000\nt_is_x = timeit.repeat(stmt=\"Action.is_action(i)\", setup='from random import randint; i = randint(1, 8)', number=N, repeat=repeat, globals=globals())\nt_meta = timeit.repeat(stmt=\"i in Action\", setup='from random import randint; i = randint(1, 8)', number=N, repeat=repeat, globals=globals())\nt_valuemap = timeit.repeat(stmt=\"i in Action._value2member_map_\", setup='from random import randint; i = randint(1, 8)', number=N, repeat=repeat, globals=globals())\n\nprint(f\"Time for is_x: {min(t_is_x)}\")\nprint(f\"Time for meta: {min(t_meta)}\")\nprint(f\"Time for value map: {min(t_valuemap)}\")\n", "Time for is_x: 0.008271969389170408\nTime for meta: 0.007943496108055115\nTime for value map: 0.0010849367827177048\n"], [], ["## through boto3 resource\ndef get_files_on_s3_resource(bucket_name, folder_path):\n    s3 = boto3.resource('s3')\n    bucket = s3.Bucket(bucket_name)\n    folder_objects = list(bucket.objects.filter(Prefix=folder_path))\n    files_on_s3 = []\n    for file in folder_objects:\n        files_on_s3.append(file.key)\n    return files_on_s3\n\n## with paginator for list_objects_v2\ndef list_s3_objects_wp(bucket_name, folder_path):\n    s3 = boto3.client('s3')\n    paginator = s3.get_paginator('list_objects_v2')\n\n    object_list = []\n    for page in paginator.paginate(Bucket=bucket_name, Prefix=folder_path):\n        for content in page.get('Contents', []):\n            object_list.append(content)\n\n    return object_list\n\n## without paginator for list_objects_v2\ndef list_s3_objects_wop(bucket_name, folder_path):\n    s3 = boto3.client('s3')\n    # get list of files on s3\n    object_list = []\n    for obj in s3.list_objects_v2(Bucket=bucket_name, Prefix=folder_path)['Contents']:\n        object_list.append(obj)\n        \n    return object_list\n\n## tried a way suggested in one of the answers above \ndef list_s3_objects_so(bucket_name, folder_path):\n    s3 = boto3.resource('s3')\n    # get list of files on s3\n    bucket = s3.Bucket(bucket_name)\n    count_obj = sum(1 for _ in bucket.objects.filter(Prefix=folder_path))\n    return count_obj\n", "bucket_name ='someBucket'\nfolder_path = 'someFolder/someKey/'\n\nstartr_time = time.time()\nfiles_on_s3 = get_files_on_s3(bucket_name, folder_path)\nend_time = time.time()\nprint('Time taken to get files on s3: ' + str(end_time - startr_time))\nprint(len(files_on_s3))\n\nstartr_time = time.time()\nfiles_on_s3 = list_s3_objects(bucket_name, folder_path)\nend_time = time.time()\nprint('Time taken to get files on s3: ' + str(end_time - startr_time))\nprint(len(files_on_s3))\n\nstartr_time = time.time()\nfiles_on_s3 = list_s3_objects_wop(bucket_name, folder_path)\nend_time = time.time()\nprint('Time taken to get files on s3: ' + str(end_time - startr_time))\nprint(len(files_on_s3))\n\nstartr_time = time.time()\nfiles_on_s3 = list_s3_objects_so(bucket_name, folder_path)\nend_time = time.time()\nprint('Time taken to get files on s3: ' + str(end_time - startr_time))\nprint(files_on_s3)\n\n\n> Time taken to get files on s3: 7.044371128082275\n> 21976\n> Time taken to get files on s3: 4.960357189178467\n> 21976\n> Time taken to get files on s3: 0.6216549873352051\n> 1000\n> Time taken to get files on s3: 7.754430055618286\n> 21976\n"], [], [], [], ["python3 --version\n", "python3 myscript.py\n"], [], ["!pip install nbformat\n"], ["% python3 --version\nPython 3.11.1\n", "python3.11 -m venv venv\n"], [], [], ["from __future__ import annotations # <-still need this.\nfrom typing import TYPE_CHECKING\n\nif TYPE_CHECKING: # <-try this,\n    from my_module import MyClass # <-if this is only for type hinting.\n"], [], [], ["export SYSTEM_VERSION_COMPAT=1\n"], [], [], ["features = pd.concat([features, input_vars.to_frame().T])\n"], [], ["from app.controllers.users import get_user_manager, UserManager\n\nImportError: cannot import name 'get_user_manager' from partially initialized module 'app.controllers.users' (most likely due to a circular import)\n"], ["import requests\n\naccess_token = get_access_token()  # from @amit's answer above\nbase_url = \"https://graph.microsoft.com/v1.0\"\n\n# example url to list folders for a user's mailbox\nurl = f\"{base_url}/users/{user_id}/mailFolders\"\nresponse = requests.get(\n     url, \n     headers={\n          'Authorization': 'Bearer ' + access_token['access_token']\n     }\n)\n"], [], ["sudo chown $(whoami):$(whoami) /var/run/docker.sock\n", "sudo nano /etc/systemd/system/sockets.target.wants/docker.socket\n", "[Unit]\nDescription=Docker Socket for the API\n\n[Socket]\nListenStream=/var/run/docker.sock\nSocketMode=0660\nSocketUser=YOUR_USERNAME_HERE\nSocketGroup=docker\n\n[Install]\nWantedBy=sockets.target\n", "$ sudo chgrp -R docker /path/to/directory \n", "$sudo chmod -R g+rw /path/to/directory \n"], ["counter = 0\nq.put((priority, counter:= counter+1, item))\n"], ["#If your index is a string\ndf.loc[\"name of the index\"] = pd.Series({\"Column 1\" : Value1, \"Column 2\" : Value2,\n\"Column 3\" : Value3, \"Column 4\" : Value4, ...})\n\n#If your index is a number\ndf.loc[len(df)] = pd.Series({\"Column 1\" : Value1, \"Column 2\" : Value2,\n\"Column 3\" : Value3, \"Column 4\" : Value4, ...})\n"], ["import re\n\ndef text_to_html_paragraphs(text):\n    # First, replace multiple newlines with a single newline,\n    # so you don't get empty paragraphs\n    text = re.sub(r'\\n\\s*\\n', '\\n', text)\n\n    # Split the text into lines\n    lines = text.split('\\n')\n\n    # Wrap each line in a <p> tag and join them\n    return ''.join(f'<p>{line.strip()}</p>\\n' for line in lines)\n\ntext = \"\"\"His this \n\nis \n\na sample\n\nString\"\"\"\n\nhtml_paragraphs = text_to_html_paragraphs(text)\nprint(html_paragraphs)\n", "<p>is</p>\n<p>a sample</p>\n<p>String</p>\n"], ["dt_cols = df.select_dtypes(include=['datetime64[ns, UTC]']).columns\nfor col in dt_cols:\n        df[col] = df[col].dt.tz_localize(None)\ndf.to_excel(f'{table_name}.xlsx', engine=\"xlsxwriter\", index=False)\n"], [], ["def flatten(model):\n    submodules = list(model.children())\n    if len(submodules) == 0:\n        return [model]\n    else:\n        res = []\n        for module in submodules:\n            res += flatten(module)\n        return res\n"], [], ["import asyncio\nfrom asyncio import create_subprocess_shell\nfrom asyncio.subprocess import PIPE, STDOUT\nimport sys\n\nasync def main():\n    # create a subprocess in asyncio and connect its stdout to the stdin of another subprocess\n\n\n    p1 = await create_subprocess_shell(\"python myfile.py\",\n                                       stdout=PIPE, stderr=STDOUT)\n    while True:\n        if p1.stdout.at_eof():\n            break\n        stdout = (await p1.stdout.readline()).decode()\n        if stdout:\n            print(f'[stdout] {stdout}')\n    await p1.wait()\n"], ["for module_name, module in model.named_modules():\n    print(f\"module_name : {module_name} , value : {module}\")\n", "import torch\nmodel = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=True).to(device = device,non_blocking=True)\n\nfor module_name, module in model.named_modules():\n    print(f\"module_name : {module_name} , value : {module}\")\n", "conv1\nbn1\nlayer1\nlayer1.0\nlayer1.0.relu\nlayer1.0.conv2\nlayer1.0.bn2\nlayer1.1\nlayer1.1.conv2\nlayer1.1.bn2\n"], ["sudo apt install python3-pip\nsudo apt-get update\n", "sudo apt install python3.10-venv\n", "python3 -m venv venv\n"], ["year = 2023\nweek = 12\n\nstartdate = datetime.date.fromisocalendar(year, week, 1)\n\ndates = []\nfor i in range(7):\n   day = startdate + datetime.timedelta(days=i)\n   dates.append(day)\n", "[\n  \"2023-03-20\",\n  \"2023-03-21\",\n  \"2023-03-22\",\n  \"2023-03-23\",\n  \"2023-03-24\",\n  \"2023-03-25\",\n  \"2023-03-26\"\n]\n"], [], [], ["pip install pip==9.0.3\npip install --upgrade pip\n"], [], [], [], ["import os\n\nif __name__ == '__main__':\n    os.chdir(\".{0}your_program_folder\".format(os.sep))\n    os.system(\"your_program.exe\")\n", "dist\n|    your_program_launcher.exe\n|\n|____your_program_folder\n|       |_____lib1\n|       |_____lib2\n|       |_____libn\n|       |     your_program.exe\n"], ["sudo apt-get install libmysqlclient-dev\n", "pipenv install mysqlclient\n"], ["pd.concat([cap[['Ticker', 'Market Cap']].iloc[:1] for cap in collector] )\n"], [], [], ["def myfunc(arr):\n ignore_list = []\n newlist = []\n for i,v in enumerate(arr):\n     if v >= 6 and v <= 9:\n         ignore_list.append(i)\n     if i in ignore_list:\n         newlist.append(0)\n     else:\n         newlist.append(v)\n\n return sum(newlist)\n"], ["import os\nfrom PIL import Image\nfolder_path = r\"C:\\Users\\ImageDatasets\"\nextensions = []\ncorupt_img_paths=[]\nfor fldr in os.listdir(folder_path):\n    sub_folder_path = os.path.join(folder_path, fldr)\n    for filee in os.listdir(sub_folder_path):\n        file_path = os.path.join(sub_folder_path, filee)\n        print('** Path: {}  **'.format(file_path), end=\"\\r\", flush=True)\n        try:\n            im = Image.open(file_path)\n        except:\n            print(file_path)\n            os.remove(file_path)\n            continue\n        else:\n            rgb_im = im.convert('RGB')\n            if filee.split('.')[1] not in extensions:\n                extensions.append(filee.split('.')[1])\n"], ["import sys\nimport time\nfrom selenium import webdriver\nfrom selenium.webdriver.chrome.service import Service\nfrom selenium.webdriver.chrome.options import ChromiumOptions\nfrom webdriver_manager.chrome import ChromeDriverManager\n\nchrome_options = ChromiumOptions()\n\nservice = Service(ChromeDriverManager().install())\n\ndriver = webdriver.Chrome(chrome_options=chrome_options, service=service)\ndriver.get(\"http://www.python.org\")\n\ntime.sleep(sys.maxsize)\ndriver.quit()\n"], [], ["for x in range(4) : \n    if not flag: continue\n    defA()\n"], [" pip install 'paramiko<=2.8.1'\n"], [], [], [], ["for i in range(1, 5):\n    if i == 2: continue\n    print(i)\n"], ["from ..models.user_model import User as user_model\nmain = Blueprint('main', __name__)\n", "main = Blueprint('main', __name__)\n# always import models after blueprint object creation.\nfrom ..models.user_model import User as user_model\n"], ["from .a import A\nfrom .b import B\n", "from models.b import B\n\n...\n"], ["df['date'] = df['date'].astype(str)\n"], ["def getNumberOfObjectsInBucket(bucketName,prefix):\n    count = 0\n    response = boto3.client('s3').list_objects_v2(Bucket=bucketName,Prefix=prefix)\n    for object in response['Contents']:\n        if object['Size'] != 0:\n            #print(object['Key'])\n            count+=1\n    return count\n", "getNumberOfObjectsInBucket('foo-test-bucket','foo-output/')\n"], ["#write a file \nenter code here\nwrite_File=open(\"sample.txt\",\"w\")\nwrite_File.write(\"line1\\nline2\\nline3\\nline4\\nline5\\nline6\\n\")\nwrite_File.close()\n\n#open a file without new line of the characters\nopen_file=open(\"sample.txt\",\"r\")\nopen_new_File=open_file.read()\nreplace_string=open_new_File.replace(\"\\n\",.\" \")\nprint(replace_string,end=\" \")\nopen_file.close()\n", "line1 line2 line3 line4 line5 line6\n"], ["pyuic6 tip.ui > tip.py && sed -i '10iimport _cf_rc\\nimport _rc_rc' tip.py\n", "sed -i \"10i' -> means insert from the 10th line onwards.\n", "import _cf_rc\n\nimport _rc_rc\n"], ["def get_layers(model: torch.nn.Module):\n    children = list(model.children())\n    return [model] if len(children) == 0 else [ci for c in children for ci in get_layers(c)]\n"], ["model = model.to(\"cuda\")\ndata = data.to(\"cuda\")\n", "model.to(\"cuda\")\ndata.to(\"cuda\")\n"], [], [], ["#here is my approach:\nfor name, m in model.named_modules():\n    if len(list(m.named_modules()))==1:\n        print(name,\"\\t\",m)\n"], [], ["train_data = list(train_ds)\nfeatures = np.concatenate([train_data[n][0] for n in range(0, len(train_data))])\ntargets = np.concatenate([train_data[n][1] for n in range(0, len(train_data))])\n\n"], ["conda install pytorch==1.12.1 torchvision==0.13.1 torchaudio==0.12.1 cudatoolkit=10.2 -c pytorch\n", "conda install pytorch==1.12.1 torchvision==0.13.1 cudatoolkit=10.2 -c pytorch\n"], ["def get_access_token():\n    tenantID = 'abc'\n    authority = 'https://login.microsoftonline.com/' + tenantID\n    clientID = 'abc'\n    clientSecret = 'abc'\n    scope = ['https://outlook.office365.com/.default']\n    app = ConfidentialClientApplication(clientID, \n          authority=authority, \n          client_credential = clientSecret)\n    access_token = app.acquire_token_for_client(scopes=scope)\n    return access_token\n\ndef generate_auth_string(user, token):\n    auth_string = f\"user={user}\\1auth=Bearer {token}\\1\\1\"\n    return auth_string\n\n#IMAP AUTHENTICATE\n imap = imaplib.IMAP4_SSL(imap_host, 993)\n imap.debug = 4\n access_token = get_access_token_to_authenticate_imap()\n imap.authenticate(\"XOAUTH2\", lambda x:generate_auth_string(\n      'useremail',\n       access_token['access_token']))\n imap.select('inbox')\n"], [], ["import datetime\nimport yfinance as yf\nnow = datetime.datetime.now().strftime(\"%Y-%m-%d\")\ndata = yf.Ticker(\"ABEV3.SA\")\ndata = data.history(start=\"2010-01-01\",  end=now)\nprint(data)\n"], ["from enum import Enum, EnumMeta\n\n\nclass MetaEnum(EnumMeta):\n    def __contains__(cls, item):\n        try:\n            cls(item)\n        except ValueError:\n            return False\n        return True    \n\n\nclass BaseEnum(Enum, metaclass=MetaEnum):\n    pass\n\n\nclass Stuff(BaseEnum):\n    foo = 1\n    bar = 5\n", ">>> 1 in Stuff\nTrue\n\n>>> Stuff.foo in Stuff\nTrue\n\n>>> 2 in Stuff\nFalse\n\n>>> 2.3 in Stuff\nFalse\n\n>>> 'zero' in Stuff\nFalse\n"], [], [], [], ["pip install ipykernel\n", "pip install --upgrade nbformat\n"], [], ["Dotted two 4096x4096 matrices in 0.28 s.\nDotted two vectors of length 524288 in 0.11 ms.\nSVD of a 2048x1024 matrix in 0.44 s.\nCholesky decomposition of a 2048x2048 matrix in 0.07 s.\nEigendecomposition of a 2048x2048 matrix in 3.83 s.\n\nTOTAL TIME = 19 seconds\n"], ["sudo apt-get install python3-pip\n"], ["num1 = int(input())\nnum2 = int(input())\nnum3 = int(input())\n\nlowest = min(num1, num2, num3)\n\nif num1 < num2 and num1 < num3:\n    lowest = num1\n\nelif num2 < num1 and num2 < num3:\n    lowest = num2\n\nelif num3 < num1 and num3 < num2:\n    lowest = num3\n\nprint(lowest)\n"], [], ["    def  Salary_Msg(self):\n        #f is called function f\n        #next use {write in}\n        return f{self.firstname} {self.Lastname} earns AUD {self.Salary}per {self.Time} \"\n"], ["ssh_client.connect(\n  server, username=ssh_user, key_filename=ssh_keypath,\n  disabled_algorithms=dict(pubkeys=[\"rsa-sha2-512\", \"rsa-sha2-256\"]))\n", "Our pubkey algorithm list: ['ssh-rsa']\nServer did not send a server-sig-algs list; defaulting to our first preferred algo ('ssh-rsa')\nNOTE: you may use the 'disabled_algorithms' SSHClient/Transport init kwarg to disable that or other algorithms if your server does not support them!\n", " client.connect(hostname=self.hostname_sfp,\n                           username=self.user_sftp,\n                           password=self.password_sftp,\n                           port=self.port_sftp,\n                           disabled_algorithms=dict(pubkeys=[\"rsa-sha2-512\", \"rsa-sha2-256\"]),\n                           allow_agent=False,\n                           look_for_keys=False\n                           )\n"], ["import paramiko.transport\nif hasattr(paramiko.transport.Transport, '_preferred_pubkeys'):\n    pk = paramiko.transport.Transport._preferred_pubkeys\n    ssh_rsa_pos = pk.index('ssh-rsa')\n    if ssh_rsa_pos >= 0:\n        fixed_pk = [\n            x for x in pk[:ssh_rsa_pos]\n            if not x.startswith('rsa-sha2-')\n        ] + [\n            pk[ssh_rsa_pos]\n        ] + [\n            x for x in pk[:ssh_rsa_pos]\n            if x.startswith('rsa-sha2-')\n        ] + list(pk[ssh_rsa_pos + 1:])\n        paramiko.transport.Transport._preferred_pubkeys = tuple(fixed_pk)\n\n"], ["DISABLED_ALGORITHMS = {'keys': ['rsa-sha2-256', 'rsa-sha2-512'], 'pubkeys':['rsa-sha2-512', 'rsa-sha2-256']}\n", "from packaging import version\nif version.parse(paramiko.__version__) > version.parse(\"2.8.1\") and version.parse(paramiko.__version__) <= version.parse(\"2.12.0\"):\n    print(f\"Paramiko Version:{paramiko.__version__}\")\n    _preferred_pubkeys = (\n    \"ssh-ed25519\",\n    \"ecdsa-sha2-nistp256\",\n    \"ecdsa-sha2-nistp384\",\n    \"ecdsa-sha2-nistp521\",\n    \"ssh-rsa\",\n    \"rsa-sha2-512\",\n    \"rsa-sha2-256\",\n    \"ssh-dss\",\n    )\n    \n    print(f\"Patching _preferred_pubkeys {paramiko.transport.Transport._preferred_pubkeys} with {_preferred_pubkeys}\")\n    paramiko.transport.Transport._preferred_pubkeys = _preferred_pubkeys\n"], [], ["def get_sentinel():\n    ...\n", "from django.conf import settings\nfrom authentication.models_utils import get_sentinel\nfrom .room import Room\n\nclass Section(models.Model):\n...\n"], [], [], ["rcc -g python -o resources.py resources.qrc\n", "pyside6-rcc -o resources.py resources.qrc\n", "# Resource object code (Python 3)\n# Created by: object code\n# Created by: The Resource Compiler for Qt version 6.4.0\n# WARNING! All changes made in this file will be lost!\n\n# from PySide6 import QtCore <-- replace this line\nfrom PyQt6 import QtCore\n", "rcc -g python resources.qrc | sed '0,/PySide6/s//PyQt6/' > resources.py\n", "pyside6-rcc reources.qrc | sed '0,/PySide6/s//PyQt6/' > resources.py  \n", "from PyQt6 import QtCore, QtGui, QtWidgets\nfrom test_ui import Ui_Window\nimport resources\n\nclass Window(QtWidgets.QWidget, Ui_Window):\n    def __init__(self):\n        super().__init__()\n        self.setupUi(self)\n\nif __name__ == '__main__':\n\n    app = QtWidgets.QApplication(['Test'])\n    window = Window()\n    window.show()\n    app.exec()\n"], [], ["target_layers =[]\nmodule_list =[module for module in model.modules()] # this is needed\nflatted_list= flatten_model(module_list)\n\nfor count, value in enumerate(flatted_list):\n    \n    if isinstance(value, (nn.Conv2d,nn.AvgPool2d,nn.BatchNorm2d)):\n    #if isinstance(value, (nn.Conv2d)):\n        print(count, value)\n        target_layers.append(value)\n\n", "1 Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n2 BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n7 Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n8 BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n9 Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n10 BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n11 Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n12 BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n15 Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n16 BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n18 Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n19 BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n20 Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n21 BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n22 Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n23 BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n26 Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n27 BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n28 Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n29 BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n30 Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n31 BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n35 Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n36 BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n37 Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n38 BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n39 Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n40 BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n43 Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n44 BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n46 Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n47 BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n48 Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n49 BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n50 Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n51 BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n54 Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n55 BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n56 Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n57 BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n58 Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n59 BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n62 Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n63 BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n64 Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n65 BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n66 Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n67 BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n71 Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n72 BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n73 Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n74 BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n75 Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n76 BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n79 Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n80 BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n82 Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n83 BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n84 Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n85 BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n86 Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n87 BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n90 Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n91 BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n92 Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n93 BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n94 Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n95 BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n98 Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n99 BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n100 Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n101 BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n102 Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n103 BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n106 Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n107 BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n108 Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n109 BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n110 Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n111 BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n114 Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n115 BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n116 Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n117 BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n118 Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n119 BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n123 Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n124 BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n125 Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n126 BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n127 Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n128 BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n131 Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n132 BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n134 Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n135 BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n136 Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n137 BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n138 Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n139 BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n142 Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n143 BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n144 Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n145 BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n146 Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n147 BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n"], ["FROM python:3 as builder\nCOPY Pipfile* /\nRUN mkdir /.venv  # The presence of a .venv folder triggers pipenv to use it by default\nRUN pipenv install --deploy\n\nFROM python:3-slim\nCOPY --from=builder /.venv /.venv\nWORKDIR /myapp\nCOPY src .\nCMD [\"/.venv/bin/python3\", \"app.py\"]\n"], [], [], ["import numpy as np\nimport pandas as pd\nimport warnings\n\ndf = pd.DataFrame({\"price\": [11.1, 12.2]}, index=[\"book1\", \"book2\"])\noriginal_prices = df[\"price\"]\nnew_prices = np.array([98, 99])\nwith warnings.catch_warnings():\n    # Setting values in-place is fine, ignore the warning in Pandas >= 1.5.0\n    # This can be removed, if Pandas 1.5.0 does not need to be supported any longer.\n    # See also: https://stackoverflow.com/q/74057367/859591\n    warnings.filterwarnings(\n        \"ignore\",\n        category=FutureWarning,\n        message=(\n            \".*will attempt to set the values inplace instead of always setting a new array. \"\n            \"To retain the old behavior, use either.*\"\n        ),\n    )\n\n    df.iloc[:, 0] = new_prices\n\ndf.iloc[:, 0]\n"], [], ["New-ServicePrincipal -AppId <APPLICATION_ID> -ServiceId <OBJECT_ID> [-Organization <ORGANIZATION_ID>]\n", "import imaplib\nimport msal\nimport pprint\n\nconf = {\n    \"authority\": \"https://login.microsoftonline.com/XXXXyourtenantIDXXXXX\",\n    \"client_id\": \"XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXXX\", #AppID\n    \"scope\": ['https://outlook.office365.com/.default'],\n    \"secret\": \"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\", #Key-Value\n    \"secret-id\": \"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\", #Key-ID\n}\n    \ndef generate_auth_string(user, token):\n    return f\"user={user}\\x01auth=Bearer {token}\\x01\\x01\"    \n\nif __name__ == \"__main__\":\n    app = msal.ConfidentialClientApplication(conf['client_id'], authority=conf['authority'],\n                                             client_credential=conf['secret'])\n\n    result = app.acquire_token_silent(conf['scope'], account=None)\n\n    if not result:\n        print(\"No suitable token in cache.  Get new one.\")\n        result = app.acquire_token_for_client(scopes=conf['scope'])\n\n    if \"access_token\" in result:\n        print(result['token_type'])\n        pprint.pprint(result)\n    else:\n        print(result.get(\"error\"))\n        print(result.get(\"error_description\"))\n        print(result.get(\"correlation_id\"))\n        \n    imap = imaplib.IMAP4('outlook.office365.com')\n    imap.starttls()\n    imap.authenticate(\"XOAUTH2\", lambda x: generate_auth_string(\"target_mailbox@example.com\", result['access_token']).encode(\"utf-8\"))\n"], [], [], [], ["from azure.storage.blob import BlobClient,ContentSettings\n\nblob = BlobClient.from_connection_string(conn_str=connection_string, container_name=container_name, blob_name=\"my_blob9\")\nimage_content_setting = ContentSettings(content_type='image/jpeg')\n\nwith open(\"/content/sample_data/kanha.png\",\"rb\") as data:\n    blob.upload_blob(data,overwrite=True,content_settings=image_content_setting)\n"], ["enc = OneHotEncoder(categories = [[0, 1]], handle_unknown='ignore')\n"], ["def clean_class_dict(class_dict):\n    return_dict = dict(class_dict)\n    for key in list(return_dict.keys()):\n        if key[0] == \"_\":\n            del return_dict[key]\n    return return_dict\n\ndef item_in_enum_titles(item: str, enum: Enum):\n    enum_dict = clean_class_dict(enum.__dict__)\n    if item in enum_dict.keys():\n        return True\n    else:\n        return False\n"], ["def split_check(bill=0.0, people=0, tax_percentage=0.09, tip_percentage=0.15):\n    bill_per_diner = ((bill + ((tax_percentage * bill) + (tip_percentage * bill))) / people)\n    return bill_per_diner\n"], [], ["pip install pytz --upgrade\npip install tzdata --upgrade\n"], ["import json\nimport msal\n\nimport requests\n\nclient_id = '***'\nclient_secret = '***'\ntenant_id = '***'\nauthority = f\"https://login.microsoftonline.com/{tenant_id}\"\n\napp = msal.ConfidentialClientApplication(\n    client_id=client_id,\n    client_credential=client_secret,\n    authority=authority)\n\nscopes = [\"https://graph.microsoft.com/.default\"]\n\nresult = None\nresult = app.acquire_token_silent(scopes, account=None)\n\nif not result:\n    print(\n        \"No suitable token exists in cache. Let's get a new one from Azure Active Directory.\")\n    result = app.acquire_token_for_client(scopes=scopes)\n\n# if \"access_token\" in result:\n#     print(\"Access token is \" + result[\"access_token\"])\n\n\nif \"access_token\" in result:\n    userId = \"***\"\n    endpoint = f'https://graph.microsoft.com/v1.0/users/{userId}/sendMail'\n    toUserEmail = \"***\"\n    email_msg = {'Message': {'Subject': \"Test Sending Email from Python\",\n                             'Body': {'ContentType': 'Text', 'Content': \"This is a test email.\"},\n                             'ToRecipients': [{'EmailAddress': {'Address': toUserEmail}}]\n                             },\n                 'SaveToSentItems': 'true'}\n    r = requests.post(endpoint,\n                      headers={'Authorization': 'Bearer ' + result['access_token']}, json=email_msg)\n    if r.ok:\n        print('Sent email successfully')\n    else:\n        print(r.json())\nelse:\n    print(result.get(\"error\"))\n    print(result.get(\"error_description\"))\n    print(result.get(\"correlation_id\"))\n"], ["x = x.to(device, dtype=torch.float32)\n\ny = y.to(device, dtype=torch.float32)\n"], ["import os\nimport ssl, shutil, re, platform\nimport zipfile\nfrom urllib.request import urlopen\nfrom pathlib import Path\n\nimport difflib\n\n\ndef chrome_driver_url(latest=False):\n    def current_chrome_version():\n        CHROME_RELEASE_URL = \"https://sites.google.com/chromium.org/driver/downloads?authuser=0\"\n        try:\n            response = urlopen(CHROME_RELEASE_URL,context=ssl.SSLContext(ssl.PROTOCOL_TLS)).read()\n        except ssl.SSLError:\n            response = urlopen(CHROME_RELEASE_URL,).read()\n\n        downloading_version = re.findall(b\"ChromeDriver \\d{2,3}\\.0\\.\\d{4}\\.\\d+\", response)\n        downloading_version = [x.decode().split(\" \")[1] for x in downloading_version]\n        downloading_version.sort(key=lambda x: [int(i) if i.isdigit() else i for i in x.split('.')])\n        downloading_version.reverse()\n        osname = platform.system()\n        if osname == 'Darwin':\n            installpath = \"/Applications/Google\\ Chrome.app/Contents/MacOS/Google\\ Chrome\"\n            verstr = os.popen(f\"{installpath} --version\").read().strip('Google Chrome ').strip()\n            ver_to_download = difflib.get_close_matches(verstr, downloading_version)\n            ver_to_download = ver_to_download[0]\n            return ver_to_download\n        elif osname == 'Windows':\n            verstr = os.popen('reg query \"HKEY_CURRENT_USER\\Software\\Google\\Chrome\\BLBeacon\" /v version').read().strip().split(\" \")\n            verstr = verstr[-1]\n            ver_to_download = difflib.get_close_matches(verstr, downloading_version)\n            ver_to_download = ver_to_download[0]\n            return ver_to_download\n        elif osname == 'Linux':\n            installpath = \"/usr/bin/google-chrome\"\n            verstr = os.popen(f\"{installpath} --version\").read().strip('Google Chrome ').strip()\n            ver_to_download = difflib.get_close_matches(verstr, downloading_version)\n            ver_to_download = ver_to_download[0]\n            return ver_to_download\n        else:\n            raise NotImplemented(f\"Unknown OS '{osname}'\")\n\n    if latest:\n        CHROME_RELEASE_URL = \"https://sites.google.com/chromium.org/driver/downloads?authuser=0\"\n        try:\n            response = urlopen(CHROME_RELEASE_URL, context=ssl.SSLContext(ssl.PROTOCOL_TLS)).read()\n        except ssl.SSLError:\n            response = urlopen(CHROME_RELEASE_URL).read()\n\n        downloading_version = re.findall(b\"ChromeDriver \\d{2,3}\\.0\\.\\d{4}\\.\\d+\", response)[0].decode().split()[1]\n    else:\n        downloading_version = current_chrome_version()\n\n    system = platform.system()\n    if system == \"Windows\":\n        url = f\"https://chromedriver.storage.googleapis.com/{downloading_version}/chromedriver_win32.zip\"\n    elif system == \"Darwin\":\n        # M1\n        if platform.processor() == 'arm':\n            url = f\"https://chromedriver.storage.googleapis.com/{downloading_version}/chromedriver_mac64_m1.zip\"\n        else:\n            url = f\"https://chromedriver.storage.googleapis.com/{downloading_version}/chromedriver_mac64.zip\"\n    elif system == \"Linux\":\n        url = f\"https://chromedriver.storage.googleapis.com/{downloading_version}/chromedriver_linux64.zip\"\n    return url\n\n\ndef download_chrome_driver(drivers_dir):\n    driver_name = \"chromedriver.exe\" if platform.system() == \"Windows\" else \"chromedriver\"\n    if (drivers_dir / driver_name).exists():\n            return\n    url = chrome_driver_url()\n    try:\n        response = urlopen(url, context=ssl.SSLContext(ssl.PROTOCOL_TLS))  \n    except ssl.SSLError:\n        response = urlopen(url)  \n\n    zip_file_path = drivers_dir / Path(url).name\n    with open(zip_file_path, 'wb') as zip_file:\n        while True:\n            chunk = response.read(1024)\n            if not chunk:\n                break\n            zip_file.write(chunk)\n\n    extracted_dir = drivers_dir / zip_file_path.stem\n    with zipfile.ZipFile(zip_file_path, \"r\") as zip_file:\n        zip_file.extractall(extracted_dir)\n    os.remove(zip_file_path)\n\n    driver_path = drivers_dir / driver_name\n    try:\n        (extracted_dir / driver_name).rename(driver_path)\n\n    except FileExistsError:\n        (extracted_dir / driver_name).replace(driver_path)\n\n    shutil.rmtree(extracted_dir)\n    os.chmod(driver_path, 0o755)\n\nif __name__ == \"__main__\":\n    chrome_driver_location = Path(\"chrome_driver\")\n    chrome_driver_location.mkdir(exist_ok=True)\n    download_chrome_driver(chrome_driver_location)\n\n"], [], [], [], [], ["parameters = ['a', 'b', 'c', 'd', 'e', 'f']\ndf = pd.DataFrame(columns=parameters)\n", "        a   b   c   d   e   f\n", "new_row = pd.Series([1,2,3,4,5,6], index=parameters, name='row1')\ndf.append(new_row)\n", "        a   b   c   d   e   f\nrow1    1   2   3   4   5   6\n", "new_row = pd.DataFrame([1,2,3,4,5,6], columns=['row1'], index=parameters).T\ndf = pd.concat((df, new_row))\n"], ["conda create --name myenv python=3.6\nCollecting package metadata (current_repodata.json): done\nSolving environment: failed with repodata from current_repodata.json, will retry with next repodata source.\nCollecting package metadata (repodata.json): done\nSolving environment: failed\nPackagesNotFoundError: The following packages are not available from current channels:\n - python=3.6\n"], ["num1 = int(input())\nnum2 = int(input())\nnum3 = int(input())\n\nif (num1 <= num2 and num1 <= num3):\nsmall = num1\n\nelif (num2 <= num1 and num2 <= num3): \nsmall = num2\nelse:\nsmall = num3\nprint(small)\n"], ["for count in range(num_samples):\n    # .... code to produce `input_vars`\n    features = features.append(input_vars)        # remove this `DataFrame.append`\n", "tmp = []                                  # initialize list\nfor count in range(num_samples):\n    # .... code to produce `input_vars`\n    tmp.append(input_vars)                        # append to the list, (not DF)\nfeatures = pd.concat(tmp)                         # concatenate after loop\n"], ["apk add --no-cache python3 py3-pip\n"], [], ["FROM pypiserver/pypiserver:latest\nENTRYPOINT [\"/entrypoint.sh\", \"run\", \"--hash-algo\", \"sha256\"]\n"], ["model = torch.load(PATH).type(torch.FloatTensor).to(device)\ninput = input.type(torch.FloatTensor).to(device)\n"], ["def appendDictToDF(df,dictToAppend):\n  df = pd.concat([df, pd.DataFrame.from_records([dictToAppend])])\n  return df\n\n# Creating an empty dataframe\ndf = pd.DataFrame(columns=['a', 'b'])\n\n# Appending a row\ndf= appendDictToDF(df,{ 'a': 1, 'b': 2 })\n"], [], ["python3 -m pip install rpy2\n", "Error in glue(.Internal(R.home()), \"library\", \"base\", \"R\", \"base\", sep = .Platform$file.sep) : \n  4 arguments passed to .Internal(paste) which requires 3\nError: could not find function \"attach\"\nError: object '.ArgsEnv' not found\nFatal error: unable to initialize the JIT\n", "conda install --yes rpy2\n"], [], ["%timeit df['code'].values[-1].   )\n", "%timeit df.loc[df.index[-1], 'code']\n", "%timeit df['code'].iat[-1]\n\n", "%timeit df['code'].tail(1).item()\n", "%timeit df.iloc[-1, df.columns.get_loc('code')]\n", "%timeit df['code'].iloc[-1]\n"], ["return FileResponse(\n    temp_file,\n    background=BackgroundTask(cleanup, file_path),\n)\n"], ["type(train_ds)\n>> tensorflow.python.data.ops.dataset_ops.PrefetchDataset\n", "[(train_features, label_batch)] = train_ds.take(1)\nprint(np.array(label_batch))\n"], [], ["# Deprecated issue has been resolved\n\n# Creating an empty dataframe\ndf = pd.DataFrame(columns=['a', 'b'])\nprint(\"df columns:\", df)\n\n# Appending a row\ndf = df.append({ 'a': 1, 'b': 2 }, ignore_index=True)\nprint(\"df column Values :\", df)\n\n# Create the new row as its own dataframe\ndf_new_row = pd.DataFrame.from_records({ 'a': [3], 'b': [4] })\ndf = pd.concat([df, df_new_row])\nprint(\"pd concat with two df's :\", df)\n"], ["    driver.get(\"https://instagram.com/\")\n    time.sleep(7)\n    acpt = browser.find_element(by=By.XPATH, value='/html/body/div[1]/div/div/div/div[2]/div/div/div[1]/div/div[2]/div/div/div/div/div/div/div/div[3]/button[2]')\n    acpt.click()\n"], [], ["import os \\\nos.environ['R_HOME'] = '/usr/lib/R'\n"], [], [], [], ["RUN adduser -D dockuser\nUSER dockuser\n"], ["/home/me/.local/lib/python3.10/site-packages/cv2\n"], ["plt.imshow(white_torch.permute(1, 2, 0))\n", "import torch\nimport torchvision\nfrom torchvision.io import read_image\nimport torchvision.transforms as T\n\n!wget 'https://images.unsplash.com/photo-1553284965-83fd3e82fa5a?ixlib=rb-1.2.1&ixid=MnwxMjA3fDB8MHxleHBsb3JlLWZlZWR8NHx8fGVufDB8fHx8&w=1000&q=80'  -O white_horse.jpg\n\nwhite_torch = torchvision.io.read_image('white_horse.jpg')\n\nT.ToPILImage()(white_torch)\n"], ["df.index = df.index.tz_localize(None)\ndf.to_excel(path)\n"], [], ["model = MyModel()\n\nif torch.cuda.is_available():\n    model.cuda()\n"], [], ["from enum import Enum, EnumMeta\nfrom typing import Any\n\nclass EnumeratorMeta(EnumMeta):\n\n    def __contains__(cls, member: Any):\n        if type(member) == cls:\n            return EnumMeta.__contains__(cls, member)\n        else:\n            try:\n                cls(member)\n            except ValueError:\n                return False\n            return True\n\n\nclass Enumerator(Enum, metaclass=EnumeratorMeta):\n    pass\n\n\nclass ENTITY_TYPES(Enumerator):\n    SERVICE: str = 'service'\n    CONFIGMAP: str = 'configmap'\n"], ["In [6]: df['col1'].take([-1]).item()\nOut[6]: 3\n"], ["import yfinance as yf\nyca = yf.Ticker(\"YCA.L\").history(interval=\"1m\", period = \"1d\")\nyca['Close'][-1]\n"], ["obj_df_encoded = pd.get_dummies(obj_df)\nprint(obj_df)\n>> 1 0\n>> 0 1\n>> 0 0\n"], [], ["num1 = int(input())\nnum2 = int(input())\nnum3 = int(input())\n\nif (num1 < num2 and num1 < num3):\n    small = num1\n\nelif (num2 < num1 and num2 < num3): \n    small = num2\nelse:\n    small = num3\nprint(small)\n"], ["pattern=r\"\\b\\w*[aeiou]{3,}\\w*\\b\"\n"], [], [], ["stocks = ['PETR4.SA', 'ELET3.SA', 'VALE3.SA']\n\ndf = yf.download(' '.join(stocks), period='1d', progress=False)\ndf = df['Close']\n\nfor stock in stocks:\n    if stock not in df or len(df[stock]) == 0: # this verification is important if trading session is closed\n        continue\n    quote = df[stock][0]\n    print('%s = %.2f'%(stock, quote))\n\n"], [], ["def split_check(bill, people, tax = 0.09, tip = 0.15)\n", "def split_check(bill, people, tax = 0.09, tip = 0.15):\n    taxes = bill * tax\n    tips  = bill * tip\n    return (bill + taxes + tips) / people\n"], [], ["sudo virtualenv venv\n"], ["def split_check(bill=0, people=0, tax_percentage=0.09, tip_percentage=0.15):\n    new_check = (bill * tax_percentage) + bill\n    new_tip = bill * tip_percentage\n    per_person = (new_check + new_tip) / people\n    return per_person\n\nbill = float(input())\npeople = int(input())\n\n# Cost per diner at the default tax and tip percentages\nprint('Cost per diner:', split_check(bill, people))\n\nbill = float(input())\npeople = int(input())\nnew_tax_percentage = float(input())\nnew_tip_percentage = float(input())\n\n# Cost per diner at different tax and tip percentages\nprint('Cost per diner:', split_check(bill, people, new_tax_percentage, new_tip_percentage))\n"], ["date_columns = df.select_dtypes(include=['datetime64[ns, UTC]']).columns\nfor date_column in date_columns:\n    df[date_column] = df[date_column].apply(str)\n"], ["import re\ndef check_web_address(text):\n  pattern = r'\\.[comeduorginfoUSnetintmilgov]*$'\n  result = re.search(pattern, text)\n  return result != None\n\nprint(check_web_address('gmail.com')) # True\nprint(check_web_address('www.google')) # False\nprint(check_web_address('www.Coursera.org')) # True\nprint(check_web_address('web-address.com/homepage')) # False\nprint(check_web_address('My_Favorite-Blog.US')) # True\n"], ["returner = []\n\nif 6 and 9 in arr:        \n    \n    a = arr.index(6)    \n    b = arr.index(9)\n    \n    if a < b:\n        \n        seq = arr[a:(b+1)]\n\n        for i in arr:    \n            if i not in seq:\n                returner.append(i)\n        return (sum(returner))\n    \n    elif a > b:\n        \n        seq = arr[b:(a+1)]\n\n        for i in arr:    \n            if i not in seq:\n                returner.append(i)\n        return (sum(returner))\n\nelif 6 in arr:\n    \n    a = arr.index(6)\n    seq = arr[a:]\n    for i in arr:    \n        if i not in slicer:\n            returner.append(i)\n    return(sum(returner))\n\nelif 9 in arr:\n    a = arr.index(9)\n    seq = arr[a:]\n    for i in arr:    \n        if i not in slicer:\n            returner.append(i)\n    return(sum(returner))\n\nelif arr == []:\n    return 0\n\nelse:\n    return (sum(arr))\n"], ["\\b[\\w]+[aeiou]{3,}[\\w]+\\b\n"], [], [], ["if 6 in mylist:        \n    return sum(mylist) - sum(mylist[mylist.index(6):mylist.index(9)+1])\nelse:\n    return sum(mylist)\n"], [], ["from sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.pipeline import Pipeline\nimport numpy as np\n\ncategorical_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n    ('encoder', OneHotEncoder(handle_unknown='ignore'))])\n\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('cat', categorical_transformer, [0])\n    ])\n", "df = pd.DataFrame(['Male', 'Female', np.nan])\npreprocessor.fit_transform(df)\narray([[0., 1., 0.],\n       [1., 0., 0.],\n       [0., 0., 1.]])\n"], [], [], [], [], [], [], ["table = \"\".join([i for i in table if not i.isdigit()])\n"], ["char_nums = [chr for chr in table if chr.isdigit()]\n\nfor i in char_nums:\n    table = table.replace(i, \"\")\nprint(table)\n"], ["table = \"table1\"\ntable_temp =\"\"\nfor i in table:\n   if i not in \"0123456789\":\n      table_temp +=i\nprint(table_temp)\n"], ["table = \"table123\"\n\nfor i in table:\n    if i.isdigit():\n        table = table.replace(i, \"\")\nprint(table)\n"], ["table = \"table1\"\ntable = table.translate(\"\".maketrans(\"\",\"\",\"0123456789\"))\nprint(table) # table\n"], [], ["function_patterns = [\n\n    r'a\\.C&&\\(b=a\\.get\\(\"n\"\\)\\)&&\\(b=([^(]+)\\(b\\),a\\.set\\(\"n\",b\\)\\)}};',\n]\n", "function_patterns = [\n\n    r'a\\.[A-Z]&&\\(b=a\\.get\\(\"n\"\\)\\)&&\\(b=([^(]+)\\(b\\)',\n]\n", "python3 -m pip install --upgrade pytube\n"], ["r'a\\.[a-zA-Z]\\s*&&\\s*\\([a-z]\\s*=\\s*a\\.get\\(\"n\"\\)\\)\\s*&&\\s*'\n\nr'\\([a-z]\\s*=\\s*([a-zA-Z0-9$]{2,3})(\\[\\d+\\])?\\([a-z]\\)'\n", "r'a\\.[a-zA-Z]\\s*&&\\s*\\([a-z]\\s*=\\s*a\\.get\\(\"n\"\\)\\)\\s*&&\\s*\\([a-z]\\s*=\\s*([a-zA-Z0-9$]{2,3})(\\[\\d+\\])?\\([a-z]\\)'\n"], ["$ pyenv install 3.8.4\n", "% pyenv install 3.8.4\npython-build: use openssl@1.1 from homebrew\npython-build: use readline from homebrew\nDownloading Python-3.8.4.tar.xz...\n-> https://www.python.org/ftp/python/3.8.4/Python-3.8.4.tar.xz\nInstalling Python-3.8.4...\npatching file Misc/NEWS.d/next/Build/2021-10-11-16-27-38.bpo-45405.iSfdW5.rst\npatching file configure\npatching file configure.ac\npython-build: use tcl-tk from homebrew\npython-build: use readline from homebrew\npython-build: use zlib from xcode sdk\n\nBUILD FAILED (OS X 12.3.1 using python-build 20180424)\n\nInspect or clean up the working tree at /var/folders/5r/61nxx8hs53x6hhzm_r86jhjrq0r6qq/T/python-build.20220504193655.2344\nResults logged to /var/folders/5r/61nxx8hs53x6hhzm_r86jhjrq0r6qq/T/python-build.20220504193655.2344.log\n\nLast 10 log lines:\nchecking for python3... python3\nchecking for --enable-universalsdk... no\nchecking for --with-universal-archs... no\nchecking MACHDEP... \"darwin\"\nchecking for gcc... clang\nchecking whether the C compiler works... no\nconfigure: error: in `/var/folders/5r/61nxx8hs53x6hhzm_r86jhjrq0r6qq/T/python-build.20220504193655.2344/Python-3.8.4':\nconfigure: error: C compiler cannot create executables\nSee `config.log' for more details\nmake: *** No targets specified and no makefile found.  Stop.\n", " % pyenv install 3.8.4\npython-build: use openssl@1.1 from homebrew\npython-build: use readline from homebrew\nDownloading Python-3.8.4.tar.xz...\n-> https://www.python.org/ftp/python/3.8.4/Python-3.8.4.tar.xz\nInstalling Python-3.8.4...\npatching file Misc/NEWS.d/next/Build/2021-10-11-16-27-38.bpo-45405.iSfdW5.rst\npatching file configure\npatching file configure.ac\npython-build: use tcl-tk from homebrew\npython-build: use readline from homebrew\npython-build: use zlib from xcode sdk\nInstalled Python-3.8.4 to /Users/{USER}/.pyenv/versions/3.8.4\n"], ["!pip install -U yt-dlp\n", "!yt-dlp -f \"bestvideo[height<=1080][ext=mp4]+bestaudio[ext=m4a]/best[ext=mp4]/best\" \"https://www.youtube.com/watch?v=AWXvSBHB210\"\n"], [], [], [], [], ["import boto3\n\nbucket = \"Sample_Bucket\"\nfolder = \"Sample_Folder\"\ns3 = boto3.resource(\"s3\") \ns3_bucket = s3.Bucket(bucket)\nfiles_in_s3 = [f.key.split(folder + \"/\")[1] for f in s3_bucket.objects.filter(Prefix=folder).all()]\n"], ["$ clang --version\nApple clang version 11.0.3 (clang-1103.0.32.62)\nTarget: x86_64-apple-darwin21.4.0\nThread model: posix\nInstalledDir: /Library/Developer/CommandLineTools\n", "sudo mv /Library/Developer/CommandLineTools /Library/Developer/CommandLineTools.old\nsudo xcode-select --install\n", "$ clang --version\nApple clang version 13.0.0 (clang-1300.0.27.3)\nTarget: x86_64-apple-darwin21.4.0\nThread model: posix\nInstalledDir: /Library/Developer/CommandLineTools/usr/bin\n"], ["class BaseModel(models.Model):\n    ...\n", "from .models import BaseModel\n...\n", "from utils.models import BaseModel\n"], ["def summer_69(arr):\nif 9 in arr :\n    sum = 0 \n    y = arr.index(9)\n    for i , l in enumerate(arr):\n        if l == 6:\n            del arr[i:y+1]\n    for i in range(len(arr)):\n        sum = sum + arr[i]\n    return sum\nelif 9 not in arr:\n    sum = 0\n    for i in range(len(arr)):\n        sum = sum + arr[i]\n    return sum \n"], [], ["foo = pd.DataFrame({'id':[1,2,3,4,5,6,7,8,9,10],\n                   'var1':random.sample(range(1, 100), 10),\n                   'var2':random.sample(range(1, 100), 10),\n                   'var3':random.sample(range(1, 100), 10),\n                   'class': ['a','a','a','a','a','b','b','c','c','c']})\n\ncl_cols = foo.filter(regex='var').columns\nX_train, X_test, y_train, y_test = train_test_split(foo[cl_cols],\n                                                        foo[['class']],\n                                                        test_size=0.33, random_state=42)\n\n\nmodel = xgboost.XGBClassifier(objective=\"multi:softmax\")\nmodel.fit(X_train, y_train)\n\ndef get_ABS_SHAP(df_shap,df):\n    #import matplotlib as plt\n    # Make a copy of the input data\n    shap_v = pd.DataFrame(df_shap)\n    feature_list = df.columns\n    shap_v.columns = feature_list\n    df_v = df.copy().reset_index().drop('index',axis=1)\n    \n    # Determine the correlation in order to plot with different colors\n    corr_list = list()\n    for i in feature_list:\n        b = np.corrcoef(shap_v[i],df_v[i])[1][0]\n        corr_list.append(b)\n    corr_df = pd.concat([pd.Series(feature_list),pd.Series(corr_list)],axis=1).fillna(0)\n \n    # Make a data frame. Column 1 is the feature, and Column 2 is the correlation coefficient\n    corr_df.columns  = ['Variable','Corr']\n    corr_df['Sign'] = np.where(corr_df['Corr']>0,'red','blue')\n    \n    shap_abs = np.abs(shap_v)\n    k=pd.DataFrame(shap_abs.mean()).reset_index()\n    k.columns = ['Variable','SHAP_abs']\n    k2 = k.merge(corr_df,left_on = 'Variable',right_on='Variable',how='inner')\n    k2 = k2.sort_values(by='SHAP_abs',ascending = True)\n    \n    k2_f = k2[['Variable', 'SHAP_abs', 'Corr']]\n    k2_f['SHAP_abs'] = k2_f['SHAP_abs'] * np.sign(k2_f['Corr'])\n    k2_f.drop(columns='Corr', inplace=True)\n    k2_f.rename(columns={'SHAP_abs': 'SHAP'}, inplace=True)\n    \n    return k2_f\n\nfoo_all = pd.DataFrame()\n\nfor k,v in list(enumerate(model.classes_)):\n\n    foo = get_ABS_SHAP(shap_values[k], X_test)\n    foo['class'] = v\n    foo_all = pd.concat([foo_all,foo])\n\nimport plotly_express as px\npx.bar(foo_all,x='SHAP', y='Variable', color='class')\n"], ["shap.summary_plot(shap_values[0], X_test)\n"], ["apk add python3\n"], [], ["import yfinance as yf\n\ntickers = ['ABEV3.SA']\nfor ticker in tickers:\n    ticker_yahoo = yf.Ticker(ticker)\n    data = ticker_yahoo.history()\n    last_quote = data['Close'].iloc[-1]\n    print(ticker, last_quote)\n"], ["pip install --upgrade keras\npip install --upgrade tensorflow\n"], [], [], ["plt.imshow(  tensor_image.permute(1, 2, 0)  )\n"], ["[accelerate]\nlibraries = Accelerate, vecLib\n", "conda config --set pip_interop_enabled true\n"], [], ["docker exec -it your_docker_id bash\nbash-5.1# pip install tzdata\n"], ["conda install pytorch cudatoolkit=11.1 -c pytorch -c nvidia\n"], ["import zoneinfo\nzoneinfo.available_timezones()\n"], [], [], ["python rename_file.py --base-folder \"f:/tmp/s13/\"\n"], ["import os\n\n# Passing the path to your parent folders\npath = r'D:\\bat4'\n\n# Getting a list of folders with date names\nfolders = os.listdir(path)\n\nfor folder in folders:\n    files = os.listdir(r'{}\\{}'.format(path, folder))\n\n    # Accessing files inside each folder\n    for file in files:\n\n        # Getting the file extension\n        extension_pos = file.rfind(\".\")\n        extension = file[extension_pos:]\n\n        # Renaming your file\n        os.rename(r'{}\\{}\\{}'.format(path, folder, file),\n                  r'{}\\{}\\{}{}'.format(path, folder, folder, extension))\n"], ["import re\ndef check_web_address(text):\n  pattern = r'^[A-Za-z0-9-_+.]*[.][A-Za-z]*$'\n  result = re.search(pattern, text)\n  return result != None\n\nprint(check_web_address(\"gmail.com\")) # True\nprint(check_web_address(\"www@google\")) # False\nprint(check_web_address(\"www.Coursera.org\")) # True\nprint(check_web_address(\"web-address.com/homepage\")) # False\nprint(check_web_address(\"My_Favorite-Blog.US\")) # True\n"], ["import os\nimport sys\n\ndef rename_first_file_in_dir(dir_path, new_file_name, keep_extension = False):\n  for current_file_name in os.listdir(dir_path):\n    current_file_path = os.path.join(dir_path, current_file_name) # full or relative path to the file in dir\n    if not os.path.isfile(current_file_path):\n      break\n    # rename only base name of file to the name of directory\n    if keep_extension:\n      file_extension = os.path.splitext(current_file_name)[1]\n      if len(file_extension) > 0:\n        new_file_name = new_file_name + file_extension \n        \n    new_file_path = os.path.join(dir_path, new_file_name)\n    print(\"File \" + current_file_name + \" renamed to \" + new_file_name + \" in \" + os.path.basename(dir_path) + \" directory\");\n    os.rename(current_file_path, new_file_path)\n    # exit after first processed file\n    break\n\nif len(sys.argv) < 2:\n  print(\"Usage: python \" + os.path.basename(__file__) + \" <directory> [keep_files_extensions]\") # help for usage\n  exit(0)\nscan_dir = sys.argv[1]\nkeep_extension = False if len(sys.argv) < 3 else not (int(sys.argv[2]) == 0) # optional parameter 0 - False, 1 - True, by default - False\nif not os.path.exists(scan_dir):\n  print(\"Error: directory \" + scan_dir + \" does not exists\")\n  exit(-1)\nif not os.path.isdir(scan_dir):\n  print(\"Error: file \" + scan_dir + \" is not a directory\")\n  exit(-1)\nprint(\"Scanning directory \" + scan_dir)\nfor file_name in os.listdir(scan_dir): # walk through directory\n  file_path = os.path.join(scan_dir, file_name)\n  if os.path.isdir(file_path):\n    rename_first_file_in_dir(file_path, file_name, keep_extension)\n"], [], [], ["df = pd.concat([df, pd.DataFrame.from_records([{ 'a': 1, 'b': 2 }])])\n", "df.loc[len(df), ['a','b']] = 1, 2\n", "df.loc[len(df), df.columns] = 3, 4\n"], [], ["import re\ndef check_web_address(text):\n  pattern = r'^[\\w\\-+.]+\\.[a-zA-z]+$'\n  result = re.search(pattern, text)\n  return result != None\n\nprint(check_web_address(\"gmail.com\")) # True  \nprint(check_web_address(\"www@google\")) # False.  \nprint(check_web_address(\"www.Coursera.org\")) # True\nprint(check_web_address(\"web-address.com/homepage\")) # False.    \nprint(check_web_address(\"My_Favorite-Blog.US\")) # True\n"], ["features= pd.concat([features, input_vars])\n"], [], ["apk add python3=~3.8\n"], ["def count_letters(text):\n  result = {}\n  # Go through each letter in the text\n  for letter in text:\n    # Check if the letter needs to be counted or not\n    if letter .isalpha() and letter not in result:\n    # Add or increment the value in the dictionary\n      result[letter.lower()]=text.lower().count(letter)\n  return result\n\nprint(count_letters(\"AaBbCc\"))\n# Should be {'a': 2, 'b': 2, 'c': 2}\n\nprint(count_letters(\"Math is fun! 2+2=4\"))\n# Should be {'m': 1, 'a': 1, 't': 1, 'h': 1, 'i': 1, 's': 1, 'f': 1, 'u': 1, 'n': 1}\n\nprint(count_letters(\"This is a sentence.\"))\n# Should be {'t': 2, 'h': 1, 'i': 2, 's': 3, 'a': 1, 'e': 3, 'n': 2, 'c': 1}\n"], ["def summer69(a):\n    for z in a:\n        if z==6 and 9 in a:\n           x=a.index(6)\n           y=a.index(9)\n           del a[x:y+1]\n           t= sum(a)\n        else:\n           t=sum(a)\n    return t\n"], [], ["from django.conf.urls import url\n", "from django.urls import re_path as url\n"], [], [], ["df = pd.Series(dic)\ndf_expected = pd.Series(dic_expected)\nassert_series_equal(df, df_expected, rtol=1e-05)\n"], ["# use an alias so I don't have to remember to avoid using \"approx\" as a variable name\nfrom pytest import approx as pytest_approx\n\n\ndef is_primitive(x):\n    return x is None or type(x) in (int, float, str, bool)\n\n\ndef approx_equal(A, B, absolute=1e-6, relative=1e-6, enforce_same_type=False):\n    if enforce_same_type and type(A) != type(B) and not is_primitive(A):\n        # I use `not is_primitive(A)` to enforce the same type only for data structures\n        return False\n\n    try:\n        is_approx_equal = (A == pytest_approx(B, rel=relative, abs=absolute))\n    except TypeError:\n        is_approx_equal = False\n\n    if is_approx_equal:\n        # pytest_approx() can only compare primitives and non-nested data structures correctly\n        # If the data structures are nested, then approx_equal() will try one of the other branches\n        return True\n    elif is_primitive(A) or is_primitive(B):\n        return False\n    elif isinstance(A, set) or isinstance(B, set):\n        # if any of the data structures is a set, convert both of them to a sorted list, but return False if the length has changed\n        len_A, len_B = len(A), len(B)\n        A, B = sorted(A), sorted(B)\n        if len_A != len(A) or len_B != len(B):\n            return False\n\n        for i in range(len(A)):\n            if not approx_equal(A[i], B[i], absolute, relative):\n                return False\n\n        return True\n    elif isinstance(A, dict) and isinstance(B, dict):\n        for k in A.keys():\n            if not approx_equal(A[k], B[k], absolute, relative):\n                return False\n\n        return True\n    elif (isinstance(A, list) or isinstance(A, tuple)) and (isinstance(B, list) or isinstance(B, tuple)):\n        for i in range(len(A)):\n            if not approx_equal(A[i], B[i], absolute, relative):\n                return False\n\n        return True\n    else:\n        return False\n\n\nprint(approx_equal([1], {1.000001}, enforce_same_type=True)) # False\nprint(approx_equal([1], {1.000001}, enforce_same_type=False)) # True\n\nprint(approx_equal([123.001, (1,2)], [123, (1,2)])) # False\nprint(approx_equal([123.000001, (1,2)], [123, (1,2)])) # True\n\nprint(approx_equal({'a': {'b': 1}, 'c': 3.141592}, {'a': {'b': 1.0000005}, 'c': 3.1415})) # False\nprint(approx_equal({'a': {'b': 1}, 'c': 3.141592}, {'a': {'b': 1.0000005}, 'c': 3.141592})) # True\n"], ["def summer_69(arr):\nresult=0\nreduction =0\nfor i in range(0,len(arr)):\n    result+=arr[i]\n    if arr[i] == 6:\n        temp = arr[arr.index(6):arr.index(9)+1]\n        reduction = sum(temp)\nreturn result - reduction\n"], ["import os\nos.environ['R_HOME'] = '/Users/<your user>/anaconda3/envs/<env name>/lib/R'\n\n# import your desired module\nfrom rpy2.robjects.packages import importr\n"], [], ["def count_letters(text):\n  result = {}\n  # Go through each letter in the text\n  text_lower=text.lower()\n  # Go through each letter in the text\n  for letter in text_lower:\n    # Check if the letter needs to be counted or not\n    if letter.isalpha() and letter != \" \":\n      if letter not in result:\n        result[letter] = 0  \n    # Add or increment the value in the dictionary\n      result[letter] += 1\n  return result\n"], [], ["pattern = r\".*\\.[A-Za-z]{1,3}.$\"\n"], [], [], ["count = 0\nclient = boto3.client('s3')\npaginator = client.get_paginator('list_objects')\nfor result in paginator.paginate(Bucket='your-bucket', Prefix='your-folder/', Delimiter='/'):\n    count += len(result.get('CommonPrefixes'))\n"], [], ["ssh_client.connect(\n  server, username=ssh_user, key_filename=ssh_keypath,\n  disabled_algorithms=dict(pubkeys=[\"rsa-sha2-512\", \"rsa-sha2-256\"]))\n"], [], ["from django.urls import include, re_path\n\nfrom myapp.views import home\n\nurlpatterns = [\n    re_path(r'^$', home, name='home'),\n    re_path(r'^myapp/', include('myapp.urls'),\n]\n", "from django.urls import include, path\n\nfrom myapp.views import home\n\nurlpatterns = [\n    path('', home, name='home'),\n    path('myapp/', include('myapp.urls'),\n]\n"], ["import pygame\nimport pygame.font\npygame.init()\n\n# Colours\nBLACK   = (  0,  0,  0)\nWHITE   = (255,255,255)\nGREEN   = (  0,255,  0)\nRED     = (255,  0,  0)\nBLUE    = (  0,  0,255)\n\n# Dimensions of screen\nsize = (400,500)\nWIDTH = 500\nHEIGHT = 400\nscreen = pygame.display.set_mode(size)\n\n# Loop Switch\ndone = False\n\n# Screen Update Speed (FPS)\nclock = pygame.time.Clock()\n\n# ------- Main Program Loop -------\nwhile not done:\n    # --- Main Event Loop ---\n    for event in pygame.event.get():\n        if event.type == pygame.QUIT:\n            done = True\n\n    #In each case you draw the rectangle and then fill the screen with green\n\n    pygame.draw.rect(screen,(78,203,245),(0,0,250,500),5)\n    pygame.display.flip()\n\n    screen.fill(GREEN)\n    \n\n    #Setting FPS\n    clock.tick(60)\n\n#Shutdown\npygame.quit()\n"], ["python3 -m pip install pyqt6rc\n"], ["sudo apt install python3-virtualenv\npip install virtualenv\n", "edd@rob:/tmp$ mkdir venvdemo\nedd@rob:/tmp$ cd venvdemo/\nedd@rob:/tmp/venvdemo$ virtualenv -p python3 venv\ncreated virtual environment CPython3.9.5.final.0-64 in 162ms\n  creator CPython3Posix(dest=/tmp/venvdemo/venv, clear=False, no_vcs_ignore=False, global=False)\n  seeder FromAppData(download=False, pip=bundle, setuptools=bundle, wheel=bundle, via=copy, app_data_dir=/home/edd/.local/share/virtualenv)\n    added seed packages: pip==20.3.4, pkg_resources==0.0.0, setuptools==44.1.1, wheel==0.34.2\n  activators BashActivator,CShellActivator,FishActivator,PowerShellActivator,PythonActivator,XonshActivator\nedd@rob:/tmp/venvdemo$ \nedd@rob:/tmp/venvdemo$ ls -a \n.  ..  venv\nedd@rob:/tmp/venvdemo$ ls -a venv/\n.  ..  bin  .gitignore  lib  pyvenv.cfg\nedd@rob:/tmp/venvdemo$ \n"], ["python3 -m venv ./some_env\n"], ["python3 -m venv ./desired_name_of_env\n"], ["D:\njupyter notebook\n"], [], ["points = (point1, point2, point3, point3D)\nxs = [point.x for point in points]\nys = [point.y for point in points]\n\nfig, ax = plt.subplots()\nax.set_aspect('equal')\nax.scatter(xs, ys)\n", "(array('d', [3.0, 2.0, 9.0]), array('d', [6.0, -1.0, 4.0]))\n", "ax.plot(line.xy[0], line.xy[1])\nax.plot(*line.xy) # Equivalent\n", "import numpy as np\nfrom matplotlib.path import Path\nfrom matplotlib.patches import PathPatch\nfrom matplotlib.collections import PatchCollection\n\n\n# Plots a Polygon to pyplot `ax`\ndef plot_polygon(ax, poly, **kwargs):\n    path = Path.make_compound_path(\n        Path(np.asarray(poly.exterior.coords)[:, :2]),\n        *[Path(np.asarray(ring.coords)[:, :2]) for ring in poly.interiors])\n\n    patch = PathPatch(path, **kwargs)\n    collection = PatchCollection([patch], **kwargs)\n    \n    ax.add_collection(collection, autolim=True)\n    ax.autoscale_view()\n    return collection\n", "from shapely.geometry import Polygon\nimport matplotlib.pyplot as plt\n\n\n# Input polygon with two holes\n# (remember exterior point order is ccw, holes cw else\n# holes may not appear as holes.)\npolygon = Polygon(shell=((0,0),(10,0),(10,10),(0,10)),\n                  holes=(((1,3),(5,3),(5,1),(1,1)),\n                         ((9,9),(9,8),(8,8),(8,9))))\n\nfig, ax = plt.subplots()\nplot_polygon(ax, polygon, facecolor='lightblue', edgecolor='red')\n"], ["jupyter lab --notebook-dir=E:/\n"], ["FROM python:3.9-alpine\n\nWORKDIR /myapp\nCOPY Pipfile Pipfile.lock ./\n\nRUN \\\n  # Install dependencies\n  && pip install --no-cache-dir micropipenv[toml] \\\n  && micropipenv install --deploy \\\n  && pip uninstall -y micropipenv[toml]\n\nCOPY src .\nCMD [\"python3\", \"app.py\"]\n"], [], [], ["from aiogram import Bot, Dispatcher, executor\n\nbot = Bot(token='your_api_token')\ndp = Dispatcher(bot)\n\nasync def notify_message() # THIS FUNCTION\n  # await bot.sendMessage(chat.id, 'Bot Started')\n  await print('Hello World')\n\n@dp.message_handler()\nasync def echo(message: types.Message):\n  await message.answer(message.text)\n\nif __name__ == '__main__':\n    executor.start(dp, notify_message())\n    executor.start_polling(dp, skip_updates=True)\n"], [], ["sudo python3 -m pip install -U pip\nsudo python3 -m pip install -U setuptools\n", "# Within the venv\npip3 install -U pip\npip3 install -U setuptools\n"], ["def count_letters(text):\n  result = {}\n  # Go through each letter in the text\n  for letter in text:\n    # Check if the letter needs to be counted or not\n    if letter.isalpha():\n      result[letter.lower()]=result.get(letter.lower(),0)+1\n    # Add or increment the value in the dictionary\n  return result\n\nprint(count_letters(\"AaBbCc\"))\n# Should be {'a': 2, 'b': 2, 'c': 2}\n\nprint(count_letters(\"Math is fun! 2+2=4\"))\n# Should be {'m': 1, 'a': 1, 't': 1, 'h': 1, 'i': 1, 's': 1, 'f': 1, 'u': 1, 'n': 1}\n\nprint(count_letters(\"This is a sentence.\"))\n# Should be {'t': 2, 'h': 1, 'i': 2, 's': 3, 'a': 1, 'e': 3, 'n': 2, 'c': 1}\n"], ["def count_letters(text):\n  result = {}\n  # Go through each letter in the text\n  for letter in text.lower():\n    # Check if the letter needs to be counted or not\n     if letter.isalpha() and letter not in result:\n       result[letter] = text.lower().count(letter)\n  return result\n\nprint(count_letters(\"AaBbCc\"))\n# Should be {'a': 2, 'b': 2, 'c': 2}\n\nprint(count_letters(\"Math is fun! 2+2=4\"))\n# Should be {'m': 1, 'a': 1, 't': 1, 'h': 1, 'i': 1, 's': 1, 'f': 1, 'u': 1, 'n': 1}\n\nprint(count_letters(\"This is a sentence.\"))\n# Should be {'t': 2, 'h': 1, 'i': 2, 's': 3, 'a': 1, 'e': 3, 'n': 2, 'c': 1}\n"], [], ["def upload_file(remote_path,local_path):\n    try:\n        blobService = BlockBlobService(account_name=SETTINGS.AZURE_ACCOUNT_NAME, account_key=SETTINGS.AZURE_ACCOUNT_KEY)\n        blobService.create_blob_from_path('data',remote_path,local_path)\n    except Exception as e:\n        logger.error(f'Unable to save azure blob data. {str(e)}')\n        raise Exception(f'Unable to save azure blob data. {str(e)}')\n"], [], ["$ sudo usermod -aG docker $(whoami)\n"], ["xnys = xcals.get_calendar(\"XNYS\", start=import_start, end=import_end)\nholidays = pd.to_datetime(xnys.day.holidays)\nholiday_mask= (holidays > import_start) & (holidays <= import_end)\nhols = holidays[holiday_mask].strftime(\"%Y-%m-%d\").tolist()\n", "fig = go.Figure(data=[go.Candlestick(x=df['date'], open=df['Open'], high=df['High'], low=df['Low'], close=df['Close'])])\n    fig.update_xaxes(\n        rangeslider_visible=True,\n        rangebreaks=[\n            # NOTE: Below values are bound (not single values), ie. hide x to y\n            dict(bounds=[\"sat\", \"mon\"]),  # hide weekends, eg. hide sat to before mon\n            dict(bounds=[16, 9.5], pattern=\"hour\"),  # hide hours outside of 9.30am-4pm\n            dict(values=hols)  # hide market holidays inside your date range\n        ]\n    )\n    fig.update_layout(\n        title='Stock Analysis',\n        yaxis_title=f'{symbol} Stock'\n    )\n\n    fig.show()\n"], [], ["# python3\nimport sys\n\ndef compute_min_refills(distance, tank, stops):\n    capacity_tank = tank\n    refill = 0\n\n    if capacity_tank >= distance:\n        return 0\n    if capacity_tank < stops[0] or (distance-stops[-1]) > capacity_tank:\n        return -1\n\n    for i in range(1, len(stops)):\n        if (stops[i]-stops[i-1]) > capacity_tank:\n            return -1\n        if stops[i] > tank:\n            tank = (stops[i-1] + capacity_tank)\n            refill += 1\n    if distance > tank:\n        refill += 1\n\n    return refill\n\n\n    if __name__ == '__main__':\n        d, m, _, *stops = map(int, sys.stdin.read().split())\n        print(compute_min_refills(d, m, stops))\n"], ["sudo apt install -y python3-dev libmysqlclient-dev libssl-dev\n"], ["brew reinstall python@3.9\n", "pip3 install numpy\npip3 install matplotlib \npip3 install opencv-contrib-python\n", "import cv2 \nprint(cv2.__version__)\n"], ["class Action(Enum):\n    NEW_CUSTOMER = 1\n    LOGIN = 2\n    BLOCK = 3\n\naction = 'new_customer'\ntry:\n    action = Action[action.upper()]\n    print(\"action type exists\")\nexcept KeyError:\n    print(\"action type doesn't exists\")\n"], ["dev = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n", "dev=torch.device(\"cuda\") \n", "dev=\"cuda\"\n", "model.to(dev)\ndata = data.to(dev)\n"], ["!pip install nbformat \n"], ["import numpy as np\nimport shapely.geometry as sg\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\n\n\ndef add_polygon_patch(coords, ax, fc='blue'):\n    patch = patches.Polygon(np.array(coords.xy).T, fc=fc)\n    ax.add_patch(patch)\n\n\nborder = [(-10, -10), (-10, 10), (10, 10), (10, -10)]  # Large square\nholes = [\n    [(-6, -2), (-6, 2), (-2, 2), (-2, -2)],  # Square hole\n    [(2, -2), (4, 2), (6, -2)]               # Triangle hole\n]\nregion = sg.Polygon(shell=border, holes=holes)\n\nfig, ax = plt.subplots(1, 1)\n\nadd_polygon_patch(region.exterior, ax)\nfor interior in region.interiors:\n    add_polygon_patch(interior, ax, 'white')\n        \nax.axis('equal')\nplt.show()\n"], ["\n  - opencv -> python[\nversion='\n>=2.7,<2.8.0a0\n>=3.5,<3.6.0a0\n>=3.6,<3.7.0a0\n>=3.7,<3.8.0a0']\n"], [], [], ["{\n\"python.testing.unittestArgs\": [\n    \"-v\",\n    \"-s\",\n    \".\",\n    \"-p\",\n    \"test_*.py\"\n],\n\"python.testing.pytestEnabled\": false,\n\"python.testing.nosetestsEnabled\": false,\n\"python.testing.unittestEnabled\": true,\n\"python.pythonPath\": \"/Users/hhh/project/bin/python\"\n}\n"], [], [], ["def count_letters(text):\n  result = {}\n  for letter in text:\n    #check if it alphabet or something else\n    # Check if the letter needs to be counted or not\n    if letter.isalpha():\n      result[letter.lower()]=result.get(letter.lower(),0)+1\n    # Add or increment the value in the dictionary\n  return result\n", "print(count_letters(\"AaBbCc\"))\n# Should be {'a': 2, 'b': 2, 'c': 2}\n", "print(count_letters(\"Math is fun! 2+2=4\"))\n# Should be {'m': 1, 'a': 1, 't': 1, 'h': 1, 'i': 1, 's': 1, 'f': 1, 'u': 1, 'n': 1}\n", "print(count_letters(\"This is a sentence.\"))\n# Should be {'t': 2, 'h': 1, 'i': 2, 's': 3, 'a': 1, 'e': 3, 'n': 2, 'c': 1}\n"], ["def  count_letters(text):\n    result = {}\n    for letter in text.lower():\n        if letter == \" \" or letter.isalpha() == False:\n            continue:\n        if letter not in result:\n            result[letter] = 0\n        result[letter] += 1\n    return result\n"], [], ["from selenium import webdriver\nimport requests\nimport zipfile\nimport wget\nimport subprocess\nimport os\n\n\nCHROMEDRIVER_PATH =  # Insert your Chromedriver path here\nCHROMEDRIVER_FOLDER = os.path.dirname(CHROMEDRIVER_PATH)\nLATEST_DRIVER_URL = \"https://chromedriver.storage.googleapis.com/LATEST_RELEASE\"\n\n\ndef download_latest_version(version_number):\n    print(\"Attempting to download latest driver online......\")\n    download_url = \"https://chromedriver.storage.googleapis.com/\" + version_number + \"/chromedriver_win32.zip\"\n    # download zip file\n    latest_driver_zip = wget.download(download_url, out=CHROMEDRIVER_FOLDER)\n    # read & extract the zip file\n    with zipfile.ZipFile(latest_driver_zip, 'r') as downloaded_zip:\n        # You can chose the folder path to extract to below:\n        downloaded_zip.extractall(path=CHROMEDRIVER_FOLDER)\n    # delete the zip file downloaded above\n    os.remove(latest_driver_zip)\n\n\ndef check_driver():\n    # run cmd line to check for existing web-driver version locally\n    cmd_run = subprocess.run(\"chromedriver --version\",\n                             capture_output=True,\n                             text=True)\n    # Extract driver version as string from terminal output\n    local_driver_version = cmd_run.stdout.split()[1]\n    print(f\"Local driver version: {local_driver_version}\")\n    # check for latest chromedriver version online\n    response = requests.get(LATEST_DRIVER_URL)\n    online_driver_version = response.text\n    print(f\"Latest online chromedriver version: {online_driver_version}\")\n    if local_driver_version == online_driver_version:\n        return True\n    else:\n        download_latest_version(online_driver_version)\n"], ["pip install jupyterlab\n", "Command \"python setup.py egg_info\" failed with error code 1 in /private/tmp/pip-build-p0u6Wd/jupyterlab\n", "$ pip --version\npip 6.1.1 from /Library/Python/2.7/site-packages (python 2.7)\n\n$ pip3 --version\npip 21.2.4 from /usr/local/lib/python3.9/site-packages/pip (python 3.9)\n", "pip3 install jupyterlab\n"], [], ["def count_letters(text):\n    result = {}\n    text = text.lower().replace(\" \",\"\")\n    text = text.replace(\"\", \" \").split()\n    dummy = []\n    dummy1 = \"\"\n\n    for x in text: # remove non-letter\n        if x.isalpha():\n            dummy.append(x)\n            dummy1 = \"\".join(dummy)\n\n    for letter in dummy1:\n        if letter not in result:\n            result[letter] = 0\n        result[letter] += 1\n    return result\n\nprint(count_letters(\"AaBbCc\"))\nprint(count_letters(\"Math is fun! 2+2=4\"))\nprint(count_letters(\"This is a sentence.\"))\n"], ["mypackage/\n  subpackage/\n    __init__.py\n    helper.py\n  main/\n    work.py\n"], ["def summer_69(arr):\n\n#first find out if 6 or 9 are in the list\n\nif 6 in arr and 9 in arr:\n\n#Then create a variable that stores the index location of the number 6 \n#and the number 9\n\n        sixer = arr.index(6)\n        niner = arr.index(9)\n\n#now return the sum of the array minus the sum of the values between \n#index of 6 and index of 9 inclusive (hence the plus 1)\n#This way will ignore the case of a 9 appearring before a 6 too.\n\n        return sum(arr) - sum(arr[sixer:niner+1])\n\n#Otherwise just return the sum of the array.\n\nelse:\n    return sum(arr)\n"], ["def summer_69(arr):\ntotal = 0\nadd = True\nfor num in arr:\n    while add:\n        if num != 6:\n            total += num\n            break\n        else:\n            add = False\n    while not add:\n        if num != 9:\n            break\n        else:\n            add = True\n            break\nreturn total\n"], [], ["jupyter lab --notebook-dir=D:/\n"], ["jupyter notebook --notebook-dir=F:/\n"], ["import datetime\n\ndef week_to_dates():\n    date = datetime.date.today()\n    week = date.strftime(\"%V\")\n\n    candidates = [date - datetime.timedelta(days=k) for k in range(14, 0, -1)] + \\\n                 [date] + \\\n                 [date + datetime.timedelta(days=k) for k in range(1, 15)]\n    return [candidate.strftime('%Y-%m-%d') for candidate in candidates if candidate.strftime(\"%V\") == week]\n"], [], ["def summer_69(lst):\n    it = iter(lst)\n    return sum(x for x in it\n               if x != 6 or 9 not in it)\n", "def summer_69(lst):\n    it = iter(lst)\n    total = 0\n    for x in it:\n        if x == 6:\n            9 in it\n        else:\n            total += x\n    return total\n", "30 out of 30 tests correct\n\n303045 us  303714 us  304335 us  306007 us  309986 us  summer_69_Accepted\n   444 us     446 us     464 us     478 us     527 us  summer_69_Kelly1\n   442 us     448 us     453 us     465 us     500 us  summer_69_Kelly2\n", "from timeit import repeat\n\ndef summer_69_Accepted(lst):\n    copyoflist = lst[:] # makes shallow copy of list\n    while True:\n        if 6 not in copyoflist:\n            return sum(copyoflist)\n\n        indexof6 = copyoflist.index(6)\n        indexof9 = copyoflist.index(9, indexof6+1) # begin search for 9 after 6\n        del copyoflist[indexof6:indexof9+1] \n\ndef summer_69_Kelly1(lst):\n    it = iter(lst)\n    return sum(x for x in it\n               if x != 6 or 9 not in it)\n\ndef summer_69_Kelly2(lst):\n    it = iter(lst)\n    total = 0\n    for x in it:\n        if x == 6:\n            9 in it\n        else:\n            total += x\n    return total\n\nfuncs = summer_69_Accepted, summer_69_Kelly1, summer_69_Kelly2\n\nfrom random import randrange, choices\n\ndef testcase():\n    def others():\n        return choices([0, 1, 2, 3, 4, 5, 7, 8], k=randrange(10))\n    lst = others()\n    for _ in range(10):\n        lst += [6, *others(), 9, *others()]\n    return lst\n\ntests = correct = 0\nfor _ in range(10):\n    lst = testcase()\n    expect = funcs[0](lst.copy())\n    for func in funcs:\n        result = func(lst.copy())\n        correct += result == expect\n        tests += 1\nprint(correct, 'out of', tests, 'tests correct')\nprint()\n\nlst = [1] * 5000 + [6, 9] * 2500\nfor func in funcs:\n    times = repeat(lambda: func(lst), number=1)\n    print(*('%6d us ' % (t * 1e6) for t in sorted(times)), func.__name__)\n"], ["symbol = \"AAPL\"\nstock = yf.Ticker(symbol)\nlatest_price = stock.history(period='1d')['Close'][0]\n\n# Completely optional but I recommend having some sort of round(er?).\n# Dealing with 148.60000610351562 is a pain.\nestimate = round(latest_price, 2) \n\nprint (estimate)\n"], [], ["pip install chromedriver-autoinstaller\n", "Just type import chromedriver_autoinstaller in the module you want to use chromedriver.\n", "from selenium import webdriver\nimport chromedriver_autoinstaller\n\n\nchromedriver_autoinstaller.install()  # Check if the current version of chromedriver exists\n                                      # and if it doesn't exist, download it automatically,\n                                      # then add chromedriver to path\n\ndriver = webdriver.Chrome()\ndriver.get(\"http://www.python.org\")\nassert \"Python\" in driver.title\n"], ["{'conv1': Conv2d(...),\n 'bn1': BatchNorm2d(...),\n 'block1':{\n    'group1':{\n        'conv1': Conv2d(...),\n        'bn1': BatchNorm2d(...),\n        'conv2': Conv2d(...),\n        'bn2': BatchNorm2d(...),\n    },\n    'group2':{ ...\n    }, ...\n}\n", "def nested_children(m: torch.nn.Module):\n    children = dict(m.named_children())\n    output = {}\n    if children == {}:\n        # if module has no children; m is last child! :O\n        return m\n    else:\n        # look for children from children... to the last child!\n        for name, child in children.items():\n            try:\n                output[name] = nested_children(child)\n            except TypeError:\n                output[name] = nested_children(child)\n    return output\n"], ["Info = pd.DataFrame(df.groupby(\"school_state\").agg(Approved=(\"project_is_approved\",lambda x: x.eq(1).sum()),Total=(\"project_is_approved\",\"count\"),Avg=(\"project_is_approved\",\"mean\"))).reset_index().sort_values(by=[\"Total\"],ascending=False).head()\n"], [], ["FROM python:3.8-slim\nWORKDIR /usr/src/app\n\nRUN apt update\nRUN apt -y install build-essential libwrap0-dev libssl-dev libc-ares-dev uuid-dev xsltproc\nRUN apt-get update -qq \\\n    && apt-get install --no-install-recommends --yes \\\n        build-essential \\\n        gcc \\\n        python3-dev \\\n        mosquitto \\\n        mosquitto-clients\n\n\nRUN pip3 install --upgrade pip setuptools wheel\n\nRUN python3 -m pip install --no-cache-dir \\\n      numpy scipy matplotlib scikit-build opencv-contrib-python-headless \\\n      influxdb paho-mqtt configparser Pillow \\\n      qrcode\n"], ["from asyncio import get_event_loop\nfrom aiogram import Bot, Dispatcher, executor, types\n\nAPI_TOKEN = 'API'\n\nbot = Bot(token=API_TOKEN)\ndp = Dispatcher(bot=bot, loop=get_event_loop())  # Initialising event loop for the dispatcher\n\nasync def notify_message():\n    print('Hello World')\n\nif __name__ == '__main__':\n    dp.loop.create_task(notify_message())  # Providing awaitable as an argument\n    executor.start_polling(dp, skip_updates=True)\n"], ["ImportError> dlopen(): Library not found\n", "no suitable image found: imageXXX found but wrong architecture\n"], [], [], ["from tensorflow import keras\n"], ["!pip install -U -q segmentation-models\n!pip install -q tensorflow==2.1\n!pip install -q keras==2.3.1\n!pip install -q tensorflow-estimator==2.1.\n\n## Imports libs\nimport os\nos.environ['CUDA_VISIBLE_DEVICES'] = '0'\nos.environ[\"SM_FRAMEWORK\"] = \"tf.keras\"\n\nfrom tensorflow import keras\nimport segmentation_models as sm\n"], ["  pattern = r\"^\\w.*\\.[a-zA-Z]*$\"\n"], ["from aiogram import Bot, Dispatcher, executor, types\n\nAPI_TOKEN = 'API'\nbot = Bot(token=API_TOKEN)\ndp = Dispatcher(bot)\n\n@dp.message_handler()\nasync def echo(message: types.Message):\n   await bot.send_message(message.chat.id, message.text)\n\ndef test_hi():\n   print(\"Hello World\")\n\nif __name__ == '__main__':\n   test_hi()\n   executor.start_polling(dp, skip_updates=True)\n"], ["train_data = [(example.numpy(), label.numpy()) for example, label in train_dataset]\n", "train_data[0][0]\ntrain_data[0][1]\n", "import pandas as pd\npd.DataFrame(train_data, columns=['example', 'label'])\n", "dataset = tf.data.Dataset.from_generator(\nlambda: train_data, ( tf.string, tf.int32)) # you should define dtypes of yours\n", "list(dataset.as_numpy_iterator())\n"], ["from pyxtension.streams import stream\n\nstream(myList)\n    .filter(condition)\n    .map(action1)\n    .map(action2)\n    .toList()\n", "stream(myList)\n    .filter(condition)\n    .mpmap(action1)   # this is for multi-processing map\n    .fastmap(action2) # this is multi-threaded map\n    .toList()\n"], [], ["def area(length, width):\n    return length * width\n\nl = 4\nw = 5\n\nprint(\"length =\", l, \"width =\", w, \"area =\", area(l, w))  # normal way\nprint(f\"length = {l} width = {w} area = {area(l,w)}\")     # Same output as above\nprint(\"length = {l} width = {w} area = {area(l,w)}\")      # without f prefixed\n", "length = 4 width = 5 area = 20\nlength = 4 width = 5 area = 20\nlength = {l} width = {w} area = {area(l,w)}\n"], ["@dp.message_handler()\nasync def echo(message: types.Message):\n    await bot.send_message(message.chat.id, message.text)\n", "2021-06-01 09:31:42,729:INFO:Bot: YourBot [@YourBot]\n2021-06-01 09:31:42,729:WARNING:Updates were skipped successfully.\n2021-06-01 09:31:42,729:INFO:Start polling.\n"], ["def summer_69(arr):\n    skate = arr\n    guitar = []\n    for i in range(len(arr)):\n        if 6 in arr:\n            guitar = skate[skate.index(6):skate.index(9)+1]\n            return abs(sum(skate) - sum(guitar))\n        else:\n            return sum(skate)\n"], [], ["fire_runner.py my_func  1,2,3\n", "fire_runner.py my_func  \\'2021-2\\',\\'20212-3\\',\\'2023-4\\'\n"], ["name = 'Niroshan'\nage  = 25;\nprint(f\"Hello I'm {name} and {age} years young\")\n", "name = 'Niroshan'\nage  = 25;\nprint(\"Hello I'm {name} and {age} years young\")\n"], ["import re\n\ntuple = (1,)\ns = \"something in \"  + re.sub(r',(?=\\))', '', str(tuple))\nprint(s)\n", "something in (1)\n"], [], ["a = (1,)\ns = f\"something in ({','.join([str(x) for x in a])})\"\nprint(s)\n", "'something in (1)'\n"], [], [], ["pip install django-rest-framework\n"], ["sudo python3.7 -m pip install -U pip\nsudo python3.7 -m pip install -U setuptools\n", "sudo python2.7 -m pip install -U pip\nsudo python2.7 -m pip install -U setuptools\nsudo apt-get install python-dev libpq-dev\n"], ["def is_power_of(number, base):\n  # Base case: when number is smaller than base.\n  if number < base:\n    # If number is equal to 1, it's a power (base**0).\n    if number == 1:\n      return True\n\n    else:\n      return False\n  # Recursive case: keep dividing number by base.\n  return is_power_of(number/base , base)\n\nprint(is_power_of(8,2)) # Should be True\nprint(is_power_of(64,4)) # Should be True\nprint(is_power_of(70,10)) # Should be False\n"], [], ["def count_letters(text):\n  result = {}\n  for letter in text.lower():\n    if letter.isalpha():\n      lettercount = text.lower().count(letter)\n      result[letter] = lettercount\n  return result\n"], ["read_config = tfds.ReadConfig(skip_prefetch = True)\ndataset_builder.as_dataset(\n    ......,\n    read_config = read_config,\n)\n"], [], ["import yfinance as yf\n\nstock = yf.Ticker(\"ABEV3.SA\")\nprice = stock.info['regularMarketPrice']\nprint(price)\n \n"], ["def myfunc(a):\nmylist=[]\nsum1 = 0\nfor b,c in enumerate(a):\n    if c==6:\n       for d in  a[:b]:\n           mylist.append(d)\nfor e,f in enumerate(a):\n    if f==9:\n       for j in a[e+1:]:\n           mylist.append(j)\nfor y in a:\n    if y==6:\n      break\n    else:\n       mylist.append(y)\nfor k in mylist:\n    sum1 = sum1+k\nprint(sum1)\n"], [], ["pip install --upgrade pip setuptools wheel\n", "pip3 install opencv-python==3.4.13.47\n"], ["sudo apt-get install python3-pip\n"], [], [], ["named_layers = dict(model.named_modules())\n", "{\n    'conv1': <some conv layer>,\n    'fc1': < some fc layer>,\n     ### and other layers \n}\n"], ["df['ts']\nOUT:\n0      1619801902867\n1      1619765681594\n2      1619712291984\n3      1619680298648\n4      1619629032109\n5      1619593388626\n6      1619531314509\n7      1619509338368\n8      1619449287828\n9      1619433411243\n10     1619103667781\n11     1619078244871\n12     1619021782951\n13     1618990214111\n14     1618931135540\n15     1618903774632\n", "df['ts'] = pd.to_datetime(df['ts'],unit='ms').dt.tz_localize('utc').dt.tz_convert('Europe/Vatican')\ndf['ts'] = df['ts'].apply(lambda a: datetime.datetime.strftime(a,\"%Y-%m-%d %H:%M:%S\"))\ndf['ts'] = pd.to_datetime(df['ts'])\n", "df['ts']\nOUT:\n0     2021-04-30 18:58:22\n1     2021-04-30 08:54:41\n2     2021-04-29 18:04:51\n3     2021-04-29 09:11:38\n4     2021-04-28 18:57:12\n5     2021-04-28 09:03:08\n6     2021-04-27 15:48:34\n7     2021-04-27 09:42:18\n8     2021-04-26 17:01:27\n9     2021-04-26 12:36:51\n10    2021-04-22 17:01:07\n11    2021-04-22 09:57:24\n12    2021-04-21 18:16:22\n13    2021-04-21 09:30:14\n14    2021-04-20 17:05:35\n15    2021-04-20 09:29:34\n"], ["from fastai.vision.all import show_image\n"], [], ["apk add --update python3 py3-pip\n"], ["fire_runner.py my_func --dates 2021-09-20,\nfire_runner.py my_func --dates \"[2021-09-20]\"\nfire_runner.py my_func --dates [2021-09-20]\n", "fire_runner.py my_func --dates \"[\\\"2021-09-20\\\"]\"\nfire_runner.py my_func --dates \"[\\\"2021-09-20\\\", \\\"2021-09-76\\\"]\"\n"], [], ["def download_chromedriver():\n    def get_latestversion(version):\n        url = 'https://chromedriver.storage.googleapis.com/LATEST_RELEASE_' + str(version)\n        response = requests.get(url)\n        version_number = response.text\n        return version_number\n    def download(download_url, driver_binaryname, target_name):\n        # download the zip file using the url built above\n        latest_driver_zip = wget.download(download_url, out='./temp/chromedriver.zip')\n\n        # extract the zip file\n        with zipfile.ZipFile(latest_driver_zip, 'r') as zip_ref:\n            zip_ref.extractall(path = './temp/') # you can specify the destination folder path here\n        # delete the zip file downloaded above\n        os.remove(latest_driver_zip)\n        os.rename(driver_binaryname, target_name)\n        os.chmod(target_name, 755)\n    if os.name == 'nt':\n        replies = os.popen(r'reg query \"HKEY_CURRENT_USER\\Software\\Google\\Chrome\\BLBeacon\" /v version').read()\n        replies = replies.split('\\n')\n        for reply in replies:\n            if 'version' in reply:\n                reply = reply.rstrip()\n                reply = reply.lstrip()\n                tokens = re.split(r\"\\s+\", reply)\n                fullversion = tokens[len(tokens) - 1]\n                tokens = fullversion.split('.')\n                version = tokens[0]\n                break\n        target_name = './bin/chromedriver-win-' + version + '.exe'\n        found = os.path.exists(target_name)\n        if not found:\n            version_number = get_latestversion(version)\n            # build the donwload url\n            download_url = \"https://chromedriver.storage.googleapis.com/\" + version_number +\"/chromedriver_win32.zip\"\n            download(download_url, './temp/chromedriver.exe', target_name)\n\n    elif os.name == 'posix':\n        reply = os.popen(r'chromium --version').read()\n\n        if reply != '':\n            reply = reply.rstrip()\n            reply = reply.lstrip()\n            tokens = re.split(r\"\\s+\", reply)\n            fullversion = tokens[1]\n            tokens = fullversion.split('.')\n            version = tokens[0]\n        else:\n            reply = os.popen(r'google-chrome --version').read()\n            reply = reply.rstrip()\n            reply = reply.lstrip()\n            tokens = re.split(r\"\\s+\", reply)\n            fullversion = tokens[2]\n            tokens = fullversion.split('.')\n            version = tokens[0]\n\n        target_name = './bin/chromedriver-linux-' + version\n        print('new chrome driver at ' + target_name)\n        found = os.path.exists(target_name)\n        if not found:\n            version_number = get_latestversion(version)\n            download_url = \"https://chromedriver.storage.googleapis.com/\" + version_number +\"/chromedriver_linux64.zip\"\n            download(download_url, './temp/chromedriver', target_name) \n \n"], ["pattern = r\"^[\\w|\\.\\-\\_]+\\.[a-zA-Z]+$\"\n"], [], [], ["import yfinance as yf\n\ntickerSymbol = 'AMD'\n\ntickerData = yf.Ticker(tickerSymbol)\ntodayData = tickerData.history(period='1d')\ntodayData['Close'][0] #use print() in case you're testing outside a interactive session\n"], ["    def floatToString(self, floatnumber:float32) -> str:\n        stringNumber:str = \"\"\n        whole:int = math.floor(floatnumber)\n        frac:int = 0\n        digits:float = float(floatnumber % 1)\n        digitsTimes100:float = float(digits) * float(100.0)\n        if digitsTimes100 is not None:\n            frac = math.floor(digitsTimes100)\n        stringNumber = str(whole)+\".\"+str(frac)\n        return stringNumber\n"], [], ["$ pip3 install --upgrade setuptools\n$ pip3 install --upgrade pip\n"], ["python3 -m pip install --user --no-cache-dir google-cloud-bigquery\npython3 -m pip install --upgrade setuptools\n", "python3 -m pip install --no-cache-dir --user --upgrade grpcio\n"], ["class Language(enum.Enum):\n    en = 'en'\n    zh = 'zh'\n\n    @classmethod\n    def has_member_key(cls, key):\n        return key in cls.__members__\n\nprint(Language.has_member_key('tu')) => False\nprint(Language.has_member_key('en')) => True\n"], [], [], ["content = \"\".join(l for l in content.splitlines() if l)\n"], ["    def count_letters(text):\n  result = {}\n  # Go through each letter in the text\n  text=text.casefold()\n  for letter in text:\n    # Check if the letter needs to be counted or not\n    if (letter.isalpha()): \n\n    # Add or increment the value in the dictionary\n      result.update({letter:text.count(letter)})\n  return result\n\nprint(count_letters(\"AaBbCc\"))\n# Should be {'a': 2, 'b': 2, 'c': 2}\n\nprint(count_letters(\"Math is fun! 2+2=4\"))\n# Should be {'m': 1, 'a': 1, 't': 1, 'h': 1, 'i': 1, 's': 1, 'f': 1, 'u': 1, 'n': 1}\n\nprint(count_letters(\"This is a sentence.\"))\n# Should be {'t': 2, 'h': 1, 'i': 2, 's': 3, 'a': 1, 'e': 3, 'n': 2, 'c': 1}\n"], [], ["python setup.py egg_info\" failed with error code 1 in /tmp/pip-install-hI6hg8/mpmath/\n", "apt-get install --upgrade python-pip -y && \\\n    python -m pip install --upgrade pip\n", "RUN apt-get install -y python-scipy\nRUN apt-get install -y python-sympy\n...\nRUN python -m pip install opencv-python==3.4.0.12\nRUN python -m pip install pyyaml\n...\n", "python -m pip install opencv-python==3.4.0.12\n"], ["date_columns = df.select_dtypes(include=['datetime64[ns, UTC]']).columns\nfor date_column in date_columns:\n    df[date_column] = df[date_column].dt.date\n    \ndf.to_excel('anbima_feed.xlsx',engine='xlsxwriter')\n"], ["plt.imshow(transforms.ToPILImage()(image), interpolation=\"bicubic\")\n#transforms.ToPILImage()(image).show() # Alternatively\n", "def show(img):\n    npimg = img.numpy()\n    plt.imshow(np.transpose(npimg, (1, 2, 0)), interpolation='nearest')\n"], [">>> model = nn.Sequential(nn.Linear(2, 2), \n                          nn.ReLU(),\n                          nn.Sequential(nn.Linear(2, 1),\n                          nn.Sigmoid()))\n\n>>> l = [module for module in model.modules() if not isinstance(module, nn.Sequential)]\n\n>>> l\n\n[Linear(in_features=2, out_features=2, bias=True),\n ReLU(),\n Linear(in_features=2, out_features=1, bias=True),\n Sigmoid()]\n"], ["from PIL import Image\nimage = Image.open(img_path)\nplt.imshow(transforms.ToPILImage()(transforms.ToTensor()(image)), interpolation=\"bicubic\")\n"], ["import yfinance as yf\n\nsymbols = [\"TSLA\", \"NIO\"]\nresult = {}\nfor symbol in symbols:\n    data = yf.Ticker(symbol)\n    today_data = data.history(period='1d')\n    result[symbol] = round((today_data['Close'][0]),2)\nprint(result)\n"], [], ["def count_letters(text):\n  result = {}\n  # Go through each letter in the text\n  for letter in text:\n    # Check if the letter needs to be counted or not\n    if letter.isalpha():\n      if letter not in result:\n        result[letter.lower()] = 1\n      else:\n        result[letter.lower()] +=1\n    # Add or increment the value in the dictionary\n    \n  return result\n\nprint(count_letters(\"AaBbCc\"))\n# Should be {'a': 2, 'b': 2, 'c': 2}\n\nprint(count_letters(\"Math is fun! 2+2=4\"))\n# Should be {'m': 1, 'a': 1, 't': 1, 'h': 1, 'i': 1, 's': 1, 'f': 1, 'u': 1, 'n': 1}\n"], ["def count_letters(text):\n  result = {}\n  # Go through each letter in the text\n  for letter in text.lower():\n    # Check if the letter needs to be counted or not\n    if(letter.isalpha()):\n      result[letter] = result.get(letter,0)+1\n    # Add or increment the value in the dictionary\n    \n  return result\n"], ["x = 12\ny = 10\n\nword_string = x + ' plus ' + y + 'equals: ' + (x+y)\n", "x = 12\ny = 10\n\nword_string = f'{x} plus {y} equals: {x+y}'\noutput: 12 plus 10 equals: 22\n"], ["exwriter = pd.ExcelWriter(fullpath, engine='xlsxwriter', options={'remove_timezone': True})\n"], ["def count_letters(text):\n  result = {}\n  # Go through each letter in the text\n  for letter in text.lower():\n    # Check if the letter needs to be counted or not\n    if letter.isalpha() and letter not in result:\n    # Add or increment the value in the dictionary\n      result[letter] = text.count(letter)\n  return result\n\nprint(count_letters(\"AaBbCc\"))\n# Should be {'a': 2, 'b': 2, 'c': 2}\n\nprint(count_letters(\"Math is fun! 2+2=4\"))\n# Should be {'m': 1, 'a': 1, 't': 1, 'h': 1, 'i': 1, 's': 1, 'f': 1, 'u': 1, 'n': 1}\n\nprint(count_letters(\"This is a sentence.\"))\n# Should be {'t': 2, 'h': 1, 'i': 2, 's': 3, 'a': 1, 'e': 3, 'n': 2, 'c': 1}\n"], ["icon = QtGui.QIcon(':/icons/myicon.png')\n", "# somewhere at the beginning of your program\nQtCore.QDir.addSearchPath('icons', 'path_to_icons/')\n\nicon = QtGui.QIcon('icons:myicon.png')\n"], ["pattern = \"^[\\w]*[\\.\\-\\+][^/@]*$\"\n"], ["from retrying import retry\nprint(\"HI\")\n"], [], ["def compute_min_number_of_refills(d, m, stops):\n    if d <= m:\n        return 0\n    total_refill = 0\n    last_refill = -1\n    limit = m \n    stops.append(d)\n    i = 0\n    while i < len(stops):\n        if stops[i] >= limit: \n            current_refill = i - 1 if stops[i] > limit else i\n            if current_refill == last_refill:\n                return -1 \n            last_refill = current_refill\n            total_refill += 1\n            limit = m + stops[current_refill]\n            i = current_refill + 1\n        else:\n            i += 1\n    return total_refill\n"], ["POWERLEVEL9K_LEFT_PROMPT_ELEMENTS=(anaconda ...ENVS)\n"], ["def get_current_price(symbol):\n    ticker = yf.Ticker(symbol)\n    todays_data = ticker.history(period='1d')\n    return todays_data['Close'][0]\n\nprint(get_current_price('TSLA'))\n"]]