[[], ["import pandas as pd\nimport random\n\nimport xgboost\nimport shap\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\n\nfoo = pd.DataFrame({'id':[1,2,3,4,5,6,7,8,9,10],\n               'var1':random.sample(range(1, 100), 10),\n               'var2':random.sample(range(1, 100), 10),\n               'var3':random.sample(range(1, 100), 10),\n               'class': ['a','a','a','a','a','b','b','c','c','c']})\n\ncl_cols = foo.filter(regex='var').columns\nX_train, X_test, y_train, y_test = train_test_split(foo[cl_cols],\n                                                    foo[['class']],\n                                                    test_size=0.33, \n                                                    random_state=42)\n\nlabel_encoder = LabelEncoder()\ny_train_encoded = label_encoder.fit_transform(y_train.values.ravel())\ny_test_encoded = label_encoder.transform(y_test.values.ravel())\n\nmodel = xgboost.XGBClassifier(objective=\"multi:softprob\", \n                              num_class=len(label_encoder.classes_))\nmodel.fit(X_train, y_train_encoded)\n\nexplainer = shap.TreeExplainer(model)\nshap_values = explainer.shap_values(X_test)\nclasses = label_encoder.inverse_transform(range(\n                            len(label_encoder.classes_)))\nshap.summary_plot(shap_values, X_test, class_names=classes)\n"], [], [], [">>> \"123AbC\".isalnum()\nTrue\n>>> \"1&A\".isalnum()\nFalse\n", ">>> all(c.isnumeric() or c.isalpha() for c in \"123AbC\")\nTrue\n>>> all(c.isnumeric() or c.isalpha() for c in \"1&A\")\nFalse\n", ">>> re.fullmatch(\"\\w\", \"123AbC\", re.A)\nTrue\n>>> re.fullmatch(\"\\w\", \"1&A\", re.A)\nFalse\n"], ["pip install Django==3.2.19\n"], ["array = [1,2,3,4,5]\nfiltered_array = [x for x in array if x > 3]\n"], ["import pandas as pd\n\nnew_row = pd.DataFrame({\"sex\": \"male\", \"age\": 40, \"survived\": False, \"name\": \"Alex\"}, index=[0])\n\n(df_dict\n  .assign(name=['Alice', 'Bob', 'Charlie'])\n  .drop(\"pclass\", axis=1)\n  .pipe(lambda df_: pd.concat([df_, new_row], ignore_index = True))\n)\n", "import pandas as pd\n\ndef append_row(df1, d):\n    df2 = pd.DataFrame(d, index=[0])\n    return pd.concat([df1, df2], ignore_index = True)\n\ndf = pd.DataFrame(columns=['a', 'b'])\n(df\n    .pipe(append_row, {'a': 1, 'b': 2 })\n)\n"], ["html = '<pre>' + my_string '</pre>'\n\n<pre>\nHis this \n\nis \n\na sample\n\nString\n</pre>\n"], ["r'a\\.[a-zA-Z]\\s*&&\\s*\\([a-z]\\s*=\\s*a\\.get\\(\"n\"\\)\\)\\s*&&\\s*'\nr'\\([a-z]\\s*=\\s*([a-zA-Z0-9$]{2,3})(\\[\\d+\\])?\\([a-z]\\)'\n", "nfunc=re.escape(function_match.group(1))),\n"], ["import pytest\nfrom collections.abc import Mapping\nfrom _pytest.python_api import ApproxMapping\n\n\ndef my_approx(expected, rel=None, abs=None, nan_ok=False):\n    if isinstance(expected, Mapping):\n        return ApproxNestedMapping(expected, rel, abs, nan_ok)\n    return pytest.approx(expected, rel, abs, nan_ok)\n\n\nclass ApproxNestedMapping(ApproxMapping):\n    def _yield_comparisons(self, actual):\n        for k in self.expected.keys():\n            if isinstance(actual[k], type(self.expected)):\n                gen = ApproxNestedMapping(\n                    self.expected[k], rel=self.rel, abs=self.abs, nan_ok=self.nan_ok\n                )._yield_comparisons(actual[k])\n                for el in gen:\n                    yield el\n            else:\n                yield actual[k], self.expected[k]\n\n    def _check_type(self):\n        for key, value in self.expected.items():\n            if not isinstance(value, type(self.expected)):\n                super()._check_type()\n", "def test_nested():\n    assert {'foo': {'bar': 0.30000001}} == my_approx({'foo': {'bar': 0.30000002}})\n"], [], ["import statsmodels\nstatsmodels.__file__\n"], ["def url(regex, view, kwargs=None, name=None):\n    return re_path(regex, view, kwargs, name)\n"], [], ["def split_check(bill, people, tax = 0.09, tip = 0.15):\n", "def split_check(bill, people, tax = 0.09, tip = 0.15):\n    tax = bill * tax\n    tip = bill * tip\n    return(bill + tax + tip) / people\n"], [], [], ["import shapely.plotting\nfrom shapely.geometry import Polygon\n\npolygon1 = Polygon([(0, 5), (1, 1), (3, 0)])\n\nshapely.plotting.plot_polygon(polygon1)\n"], [], ["# Build Python packages through an intermediate stage based on ubuntu.\nFROM ubuntu:20.04 as builder\nRUN apt-get update -y\nARG DEBIAN_FRONTEND=noninteractives\n\n# Install system dependencies required to install a few python packages\n# These could be different based on the python package you want to install\nRUN apt-get install wget -y\nRUN apt-get install libtool build-essential autoconf automake pkg-config libtool-bin -y\nRUN apt-get update && apt-get install -y cmake python3-dev\n\n# In my case, I need the python packages `fb-re2` & `zeromq`\nRUN apt-get install -y libre2-dev\n# Install system dependency for `libzmq`\nWORKDIR /zeromq\nRUN wget -O zeromq-4.3.2.tar.gz https://github.com/zeromq/libzmq/releases/download/v4.3.2/zeromq-4.3.2.tar.gz &&\\\n    tar -xzf zeromq-4.3.2.tar.gz\nWORKDIR /zeromq/zeromq-4.3.2\nRUN ./autogen.sh && ./configure && make && make install\n\n\n# Update package lists and install necessary dependencies\nRUN apt-get update && apt-get install -y \\\n    software-properties-common \\\n    && add-apt-repository ppa:deadsnakes/ppa\n\n# Install Python 3.7 and pip\nRUN apt-get update && apt-get install -y \\\n    python3.7 \\\n    python3.7-dev \\\n    python3-pip \\\n    && rm -rf /var/lib/apt/lists/*\n\n# Set python3.7 as the default python\nRUN ln -s /usr/bin/python3.7 /usr/bin/python\nRUN apt-get update && apt-get install python3.7-distutils -y\nRUN apt-get install locate tcpdump -y\nRUN python -m pip install --no-binary=:all: pyzmq==18.0.2\nRUN python -m pip install fb-re2\n\n# Install a couple of other python libraries\nRUN python -m pip install --no-binary=:all: psutil==5.6.7\nRUN python -m pip install --no-binary=:all: netifaces==0.11.0\n\n### Final image build ###\n# Build the base image for python based applications like a webserver.\nFROM python:3.7.16-slim-buster\n\n### From the intermediate build stage, copy the generated outputs to our final python image\nCOPY --from=builder /usr/local/lib/libzmq* /usr/local/lib\nCOPY --from=builder /usr/local/lib/python3.7/dist-packages/zmq/ /usr/local/lib/python3.7/site-packages/zmq\nCOPY --from=builder /usr/local/lib/python3.7/dist-packages/pyzmq-18.0.2.egg-info/ /usr/local/lib/python3.7/site-packages/pyzmq-18.0.2.egg-info\n\nCOPY --from=builder /usr/local/lib/python3.7/dist-packages/psutil/ /usr/local/lib/python3.7/site-packages/psutil\nCOPY --from=builder /usr/local/lib/python3.7/dist-packages/netifaces* /usr/local/lib/python3.7/site-packages/\n\nRUN apt-get update && apt-get install -y libre2-dev\nCOPY --from=builder /usr/local/lib/python3.7/dist-packages/*re2* /usr/local/lib/python3.7/site-packages/\nCOPY --from=builder /usr/local/lib/python3.7/dist-packages/fb_re2-1.0.7.dist-info/ /usr/local/lib/python3.7/site-packages/fb_re2-1.0.7.dist-info\n## END of copying from intermediate ubuntu stage\n\nWORKDIR /my/work/dir/\nCOPY requirements.txt .\n\n# Install other python packages through requirements.txt\n# It will disregard any package installation failure\n# Logs can later be found in `/var/log/python_package_installation.log` inside the container\nRUN set -e && cat requirements.txt | xargs -n 1 pip install > /var/log/python_package_installation.log 2>&1 || true\n\nEXPOSE 18000\n# Let's run a simple python server, so that we can go to the\n# container's shell and debug ourselves\nCMD python3 -m http.server\n\n"], [], ["zoneinfo._common.ZoneInfoNotFoundError: 'No time zone found with key UTC+8'\n", "#settings.py\nTIME_ZONE = 'UTC+8'\n", "#settings.py\nTIME_ZONE = 'Asia/ShangHai'\n"], ["data = yaml.full_load(f) # around line 1391\n", "data = yaml.safeload(f)  # quoting from Salim Tekin\n                                     \n"], ["try:\n    ssh.connect(ip, **args)\nexcept paramiko.ssh_exception.AuthenticationException:\n    ssh.connect(ip, \n                disabled_algorithms=dict(keys=['rsa-sha2-256', 'rsa-sha2-512'],\n                                         pubkeys=[\"rsa-sha2-512\",\"rsa-sha2-256\"]), \n                **args)\n"], ["import tempfile\nfrom fastapi import FileResponse\n\n\nclass TempFileResponse(FileResponse):\n    def __init__(self, prefix, **params) -> None:\n        self.temp_file = tempfile.NamedTemporaryFile(prefix=prefix)\n        super().__init__(path=self.temp_file.name, **params)\n\n    def __del__(self):\n        # This will delete the file\n        self.temp_file.close()\n\n\n@router.get(\"/produce-data\", response_class=FileResponse)\nasync def produce() -> FileResponse:\n    file_name = \"some_file_data.txt\"\n    logger.info(f\"Downloading data as {file_name}\")\n    response_file = TempFileResponse(prefix=\"some_file_\", filename=file_name)\n    with open(response_file.temp_file.name, \"w\") as f:\n        f.write(\"Hello, world!\")\n    return response_file\n"], ["from aiogram import Bot, Dispatcher, executor, types\n\nAPI_TOKEN = 'API'\n\nbot = Bot(token=API_TOKEN)\ndp = Dispatcher(bot)\n\n@dp.message_handler()\nasync def echo(message: types.Message):\n  await message.answer(message.text)\n\nasync def notify_message(dp: Dispatcher) # THIS FUNCTION\n  print('Hello World')\n\nif __name__ == '__main__':\n   executor.start_polling(dp, skip_updates=True, on_startup=notify_message)\n", "from aiogram import Bot, Dispatcher, executor, types\n\nAPI_TOKEN = 'API'\n\nbot = Bot(token=API_TOKEN)\ndp = Dispatcher(bot)\n\n@dp.message_handler()\nasync def echo(message: types.Message):\n  await message.answer(message.text)\n\nasync def notify_message() # THIS FUNCTION\n  # await print('Hello World')\n  print('Hello, world') # you shouldn't await the print fucntion, because it isn't async.\n\nif __name__ == '__main__':\n   await notifty_message()\n   executor.start_polling(dp, skip_updates=True)\n", "from aiogram import Bot, Dispatcher, executor, types\n\nAPI_TOKEN = 'API'\n\nbot = Bot(token=API_TOKEN)\ndp = Dispatcher(bot)\n\n@dp.message_handler()\nasync def echo(message: types.Message):\n  await message.answer(message.text)\n\ndef notify_message() # THIS FUNCTION\n  print('Hello, world')\n\nif __name__ == '__main__':\n   notifty_message()\n   executor.start_polling(dp, skip_updates=True)\n"], [], ["def flatten_model(modules):\n    def flatten_list(_2d_list):\n        flat_list = []\n        # Iterate through the outer list\n        for element in _2d_list:\n            if type(element) is list:\n                # If the element is of type list, iterate through the sublist\n                for item in element:\n                    flat_list.append(item)\n            else:\n                flat_list.append(element)\n        return flat_list\n\n    ret = []\n    try:\n        for _, n in modules:\n            ret.append(flatten_model(n))\n    except:\n        try:\n            if str(modules._modules.items()) == \"odict_items([])\":\n                ret.append(modules)\n            else:\n                for _, n in modules._modules.items():\n                    ret.append(flatten_model(n))\n        except:\n            ret.append(modules)\n    return flatten_list(ret)\n"], ["from azure.storage.blob import BlobClient\n\nblob_client = BlobClient.from_connection_string(\n        conn_str='my_conn_str',\n        container_name='my_container_name',\n        blob_name='my_blob_name')\n\nwith open(\"./SampleSource.txt\", \"rb\") as data:\n    blob.upload_blob(data)\n"], [], ["Build Failed\nError: PythonPipBuilder:ResolveDependencies - pip executable not found in your python environment at ..\\Python310\\python.EXE\n"], [], ["num1 = int(input())\nnum2 = int(input())\nnum3 = int(input())\n\nsmallest_num = min(num1, num2, num3)\nif (num1 < num2):\n    if (num1 < num3):\n        smallest_num = num1\nelif (num2 < num1):\n    if (num2 < num3):\n        smallest_num = num2\nelif (num3 < num2):\n    if (num3 < num1):\n        smallest_num = num3\n\nprint(smallest_num)\n"], ["pip3 upip3 uninstall virtualenvninstall virtualenv\nsudo pip3 uninstall virtualenv\nsudo apt purge python3-virtualenv\n"], ["import re\n\ncontent = '\\r\\n\\r\\n\\r\\n\\r\\n\\r\\ntest'\ncontent = re.sub(r'(\\r\\n)+', r'\\r\\n', content)  # '\\r\\ntest'\n"], ["pygame.draw.rect(your surface name, color, (x, y, length, width))\n"], ["import yfinance as yf\n\ndef current_price(instrument):\n    data = yf.Ticker(instrument).history(period=\"1d\", interval=\"1m\")\n    return data[\"Close\"].iloc[-1]\n\nprint(current_price(\"TSLA\"))\n"], ["$ snap install powershell\n$ pwsh\nps> install-module exchangeonlinemanagement\nps> Connect-ExchangeOnline\nps> New-ServicePrincipal -AppId <appid> -ObjectId <objid>\nps> Add-MailboxPermission -Identity <email@domain> -User <ObjectId> -AccessRights FullAccess`\nps> exit\n$\n"], ["new_df.fillna(\"Others\",inplace=True,axis = 1)\n\nnew_df = pd.get_dummies(new_df, columns=cat_col)\n\ncol_to_drop = [col for col in new_df.columns.tolist() if col.__contains__(\"Others\")]\n\nnew_df.drop(col_to_drop, axis=1,inplace=True)\n", "cat_col = data.dtypes[data.dtypes == 'O'].index.tolist() #to get the list of categorical variables\n\nnew_df = pd.get_dummies(new_df, columns=cat_col, drop_first=True,dummy_na=True)\n"], ["from itertools import count\n\nunique = count()\n\nq.put((priority, next(unique), item))\n", "from functools import total_ordering\n\n@total_ordering\nclass PrioritizedItem:\n    def __init__(self, priority, item):\n        self.priority = priority\n        self.item = item\n\n    def __eq__(self, other):\n        if not isinstance(other, __class__):\n            return NotImplemented\n        return self.priority == other.priority\n\n    def __lt__(self, other):\n        if not isinstance(other, __class__):\n            return NotImplemented\n        return self.priority < other.priority\n"], ["apt install -y software-properties-common\nadd-apt-repository ppa:deadsnakes/ppa\napt install python3.10\n", "root@XXX:/home/XXX# python\npython            python2           python2.7         python2.7-config  python2-config    python3           python3.10        python3.8         python3.8-config  python3-config    python3-wsdump    python-config     \n\nroot@XXX:/home/XXX# python3.10\nPython 3.10.12 (main, Jun  7 2023, 12:45:35) [GCC 9.4.0] on linux\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n>>> exit\nUse exit() or Ctrl-D (i.e. EOF) to exit\n>>> \n", "root@XXX:/home/XXX# update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.10 1\n", "root@XXX:/home/XXX# update-alternatives --config python3\nThere are 2 choices for the alternative python3 (providing /usr/bin/python3).\n\n  Selection    Path                 Priority   Status\n------------------------------------------------------------\n* 0            /usr/bin/python3.8    1         auto mode\n  1            /usr/bin/python3.10   1         manual mode\n  2            /usr/bin/python3.8    1         manual mode\n\nPress <enter> to keep the current choice[*], or type selection number: 1\nupdate-alternatives: using /usr/bin/python3.10 to provide /usr/bin/python3 (python3) in manual mode\n", "root@XXX:/home/XXX# update-alternatives --config python3\nThere are 2 choices for the alternative python3 (providing /usr/bin/python3).\n\n  Selection    Path                 Priority   Status\n------------------------------------------------------------\n  0            /usr/bin/python3.10   1         auto mode\n* 1            /usr/bin/python3.10   1         manual mode\n  2            /usr/bin/python3.8    1         manual mode\n\nPress <enter> to keep the current choice[*], or type selection number: \n", "root@XXX:/home/XXX# python3 --version\nPython 3.10.12\n", "root@XXX:/home/XXX# apt-get install -y python3-pip\n", "root@XXX:/home/XXX# apt-get install -y python3.10-venv\n"], ["def preProcesser(board: chess.Board):\n    chess_dict = {\n            1 : [1,0,0,0,0,0],\n            2 : [0,1,0,0,0,0],\n            3 : [0,0,1,0,0,0],\n            4 : [0,0,0,1,0,0],\n            5 : [0,0,0,0,1,0],\n            6 : [0,0,0,0,0,1],\n            0 : [0,0,0,0,0,0]\n        }\n    return torch.from_numpy(np.array([np.array(chess_dict[(board.piece_type_at(sq) if board.piece_type_at(sq) else 0)])*(-1 if board.color_at(sq)==False else 1) for sq in chess.SQUARES]).astype(np.float16).reshape(-1))\n"], [], ["pip install -r requirements.txt\n"], ["import re\n\ntable = 'table1'\n\ntable = re.sub(r'\\d+', '', table)\n"], ["{\n    \"jupyter.interactiveWindow.textEditor.executeSelection.\": true\n}\n\n", "\"python.dataScience.sendSelectionToInteractiveWindow\": false\n"], [], [], ["conda install -c conda-forge nbformat\n", "pip install --upgrade nbformat\n\n"], ["from dataclasses import dataclass\n\n@dataclass\nclass XY:\n    \"2d point\"\n    x: float or int\n    y: float or int\n\npoints = [XY(1, 2), XY(3, 4), XY(5, 6), XY(7, 8)]\ndata_dict = dict(zip(('x', 'y'), zip(*(vars(p).values() for p in points))))\n\nprint(data_dict)\n", "{'x': (1, 3, 5, 7), 'y': (2, 4, 6, 8)}\n"], ["(a - a[..., [0]]).sum(-1) == 0\n"], ["apt install pkg-config\n"], ["import en_core_web_sm\nnlp = en_core_web_sm.load()\n\ndoc = nlp(text)\nxxxxxxx\n"], [], ["import pandas as pd\n\n\ndef my_append(self, x, ignore_index=False):\n    if ignore_index:\n        return pd.concat([self, x])\n    else:\n        return pd.concat([self, x]).reset_index(drop=True)\n\n\nif not hasattr(pd.DataFrame, \"append\"):\n    setattr(pd.DataFrame, \"append\", my_append)\n\n"], [], [], ["XY = namedtuple('XY', ['x', 'y'])\n", "points = [XY(1,2), XY(3,4), XY(5,6), XY(7,8)]\nxs, ys = zip(*points)\n# (1, 3, 5, 7)\n# (2, 4, 6, 8)\n", "def idataclass(**kwargs):     \n    def deco(cls):\n        cls = dataclass(cls, **kwargs)\n        cls.__iter__  = lambda s: (getattr(s, field.name) for field  in fields(s))\n        return cls\n    return deco\n\n \n@idataclass()\nclass XY:\n    x: float | int\n    y: float | int\n"], [], ["pattern = r\"[\\w]+[aeiou]{3,}[a-z]+\"\n"], ["(base) C:\\>cd /d d:\n(base) D:\\>jupyter notebook\n"], ["df.iloc[:, 1:] = df.iloc[:, 1:].apply(pd.to_numeric)\n", "df[df.columns[1:]] = df[df.columns[1:]].apply(pd.to_numeric)\n", "df[df.columns[1:]] = df[df.columns[1:]].astype(float)\n"], [], [], ["from operator import attrgetter\nfrom dataclasses import dataclass\n\n@dataclass\nclass XY:\n    \"2d point\"\n    x: float | int\n    y: float | int\n\npoints = [XY(1,2), XY(3,4), XY(5,6), XY(7,8)]\nxs, ys = map(list, zip(*map(attrgetter('x', 'y'), points)))\n"], [], ["def pt2iter(pt):\n    yield pt.x\n    yield pt.y\n\nxs, ys = zip(*map(pt2iter, points))\n", "def pt2iter(pt):\n    return pt.x, pt.y\n"], ["from dataclasses import dataclass, astuple\n\n@dataclass\nclass XY:\n    \"2d point\"\n    x: float | int\n    y: float | int\n    def __iter__(self):\n        return iter(astuple(self))\n\npoints = [XY(1,2), XY(3,4), XY(5,6), XY(7,8)]\nxs, ys = zip(*points)\n", "xs, ys = zip(*map(astuple, points))\n"], [], ["(1, 3, 5, 7)\n(2, 4, 6, 8)\n"], ["import boto3\n\nfileCount = 0\n\n# One-liner\nfileCount = sum([page['KeyCount'] for page in boto3.client('s3').get_paginator('list_objects_v2').paginate(Bucket=bucket,Prefix=File)])\n\n# More readable\ns3 = boto3.client('s3')\ns3p = s3.get_paginator('list_objects_v2')\ns3i = s3p.paginate(Bucket=bucket,Prefix=File)\nfileCount = sum(KeyCount for KeyCount in s3i.search('KeyCount'))\n# Or\nfor KeyCount in s3i.search('KeyCount'):\n  fileCount += KeyCount\n\n"], ["pip install torch\n", "%pip install torch\n"], [], ["if(raw_code == \"\"):\n    return \"\"\n", "if(raw_code == \"\"):\n    return []\n", "if(match != None):\n    code_lines_list = find_object_from_startpoint(js, match.span()[1]).split('\\n')\n    joined_lines = \"\".join(code_lines_list)\n    # Prepend function definition (e.g. `Dea=function(a)`)\n    return match.group(0) + joined_lines\nelse:\n    return \"\"\n"], ["camera.set(cv2.CAP_PROP_FOURCC, cv2.VideoWriter.fourcc('M', 'J', 'P', 'G'))\n"], [], ["'blas=*=accelerate'\n"], ["def longest(numbers):\nmy_max, count_ = 1, 1\nstart_idx, end_idx = 0, 0\nfor i in range(len(numbers)-1):\n    # if difference between number and his follower is 1,they are in sequence\n    if numbers[i+1]-numbers[i] ==1:\n        count_ = count_+1\n    else:\n        if count_ > my_max :\n            my_max = count_\n            end_idx = i\n            start_idx = i+1 - my_max\n        # Reset counter\n        count_ = 1\nif count_ > my_max:\n    my_max = count_\n    end_idx = i+1\n    start_idx = i+2-my_max\nreturn (start_idx,end_idx,my_max)\n"], [], [], [], [], [], ["pip install pandas\n"], [], [], [], [], ["function_patterns = [\n    # https://github.com/ytdl-org/youtube-dl/issues/29326#issuecomment-865985377\n    # https://github.com/yt-dlp/yt-dlp/commit/48416bc4a8f1d5ff07d5977659cb8ece7640dcd8\n    # var Bpa = [iha];\n    # ...\n    # a.C && (b = a.get(\"n\")) && (b = Bpa[0](b), a.set(\"n\", b),\n    # Bpa.length || iha(\"\")) }};\n    # In the above case, `iha` is the relevant function name\n    r'a\\.[a-zA-Z]\\s*&&\\s*\\([a-z]\\s*=\\s*a\\.get\\(\"n\"\\)\\)\\s*&&.*?\\|\\|\\s*([a-z]+)',\n    r'\\([a-z]\\s*=\\s*([a-zA-Z0-9$]+)(\\[\\d+\\])?\\([a-z]\\)', ]\n"], ["def BracketMatcher(strParam: str) -> bool:\n  pairs = {'(':')', '[':']', '{':'}'}\n  stack = []\n  for c in strParam:\n    if c in '([{':\n      stack.append(c)\n    elif c in ')]}':\n      if not stack or c != pairs[stack[-1]]:\n        return False\n      stack.pop()\n  return len(stack) == 0\n"], [], ["df.iloc[-1, 0]\n"], ["/opt/random/nonstandard/whoa/pip\n/usr/local/bin/pip\n/usr/bin/pip\n", "/opt/random/nonstandard/whoa/pip --version\n"], ["pattern = \"^[a-zA-Z0-9-+_.@]*\\.+[^@/]*$\"\n"], ["from django.conf import settings\nimport authentication\nfrom .room import Room\n\nclass Section(models.Model):\n    ...\n    boss = models.ForeignKey(settings.AUTH_USER_MODEL, on_delete=models.SET(authentication.models.get_sential), ...)\n    surrogate = models.ForeignKey(settings.AUTH_USER_MODEL, on_delete=models.SET(get_sentinel), ...)\n    room = models.ForeignKey(Room, on_delete=models.SET_NULL, ...)\n    is_subordinate_to = models.ForeignKey('self', on_delete=models.SET_NULL, ...)\n"], ["error: invalid version number in 'MACOSX_DEPLOYMENT_TARGET='\n", "export MACOSX_DEPLOYMENT_TARGET=11\n"], [], [">>> name = \"Fred\"\n>>> f\"He said his name is {name}.\"\n\"He said his name is Fred.\"\n\n>>> name = \"Fred\"\n>>> f\"He said his name is {name!r}.\"\n\"He said his name is Fred.\"\n\n>>> f\"He said his name is {repr(name)}.\" # repr() is equivalent to !r\n\"He said his name is Fred.\"\n\n>>> width = 10\n>>> precision = 4\n>>> value = decimal.Decimal(\"12.34567\")\n>>> f\"result: {value:{width}.{precision}}\" # nested fields\nresult: 12.35\n\n>>> today = datetime(year=2023, month=1, day=27)\n>>> f\"{today:%B %d, %Y}\" # using date format specifier\nJanuary 27, 2023\n\n>>> number = 1024\n>>> f\"{number:#0x}\" # using integer format specifier\n0x400\n"], ["from selenium import webdriver\nfrom selenium.common import NoSuchElementException, TimeoutException\nfrom selenium.webdriver.support.wait import WebDriverWait\nfrom selenium.webdriver.support import expected_conditions as EC\nfrom selenium.webdriver.common.keys import Keys\nfrom time import sleep\n\n# I used Chrome but you can used any browser\n \n# ---- Optional - add options to keep the webpage open ----\noptions = webdriver.ChromeOptions()\noptions.add_experimental_option(\"detach\", True)\n\ndriver = webdriver.Chrome(options=options)\n", "try:\n     notification_off = WebDriverWait(driver, 20).until(EC.presence_of_element_located(('xpath', '//*[@id=\"mount_0_0_LP\"]/div/div/div[3]/div/div/div[1]/div/div[2]/div/div/div/div/div[2]/div/div/div[3]/button[2]')))\nexcept TimeoutException:\n    print(\"no such element found\")\nelse:\n    click_anywhere.click()\n\n", "sleep(20)\ntry:\n     not_off = driver.find_element('name', 'Not Now')\nexcept NoSuchElementException:\n     print('No such element found')\nelse:\n      not_off.click()\n", "sleep(5)\ntry:\n    notification_off = driver.find_elements('css selector', 'button')\nexcept NoSuchElementException:\n    print(\"notification element not found\")\nelse:\n    # dictionary comprehension\n    not_off = [item for item in notification_off if item.text == \"Not Now\"]\n    not_off[0].click()\n"], [], [], ["pip3 install pip==21.0.1 poetry==1.1.8 poetry-core==1.0.4\n", "poetry cache clear --all .\n"], [], ["def summer_69(nums):\n    total = 0\n    ignore_section = False\n\n    for num in nums:\n        if num == 6:\n            ignore_section = True\n        elif num == 9:\n            ignore_section = False\n        elif not ignore_section:\n            total += num\n\n    return total\n"], [" dataset, dataset_info = tfds.load('malaria', with_info=True, as_supervised=True,shuffle_files=True,split[\"train\"],data_dir=\"you_dir\\tensorflow_datasets\\\\\")\n", "  for i, (image, label) in enumerate(train_dataset.take(16)):\n        ax = plt.subplot(4, 4, i+1)\n        plt.imshow(image)\n        plt.title(dataset_info.features['label'].int2str(label))\n        plt.axis('off')\n\nplt.show()\n"], ["opencv-python-headless                  4.7.0.72\n"], ["def min_refills(distance, tank, stops):\n    stop_list = []\n    stops.append(distance) # append the destination to the stop list\n    # write your code here\n    if distance <= tank: # if the travel distance <= distance travelled in one full tank\n        return 0\n    else:\n        start = 0\n        prev = 0\n        for stop in stops:\n            \n            if stop - start < tank:     # if refueling stop is closer to the starting point than the car can travel in one full tank\n                prev = stop     # move prev pointer to the refueling stop\n            elif (stop - start == tank) and (stop != distance):     # don't consider destination as a refueling stop\n                start = stop    # move the starting point to the current gas stop\n                stop_list.append(stop)      # add the refueling stop to the stop list\n                prev = stop     # move the prev pointer to the stop\n            elif stop - start > tank:\n                start = prev    # move the starting point to the prev gas stop\n                if stop - start > tank:     # if next refuleing stop is farther than the dist. car can go in one full tank\n                    return -1\n                stop_list.append(prev)      # add the refueling stop to the list\n                prev = stop     # move the prev pointer the stop\n\n    return len(stop_list)\n"], ["string = \"11234\"\nstring_asList = list(string)       #converts sting into list\n\nstring_asList[0] = \"I\"             #replace element at [O] index\nstring = ''.join(string_asList)    #converts list back to string\n\nprint(string)\n"], [], ["import os\nfrom shutil import move\nfrom glob import iglob\nfrom pathlib import Path\nfrom concurrent.futures import ThreadPoolExecutor\n\n\n# The .py file has to be on the same directory as the folders containing the files!\nroot = Path(__file__).parent\n\n# Using threading in case the operation becomes I/O bound (many files)\nwith ThreadPoolExecutor() as executor:\n    for file in iglob(str(root / \"**\" / \"*\")):\n        file = Path(file)\n\n        # The new filename is the name of the directory, and the suffix(es) of the original file\n        new_filename = f\"{file.parent.name}{''.join(file.suffixes)}\"\n\n        # Move AND rename simultaneosly\n        executor.submit(move, file, root / new_filename)\n\n        # Delete directory because it is empty, and has no utility; ommit this line if not True\n        executor.submit(os.rmdir, file.parent)\n", "import os\nfrom shutil import move\nfrom glob import iglob\nfrom pathlib import Path\nfrom concurrent.futures import ThreadPoolExecutor\n\n\nRENAME_ONLY = True\n\n\n# The .py file has to be on the same directory as the folders containing the files!\nroot = Path(__file__).parent\n\n# Using threading in case the operation becomes I/O bound\nwith ThreadPoolExecutor() as executor:\n    for file in iglob(str(root / \"**\" / \"*\")):\n        file = Path(file)\n\n        # The new filename is the name of the directory, and the suffix(es) of the original file\n        new_filename = f\"{file.parent.name}{''.join(file.suffixes)}\"\n\n        if RENAME_ONLY:\n            executor.submit(os.rename, file, file.parent / new_filename)\n        else:\n            # Move AND rename simultaneosly\n            executor.submit(move, file, root / new_filename)\n\n            # Delete directory because it is empty, and has no utility; ommit this line if not True\n            executor.submit(os.rmdir, file.parent)\n"], ["apk fetch python3 py3-pip libbz2 libexpat libffi gdbm mpdecimal libpanelw readline \\\n    sqlite-libs py3-setuptools libgcc libstdc++ py3-packaging py3-parsing\n", "ENV PYTHONUNBUFFERED=1\nCOPY ./*.apk .\n\nRUN apk add --allow-untrusted --no-network libgcc* libstdc++* gdbm* libbz2* \\\n    libexpat* libffi* libpanel* mpdecimal* \\\n    readline* sqlite* \\\n    python3-3.11.4-r0.apk py3-parsing* py3-packaging* py3-setuptools* py3-pip-23.1.2-r0.apk && \\\n    rm *.apk && \\\n    ln -sf python3 /usr/bin/python\n"], ["import boto3\n\ndef count_objects_in_s3_folder(bucket_name, folder_name):\n    # Create an S3 client\n    s3 = boto3.client('s3')\n\n    # Specify the bucket and prefix (folder) within the bucket\n    bucket = {'Bucket': bucket_name}\n    prefix = folder_name + '/'\n\n    # Initialize the object count\n    object_count = 0\n\n    # Use the list_objects_v2 API to retrieve the objects in the folder\n    paginator = s3.get_paginator('list_objects_v2')\n    response_iterator = paginator.paginate(Bucket=bucket_name, Prefix=prefix)\n\n    # Iterate through the paginated responses\n    for response in response_iterator:\n        if 'Contents' in response:\n            object_count += len(response['Contents'])\n\n    print(f\"Number of objects in folder '{folder_name}': {object_count}\")\n\n# Provide the S3 bucket name and folder name to count objects in\nbucket_name = 'your_bucket_name'\nfolder_name = 'your_folder_name'\n\ncount_objects_in_s3_folder(bucket_name, folder_name)\n"], [], [], [], [], ["fig.update_xaxes(\n    rangebreaks=[dict(values=pd.date_range(start=\"2023-05-28\",end=\"2023-06-09\"))] # hide dates with no values\n)\n"], ["    <RCC>\n      <qresource prefix=\"/\">\n        <file>icons/myicon.png</file>\n      </qresource>\n    </RCC>\n", "    sed 's/:\\/icons\\//icons:/g' pyuic6_output_file.py > patched_file.py\n", "    QtCore.QDir.setSearchPaths(\"icons\", [os.path.join(os.path.dirname(__file__), 'icons')])\n"], ["// Step 1: Define the enums\nService = Enum('Service', ['Plumbing', 'Electrical', 'Carpentry', 'Special'])\nPlumbing = Enum('Plumbing', ['REGULAR', 'EXPRESS'])\nElectrical = Enum('Electrical', ['REGULAR', 'REWIRING', 'NEWSOCKETS'])\nCarpentry = Enum('Carpentry', ['REPAIR', 'NEW'])\nSpecial = Enum('Special', ['DEEPCLEAN', 'TOILETS'])\n\n    \n// step 2, define a dict to keep a track of your enums\nenumlist = {\n    'Plumbing' : Plumbing,\n    'Electrical' : Electrical,\n    'Carpentry' : Carpentry,\n    'Special' : Special\n}\n\n\n// step 3 : functions to convert an enum to and from string   \ndef str_to_enum(namestring):\n    try:\n        if namestring.split(\".\", 2)[0] not in enumlist:\n            return None\n        return enumlist[namestring.split(\".\", 2)[0]][namestring.split(\".\", 2)[1]]\n    except KeyError as e:\n        return None\n        \ndef enum_to_tr(value):\n    if not isinstance(value, Enum):\n        return None\n    return str(value)\n\n// step 4, a function to check if the enum named has the key needed\n\ndef is_in(enumname, keystr):   \n    supposedEnum = f'{enumname}.{keystr}'\n    \n    if str_to_enum(supposedEnum) is None:\n        return False\n    return True\n"], ["import timeit\nfrom enum import Enum, EnumMeta\nfrom random import randint\n\n\nclass MetaEnum(EnumMeta):\n    def __contains__(cls, item):\n        try:\n            cls(item)\n        except ValueError:\n            return False\n        return True    \n\n\nclass BaseEnum(Enum, metaclass=MetaEnum):\n    pass\n\n\nclass Action(BaseEnum):\n    A = 1\n    B = 2\n    C = 3\n    D = 4\n    \n    def is_action(obj):\n        try:\n            Action(obj)\n        except ValueError:\n            return False\n        return True\n\nrepeat, N = 100, 10000\nt_is_x = timeit.repeat(stmt=\"Action.is_action(i)\", setup='from random import randint; i = randint(1, 8)', number=N, repeat=repeat, globals=globals())\nt_meta = timeit.repeat(stmt=\"i in Action\", setup='from random import randint; i = randint(1, 8)', number=N, repeat=repeat, globals=globals())\nt_valuemap = timeit.repeat(stmt=\"i in Action._value2member_map_\", setup='from random import randint; i = randint(1, 8)', number=N, repeat=repeat, globals=globals())\n\nprint(f\"Time for is_x: {min(t_is_x)}\")\nprint(f\"Time for meta: {min(t_meta)}\")\nprint(f\"Time for value map: {min(t_valuemap)}\")\n", "Time for is_x: 0.008271969389170408\nTime for meta: 0.007943496108055115\nTime for value map: 0.0010849367827177048\n"], [], ["## through boto3 resource\ndef get_files_on_s3_resource(bucket_name, folder_path):\n    s3 = boto3.resource('s3')\n    bucket = s3.Bucket(bucket_name)\n    folder_objects = list(bucket.objects.filter(Prefix=folder_path))\n    files_on_s3 = []\n    for file in folder_objects:\n        files_on_s3.append(file.key)\n    return files_on_s3\n\n## with paginator for list_objects_v2\ndef list_s3_objects_wp(bucket_name, folder_path):\n    s3 = boto3.client('s3')\n    paginator = s3.get_paginator('list_objects_v2')\n\n    object_list = []\n    for page in paginator.paginate(Bucket=bucket_name, Prefix=folder_path):\n        for content in page.get('Contents', []):\n            object_list.append(content)\n\n    return object_list\n\n## without paginator for list_objects_v2\ndef list_s3_objects_wop(bucket_name, folder_path):\n    s3 = boto3.client('s3')\n    # get list of files on s3\n    object_list = []\n    for obj in s3.list_objects_v2(Bucket=bucket_name, Prefix=folder_path)['Contents']:\n        object_list.append(obj)\n        \n    return object_list\n\n## tried a way suggested in one of the answers above \ndef list_s3_objects_so(bucket_name, folder_path):\n    s3 = boto3.resource('s3')\n    # get list of files on s3\n    bucket = s3.Bucket(bucket_name)\n    count_obj = sum(1 for _ in bucket.objects.filter(Prefix=folder_path))\n    return count_obj\n", "bucket_name ='someBucket'\nfolder_path = 'someFolder/someKey/'\n\nstartr_time = time.time()\nfiles_on_s3 = get_files_on_s3(bucket_name, folder_path)\nend_time = time.time()\nprint('Time taken to get files on s3: ' + str(end_time - startr_time))\nprint(len(files_on_s3))\n\nstartr_time = time.time()\nfiles_on_s3 = list_s3_objects(bucket_name, folder_path)\nend_time = time.time()\nprint('Time taken to get files on s3: ' + str(end_time - startr_time))\nprint(len(files_on_s3))\n\nstartr_time = time.time()\nfiles_on_s3 = list_s3_objects_wop(bucket_name, folder_path)\nend_time = time.time()\nprint('Time taken to get files on s3: ' + str(end_time - startr_time))\nprint(len(files_on_s3))\n\nstartr_time = time.time()\nfiles_on_s3 = list_s3_objects_so(bucket_name, folder_path)\nend_time = time.time()\nprint('Time taken to get files on s3: ' + str(end_time - startr_time))\nprint(files_on_s3)\n\n\n> Time taken to get files on s3: 7.044371128082275\n> 21976\n> Time taken to get files on s3: 4.960357189178467\n> 21976\n> Time taken to get files on s3: 0.6216549873352051\n> 1000\n> Time taken to get files on s3: 7.754430055618286\n> 21976\n"], [], [], [], ["python3 --version\n", "python3 myscript.py\n"], [], ["!pip install nbformat\n"], ["% python3 --version\nPython 3.11.1\n", "python3.11 -m venv venv\n"], [], [], ["from __future__ import annotations # <-still need this.\nfrom typing import TYPE_CHECKING\n\nif TYPE_CHECKING: # <-try this,\n    from my_module import MyClass # <-if this is only for type hinting.\n"], [], [], ["export SYSTEM_VERSION_COMPAT=1\n"], [], [], ["features = pd.concat([features, input_vars.to_frame().T])\n"], [], ["from app.controllers.users import get_user_manager, UserManager\n\nImportError: cannot import name 'get_user_manager' from partially initialized module 'app.controllers.users' (most likely due to a circular import)\n"], ["import requests\n\naccess_token = get_access_token()  # from @amit's answer above\nbase_url = \"https://graph.microsoft.com/v1.0\"\n\n# example url to list folders for a user's mailbox\nurl = f\"{base_url}/users/{user_id}/mailFolders\"\nresponse = requests.get(\n     url, \n     headers={\n          'Authorization': 'Bearer ' + access_token['access_token']\n     }\n)\n"], [], ["sudo chown $(whoami):$(whoami) /var/run/docker.sock\n", "sudo nano /etc/systemd/system/sockets.target.wants/docker.socket\n", "[Unit]\nDescription=Docker Socket for the API\n\n[Socket]\nListenStream=/var/run/docker.sock\nSocketMode=0660\nSocketUser=YOUR_USERNAME_HERE\nSocketGroup=docker\n\n[Install]\nWantedBy=sockets.target\n", "$ sudo chgrp -R docker /path/to/directory \n", "$sudo chmod -R g+rw /path/to/directory \n"], ["counter = 0\nq.put((priority, counter:= counter+1, item))\n"], ["#If your index is a string\ndf.loc[\"name of the index\"] = pd.Series({\"Column 1\" : Value1, \"Column 2\" : Value2,\n\"Column 3\" : Value3, \"Column 4\" : Value4, ...})\n\n#If your index is a number\ndf.loc[len(df)] = pd.Series({\"Column 1\" : Value1, \"Column 2\" : Value2,\n\"Column 3\" : Value3, \"Column 4\" : Value4, ...})\n"], ["import re\n\ndef text_to_html_paragraphs(text):\n    # First, replace multiple newlines with a single newline,\n    # so you don't get empty paragraphs\n    text = re.sub(r'\\n\\s*\\n', '\\n', text)\n\n    # Split the text into lines\n    lines = text.split('\\n')\n\n    # Wrap each line in a <p> tag and join them\n    return ''.join(f'<p>{line.strip()}</p>\\n' for line in lines)\n\ntext = \"\"\"His this \n\nis \n\na sample\n\nString\"\"\"\n\nhtml_paragraphs = text_to_html_paragraphs(text)\nprint(html_paragraphs)\n", "<p>is</p>\n<p>a sample</p>\n<p>String</p>\n"], ["dt_cols = df.select_dtypes(include=['datetime64[ns, UTC]']).columns\nfor col in dt_cols:\n        df[col] = df[col].dt.tz_localize(None)\ndf.to_excel(f'{table_name}.xlsx', engine=\"xlsxwriter\", index=False)\n"], [], ["def flatten(model):\n    submodules = list(model.children())\n    if len(submodules) == 0:\n        return [model]\n    else:\n        res = []\n        for module in submodules:\n            res += flatten(module)\n        return res\n"], [], ["import asyncio\nfrom asyncio import create_subprocess_shell\nfrom asyncio.subprocess import PIPE, STDOUT\nimport sys\n\nasync def main():\n    # create a subprocess in asyncio and connect its stdout to the stdin of another subprocess\n\n\n    p1 = await create_subprocess_shell(\"python myfile.py\",\n                                       stdout=PIPE, stderr=STDOUT)\n    while True:\n        if p1.stdout.at_eof():\n            break\n        stdout = (await p1.stdout.readline()).decode()\n        if stdout:\n            print(f'[stdout] {stdout}')\n    await p1.wait()\n"], ["for module_name, module in model.named_modules():\n    print(f\"module_name : {module_name} , value : {module}\")\n", "import torch\nmodel = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=True).to(device = device,non_blocking=True)\n\nfor module_name, module in model.named_modules():\n    print(f\"module_name : {module_name} , value : {module}\")\n", "conv1\nbn1\nlayer1\nlayer1.0\nlayer1.0.relu\nlayer1.0.conv2\nlayer1.0.bn2\nlayer1.1\nlayer1.1.conv2\nlayer1.1.bn2\n"], ["sudo apt install python3-pip\nsudo apt-get update\n", "sudo apt install python3.10-venv\n", "python3 -m venv venv\n"], ["year = 2023\nweek = 12\n\nstartdate = datetime.date.fromisocalendar(year, week, 1)\n\ndates = []\nfor i in range(7):\n   day = startdate + datetime.timedelta(days=i)\n   dates.append(day)\n", "[\n  \"2023-03-20\",\n  \"2023-03-21\",\n  \"2023-03-22\",\n  \"2023-03-23\",\n  \"2023-03-24\",\n  \"2023-03-25\",\n  \"2023-03-26\"\n]\n"], [], [], ["pip install pip==9.0.3\npip install --upgrade pip\n"], [], [], [], ["import os\n\nif __name__ == '__main__':\n    os.chdir(\".{0}your_program_folder\".format(os.sep))\n    os.system(\"your_program.exe\")\n", "dist\n|    your_program_launcher.exe\n|\n|____your_program_folder\n|       |_____lib1\n|       |_____lib2\n|       |_____libn\n|       |     your_program.exe\n"], ["sudo apt-get install libmysqlclient-dev\n", "pipenv install mysqlclient\n"], ["pd.concat([cap[['Ticker', 'Market Cap']].iloc[:1] for cap in collector] )\n"], [], [], ["def myfunc(arr):\n ignore_list = []\n newlist = []\n for i,v in enumerate(arr):\n     if v >= 6 and v <= 9:\n         ignore_list.append(i)\n     if i in ignore_list:\n         newlist.append(0)\n     else:\n         newlist.append(v)\n\n return sum(newlist)\n"], ["import os\nfrom PIL import Image\nfolder_path = r\"C:\\Users\\ImageDatasets\"\nextensions = []\ncorupt_img_paths=[]\nfor fldr in os.listdir(folder_path):\n    sub_folder_path = os.path.join(folder_path, fldr)\n    for filee in os.listdir(sub_folder_path):\n        file_path = os.path.join(sub_folder_path, filee)\n        print('** Path: {}  **'.format(file_path), end=\"\\r\", flush=True)\n        try:\n            im = Image.open(file_path)\n        except:\n            print(file_path)\n            os.remove(file_path)\n            continue\n        else:\n            rgb_im = im.convert('RGB')\n            if filee.split('.')[1] not in extensions:\n                extensions.append(filee.split('.')[1])\n"], ["import sys\nimport time\nfrom selenium import webdriver\nfrom selenium.webdriver.chrome.service import Service\nfrom selenium.webdriver.chrome.options import ChromiumOptions\nfrom webdriver_manager.chrome import ChromeDriverManager\n\nchrome_options = ChromiumOptions()\n\nservice = Service(ChromeDriverManager().install())\n\ndriver = webdriver.Chrome(chrome_options=chrome_options, service=service)\ndriver.get(\"http://www.python.org\")\n\ntime.sleep(sys.maxsize)\ndriver.quit()\n"], [], ["for x in range(4) : \n    if not flag: continue\n    defA()\n"], [" pip install 'paramiko<=2.8.1'\n"], [], [], [], ["for i in range(1, 5):\n    if i == 2: continue\n    print(i)\n"], ["from ..models.user_model import User as user_model\nmain = Blueprint('main', __name__)\n", "main = Blueprint('main', __name__)\n# always import models after blueprint object creation.\nfrom ..models.user_model import User as user_model\n"], ["from .a import A\nfrom .b import B\n", "from models.b import B\n\n...\n"], ["df['date'] = df['date'].astype(str)\n"], ["def getNumberOfObjectsInBucket(bucketName,prefix):\n    count = 0\n    response = boto3.client('s3').list_objects_v2(Bucket=bucketName,Prefix=prefix)\n    for object in response['Contents']:\n        if object['Size'] != 0:\n            #print(object['Key'])\n            count+=1\n    return count\n", "getNumberOfObjectsInBucket('foo-test-bucket','foo-output/')\n"], ["#write a file \nenter code here\nwrite_File=open(\"sample.txt\",\"w\")\nwrite_File.write(\"line1\\nline2\\nline3\\nline4\\nline5\\nline6\\n\")\nwrite_File.close()\n\n#open a file without new line of the characters\nopen_file=open(\"sample.txt\",\"r\")\nopen_new_File=open_file.read()\nreplace_string=open_new_File.replace(\"\\n\",.\" \")\nprint(replace_string,end=\" \")\nopen_file.close()\n", "line1 line2 line3 line4 line5 line6\n"], ["pyuic6 tip.ui > tip.py && sed -i '10iimport _cf_rc\\nimport _rc_rc' tip.py\n", "sed -i \"10i' -> means insert from the 10th line onwards.\n", "import _cf_rc\n\nimport _rc_rc\n"], ["def get_layers(model: torch.nn.Module):\n    children = list(model.children())\n    return [model] if len(children) == 0 else [ci for c in children for ci in get_layers(c)]\n"], ["model = model.to(\"cuda\")\ndata = data.to(\"cuda\")\n", "model.to(\"cuda\")\ndata.to(\"cuda\")\n"], [], [], ["#here is my approach:\nfor name, m in model.named_modules():\n    if len(list(m.named_modules()))==1:\n        print(name,\"\\t\",m)\n"], [], ["train_data = list(train_ds)\nfeatures = np.concatenate([train_data[n][0] for n in range(0, len(train_data))])\ntargets = np.concatenate([train_data[n][1] for n in range(0, len(train_data))])\n\n"], ["conda install pytorch==1.12.1 torchvision==0.13.1 torchaudio==0.12.1 cudatoolkit=10.2 -c pytorch\n", "conda install pytorch==1.12.1 torchvision==0.13.1 cudatoolkit=10.2 -c pytorch\n"], ["def get_access_token():\n    tenantID = 'abc'\n    authority = 'https://login.microsoftonline.com/' + tenantID\n    clientID = 'abc'\n    clientSecret = 'abc'\n    scope = ['https://outlook.office365.com/.default']\n    app = ConfidentialClientApplication(clientID, \n          authority=authority, \n          client_credential = clientSecret)\n    access_token = app.acquire_token_for_client(scopes=scope)\n    return access_token\n\ndef generate_auth_string(user, token):\n    auth_string = f\"user={user}\\1auth=Bearer {token}\\1\\1\"\n    return auth_string\n\n#IMAP AUTHENTICATE\n imap = imaplib.IMAP4_SSL(imap_host, 993)\n imap.debug = 4\n access_token = get_access_token_to_authenticate_imap()\n imap.authenticate(\"XOAUTH2\", lambda x:generate_auth_string(\n      'useremail',\n       access_token['access_token']))\n imap.select('inbox')\n"], [], ["import datetime\nimport yfinance as yf\nnow = datetime.datetime.now().strftime(\"%Y-%m-%d\")\ndata = yf.Ticker(\"ABEV3.SA\")\ndata = data.history(start=\"2010-01-01\",  end=now)\nprint(data)\n"], ["from enum import Enum, EnumMeta\n\n\nclass MetaEnum(EnumMeta):\n    def __contains__(cls, item):\n        try:\n            cls(item)\n        except ValueError:\n            return False\n        return True    \n\n\nclass BaseEnum(Enum, metaclass=MetaEnum):\n    pass\n\n\nclass Stuff(BaseEnum):\n    foo = 1\n    bar = 5\n", ">>> 1 in Stuff\nTrue\n\n>>> Stuff.foo in Stuff\nTrue\n\n>>> 2 in Stuff\nFalse\n\n>>> 2.3 in Stuff\nFalse\n\n>>> 'zero' in Stuff\nFalse\n"], [], [], [], ["pip install ipykernel\n", "pip install --upgrade nbformat\n"], [], ["Dotted two 4096x4096 matrices in 0.28 s.\nDotted two vectors of length 524288 in 0.11 ms.\nSVD of a 2048x1024 matrix in 0.44 s.\nCholesky decomposition of a 2048x2048 matrix in 0.07 s.\nEigendecomposition of a 2048x2048 matrix in 3.83 s.\n\nTOTAL TIME = 19 seconds\n"], ["sudo apt-get install python3-pip\n"], ["num1 = int(input())\nnum2 = int(input())\nnum3 = int(input())\n\nlowest = min(num1, num2, num3)\n\nif num1 < num2 and num1 < num3:\n    lowest = num1\n\nelif num2 < num1 and num2 < num3:\n    lowest = num2\n\nelif num3 < num1 and num3 < num2:\n    lowest = num3\n\nprint(lowest)\n"], [], ["    def  Salary_Msg(self):\n        #f is called function f\n        #next use {write in}\n        return f{self.firstname} {self.Lastname} earns AUD {self.Salary}per {self.Time} \"\n"], ["ssh_client.connect(\n  server, username=ssh_user, key_filename=ssh_keypath,\n  disabled_algorithms=dict(pubkeys=[\"rsa-sha2-512\", \"rsa-sha2-256\"]))\n", "Our pubkey algorithm list: ['ssh-rsa']\nServer did not send a server-sig-algs list; defaulting to our first preferred algo ('ssh-rsa')\nNOTE: you may use the 'disabled_algorithms' SSHClient/Transport init kwarg to disable that or other algorithms if your server does not support them!\n", " client.connect(hostname=self.hostname_sfp,\n                           username=self.user_sftp,\n                           password=self.password_sftp,\n                           port=self.port_sftp,\n                           disabled_algorithms=dict(pubkeys=[\"rsa-sha2-512\", \"rsa-sha2-256\"]),\n                           allow_agent=False,\n                           look_for_keys=False\n                           )\n"], ["import paramiko.transport\nif hasattr(paramiko.transport.Transport, '_preferred_pubkeys'):\n    pk = paramiko.transport.Transport._preferred_pubkeys\n    ssh_rsa_pos = pk.index('ssh-rsa')\n    if ssh_rsa_pos >= 0:\n        fixed_pk = [\n            x for x in pk[:ssh_rsa_pos]\n            if not x.startswith('rsa-sha2-')\n        ] + [\n            pk[ssh_rsa_pos]\n        ] + [\n            x for x in pk[:ssh_rsa_pos]\n            if x.startswith('rsa-sha2-')\n        ] + list(pk[ssh_rsa_pos + 1:])\n        paramiko.transport.Transport._preferred_pubkeys = tuple(fixed_pk)\n\n"], ["DISABLED_ALGORITHMS = {'keys': ['rsa-sha2-256', 'rsa-sha2-512'], 'pubkeys':['rsa-sha2-512', 'rsa-sha2-256']}\n", "from packaging import version\nif version.parse(paramiko.__version__) > version.parse(\"2.8.1\") and version.parse(paramiko.__version__) <= version.parse(\"2.12.0\"):\n    print(f\"Paramiko Version:{paramiko.__version__}\")\n    _preferred_pubkeys = (\n    \"ssh-ed25519\",\n    \"ecdsa-sha2-nistp256\",\n    \"ecdsa-sha2-nistp384\",\n    \"ecdsa-sha2-nistp521\",\n    \"ssh-rsa\",\n    \"rsa-sha2-512\",\n    \"rsa-sha2-256\",\n    \"ssh-dss\",\n    )\n    \n    print(f\"Patching _preferred_pubkeys {paramiko.transport.Transport._preferred_pubkeys} with {_preferred_pubkeys}\")\n    paramiko.transport.Transport._preferred_pubkeys = _preferred_pubkeys\n"], [], ["def get_sentinel():\n    ...\n", "from django.conf import settings\nfrom authentication.models_utils import get_sentinel\nfrom .room import Room\n\nclass Section(models.Model):\n...\n"], [], [], ["rcc -g python -o resources.py resources.qrc\n", "pyside6-rcc -o resources.py resources.qrc\n", "# Resource object code (Python 3)\n# Created by: object code\n# Created by: The Resource Compiler for Qt version 6.4.0\n# WARNING! All changes made in this file will be lost!\n\n# from PySide6 import QtCore <-- replace this line\nfrom PyQt6 import QtCore\n", "rcc -g python resources.qrc | sed '0,/PySide6/s//PyQt6/' > resources.py\n", "pyside6-rcc reources.qrc | sed '0,/PySide6/s//PyQt6/' > resources.py  \n", "from PyQt6 import QtCore, QtGui, QtWidgets\nfrom test_ui import Ui_Window\nimport resources\n\nclass Window(QtWidgets.QWidget, Ui_Window):\n    def __init__(self):\n        super().__init__()\n        self.setupUi(self)\n\nif __name__ == '__main__':\n\n    app = QtWidgets.QApplication(['Test'])\n    window = Window()\n    window.show()\n    app.exec()\n"], [], ["target_layers =[]\nmodule_list =[module for module in model.modules()] # this is needed\nflatted_list= flatten_model(module_list)\n\nfor count, value in enumerate(flatted_list):\n    \n    if isinstance(value, (nn.Conv2d,nn.AvgPool2d,nn.BatchNorm2d)):\n    #if isinstance(value, (nn.Conv2d)):\n        print(count, value)\n        target_layers.append(value)\n\n", "1 Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n2 BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n7 Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n8 BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n9 Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n10 BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n11 Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n12 BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n15 Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n16 BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n18 Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n19 BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n20 Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n21 BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n22 Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n23 BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n26 Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n27 BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n28 Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n29 BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n30 Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n31 BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n35 Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n36 BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n37 Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n38 BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n39 Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n40 BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n43 Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n44 BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n46 Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n47 BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n48 Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n49 BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n50 Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n51 BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n54 Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n55 BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n56 Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n57 BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n58 Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n59 BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n62 Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n63 BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n64 Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n65 BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n66 Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n67 BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n71 Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n72 BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n73 Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n74 BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n75 Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n76 BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n79 Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n80 BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n82 Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n83 BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n84 Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n85 BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n86 Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n87 BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n90 Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n91 BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n92 Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n93 BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n94 Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n95 BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n98 Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n99 BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n100 Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n101 BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n102 Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n103 BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n106 Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n107 BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n108 Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n109 BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n110 Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n111 BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n114 Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n115 BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n116 Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n117 BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n118 Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n119 BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n123 Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n124 BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n125 Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n126 BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n127 Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n128 BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n131 Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n132 BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n134 Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n135 BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n136 Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n137 BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n138 Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n139 BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n142 Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n143 BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n144 Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n145 BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n146 Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n147 BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n"], ["FROM python:3 as builder\nCOPY Pipfile* /\nRUN mkdir /.venv  # The presence of a .venv folder triggers pipenv to use it by default\nRUN pipenv install --deploy\n\nFROM python:3-slim\nCOPY --from=builder /.venv /.venv\nWORKDIR /myapp\nCOPY src .\nCMD [\"/.venv/bin/python3\", \"app.py\"]\n"], [], [], ["import numpy as np\nimport pandas as pd\nimport warnings\n\ndf = pd.DataFrame({\"price\": [11.1, 12.2]}, index=[\"book1\", \"book2\"])\noriginal_prices = df[\"price\"]\nnew_prices = np.array([98, 99])\nwith warnings.catch_warnings():\n    # Setting values in-place is fine, ignore the warning in Pandas >= 1.5.0\n    # This can be removed, if Pandas 1.5.0 does not need to be supported any longer.\n    # See also: https://stackoverflow.com/q/74057367/859591\n    warnings.filterwarnings(\n        \"ignore\",\n        category=FutureWarning,\n        message=(\n            \".*will attempt to set the values inplace instead of always setting a new array. \"\n            \"To retain the old behavior, use either.*\"\n        ),\n    )\n\n    df.iloc[:, 0] = new_prices\n\ndf.iloc[:, 0]\n"], [], ["New-ServicePrincipal -AppId <APPLICATION_ID> -ServiceId <OBJECT_ID> [-Organization <ORGANIZATION_ID>]\n", "import imaplib\nimport msal\nimport pprint\n\nconf = {\n    \"authority\": \"https://login.microsoftonline.com/XXXXyourtenantIDXXXXX\",\n    \"client_id\": \"XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXXX\", #AppID\n    \"scope\": ['https://outlook.office365.com/.default'],\n    \"secret\": \"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\", #Key-Value\n    \"secret-id\": \"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\", #Key-ID\n}\n    \ndef generate_auth_string(user, token):\n    return f\"user={user}\\x01auth=Bearer {token}\\x01\\x01\"    \n\nif __name__ == \"__main__\":\n    app = msal.ConfidentialClientApplication(conf['client_id'], authority=conf['authority'],\n                                             client_credential=conf['secret'])\n\n    result = app.acquire_token_silent(conf['scope'], account=None)\n\n    if not result:\n        print(\"No suitable token in cache.  Get new one.\")\n        result = app.acquire_token_for_client(scopes=conf['scope'])\n\n    if \"access_token\" in result:\n        print(result['token_type'])\n        pprint.pprint(result)\n    else:\n        print(result.get(\"error\"))\n        print(result.get(\"error_description\"))\n        print(result.get(\"correlation_id\"))\n        \n    imap = imaplib.IMAP4('outlook.office365.com')\n    imap.starttls()\n    imap.authenticate(\"XOAUTH2\", lambda x: generate_auth_string(\"target_mailbox@example.com\", result['access_token']).encode(\"utf-8\"))\n"], [], [], [], ["from azure.storage.blob import BlobClient,ContentSettings\n\nblob = BlobClient.from_connection_string(conn_str=connection_string, container_name=container_name, blob_name=\"my_blob9\")\nimage_content_setting = ContentSettings(content_type='image/jpeg')\n\nwith open(\"/content/sample_data/kanha.png\",\"rb\") as data:\n    blob.upload_blob(data,overwrite=True,content_settings=image_content_setting)\n"], ["enc = OneHotEncoder(categories = [[0, 1]], handle_unknown='ignore')\n"], ["def clean_class_dict(class_dict):\n    return_dict = dict(class_dict)\n    for key in list(return_dict.keys()):\n        if key[0] == \"_\":\n            del return_dict[key]\n    return return_dict\n\ndef item_in_enum_titles(item: str, enum: Enum):\n    enum_dict = clean_class_dict(enum.__dict__)\n    if item in enum_dict.keys():\n        return True\n    else:\n        return False\n"], ["def split_check(bill=0.0, people=0, tax_percentage=0.09, tip_percentage=0.15):\n    bill_per_diner = ((bill + ((tax_percentage * bill) + (tip_percentage * bill))) / people)\n    return bill_per_diner\n"], [], ["pip install pytz --upgrade\npip install tzdata --upgrade\n"], ["import json\nimport msal\n\nimport requests\n\nclient_id = '***'\nclient_secret = '***'\ntenant_id = '***'\nauthority = f\"https://login.microsoftonline.com/{tenant_id}\"\n\napp = msal.ConfidentialClientApplication(\n    client_id=client_id,\n    client_credential=client_secret,\n    authority=authority)\n\nscopes = [\"https://graph.microsoft.com/.default\"]\n\nresult = None\nresult = app.acquire_token_silent(scopes, account=None)\n\nif not result:\n    print(\n        \"No suitable token exists in cache. Let's get a new one from Azure Active Directory.\")\n    result = app.acquire_token_for_client(scopes=scopes)\n\n# if \"access_token\" in result:\n#     print(\"Access token is \" + result[\"access_token\"])\n\n\nif \"access_token\" in result:\n    userId = \"***\"\n    endpoint = f'https://graph.microsoft.com/v1.0/users/{userId}/sendMail'\n    toUserEmail = \"***\"\n    email_msg = {'Message': {'Subject': \"Test Sending Email from Python\",\n                             'Body': {'ContentType': 'Text', 'Content': \"This is a test email.\"},\n                             'ToRecipients': [{'EmailAddress': {'Address': toUserEmail}}]\n                             },\n                 'SaveToSentItems': 'true'}\n    r = requests.post(endpoint,\n                      headers={'Authorization': 'Bearer ' + result['access_token']}, json=email_msg)\n    if r.ok:\n        print('Sent email successfully')\n    else:\n        print(r.json())\nelse:\n    print(result.get(\"error\"))\n    print(result.get(\"error_description\"))\n    print(result.get(\"correlation_id\"))\n"], ["x = x.to(device, dtype=torch.float32)\n\ny = y.to(device, dtype=torch.float32)\n"], ["import os\nimport ssl, shutil, re, platform\nimport zipfile\nfrom urllib.request import urlopen\nfrom pathlib import Path\n\nimport difflib\n\n\ndef chrome_driver_url(latest=False):\n    def current_chrome_version():\n        CHROME_RELEASE_URL = \"https://sites.google.com/chromium.org/driver/downloads?authuser=0\"\n        try:\n            response = urlopen(CHROME_RELEASE_URL,context=ssl.SSLContext(ssl.PROTOCOL_TLS)).read()\n        except ssl.SSLError:\n            response = urlopen(CHROME_RELEASE_URL,).read()\n\n        downloading_version = re.findall(b\"ChromeDriver \\d{2,3}\\.0\\.\\d{4}\\.\\d+\", response)\n        downloading_version = [x.decode().split(\" \")[1] for x in downloading_version]\n        downloading_version.sort(key=lambda x: [int(i) if i.isdigit() else i for i in x.split('.')])\n        downloading_version.reverse()\n        osname = platform.system()\n        if osname == 'Darwin':\n            installpath = \"/Applications/Google\\ Chrome.app/Contents/MacOS/Google\\ Chrome\"\n            verstr = os.popen(f\"{installpath} --version\").read().strip('Google Chrome ').strip()\n            ver_to_download = difflib.get_close_matches(verstr, downloading_version)\n            ver_to_download = ver_to_download[0]\n            return ver_to_download\n        elif osname == 'Windows':\n            verstr = os.popen('reg query \"HKEY_CURRENT_USER\\Software\\Google\\Chrome\\BLBeacon\" /v version').read().strip().split(\" \")\n            verstr = verstr[-1]\n            ver_to_download = difflib.get_close_matches(verstr, downloading_version)\n            ver_to_download = ver_to_download[0]\n            return ver_to_download\n        elif osname == 'Linux':\n            installpath = \"/usr/bin/google-chrome\"\n            verstr = os.popen(f\"{installpath} --version\").read().strip('Google Chrome ').strip()\n            ver_to_download = difflib.get_close_matches(verstr, downloading_version)\n            ver_to_download = ver_to_download[0]\n            return ver_to_download\n        else:\n            raise NotImplemented(f\"Unknown OS '{osname}'\")\n\n    if latest:\n        CHROME_RELEASE_URL = \"https://sites.google.com/chromium.org/driver/downloads?authuser=0\"\n        try:\n            response = urlopen(CHROME_RELEASE_URL, context=ssl.SSLContext(ssl.PROTOCOL_TLS)).read()\n        except ssl.SSLError:\n            response = urlopen(CHROME_RELEASE_URL).read()\n\n        downloading_version = re.findall(b\"ChromeDriver \\d{2,3}\\.0\\.\\d{4}\\.\\d+\", response)[0].decode().split()[1]\n    else:\n        downloading_version = current_chrome_version()\n\n    system = platform.system()\n    if system == \"Windows\":\n        url = f\"https://chromedriver.storage.googleapis.com/{downloading_version}/chromedriver_win32.zip\"\n    elif system == \"Darwin\":\n        # M1\n        if platform.processor() == 'arm':\n            url = f\"https://chromedriver.storage.googleapis.com/{downloading_version}/chromedriver_mac64_m1.zip\"\n        else:\n            url = f\"https://chromedriver.storage.googleapis.com/{downloading_version}/chromedriver_mac64.zip\"\n    elif system == \"Linux\":\n        url = f\"https://chromedriver.storage.googleapis.com/{downloading_version}/chromedriver_linux64.zip\"\n    return url\n\n\ndef download_chrome_driver(drivers_dir):\n    driver_name = \"chromedriver.exe\" if platform.system() == \"Windows\" else \"chromedriver\"\n    if (drivers_dir / driver_name).exists():\n            return\n    url = chrome_driver_url()\n    try:\n        response = urlopen(url, context=ssl.SSLContext(ssl.PROTOCOL_TLS))  \n    except ssl.SSLError:\n        response = urlopen(url)  \n\n    zip_file_path = drivers_dir / Path(url).name\n    with open(zip_file_path, 'wb') as zip_file:\n        while True:\n            chunk = response.read(1024)\n            if not chunk:\n                break\n            zip_file.write(chunk)\n\n    extracted_dir = drivers_dir / zip_file_path.stem\n    with zipfile.ZipFile(zip_file_path, \"r\") as zip_file:\n        zip_file.extractall(extracted_dir)\n    os.remove(zip_file_path)\n\n    driver_path = drivers_dir / driver_name\n    try:\n        (extracted_dir / driver_name).rename(driver_path)\n\n    except FileExistsError:\n        (extracted_dir / driver_name).replace(driver_path)\n\n    shutil.rmtree(extracted_dir)\n    os.chmod(driver_path, 0o755)\n\nif __name__ == \"__main__\":\n    chrome_driver_location = Path(\"chrome_driver\")\n    chrome_driver_location.mkdir(exist_ok=True)\n    download_chrome_driver(chrome_driver_location)\n\n"], [], [], [], [], ["parameters = ['a', 'b', 'c', 'd', 'e', 'f']\ndf = pd.DataFrame(columns=parameters)\n", "        a   b   c   d   e   f\n", "new_row = pd.Series([1,2,3,4,5,6], index=parameters, name='row1')\ndf.append(new_row)\n", "        a   b   c   d   e   f\nrow1    1   2   3   4   5   6\n", "new_row = pd.DataFrame([1,2,3,4,5,6], columns=['row1'], index=parameters).T\ndf = pd.concat((df, new_row))\n"], ["conda create --name myenv python=3.6\nCollecting package metadata (current_repodata.json): done\nSolving environment: failed with repodata from current_repodata.json, will retry with next repodata source.\nCollecting package metadata (repodata.json): done\nSolving environment: failed\nPackagesNotFoundError: The following packages are not available from current channels:\n - python=3.6\n"], ["num1 = int(input())\nnum2 = int(input())\nnum3 = int(input())\n\nif (num1 <= num2 and num1 <= num3):\nsmall = num1\n\nelif (num2 <= num1 and num2 <= num3): \nsmall = num2\nelse:\nsmall = num3\nprint(small)\n"], ["for count in range(num_samples):\n    # .... code to produce `input_vars`\n    features = features.append(input_vars)        # remove this `DataFrame.append`\n", "tmp = []                                  # initialize list\nfor count in range(num_samples):\n    # .... code to produce `input_vars`\n    tmp.append(input_vars)                        # append to the list, (not DF)\nfeatures = pd.concat(tmp)                         # concatenate after loop\n"], ["apk add --no-cache python3 py3-pip\n"], [], ["FROM pypiserver/pypiserver:latest\nENTRYPOINT [\"/entrypoint.sh\", \"run\", \"--hash-algo\", \"sha256\"]\n"], ["model = torch.load(PATH).type(torch.FloatTensor).to(device)\ninput = input.type(torch.FloatTensor).to(device)\n"], ["def appendDictToDF(df,dictToAppend):\n  df = pd.concat([df, pd.DataFrame.from_records([dictToAppend])])\n  return df\n\n# Creating an empty dataframe\ndf = pd.DataFrame(columns=['a', 'b'])\n\n# Appending a row\ndf= appendDictToDF(df,{ 'a': 1, 'b': 2 })\n"], [], ["python3 -m pip install rpy2\n", "Error in glue(.Internal(R.home()), \"library\", \"base\", \"R\", \"base\", sep = .Platform$file.sep) : \n  4 arguments passed to .Internal(paste) which requires 3\nError: could not find function \"attach\"\nError: object '.ArgsEnv' not found\nFatal error: unable to initialize the JIT\n", "conda install --yes rpy2\n"], [], ["%timeit df['code'].values[-1].   )\n", "%timeit df.loc[df.index[-1], 'code']\n", "%timeit df['code'].iat[-1]\n\n", "%timeit df['code'].tail(1).item()\n", "%timeit df.iloc[-1, df.columns.get_loc('code')]\n", "%timeit df['code'].iloc[-1]\n"], ["return FileResponse(\n    temp_file,\n    background=BackgroundTask(cleanup, file_path),\n)\n"], ["type(train_ds)\n>> tensorflow.python.data.ops.dataset_ops.PrefetchDataset\n", "[(train_features, label_batch)] = train_ds.take(1)\nprint(np.array(label_batch))\n"], [], ["# Deprecated issue has been resolved\n\n# Creating an empty dataframe\ndf = pd.DataFrame(columns=['a', 'b'])\nprint(\"df columns:\", df)\n\n# Appending a row\ndf = df.append({ 'a': 1, 'b': 2 }, ignore_index=True)\nprint(\"df column Values :\", df)\n\n# Create the new row as its own dataframe\ndf_new_row = pd.DataFrame.from_records({ 'a': [3], 'b': [4] })\ndf = pd.concat([df, df_new_row])\nprint(\"pd concat with two df's :\", df)\n"], ["    driver.get(\"https://instagram.com/\")\n    time.sleep(7)\n    acpt = browser.find_element(by=By.XPATH, value='/html/body/div[1]/div/div/div/div[2]/div/div/div[1]/div/div[2]/div/div/div/div/div/div/div/div[3]/button[2]')\n    acpt.click()\n"], [], ["import os \\\nos.environ['R_HOME'] = '/usr/lib/R'\n"], [], [], [], ["RUN adduser -D dockuser\nUSER dockuser\n"], ["/home/me/.local/lib/python3.10/site-packages/cv2\n"], ["plt.imshow(white_torch.permute(1, 2, 0))\n", "import torch\nimport torchvision\nfrom torchvision.io import read_image\nimport torchvision.transforms as T\n\n!wget 'https://images.unsplash.com/photo-1553284965-83fd3e82fa5a?ixlib=rb-1.2.1&ixid=MnwxMjA3fDB8MHxleHBsb3JlLWZlZWR8NHx8fGVufDB8fHx8&w=1000&q=80'  -O white_horse.jpg\n\nwhite_torch = torchvision.io.read_image('white_horse.jpg')\n\nT.ToPILImage()(white_torch)\n"], ["df.index = df.index.tz_localize(None)\ndf.to_excel(path)\n"], [], ["model = MyModel()\n\nif torch.cuda.is_available():\n    model.cuda()\n"], [], ["from enum import Enum, EnumMeta\nfrom typing import Any\n\nclass EnumeratorMeta(EnumMeta):\n\n    def __contains__(cls, member: Any):\n        if type(member) == cls:\n            return EnumMeta.__contains__(cls, member)\n        else:\n            try:\n                cls(member)\n            except ValueError:\n                return False\n            return True\n\n\nclass Enumerator(Enum, metaclass=EnumeratorMeta):\n    pass\n\n\nclass ENTITY_TYPES(Enumerator):\n    SERVICE: str = 'service'\n    CONFIGMAP: str = 'configmap'\n"], ["In [6]: df['col1'].take([-1]).item()\nOut[6]: 3\n"], ["import yfinance as yf\nyca = yf.Ticker(\"YCA.L\").history(interval=\"1m\", period = \"1d\")\nyca['Close'][-1]\n"], ["obj_df_encoded = pd.get_dummies(obj_df)\nprint(obj_df)\n>> 1 0\n>> 0 1\n>> 0 0\n"], [], ["num1 = int(input())\nnum2 = int(input())\nnum3 = int(input())\n\nif (num1 < num2 and num1 < num3):\n    small = num1\n\nelif (num2 < num1 and num2 < num3): \n    small = num2\nelse:\n    small = num3\nprint(small)\n"], ["pattern=r\"\\b\\w*[aeiou]{3,}\\w*\\b\"\n"], [], [], ["stocks = ['PETR4.SA', 'ELET3.SA', 'VALE3.SA']\n\ndf = yf.download(' '.join(stocks), period='1d', progress=False)\ndf = df['Close']\n\nfor stock in stocks:\n    if stock not in df or len(df[stock]) == 0: # this verification is important if trading session is closed\n        continue\n    quote = df[stock][0]\n    print('%s = %.2f'%(stock, quote))\n\n"], [], ["def split_check(bill, people, tax = 0.09, tip = 0.15)\n", "def split_check(bill, people, tax = 0.09, tip = 0.15):\n    taxes = bill * tax\n    tips  = bill * tip\n    return (bill + taxes + tips) / people\n"], [], ["sudo virtualenv venv\n"], ["def split_check(bill=0, people=0, tax_percentage=0.09, tip_percentage=0.15):\n    new_check = (bill * tax_percentage) + bill\n    new_tip = bill * tip_percentage\n    per_person = (new_check + new_tip) / people\n    return per_person\n\nbill = float(input())\npeople = int(input())\n\n# Cost per diner at the default tax and tip percentages\nprint('Cost per diner:', split_check(bill, people))\n\nbill = float(input())\npeople = int(input())\nnew_tax_percentage = float(input())\nnew_tip_percentage = float(input())\n\n# Cost per diner at different tax and tip percentages\nprint('Cost per diner:', split_check(bill, people, new_tax_percentage, new_tip_percentage))\n"], ["date_columns = df.select_dtypes(include=['datetime64[ns, UTC]']).columns\nfor date_column in date_columns:\n    df[date_column] = df[date_column].apply(str)\n"], ["import re\ndef check_web_address(text):\n  pattern = r'\\.[comeduorginfoUSnetintmilgov]*$'\n  result = re.search(pattern, text)\n  return result != None\n\nprint(check_web_address('gmail.com')) # True\nprint(check_web_address('www.google')) # False\nprint(check_web_address('www.Coursera.org')) # True\nprint(check_web_address('web-address.com/homepage')) # False\nprint(check_web_address('My_Favorite-Blog.US')) # True\n"], ["returner = []\n\nif 6 and 9 in arr:        \n    \n    a = arr.index(6)    \n    b = arr.index(9)\n    \n    if a < b:\n        \n        seq = arr[a:(b+1)]\n\n        for i in arr:    \n            if i not in seq:\n                returner.append(i)\n        return (sum(returner))\n    \n    elif a > b:\n        \n        seq = arr[b:(a+1)]\n\n        for i in arr:    \n            if i not in seq:\n                returner.append(i)\n        return (sum(returner))\n\nelif 6 in arr:\n    \n    a = arr.index(6)\n    seq = arr[a:]\n    for i in arr:    \n        if i not in slicer:\n            returner.append(i)\n    return(sum(returner))\n\nelif 9 in arr:\n    a = arr.index(9)\n    seq = arr[a:]\n    for i in arr:    \n        if i not in slicer:\n            returner.append(i)\n    return(sum(returner))\n\nelif arr == []:\n    return 0\n\nelse:\n    return (sum(arr))\n"], ["\\b[\\w]+[aeiou]{3,}[\\w]+\\b\n"], [], [], ["if 6 in mylist:        \n    return sum(mylist) - sum(mylist[mylist.index(6):mylist.index(9)+1])\nelse:\n    return sum(mylist)\n"], [], ["from sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.pipeline import Pipeline\nimport numpy as np\n\ncategorical_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n    ('encoder', OneHotEncoder(handle_unknown='ignore'))])\n\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('cat', categorical_transformer, [0])\n    ])\n", "df = pd.DataFrame(['Male', 'Female', np.nan])\npreprocessor.fit_transform(df)\narray([[0., 1., 0.],\n       [1., 0., 0.],\n       [0., 0., 1.]])\n"], [], [], [], [], [], [], ["table = \"\".join([i for i in table if not i.isdigit()])\n"], ["char_nums = [chr for chr in table if chr.isdigit()]\n\nfor i in char_nums:\n    table = table.replace(i, \"\")\nprint(table)\n"], ["table = \"table1\"\ntable_temp =\"\"\nfor i in table:\n   if i not in \"0123456789\":\n      table_temp +=i\nprint(table_temp)\n"], ["table = \"table123\"\n\nfor i in table:\n    if i.isdigit():\n        table = table.replace(i, \"\")\nprint(table)\n"], ["table = \"table1\"\ntable = table.translate(\"\".maketrans(\"\",\"\",\"0123456789\"))\nprint(table) # table\n"], [], ["function_patterns = [\n\n    r'a\\.C&&\\(b=a\\.get\\(\"n\"\\)\\)&&\\(b=([^(]+)\\(b\\),a\\.set\\(\"n\",b\\)\\)}};',\n]\n", "function_patterns = [\n\n    r'a\\.[A-Z]&&\\(b=a\\.get\\(\"n\"\\)\\)&&\\(b=([^(]+)\\(b\\)',\n]\n", "python3 -m pip install --upgrade pytube\n"], ["r'a\\.[a-zA-Z]\\s*&&\\s*\\([a-z]\\s*=\\s*a\\.get\\(\"n\"\\)\\)\\s*&&\\s*'\n\nr'\\([a-z]\\s*=\\s*([a-zA-Z0-9$]{2,3})(\\[\\d+\\])?\\([a-z]\\)'\n", "r'a\\.[a-zA-Z]\\s*&&\\s*\\([a-z]\\s*=\\s*a\\.get\\(\"n\"\\)\\)\\s*&&\\s*\\([a-z]\\s*=\\s*([a-zA-Z0-9$]{2,3})(\\[\\d+\\])?\\([a-z]\\)'\n"], ["$ pyenv install 3.8.4\n", "% pyenv install 3.8.4\npython-build: use openssl@1.1 from homebrew\npython-build: use readline from homebrew\nDownloading Python-3.8.4.tar.xz...\n-> https://www.python.org/ftp/python/3.8.4/Python-3.8.4.tar.xz\nInstalling Python-3.8.4...\npatching file Misc/NEWS.d/next/Build/2021-10-11-16-27-38.bpo-45405.iSfdW5.rst\npatching file configure\npatching file configure.ac\npython-build: use tcl-tk from homebrew\npython-build: use readline from homebrew\npython-build: use zlib from xcode sdk\n\nBUILD FAILED (OS X 12.3.1 using python-build 20180424)\n\nInspect or clean up the working tree at /var/folders/5r/61nxx8hs53x6hhzm_r86jhjrq0r6qq/T/python-build.20220504193655.2344\nResults logged to /var/folders/5r/61nxx8hs53x6hhzm_r86jhjrq0r6qq/T/python-build.20220504193655.2344.log\n\nLast 10 log lines:\nchecking for python3... python3\nchecking for --enable-universalsdk... no\nchecking for --with-universal-archs... no\nchecking MACHDEP... \"darwin\"\nchecking for gcc... clang\nchecking whether the C compiler works... no\nconfigure: error: in `/var/folders/5r/61nxx8hs53x6hhzm_r86jhjrq0r6qq/T/python-build.20220504193655.2344/Python-3.8.4':\nconfigure: error: C compiler cannot create executables\nSee `config.log' for more details\nmake: *** No targets specified and no makefile found.  Stop.\n", " % pyenv install 3.8.4\npython-build: use openssl@1.1 from homebrew\npython-build: use readline from homebrew\nDownloading Python-3.8.4.tar.xz...\n-> https://www.python.org/ftp/python/3.8.4/Python-3.8.4.tar.xz\nInstalling Python-3.8.4...\npatching file Misc/NEWS.d/next/Build/2021-10-11-16-27-38.bpo-45405.iSfdW5.rst\npatching file configure\npatching file configure.ac\npython-build: use tcl-tk from homebrew\npython-build: use readline from homebrew\npython-build: use zlib from xcode sdk\nInstalled Python-3.8.4 to /Users/{USER}/.pyenv/versions/3.8.4\n"], ["!pip install -U yt-dlp\n", "!yt-dlp -f \"bestvideo[height<=1080][ext=mp4]+bestaudio[ext=m4a]/best[ext=mp4]/best\" \"https://www.youtube.com/watch?v=AWXvSBHB210\"\n"], [], [], [], [], ["import boto3\n\nbucket = \"Sample_Bucket\"\nfolder = \"Sample_Folder\"\ns3 = boto3.resource(\"s3\") \ns3_bucket = s3.Bucket(bucket)\nfiles_in_s3 = [f.key.split(folder + \"/\")[1] for f in s3_bucket.objects.filter(Prefix=folder).all()]\n"], ["$ clang --version\nApple clang version 11.0.3 (clang-1103.0.32.62)\nTarget: x86_64-apple-darwin21.4.0\nThread model: posix\nInstalledDir: /Library/Developer/CommandLineTools\n", "sudo mv /Library/Developer/CommandLineTools /Library/Developer/CommandLineTools.old\nsudo xcode-select --install\n", "$ clang --version\nApple clang version 13.0.0 (clang-1300.0.27.3)\nTarget: x86_64-apple-darwin21.4.0\nThread model: posix\nInstalledDir: /Library/Developer/CommandLineTools/usr/bin\n"], ["class BaseModel(models.Model):\n    ...\n", "from .models import BaseModel\n...\n", "from utils.models import BaseModel\n"], ["def summer_69(arr):\nif 9 in arr :\n    sum = 0 \n    y = arr.index(9)\n    for i , l in enumerate(arr):\n        if l == 6:\n            del arr[i:y+1]\n    for i in range(len(arr)):\n        sum = sum + arr[i]\n    return sum\nelif 9 not in arr:\n    sum = 0\n    for i in range(len(arr)):\n        sum = sum + arr[i]\n    return sum \n"], [], ["foo = pd.DataFrame({'id':[1,2,3,4,5,6,7,8,9,10],\n                   'var1':random.sample(range(1, 100), 10),\n                   'var2':random.sample(range(1, 100), 10),\n                   'var3':random.sample(range(1, 100), 10),\n                   'class': ['a','a','a','a','a','b','b','c','c','c']})\n\ncl_cols = foo.filter(regex='var').columns\nX_train, X_test, y_train, y_test = train_test_split(foo[cl_cols],\n                                                        foo[['class']],\n                                                        test_size=0.33, random_state=42)\n\n\nmodel = xgboost.XGBClassifier(objective=\"multi:softmax\")\nmodel.fit(X_train, y_train)\n\ndef get_ABS_SHAP(df_shap,df):\n    #import matplotlib as plt\n    # Make a copy of the input data\n    shap_v = pd.DataFrame(df_shap)\n    feature_list = df.columns\n    shap_v.columns = feature_list\n    df_v = df.copy().reset_index().drop('index',axis=1)\n    \n    # Determine the correlation in order to plot with different colors\n    corr_list = list()\n    for i in feature_list:\n        b = np.corrcoef(shap_v[i],df_v[i])[1][0]\n        corr_list.append(b)\n    corr_df = pd.concat([pd.Series(feature_list),pd.Series(corr_list)],axis=1).fillna(0)\n \n    # Make a data frame. Column 1 is the feature, and Column 2 is the correlation coefficient\n    corr_df.columns  = ['Variable','Corr']\n    corr_df['Sign'] = np.where(corr_df['Corr']>0,'red','blue')\n    \n    shap_abs = np.abs(shap_v)\n    k=pd.DataFrame(shap_abs.mean()).reset_index()\n    k.columns = ['Variable','SHAP_abs']\n    k2 = k.merge(corr_df,left_on = 'Variable',right_on='Variable',how='inner')\n    k2 = k2.sort_values(by='SHAP_abs',ascending = True)\n    \n    k2_f = k2[['Variable', 'SHAP_abs', 'Corr']]\n    k2_f['SHAP_abs'] = k2_f['SHAP_abs'] * np.sign(k2_f['Corr'])\n    k2_f.drop(columns='Corr', inplace=True)\n    k2_f.rename(columns={'SHAP_abs': 'SHAP'}, inplace=True)\n    \n    return k2_f\n\nfoo_all = pd.DataFrame()\n\nfor k,v in list(enumerate(model.classes_)):\n\n    foo = get_ABS_SHAP(shap_values[k], X_test)\n    foo['class'] = v\n    foo_all = pd.concat([foo_all,foo])\n\nimport plotly_express as px\npx.bar(foo_all,x='SHAP', y='Variable', color='class')\n"], ["shap.summary_plot(shap_values[0], X_test)\n"], ["apk add python3\n"], [], ["import yfinance as yf\n\ntickers = ['ABEV3.SA']\nfor ticker in tickers:\n    ticker_yahoo = yf.Ticker(ticker)\n    data = ticker_yahoo.history()\n    last_quote = data['Close'].iloc[-1]\n    print(ticker, last_quote)\n"], ["pip install --upgrade keras\npip install --upgrade tensorflow\n"], [], [], ["plt.imshow(  tensor_image.permute(1, 2, 0)  )\n"], ["[accelerate]\nlibraries = Accelerate, vecLib\n", "conda config --set pip_interop_enabled true\n"], [], ["docker exec -it your_docker_id bash\nbash-5.1# pip install tzdata\n"], ["conda install pytorch cudatoolkit=11.1 -c pytorch -c nvidia\n"], ["import zoneinfo\nzoneinfo.available_timezones()\n"], [], [], ["python rename_file.py --base-folder \"f:/tmp/s13/\"\n"], ["import os\n\n# Passing the path to your parent folders\npath = r'D:\\bat4'\n\n# Getting a list of folders with date names\nfolders = os.listdir(path)\n\nfor folder in folders:\n    files = os.listdir(r'{}\\{}'.format(path, folder))\n\n    # Accessing files inside each folder\n    for file in files:\n\n        # Getting the file extension\n        extension_pos = file.rfind(\".\")\n        extension = file[extension_pos:]\n\n        # Renaming your file\n        os.rename(r'{}\\{}\\{}'.format(path, folder, file),\n                  r'{}\\{}\\{}{}'.format(path, folder, folder, extension))\n"], ["import re\ndef check_web_address(text):\n  pattern = r'^[A-Za-z0-9-_+.]*[.][A-Za-z]*$'\n  result = re.search(pattern, text)\n  return result != None\n\nprint(check_web_address(\"gmail.com\")) # True\nprint(check_web_address(\"www@google\")) # False\nprint(check_web_address(\"www.Coursera.org\")) # True\nprint(check_web_address(\"web-address.com/homepage\")) # False\nprint(check_web_address(\"My_Favorite-Blog.US\")) # True\n"], ["import os\nimport sys\n\ndef rename_first_file_in_dir(dir_path, new_file_name, keep_extension = False):\n  for current_file_name in os.listdir(dir_path):\n    current_file_path = os.path.join(dir_path, current_file_name) # full or relative path to the file in dir\n    if not os.path.isfile(current_file_path):\n      break\n    # rename only base name of file to the name of directory\n    if keep_extension:\n      file_extension = os.path.splitext(current_file_name)[1]\n      if len(file_extension) > 0:\n        new_file_name = new_file_name + file_extension \n        \n    new_file_path = os.path.join(dir_path, new_file_name)\n    print(\"File \" + current_file_name + \" renamed to \" + new_file_name + \" in \" + os.path.basename(dir_path) + \" directory\");\n    os.rename(current_file_path, new_file_path)\n    # exit after first processed file\n    break\n\nif len(sys.argv) < 2:\n  print(\"Usage: python \" + os.path.basename(__file__) + \" <directory> [keep_files_extensions]\") # help for usage\n  exit(0)\nscan_dir = sys.argv[1]\nkeep_extension = False if len(sys.argv) < 3 else not (int(sys.argv[2]) == 0) # optional parameter 0 - False, 1 - True, by default - False\nif not os.path.exists(scan_dir):\n  print(\"Error: directory \" + scan_dir + \" does not exists\")\n  exit(-1)\nif not os.path.isdir(scan_dir):\n  print(\"Error: file \" + scan_dir + \" is not a directory\")\n  exit(-1)\nprint(\"Scanning directory \" + scan_dir)\nfor file_name in os.listdir(scan_dir): # walk through directory\n  file_path = os.path.join(scan_dir, file_name)\n  if os.path.isdir(file_path):\n    rename_first_file_in_dir(file_path, file_name, keep_extension)\n"], [], [], ["df = pd.concat([df, pd.DataFrame.from_records([{ 'a': 1, 'b': 2 }])])\n", "df.loc[len(df), ['a','b']] = 1, 2\n", "df.loc[len(df), df.columns] = 3, 4\n"], [], ["import re\ndef check_web_address(text):\n  pattern = r'^[\\w\\-+.]+\\.[a-zA-z]+$'\n  result = re.search(pattern, text)\n  return result != None\n\nprint(check_web_address(\"gmail.com\")) # True  \nprint(check_web_address(\"www@google\")) # False.  \nprint(check_web_address(\"www.Coursera.org\")) # True\nprint(check_web_address(\"web-address.com/homepage\")) # False.    \nprint(check_web_address(\"My_Favorite-Blog.US\")) # True\n"], ["features= pd.concat([features, input_vars])\n"], [], ["apk add python3=~3.8\n"], ["def count_letters(text):\n  result = {}\n  # Go through each letter in the text\n  for letter in text:\n    # Check if the letter needs to be counted or not\n    if letter .isalpha() and letter not in result:\n    # Add or increment the value in the dictionary\n      result[letter.lower()]=text.lower().count(letter)\n  return result\n\nprint(count_letters(\"AaBbCc\"))\n# Should be {'a': 2, 'b': 2, 'c': 2}\n\nprint(count_letters(\"Math is fun! 2+2=4\"))\n# Should be {'m': 1, 'a': 1, 't': 1, 'h': 1, 'i': 1, 's': 1, 'f': 1, 'u': 1, 'n': 1}\n\nprint(count_letters(\"This is a sentence.\"))\n# Should be {'t': 2, 'h': 1, 'i': 2, 's': 3, 'a': 1, 'e': 3, 'n': 2, 'c': 1}\n"], ["def summer69(a):\n    for z in a:\n        if z==6 and 9 in a:\n           x=a.index(6)\n           y=a.index(9)\n           del a[x:y+1]\n           t= sum(a)\n        else:\n           t=sum(a)\n    return t\n"], [], ["from django.conf.urls import url\n", "from django.urls import re_path as url\n"], [], [], ["df = pd.Series(dic)\ndf_expected = pd.Series(dic_expected)\nassert_series_equal(df, df_expected, rtol=1e-05)\n"], ["# use an alias so I don't have to remember to avoid using \"approx\" as a variable name\nfrom pytest import approx as pytest_approx\n\n\ndef is_primitive(x):\n    return x is None or type(x) in (int, float, str, bool)\n\n\ndef approx_equal(A, B, absolute=1e-6, relative=1e-6, enforce_same_type=False):\n    if enforce_same_type and type(A) != type(B) and not is_primitive(A):\n        # I use `not is_primitive(A)` to enforce the same type only for data structures\n        return False\n\n    try:\n        is_approx_equal = (A == pytest_approx(B, rel=relative, abs=absolute))\n    except TypeError:\n        is_approx_equal = False\n\n    if is_approx_equal:\n        # pytest_approx() can only compare primitives and non-nested data structures correctly\n        # If the data structures are nested, then approx_equal() will try one of the other branches\n        return True\n    elif is_primitive(A) or is_primitive(B):\n        return False\n    elif isinstance(A, set) or isinstance(B, set):\n        # if any of the data structures is a set, convert both of them to a sorted list, but return False if the length has changed\n        len_A, len_B = len(A), len(B)\n        A, B = sorted(A), sorted(B)\n        if len_A != len(A) or len_B != len(B):\n            return False\n\n        for i in range(len(A)):\n            if not approx_equal(A[i], B[i], absolute, relative):\n                return False\n\n        return True\n    elif isinstance(A, dict) and isinstance(B, dict):\n        for k in A.keys():\n            if not approx_equal(A[k], B[k], absolute, relative):\n                return False\n\n        return True\n    elif (isinstance(A, list) or isinstance(A, tuple)) and (isinstance(B, list) or isinstance(B, tuple)):\n        for i in range(len(A)):\n            if not approx_equal(A[i], B[i], absolute, relative):\n                return False\n\n        return True\n    else:\n        return False\n\n\nprint(approx_equal([1], {1.000001}, enforce_same_type=True)) # False\nprint(approx_equal([1], {1.000001}, enforce_same_type=False)) # True\n\nprint(approx_equal([123.001, (1,2)], [123, (1,2)])) # False\nprint(approx_equal([123.000001, (1,2)], [123, (1,2)])) # True\n\nprint(approx_equal({'a': {'b': 1}, 'c': 3.141592}, {'a': {'b': 1.0000005}, 'c': 3.1415})) # False\nprint(approx_equal({'a': {'b': 1}, 'c': 3.141592}, {'a': {'b': 1.0000005}, 'c': 3.141592})) # True\n"], ["def summer_69(arr):\nresult=0\nreduction =0\nfor i in range(0,len(arr)):\n    result+=arr[i]\n    if arr[i] == 6:\n        temp = arr[arr.index(6):arr.index(9)+1]\n        reduction = sum(temp)\nreturn result - reduction\n"], ["import os\nos.environ['R_HOME'] = '/Users/<your user>/anaconda3/envs/<env name>/lib/R'\n\n# import your desired module\nfrom rpy2.robjects.packages import importr\n"], [], ["def count_letters(text):\n  result = {}\n  # Go through each letter in the text\n  text_lower=text.lower()\n  # Go through each letter in the text\n  for letter in text_lower:\n    # Check if the letter needs to be counted or not\n    if letter.isalpha() and letter != \" \":\n      if letter not in result:\n        result[letter] = 0  \n    # Add or increment the value in the dictionary\n      result[letter] += 1\n  return result\n"], [], ["pattern = r\".*\\.[A-Za-z]{1,3}.$\"\n"], [], [], ["count = 0\nclient = boto3.client('s3')\npaginator = client.get_paginator('list_objects')\nfor result in paginator.paginate(Bucket='your-bucket', Prefix='your-folder/', Delimiter='/'):\n    count += len(result.get('CommonPrefixes'))\n"], [], ["ssh_client.connect(\n  server, username=ssh_user, key_filename=ssh_keypath,\n  disabled_algorithms=dict(pubkeys=[\"rsa-sha2-512\", \"rsa-sha2-256\"]))\n"], [], ["from django.urls import include, re_path\n\nfrom myapp.views import home\n\nurlpatterns = [\n    re_path(r'^$', home, name='home'),\n    re_path(r'^myapp/', include('myapp.urls'),\n]\n", "from django.urls import include, path\n\nfrom myapp.views import home\n\nurlpatterns = [\n    path('', home, name='home'),\n    path('myapp/', include('myapp.urls'),\n]\n"], ["import pygame\nimport pygame.font\npygame.init()\n\n# Colours\nBLACK   = (  0,  0,  0)\nWHITE   = (255,255,255)\nGREEN   = (  0,255,  0)\nRED     = (255,  0,  0)\nBLUE    = (  0,  0,255)\n\n# Dimensions of screen\nsize = (400,500)\nWIDTH = 500\nHEIGHT = 400\nscreen = pygame.display.set_mode(size)\n\n# Loop Switch\ndone = False\n\n# Screen Update Speed (FPS)\nclock = pygame.time.Clock()\n\n# ------- Main Program Loop -------\nwhile not done:\n    # --- Main Event Loop ---\n    for event in pygame.event.get():\n        if event.type == pygame.QUIT:\n            done = True\n\n    #In each case you draw the rectangle and then fill the screen with green\n\n    pygame.draw.rect(screen,(78,203,245),(0,0,250,500),5)\n    pygame.display.flip()\n\n    screen.fill(GREEN)\n    \n\n    #Setting FPS\n    clock.tick(60)\n\n#Shutdown\npygame.quit()\n"], ["python3 -m pip install pyqt6rc\n"], ["sudo apt install python3-virtualenv\npip install virtualenv\n", "edd@rob:/tmp$ mkdir venvdemo\nedd@rob:/tmp$ cd venvdemo/\nedd@rob:/tmp/venvdemo$ virtualenv -p python3 venv\ncreated virtual environment CPython3.9.5.final.0-64 in 162ms\n  creator CPython3Posix(dest=/tmp/venvdemo/venv, clear=False, no_vcs_ignore=False, global=False)\n  seeder FromAppData(download=False, pip=bundle, setuptools=bundle, wheel=bundle, via=copy, app_data_dir=/home/edd/.local/share/virtualenv)\n    added seed packages: pip==20.3.4, pkg_resources==0.0.0, setuptools==44.1.1, wheel==0.34.2\n  activators BashActivator,CShellActivator,FishActivator,PowerShellActivator,PythonActivator,XonshActivator\nedd@rob:/tmp/venvdemo$ \nedd@rob:/tmp/venvdemo$ ls -a \n.  ..  venv\nedd@rob:/tmp/venvdemo$ ls -a venv/\n.  ..  bin  .gitignore  lib  pyvenv.cfg\nedd@rob:/tmp/venvdemo$ \n"], ["python3 -m venv ./some_env\n"], ["python3 -m venv ./desired_name_of_env\n"], ["D:\njupyter notebook\n"], [], ["points = (point1, point2, point3, point3D)\nxs = [point.x for point in points]\nys = [point.y for point in points]\n\nfig, ax = plt.subplots()\nax.set_aspect('equal')\nax.scatter(xs, ys)\n", "(array('d', [3.0, 2.0, 9.0]), array('d', [6.0, -1.0, 4.0]))\n", "ax.plot(line.xy[0], line.xy[1])\nax.plot(*line.xy) # Equivalent\n", "import numpy as np\nfrom matplotlib.path import Path\nfrom matplotlib.patches import PathPatch\nfrom matplotlib.collections import PatchCollection\n\n\n# Plots a Polygon to pyplot `ax`\ndef plot_polygon(ax, poly, **kwargs):\n    path = Path.make_compound_path(\n        Path(np.asarray(poly.exterior.coords)[:, :2]),\n        *[Path(np.asarray(ring.coords)[:, :2]) for ring in poly.interiors])\n\n    patch = PathPatch(path, **kwargs)\n    collection = PatchCollection([patch], **kwargs)\n    \n    ax.add_collection(collection, autolim=True)\n    ax.autoscale_view()\n    return collection\n", "from shapely.geometry import Polygon\nimport matplotlib.pyplot as plt\n\n\n# Input polygon with two holes\n# (remember exterior point order is ccw, holes cw else\n# holes may not appear as holes.)\npolygon = Polygon(shell=((0,0),(10,0),(10,10),(0,10)),\n                  holes=(((1,3),(5,3),(5,1),(1,1)),\n                         ((9,9),(9,8),(8,8),(8,9))))\n\nfig, ax = plt.subplots()\nplot_polygon(ax, polygon, facecolor='lightblue', edgecolor='red')\n"], ["jupyter lab --notebook-dir=E:/\n"], ["FROM python:3.9-alpine\n\nWORKDIR /myapp\nCOPY Pipfile Pipfile.lock ./\n\nRUN \\\n  # Install dependencies\n  && pip install --no-cache-dir micropipenv[toml] \\\n  && micropipenv install --deploy \\\n  && pip uninstall -y micropipenv[toml]\n\nCOPY src .\nCMD [\"python3\", \"app.py\"]\n"], [], [], ["from aiogram import Bot, Dispatcher, executor\n\nbot = Bot(token='your_api_token')\ndp = Dispatcher(bot)\n\nasync def notify_message() # THIS FUNCTION\n  # await bot.sendMessage(chat.id, 'Bot Started')\n  await print('Hello World')\n\n@dp.message_handler()\nasync def echo(message: types.Message):\n  await message.answer(message.text)\n\nif __name__ == '__main__':\n    executor.start(dp, notify_message())\n    executor.start_polling(dp, skip_updates=True)\n"], [], ["sudo python3 -m pip install -U pip\nsudo python3 -m pip install -U setuptools\n", "# Within the venv\npip3 install -U pip\npip3 install -U setuptools\n"], ["def count_letters(text):\n  result = {}\n  # Go through each letter in the text\n  for letter in text:\n    # Check if the letter needs to be counted or not\n    if letter.isalpha():\n      result[letter.lower()]=result.get(letter.lower(),0)+1\n    # Add or increment the value in the dictionary\n  return result\n\nprint(count_letters(\"AaBbCc\"))\n# Should be {'a': 2, 'b': 2, 'c': 2}\n\nprint(count_letters(\"Math is fun! 2+2=4\"))\n# Should be {'m': 1, 'a': 1, 't': 1, 'h': 1, 'i': 1, 's': 1, 'f': 1, 'u': 1, 'n': 1}\n\nprint(count_letters(\"This is a sentence.\"))\n# Should be {'t': 2, 'h': 1, 'i': 2, 's': 3, 'a': 1, 'e': 3, 'n': 2, 'c': 1}\n"], ["def count_letters(text):\n  result = {}\n  # Go through each letter in the text\n  for letter in text.lower():\n    # Check if the letter needs to be counted or not\n     if letter.isalpha() and letter not in result:\n       result[letter] = text.lower().count(letter)\n  return result\n\nprint(count_letters(\"AaBbCc\"))\n# Should be {'a': 2, 'b': 2, 'c': 2}\n\nprint(count_letters(\"Math is fun! 2+2=4\"))\n# Should be {'m': 1, 'a': 1, 't': 1, 'h': 1, 'i': 1, 's': 1, 'f': 1, 'u': 1, 'n': 1}\n\nprint(count_letters(\"This is a sentence.\"))\n# Should be {'t': 2, 'h': 1, 'i': 2, 's': 3, 'a': 1, 'e': 3, 'n': 2, 'c': 1}\n"], [], ["def upload_file(remote_path,local_path):\n    try:\n        blobService = BlockBlobService(account_name=SETTINGS.AZURE_ACCOUNT_NAME, account_key=SETTINGS.AZURE_ACCOUNT_KEY)\n        blobService.create_blob_from_path('data',remote_path,local_path)\n    except Exception as e:\n        logger.error(f'Unable to save azure blob data. {str(e)}')\n        raise Exception(f'Unable to save azure blob data. {str(e)}')\n"], [], ["$ sudo usermod -aG docker $(whoami)\n"], ["xnys = xcals.get_calendar(\"XNYS\", start=import_start, end=import_end)\nholidays = pd.to_datetime(xnys.day.holidays)\nholiday_mask= (holidays > import_start) & (holidays <= import_end)\nhols = holidays[holiday_mask].strftime(\"%Y-%m-%d\").tolist()\n", "fig = go.Figure(data=[go.Candlestick(x=df['date'], open=df['Open'], high=df['High'], low=df['Low'], close=df['Close'])])\n    fig.update_xaxes(\n        rangeslider_visible=True,\n        rangebreaks=[\n            # NOTE: Below values are bound (not single values), ie. hide x to y\n            dict(bounds=[\"sat\", \"mon\"]),  # hide weekends, eg. hide sat to before mon\n            dict(bounds=[16, 9.5], pattern=\"hour\"),  # hide hours outside of 9.30am-4pm\n            dict(values=hols)  # hide market holidays inside your date range\n        ]\n    )\n    fig.update_layout(\n        title='Stock Analysis',\n        yaxis_title=f'{symbol} Stock'\n    )\n\n    fig.show()\n"], [], ["# python3\nimport sys\n\ndef compute_min_refills(distance, tank, stops):\n    capacity_tank = tank\n    refill = 0\n\n    if capacity_tank >= distance:\n        return 0\n    if capacity_tank < stops[0] or (distance-stops[-1]) > capacity_tank:\n        return -1\n\n    for i in range(1, len(stops)):\n        if (stops[i]-stops[i-1]) > capacity_tank:\n            return -1\n        if stops[i] > tank:\n            tank = (stops[i-1] + capacity_tank)\n            refill += 1\n    if distance > tank:\n        refill += 1\n\n    return refill\n\n\n    if __name__ == '__main__':\n        d, m, _, *stops = map(int, sys.stdin.read().split())\n        print(compute_min_refills(d, m, stops))\n"], ["sudo apt install -y python3-dev libmysqlclient-dev libssl-dev\n"], ["brew reinstall python@3.9\n", "pip3 install numpy\npip3 install matplotlib \npip3 install opencv-contrib-python\n", "import cv2 \nprint(cv2.__version__)\n"], ["class Action(Enum):\n    NEW_CUSTOMER = 1\n    LOGIN = 2\n    BLOCK = 3\n\naction = 'new_customer'\ntry:\n    action = Action[action.upper()]\n    print(\"action type exists\")\nexcept KeyError:\n    print(\"action type doesn't exists\")\n"], ["dev = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n", "dev=torch.device(\"cuda\") \n", "dev=\"cuda\"\n", "model.to(dev)\ndata = data.to(dev)\n"], ["!pip install nbformat \n"], ["import numpy as np\nimport shapely.geometry as sg\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\n\n\ndef add_polygon_patch(coords, ax, fc='blue'):\n    patch = patches.Polygon(np.array(coords.xy).T, fc=fc)\n    ax.add_patch(patch)\n\n\nborder = [(-10, -10), (-10, 10), (10, 10), (10, -10)]  # Large square\nholes = [\n    [(-6, -2), (-6, 2), (-2, 2), (-2, -2)],  # Square hole\n    [(2, -2), (4, 2), (6, -2)]               # Triangle hole\n]\nregion = sg.Polygon(shell=border, holes=holes)\n\nfig, ax = plt.subplots(1, 1)\n\nadd_polygon_patch(region.exterior, ax)\nfor interior in region.interiors:\n    add_polygon_patch(interior, ax, 'white')\n        \nax.axis('equal')\nplt.show()\n"], ["\n  - opencv -> python[\nversion='\n>=2.7,<2.8.0a0\n>=3.5,<3.6.0a0\n>=3.6,<3.7.0a0\n>=3.7,<3.8.0a0']\n"], [], [], ["{\n\"python.testing.unittestArgs\": [\n    \"-v\",\n    \"-s\",\n    \".\",\n    \"-p\",\n    \"test_*.py\"\n],\n\"python.testing.pytestEnabled\": false,\n\"python.testing.nosetestsEnabled\": false,\n\"python.testing.unittestEnabled\": true,\n\"python.pythonPath\": \"/Users/hhh/project/bin/python\"\n}\n"], [], [], ["def count_letters(text):\n  result = {}\n  for letter in text:\n    #check if it alphabet or something else\n    # Check if the letter needs to be counted or not\n    if letter.isalpha():\n      result[letter.lower()]=result.get(letter.lower(),0)+1\n    # Add or increment the value in the dictionary\n  return result\n", "print(count_letters(\"AaBbCc\"))\n# Should be {'a': 2, 'b': 2, 'c': 2}\n", "print(count_letters(\"Math is fun! 2+2=4\"))\n# Should be {'m': 1, 'a': 1, 't': 1, 'h': 1, 'i': 1, 's': 1, 'f': 1, 'u': 1, 'n': 1}\n", "print(count_letters(\"This is a sentence.\"))\n# Should be {'t': 2, 'h': 1, 'i': 2, 's': 3, 'a': 1, 'e': 3, 'n': 2, 'c': 1}\n"], ["def  count_letters(text):\n    result = {}\n    for letter in text.lower():\n        if letter == \" \" or letter.isalpha() == False:\n            continue:\n        if letter not in result:\n            result[letter] = 0\n        result[letter] += 1\n    return result\n"], [], ["from selenium import webdriver\nimport requests\nimport zipfile\nimport wget\nimport subprocess\nimport os\n\n\nCHROMEDRIVER_PATH =  # Insert your Chromedriver path here\nCHROMEDRIVER_FOLDER = os.path.dirname(CHROMEDRIVER_PATH)\nLATEST_DRIVER_URL = \"https://chromedriver.storage.googleapis.com/LATEST_RELEASE\"\n\n\ndef download_latest_version(version_number):\n    print(\"Attempting to download latest driver online......\")\n    download_url = \"https://chromedriver.storage.googleapis.com/\" + version_number + \"/chromedriver_win32.zip\"\n    # download zip file\n    latest_driver_zip = wget.download(download_url, out=CHROMEDRIVER_FOLDER)\n    # read & extract the zip file\n    with zipfile.ZipFile(latest_driver_zip, 'r') as downloaded_zip:\n        # You can chose the folder path to extract to below:\n        downloaded_zip.extractall(path=CHROMEDRIVER_FOLDER)\n    # delete the zip file downloaded above\n    os.remove(latest_driver_zip)\n\n\ndef check_driver():\n    # run cmd line to check for existing web-driver version locally\n    cmd_run = subprocess.run(\"chromedriver --version\",\n                             capture_output=True,\n                             text=True)\n    # Extract driver version as string from terminal output\n    local_driver_version = cmd_run.stdout.split()[1]\n    print(f\"Local driver version: {local_driver_version}\")\n    # check for latest chromedriver version online\n    response = requests.get(LATEST_DRIVER_URL)\n    online_driver_version = response.text\n    print(f\"Latest online chromedriver version: {online_driver_version}\")\n    if local_driver_version == online_driver_version:\n        return True\n    else:\n        download_latest_version(online_driver_version)\n"], ["pip install jupyterlab\n", "Command \"python setup.py egg_info\" failed with error code 1 in /private/tmp/pip-build-p0u6Wd/jupyterlab\n", "$ pip --version\npip 6.1.1 from /Library/Python/2.7/site-packages (python 2.7)\n\n$ pip3 --version\npip 21.2.4 from /usr/local/lib/python3.9/site-packages/pip (python 3.9)\n", "pip3 install jupyterlab\n"], [], ["def count_letters(text):\n    result = {}\n    text = text.lower().replace(\" \",\"\")\n    text = text.replace(\"\", \" \").split()\n    dummy = []\n    dummy1 = \"\"\n\n    for x in text: # remove non-letter\n        if x.isalpha():\n            dummy.append(x)\n            dummy1 = \"\".join(dummy)\n\n    for letter in dummy1:\n        if letter not in result:\n            result[letter] = 0\n        result[letter] += 1\n    return result\n\nprint(count_letters(\"AaBbCc\"))\nprint(count_letters(\"Math is fun! 2+2=4\"))\nprint(count_letters(\"This is a sentence.\"))\n"], ["mypackage/\n  subpackage/\n    __init__.py\n    helper.py\n  main/\n    work.py\n"], ["def summer_69(arr):\n\n#first find out if 6 or 9 are in the list\n\nif 6 in arr and 9 in arr:\n\n#Then create a variable that stores the index location of the number 6 \n#and the number 9\n\n        sixer = arr.index(6)\n        niner = arr.index(9)\n\n#now return the sum of the array minus the sum of the values between \n#index of 6 and index of 9 inclusive (hence the plus 1)\n#This way will ignore the case of a 9 appearring before a 6 too.\n\n        return sum(arr) - sum(arr[sixer:niner+1])\n\n#Otherwise just return the sum of the array.\n\nelse:\n    return sum(arr)\n"], ["def summer_69(arr):\ntotal = 0\nadd = True\nfor num in arr:\n    while add:\n        if num != 6:\n            total += num\n            break\n        else:\n            add = False\n    while not add:\n        if num != 9:\n            break\n        else:\n            add = True\n            break\nreturn total\n"], [], ["jupyter lab --notebook-dir=D:/\n"], ["jupyter notebook --notebook-dir=F:/\n"], ["import datetime\n\ndef week_to_dates():\n    date = datetime.date.today()\n    week = date.strftime(\"%V\")\n\n    candidates = [date - datetime.timedelta(days=k) for k in range(14, 0, -1)] + \\\n                 [date] + \\\n                 [date + datetime.timedelta(days=k) for k in range(1, 15)]\n    return [candidate.strftime('%Y-%m-%d') for candidate in candidates if candidate.strftime(\"%V\") == week]\n"], [], ["def summer_69(lst):\n    it = iter(lst)\n    return sum(x for x in it\n               if x != 6 or 9 not in it)\n", "def summer_69(lst):\n    it = iter(lst)\n    total = 0\n    for x in it:\n        if x == 6:\n            9 in it\n        else:\n            total += x\n    return total\n", "30 out of 30 tests correct\n\n303045 us  303714 us  304335 us  306007 us  309986 us  summer_69_Accepted\n   444 us     446 us     464 us     478 us     527 us  summer_69_Kelly1\n   442 us     448 us     453 us     465 us     500 us  summer_69_Kelly2\n", "from timeit import repeat\n\ndef summer_69_Accepted(lst):\n    copyoflist = lst[:] # makes shallow copy of list\n    while True:\n        if 6 not in copyoflist:\n            return sum(copyoflist)\n\n        indexof6 = copyoflist.index(6)\n        indexof9 = copyoflist.index(9, indexof6+1) # begin search for 9 after 6\n        del copyoflist[indexof6:indexof9+1] \n\ndef summer_69_Kelly1(lst):\n    it = iter(lst)\n    return sum(x for x in it\n               if x != 6 or 9 not in it)\n\ndef summer_69_Kelly2(lst):\n    it = iter(lst)\n    total = 0\n    for x in it:\n        if x == 6:\n            9 in it\n        else:\n            total += x\n    return total\n\nfuncs = summer_69_Accepted, summer_69_Kelly1, summer_69_Kelly2\n\nfrom random import randrange, choices\n\ndef testcase():\n    def others():\n        return choices([0, 1, 2, 3, 4, 5, 7, 8], k=randrange(10))\n    lst = others()\n    for _ in range(10):\n        lst += [6, *others(), 9, *others()]\n    return lst\n\ntests = correct = 0\nfor _ in range(10):\n    lst = testcase()\n    expect = funcs[0](lst.copy())\n    for func in funcs:\n        result = func(lst.copy())\n        correct += result == expect\n        tests += 1\nprint(correct, 'out of', tests, 'tests correct')\nprint()\n\nlst = [1] * 5000 + [6, 9] * 2500\nfor func in funcs:\n    times = repeat(lambda: func(lst), number=1)\n    print(*('%6d us ' % (t * 1e6) for t in sorted(times)), func.__name__)\n"], ["symbol = \"AAPL\"\nstock = yf.Ticker(symbol)\nlatest_price = stock.history(period='1d')['Close'][0]\n\n# Completely optional but I recommend having some sort of round(er?).\n# Dealing with 148.60000610351562 is a pain.\nestimate = round(latest_price, 2) \n\nprint (estimate)\n"], [], ["pip install chromedriver-autoinstaller\n", "Just type import chromedriver_autoinstaller in the module you want to use chromedriver.\n", "from selenium import webdriver\nimport chromedriver_autoinstaller\n\n\nchromedriver_autoinstaller.install()  # Check if the current version of chromedriver exists\n                                      # and if it doesn't exist, download it automatically,\n                                      # then add chromedriver to path\n\ndriver = webdriver.Chrome()\ndriver.get(\"http://www.python.org\")\nassert \"Python\" in driver.title\n"], ["{'conv1': Conv2d(...),\n 'bn1': BatchNorm2d(...),\n 'block1':{\n    'group1':{\n        'conv1': Conv2d(...),\n        'bn1': BatchNorm2d(...),\n        'conv2': Conv2d(...),\n        'bn2': BatchNorm2d(...),\n    },\n    'group2':{ ...\n    }, ...\n}\n", "def nested_children(m: torch.nn.Module):\n    children = dict(m.named_children())\n    output = {}\n    if children == {}:\n        # if module has no children; m is last child! :O\n        return m\n    else:\n        # look for children from children... to the last child!\n        for name, child in children.items():\n            try:\n                output[name] = nested_children(child)\n            except TypeError:\n                output[name] = nested_children(child)\n    return output\n"], ["Info = pd.DataFrame(df.groupby(\"school_state\").agg(Approved=(\"project_is_approved\",lambda x: x.eq(1).sum()),Total=(\"project_is_approved\",\"count\"),Avg=(\"project_is_approved\",\"mean\"))).reset_index().sort_values(by=[\"Total\"],ascending=False).head()\n"], [], ["FROM python:3.8-slim\nWORKDIR /usr/src/app\n\nRUN apt update\nRUN apt -y install build-essential libwrap0-dev libssl-dev libc-ares-dev uuid-dev xsltproc\nRUN apt-get update -qq \\\n    && apt-get install --no-install-recommends --yes \\\n        build-essential \\\n        gcc \\\n        python3-dev \\\n        mosquitto \\\n        mosquitto-clients\n\n\nRUN pip3 install --upgrade pip setuptools wheel\n\nRUN python3 -m pip install --no-cache-dir \\\n      numpy scipy matplotlib scikit-build opencv-contrib-python-headless \\\n      influxdb paho-mqtt configparser Pillow \\\n      qrcode\n"], ["from asyncio import get_event_loop\nfrom aiogram import Bot, Dispatcher, executor, types\n\nAPI_TOKEN = 'API'\n\nbot = Bot(token=API_TOKEN)\ndp = Dispatcher(bot=bot, loop=get_event_loop())  # Initialising event loop for the dispatcher\n\nasync def notify_message():\n    print('Hello World')\n\nif __name__ == '__main__':\n    dp.loop.create_task(notify_message())  # Providing awaitable as an argument\n    executor.start_polling(dp, skip_updates=True)\n"], ["ImportError> dlopen(): Library not found\n", "no suitable image found: imageXXX found but wrong architecture\n"], [], [], ["from tensorflow import keras\n"], ["!pip install -U -q segmentation-models\n!pip install -q tensorflow==2.1\n!pip install -q keras==2.3.1\n!pip install -q tensorflow-estimator==2.1.\n\n## Imports libs\nimport os\nos.environ['CUDA_VISIBLE_DEVICES'] = '0'\nos.environ[\"SM_FRAMEWORK\"] = \"tf.keras\"\n\nfrom tensorflow import keras\nimport segmentation_models as sm\n"], ["  pattern = r\"^\\w.*\\.[a-zA-Z]*$\"\n"], ["from aiogram import Bot, Dispatcher, executor, types\n\nAPI_TOKEN = 'API'\nbot = Bot(token=API_TOKEN)\ndp = Dispatcher(bot)\n\n@dp.message_handler()\nasync def echo(message: types.Message):\n   await bot.send_message(message.chat.id, message.text)\n\ndef test_hi():\n   print(\"Hello World\")\n\nif __name__ == '__main__':\n   test_hi()\n   executor.start_polling(dp, skip_updates=True)\n"], ["train_data = [(example.numpy(), label.numpy()) for example, label in train_dataset]\n", "train_data[0][0]\ntrain_data[0][1]\n", "import pandas as pd\npd.DataFrame(train_data, columns=['example', 'label'])\n", "dataset = tf.data.Dataset.from_generator(\nlambda: train_data, ( tf.string, tf.int32)) # you should define dtypes of yours\n", "list(dataset.as_numpy_iterator())\n"], ["from pyxtension.streams import stream\n\nstream(myList)\n    .filter(condition)\n    .map(action1)\n    .map(action2)\n    .toList()\n", "stream(myList)\n    .filter(condition)\n    .mpmap(action1)   # this is for multi-processing map\n    .fastmap(action2) # this is multi-threaded map\n    .toList()\n"], [], ["def area(length, width):\n    return length * width\n\nl = 4\nw = 5\n\nprint(\"length =\", l, \"width =\", w, \"area =\", area(l, w))  # normal way\nprint(f\"length = {l} width = {w} area = {area(l,w)}\")     # Same output as above\nprint(\"length = {l} width = {w} area = {area(l,w)}\")      # without f prefixed\n", "length = 4 width = 5 area = 20\nlength = 4 width = 5 area = 20\nlength = {l} width = {w} area = {area(l,w)}\n"], ["@dp.message_handler()\nasync def echo(message: types.Message):\n    await bot.send_message(message.chat.id, message.text)\n", "2021-06-01 09:31:42,729:INFO:Bot: YourBot [@YourBot]\n2021-06-01 09:31:42,729:WARNING:Updates were skipped successfully.\n2021-06-01 09:31:42,729:INFO:Start polling.\n"], ["def summer_69(arr):\n    skate = arr\n    guitar = []\n    for i in range(len(arr)):\n        if 6 in arr:\n            guitar = skate[skate.index(6):skate.index(9)+1]\n            return abs(sum(skate) - sum(guitar))\n        else:\n            return sum(skate)\n"], [], ["fire_runner.py my_func  1,2,3\n", "fire_runner.py my_func  \\'2021-2\\',\\'20212-3\\',\\'2023-4\\'\n"], ["name = 'Niroshan'\nage  = 25;\nprint(f\"Hello I'm {name} and {age} years young\")\n", "name = 'Niroshan'\nage  = 25;\nprint(\"Hello I'm {name} and {age} years young\")\n"], ["import re\n\ntuple = (1,)\ns = \"something in \"  + re.sub(r',(?=\\))', '', str(tuple))\nprint(s)\n", "something in (1)\n"], [], ["a = (1,)\ns = f\"something in ({','.join([str(x) for x in a])})\"\nprint(s)\n", "'something in (1)'\n"], [], [], ["pip install django-rest-framework\n"], ["sudo python3.7 -m pip install -U pip\nsudo python3.7 -m pip install -U setuptools\n", "sudo python2.7 -m pip install -U pip\nsudo python2.7 -m pip install -U setuptools\nsudo apt-get install python-dev libpq-dev\n"], ["def is_power_of(number, base):\n  # Base case: when number is smaller than base.\n  if number < base:\n    # If number is equal to 1, it's a power (base**0).\n    if number == 1:\n      return True\n\n    else:\n      return False\n  # Recursive case: keep dividing number by base.\n  return is_power_of(number/base , base)\n\nprint(is_power_of(8,2)) # Should be True\nprint(is_power_of(64,4)) # Should be True\nprint(is_power_of(70,10)) # Should be False\n"], [], ["def count_letters(text):\n  result = {}\n  for letter in text.lower():\n    if letter.isalpha():\n      lettercount = text.lower().count(letter)\n      result[letter] = lettercount\n  return result\n"], ["read_config = tfds.ReadConfig(skip_prefetch = True)\ndataset_builder.as_dataset(\n    ......,\n    read_config = read_config,\n)\n"], [], ["import yfinance as yf\n\nstock = yf.Ticker(\"ABEV3.SA\")\nprice = stock.info['regularMarketPrice']\nprint(price)\n \n"], ["def myfunc(a):\nmylist=[]\nsum1 = 0\nfor b,c in enumerate(a):\n    if c==6:\n       for d in  a[:b]:\n           mylist.append(d)\nfor e,f in enumerate(a):\n    if f==9:\n       for j in a[e+1:]:\n           mylist.append(j)\nfor y in a:\n    if y==6:\n      break\n    else:\n       mylist.append(y)\nfor k in mylist:\n    sum1 = sum1+k\nprint(sum1)\n"], [], ["pip install --upgrade pip setuptools wheel\n", "pip3 install opencv-python==3.4.13.47\n"], ["sudo apt-get install python3-pip\n"], [], [], ["named_layers = dict(model.named_modules())\n", "{\n    'conv1': <some conv layer>,\n    'fc1': < some fc layer>,\n     ### and other layers \n}\n"], ["df['ts']\nOUT:\n0      1619801902867\n1      1619765681594\n2      1619712291984\n3      1619680298648\n4      1619629032109\n5      1619593388626\n6      1619531314509\n7      1619509338368\n8      1619449287828\n9      1619433411243\n10     1619103667781\n11     1619078244871\n12     1619021782951\n13     1618990214111\n14     1618931135540\n15     1618903774632\n", "df['ts'] = pd.to_datetime(df['ts'],unit='ms').dt.tz_localize('utc').dt.tz_convert('Europe/Vatican')\ndf['ts'] = df['ts'].apply(lambda a: datetime.datetime.strftime(a,\"%Y-%m-%d %H:%M:%S\"))\ndf['ts'] = pd.to_datetime(df['ts'])\n", "df['ts']\nOUT:\n0     2021-04-30 18:58:22\n1     2021-04-30 08:54:41\n2     2021-04-29 18:04:51\n3     2021-04-29 09:11:38\n4     2021-04-28 18:57:12\n5     2021-04-28 09:03:08\n6     2021-04-27 15:48:34\n7     2021-04-27 09:42:18\n8     2021-04-26 17:01:27\n9     2021-04-26 12:36:51\n10    2021-04-22 17:01:07\n11    2021-04-22 09:57:24\n12    2021-04-21 18:16:22\n13    2021-04-21 09:30:14\n14    2021-04-20 17:05:35\n15    2021-04-20 09:29:34\n"], ["from fastai.vision.all import show_image\n"], [], ["apk add --update python3 py3-pip\n"], ["fire_runner.py my_func --dates 2021-09-20,\nfire_runner.py my_func --dates \"[2021-09-20]\"\nfire_runner.py my_func --dates [2021-09-20]\n", "fire_runner.py my_func --dates \"[\\\"2021-09-20\\\"]\"\nfire_runner.py my_func --dates \"[\\\"2021-09-20\\\", \\\"2021-09-76\\\"]\"\n"], [], ["def download_chromedriver():\n    def get_latestversion(version):\n        url = 'https://chromedriver.storage.googleapis.com/LATEST_RELEASE_' + str(version)\n        response = requests.get(url)\n        version_number = response.text\n        return version_number\n    def download(download_url, driver_binaryname, target_name):\n        # download the zip file using the url built above\n        latest_driver_zip = wget.download(download_url, out='./temp/chromedriver.zip')\n\n        # extract the zip file\n        with zipfile.ZipFile(latest_driver_zip, 'r') as zip_ref:\n            zip_ref.extractall(path = './temp/') # you can specify the destination folder path here\n        # delete the zip file downloaded above\n        os.remove(latest_driver_zip)\n        os.rename(driver_binaryname, target_name)\n        os.chmod(target_name, 755)\n    if os.name == 'nt':\n        replies = os.popen(r'reg query \"HKEY_CURRENT_USER\\Software\\Google\\Chrome\\BLBeacon\" /v version').read()\n        replies = replies.split('\\n')\n        for reply in replies:\n            if 'version' in reply:\n                reply = reply.rstrip()\n                reply = reply.lstrip()\n                tokens = re.split(r\"\\s+\", reply)\n                fullversion = tokens[len(tokens) - 1]\n                tokens = fullversion.split('.')\n                version = tokens[0]\n                break\n        target_name = './bin/chromedriver-win-' + version + '.exe'\n        found = os.path.exists(target_name)\n        if not found:\n            version_number = get_latestversion(version)\n            # build the donwload url\n            download_url = \"https://chromedriver.storage.googleapis.com/\" + version_number +\"/chromedriver_win32.zip\"\n            download(download_url, './temp/chromedriver.exe', target_name)\n\n    elif os.name == 'posix':\n        reply = os.popen(r'chromium --version').read()\n\n        if reply != '':\n            reply = reply.rstrip()\n            reply = reply.lstrip()\n            tokens = re.split(r\"\\s+\", reply)\n            fullversion = tokens[1]\n            tokens = fullversion.split('.')\n            version = tokens[0]\n        else:\n            reply = os.popen(r'google-chrome --version').read()\n            reply = reply.rstrip()\n            reply = reply.lstrip()\n            tokens = re.split(r\"\\s+\", reply)\n            fullversion = tokens[2]\n            tokens = fullversion.split('.')\n            version = tokens[0]\n\n        target_name = './bin/chromedriver-linux-' + version\n        print('new chrome driver at ' + target_name)\n        found = os.path.exists(target_name)\n        if not found:\n            version_number = get_latestversion(version)\n            download_url = \"https://chromedriver.storage.googleapis.com/\" + version_number +\"/chromedriver_linux64.zip\"\n            download(download_url, './temp/chromedriver', target_name) \n \n"], ["pattern = r\"^[\\w|\\.\\-\\_]+\\.[a-zA-Z]+$\"\n"], [], [], ["import yfinance as yf\n\ntickerSymbol = 'AMD'\n\ntickerData = yf.Ticker(tickerSymbol)\ntodayData = tickerData.history(period='1d')\ntodayData['Close'][0] #use print() in case you're testing outside a interactive session\n"], ["    def floatToString(self, floatnumber:float32) -> str:\n        stringNumber:str = \"\"\n        whole:int = math.floor(floatnumber)\n        frac:int = 0\n        digits:float = float(floatnumber % 1)\n        digitsTimes100:float = float(digits) * float(100.0)\n        if digitsTimes100 is not None:\n            frac = math.floor(digitsTimes100)\n        stringNumber = str(whole)+\".\"+str(frac)\n        return stringNumber\n"], [], ["$ pip3 install --upgrade setuptools\n$ pip3 install --upgrade pip\n"], ["python3 -m pip install --user --no-cache-dir google-cloud-bigquery\npython3 -m pip install --upgrade setuptools\n", "python3 -m pip install --no-cache-dir --user --upgrade grpcio\n"], ["class Language(enum.Enum):\n    en = 'en'\n    zh = 'zh'\n\n    @classmethod\n    def has_member_key(cls, key):\n        return key in cls.__members__\n\nprint(Language.has_member_key('tu')) => False\nprint(Language.has_member_key('en')) => True\n"], [], [], ["content = \"\".join(l for l in content.splitlines() if l)\n"], ["    def count_letters(text):\n  result = {}\n  # Go through each letter in the text\n  text=text.casefold()\n  for letter in text:\n    # Check if the letter needs to be counted or not\n    if (letter.isalpha()): \n\n    # Add or increment the value in the dictionary\n      result.update({letter:text.count(letter)})\n  return result\n\nprint(count_letters(\"AaBbCc\"))\n# Should be {'a': 2, 'b': 2, 'c': 2}\n\nprint(count_letters(\"Math is fun! 2+2=4\"))\n# Should be {'m': 1, 'a': 1, 't': 1, 'h': 1, 'i': 1, 's': 1, 'f': 1, 'u': 1, 'n': 1}\n\nprint(count_letters(\"This is a sentence.\"))\n# Should be {'t': 2, 'h': 1, 'i': 2, 's': 3, 'a': 1, 'e': 3, 'n': 2, 'c': 1}\n"], [], ["python setup.py egg_info\" failed with error code 1 in /tmp/pip-install-hI6hg8/mpmath/\n", "apt-get install --upgrade python-pip -y && \\\n    python -m pip install --upgrade pip\n", "RUN apt-get install -y python-scipy\nRUN apt-get install -y python-sympy\n...\nRUN python -m pip install opencv-python==3.4.0.12\nRUN python -m pip install pyyaml\n...\n", "python -m pip install opencv-python==3.4.0.12\n"], ["date_columns = df.select_dtypes(include=['datetime64[ns, UTC]']).columns\nfor date_column in date_columns:\n    df[date_column] = df[date_column].dt.date\n    \ndf.to_excel('anbima_feed.xlsx',engine='xlsxwriter')\n"], ["plt.imshow(transforms.ToPILImage()(image), interpolation=\"bicubic\")\n#transforms.ToPILImage()(image).show() # Alternatively\n", "def show(img):\n    npimg = img.numpy()\n    plt.imshow(np.transpose(npimg, (1, 2, 0)), interpolation='nearest')\n"], [">>> model = nn.Sequential(nn.Linear(2, 2), \n                          nn.ReLU(),\n                          nn.Sequential(nn.Linear(2, 1),\n                          nn.Sigmoid()))\n\n>>> l = [module for module in model.modules() if not isinstance(module, nn.Sequential)]\n\n>>> l\n\n[Linear(in_features=2, out_features=2, bias=True),\n ReLU(),\n Linear(in_features=2, out_features=1, bias=True),\n Sigmoid()]\n"], ["from PIL import Image\nimage = Image.open(img_path)\nplt.imshow(transforms.ToPILImage()(transforms.ToTensor()(image)), interpolation=\"bicubic\")\n"], ["import yfinance as yf\n\nsymbols = [\"TSLA\", \"NIO\"]\nresult = {}\nfor symbol in symbols:\n    data = yf.Ticker(symbol)\n    today_data = data.history(period='1d')\n    result[symbol] = round((today_data['Close'][0]),2)\nprint(result)\n"], [], ["def count_letters(text):\n  result = {}\n  # Go through each letter in the text\n  for letter in text:\n    # Check if the letter needs to be counted or not\n    if letter.isalpha():\n      if letter not in result:\n        result[letter.lower()] = 1\n      else:\n        result[letter.lower()] +=1\n    # Add or increment the value in the dictionary\n    \n  return result\n\nprint(count_letters(\"AaBbCc\"))\n# Should be {'a': 2, 'b': 2, 'c': 2}\n\nprint(count_letters(\"Math is fun! 2+2=4\"))\n# Should be {'m': 1, 'a': 1, 't': 1, 'h': 1, 'i': 1, 's': 1, 'f': 1, 'u': 1, 'n': 1}\n"], ["def count_letters(text):\n  result = {}\n  # Go through each letter in the text\n  for letter in text.lower():\n    # Check if the letter needs to be counted or not\n    if(letter.isalpha()):\n      result[letter] = result.get(letter,0)+1\n    # Add or increment the value in the dictionary\n    \n  return result\n"], ["x = 12\ny = 10\n\nword_string = x + ' plus ' + y + 'equals: ' + (x+y)\n", "x = 12\ny = 10\n\nword_string = f'{x} plus {y} equals: {x+y}'\noutput: 12 plus 10 equals: 22\n"], ["exwriter = pd.ExcelWriter(fullpath, engine='xlsxwriter', options={'remove_timezone': True})\n"], ["def count_letters(text):\n  result = {}\n  # Go through each letter in the text\n  for letter in text.lower():\n    # Check if the letter needs to be counted or not\n    if letter.isalpha() and letter not in result:\n    # Add or increment the value in the dictionary\n      result[letter] = text.count(letter)\n  return result\n\nprint(count_letters(\"AaBbCc\"))\n# Should be {'a': 2, 'b': 2, 'c': 2}\n\nprint(count_letters(\"Math is fun! 2+2=4\"))\n# Should be {'m': 1, 'a': 1, 't': 1, 'h': 1, 'i': 1, 's': 1, 'f': 1, 'u': 1, 'n': 1}\n\nprint(count_letters(\"This is a sentence.\"))\n# Should be {'t': 2, 'h': 1, 'i': 2, 's': 3, 'a': 1, 'e': 3, 'n': 2, 'c': 1}\n"], ["icon = QtGui.QIcon(':/icons/myicon.png')\n", "# somewhere at the beginning of your program\nQtCore.QDir.addSearchPath('icons', 'path_to_icons/')\n\nicon = QtGui.QIcon('icons:myicon.png')\n"], ["pattern = \"^[\\w]*[\\.\\-\\+][^/@]*$\"\n"], ["from retrying import retry\nprint(\"HI\")\n"], [], ["def compute_min_number_of_refills(d, m, stops):\n    if d <= m:\n        return 0\n    total_refill = 0\n    last_refill = -1\n    limit = m \n    stops.append(d)\n    i = 0\n    while i < len(stops):\n        if stops[i] >= limit: \n            current_refill = i - 1 if stops[i] > limit else i\n            if current_refill == last_refill:\n                return -1 \n            last_refill = current_refill\n            total_refill += 1\n            limit = m + stops[current_refill]\n            i = current_refill + 1\n        else:\n            i += 1\n    return total_refill\n"], ["POWERLEVEL9K_LEFT_PROMPT_ELEMENTS=(anaconda ...ENVS)\n"], ["def get_current_price(symbol):\n    ticker = yf.Ticker(symbol)\n    todays_data = ticker.history(period='1d')\n    return todays_data['Close'][0]\n\nprint(get_current_price('TSLA'))\n"], [], ["import pandas as pd\n# Adjust time zone from columns\ndf['date'] = pd.to_datetime( df['date'], errors='coerce',utc=True)\n# Export to excel\ndf.to_excel('filename.xlsx')\n"], [], ["import plotly.graph_objects as go\n\nfig.add_trace(go.Candlestick(x=df['begin'], ...)\n\nfig.layout = dict(title=ticker, xaxis = dict(type=\"category\", categoryorder='category ascending'))\nfig.show()\n"], ["import chromedriver_autoinstaller\nfrom selenium import webdriver\n\nopt = webdriver.ChromeOptions()\nopt.add_argument(\"--start-maximized\")\n\nchromedriver_autoinstaller.install()\ndriver = webdriver.Chrome(options=opt)\ndriver.get('https://stackoverflow.com/')\n"], [], [], [], [], [], [], [], ["from sklearn.preprocessing.data import QuantileTransformer\n", "from sklearn.preprocessing import QuantileTransformer\n"], ["% sudo rm -rf /Library/Developer/CommandLineTools\n% sudo xcode-select --switch /Applications/Xcode.app\n% brew uninstall llvm # if installed via brew\n% clang --version\nApple clang version 12.0.0 (clang-1200.0.32.28)\nTarget: x86_64-apple-darwin20.2.0\nThread model: posix\nInstalledDir: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin\n"], [], [], [], [], [], [], [], [], ["import tensorflow as tf\nimport numpy as np\n\ninputs = np.random.rand(100, 99)\ntargets = np.random.rand(100)\n\nds = tf.data.Dataset.from_tensor_slices((inputs, targets))\n\nX_train = list(map(lambda x: x[0], ds))\ny_train = list(map(lambda x: x[1], ds))\n"], [], ["def get_children(model: torch.nn.Module):\n    # get children form model!\n    children = list(model.children())\n    flatt_children = []\n    if children == []:\n        # if model has no children; model is last child! :O\n        return model\n    else:\n       # look for children from children... to the last child!\n       for child in children:\n            try:\n                flatt_children.extend(get_children(child))\n            except TypeError:\n                flatt_children.append(get_children(child))\n    return flatt_children\n"], ["$ python3 -m pip install --upgrade pip\n"], ["% sudo rm -rf /Library/Developer/CommandLineTools\n% sudo xcode-select --install\n% clang --version\nApple clang version 12.0.0 (clang-1200.0.32.27)\nTarget: x86_64-apple-darwin20.1.0\nThread model: posix\nInstalledDir: /Library/Developer/CommandLineTools/usr/bin\n"], [], ["def summer_69(arr):\n    y = []\n    for x in arr:\n        if 6 in arr:\n            a = arr.index(6)\n            b = arr.index(9)\n            del arr[a:b+1]\n            y = arr\n        elif arr == []:\n            return \"0\"\n        else:\n            return sum(arr)\n    return sum(y)\nprint(summer_69([]))                                                          #0\nprint(summer_69([1, 3, 5]))                                                   #9\nprint(summer_69([4, 5, 6, 7, 8, 9]))                                          #9\nprint(summer_69([2, 1, 6, 9, 11]))                                            #14\nprint(summer_69([2, 1, 6, 9, 6, 11, 25, 36, 11, 9, 4, 6, 4, 6, 3, 9, 15]))    #22\n"], ["\"jupyter.codeLenses\": \" \",\n"], ["g2 = df.groupby([\"Description\",\"CustomerID\"],as_index=False).agg({'Quantity':{\"maxQ\":np.max,\"minQ\":np.min,\"meanQ\":np.mean}})\ng2.columns = [\"Description\",\"CustomerID\",\"maxQ\",\"minQ\",'meanQ']\n", "g2 = df.groupby([\"Description\",\"CustomerID\"],as_index=False).agg({'Quantity':{np.max,np.min,np.mean}})\ng2.columns = [\"Description\",\"CustomerID\",\"maxQ\",\"minQ\",'meanQ']\n"], ["sudo xcode-select --switch /Applications/Xcode.app/\n", "sudo xcode-select --switch /Library/Developer/CommandLineTools\n"], [">>> softwareupdate --all --install --force\nSoftware Update Tool\n\nFinding available software\nNo updates are available.\n", "sudo rm -rf /Library/Developer/CommandLineTools\nsudo xcode-select --install\n"], [], [], ["def count_letters(text):\n  result = {}\n  # Go through each letter in the text\n  for letter in text:\n    # Check if the letter needs to be counted or not\n    if type(letter)==str:\n    # Add or increment the value in the dictionary\n     if letter not in result:\n       result[letter.lower()]=1\n     else:\n        result[letter.lower()]+=1\n\n\n    \n  return result\n\nprint(count_letters(\"AaBbCc\"))\n# Should be {'a': 2, 'b': 2, 'c': 2}\n\nprint(count_letters(\"Math is fun! 2+2=4\"))\n# Should be {'m': 1, 'a': 1, 't': 1, 'h': 1, 'i': 1, 's': 1, 'f': 1, 'u': 1, 'n': 1}\n\nprint(count_letters(\"This is a sentence.\"))\n# Should be {'t': 2, 'h': 1, 'i': 2, 's': 3, 'a': 1, 'e': 3, 'n': 2, 'c': 1}\n"], ["def filter_substring(seq, start, end):\nflag = False\nfor char in seq:\n    if char == start:\n        flag = True\n        continue\n    elif flag:\n        if char == end:\n            flag = False \n        else:\n            continue\n    else:\n        yield char\n\ndef summer_69(seq, start, end):\n    return sum(filter_substring(seq, start, end))\n\ndef print_substring(string, start, end):\n    return list(filter_substring(string, start, end))\n", "seq = [4, 5, 9, 6, 2, 9, 5, 6, 1, 9, 2]\nprint(summer_69(seq, start=6, end=9))\n\n\nstring = \"abcdef\"\nprint(print_substring(string, start='c', end='e'))\n"], ["import os\nimport tempfile\n\nfrom fastapi import FastAPI\nfrom fastapi.responses import FileResponse\n\nfrom starlette.background import BackgroundTasks\n\napp = FastAPI()\n\n\ndef remove_file(path: str) -> None:\n    os.unlink(path)\n\n\n@app.post(\"/send\")\nasync def send(background_tasks: BackgroundTasks):\n    fd, path = tempfile.mkstemp(suffix='.txt')\n    with os.fdopen(fd, 'w') as f:\n        f.write('TEST\\n')\n    background_tasks.add_task(remove_file, path)\n    return FileResponse(path)\n", "import os\nimport tempfile\n\nfrom fastapi import FastAPI, Depends\nfrom fastapi.responses import FileResponse\n\n\napp = FastAPI()\n\n\ndef create_temp_file():\n    fd, path = tempfile.mkstemp(suffix='.txt')\n    with os.fdopen(fd, 'w') as f:\n        f.write('TEST\\n')\n    try:\n        yield path\n    finally:\n        os.unlink(path)\n\n\n@app.post(\"/send\")\nasync def send(file_path=Depends(create_temp_file)):\n    return FileResponse(file_path)\n"], ["    from azure.storage.blob import (\n       BlobServiceClient,\n       ContentSettings\n    )\n\n    storage_connection_string='DefaultEndpointsProtocol=https;AccountName=<STORAGE_ACCOUNT_NAME>;AccountKey=<ACCOUNT_KEY>;EndpointSuffix=core.windows.net'\n    container_name =\n    blob_service_client = BlobServiceClient.(\n        conn_str=storage_connection_string\n        )\n    logging.debug(f'getting client for container : {container_name}')\n    container_client = \n    blob_service_client.get_container_client(container=container_name)\n    blob_client = container_client.get_blob_client(blob_name)\n    if blob_client.exists():\n        blob_client.delete_blob()\n    blob_client =blob_service_client.get_blob_client(container=container_name, \n    blob=blob_name)\n    try:\n        with open(filename, \"rb\") as data:\n             blob.upload(data)\n        content_settings =ContentSettings(content_type='image/png')\n        logging.debug(f'setting the content type : {content_settings}')\n    except Exception as e:\n        logging.error(str(e))\n"], ["@echo ON\ntitle Launch Jupyter notebooks from Drive D\njupyter notebook --notebook-dir=D:\n@echo OFF\n"], ["cd D:\n", "jupyter notebook\n"], ["xaxis=dict(type = \"category\")\n"], [], ["spacy.cli.download(\"en\")\n\nnlp = spacy.load('en_core_web_sm')\n"], ["#Pseudo\ndf['date'] = old_dates\ndf['date'] = df['date'].apply(lambda a: pd.to_datetime(a).date()) \n# .date() removes timezone\n\n...df.to_excel etc.\n"], ["create table bow (\n  doc_id int,\n  word text,\n  count int)\n"], [], [], ["   * when you get this error::RuntimeError: Input type \n   (torch.FloatTensor) and weight type (torch.cuda.FloatTensor should \n   be the same\n   # Move tensors to GPU is CUDA is available\n   # Check if CUDA is available\n\n  train_on_gpu = torch.cuda.is_available()\n\n  If train_on_gpu:\n      print(\"CUDA is available! Training on GPU...\")\n  else:\n      print(\"CUDA is not available. Training on CPU...\")\n\n -------------------\n # Move tensors to GPU is CUDA is available\nif train_on_gpu:\n\nmodel.cuda()\n"], ["!python -m spacy download en_core_web_md\n", "!python -m spacy download en_core_web_sm'\n", "!python -m spacy download en_core_web_lg\n"], ["fig.update_xaxes(\n    rangebreaks=[dict(values=dt_breaks)] # hide dates with no values\n)\n", "import pandas as pd\nimport plotly.express as px\n\ndf = pd.DataFrame({'Date': {0: '2019-06-03',\n                          1: '2019-06-03',\n                          2: '2019-06-03',\n                          3: '2019-06-04',\n                          4: '2019-06-05',\n                          5: '2019-06-05',\n                          6: '2019-06-06',\n                          7: '2019-06-07',\n                          8: '2019-06-08',\n                          9: '2019-06-09',\n                          10: '2019-06-10',\n                          11: '2019-06-11',\n                          12: '2019-07-12',\n                          13: '2019-07-13',\n                          14: '2019-07-14',\n                          15: '2019-07-14',\n                          16: '2019-07-15',\n                          17: '2019-07-16',\n                          18: '2019-07-17',\n                          19: '2019-07-18'},\n                         'Category': {0: '\"25M\"',\n                          1: '\"25M\"',\n                          2: '\"50M\"',\n                          3: '\"25M\"',\n                          4: '\"50M\"',\n                          5: '\"50M\"',\n                          6: '\"100M\"',\n                          7: '\"25M\"',\n                          8: '\"100M\"',\n                          9: '\"25M\"',\n                          10: '\"50M\"',\n                          11: '\"25M\"',\n                          12: '\"50M\"',\n                          13: '\"50M\"',\n                          14: '\"100M\"',\n                          15: '\"50M\"',\n                          16: '\"100M\"',\n                          17: '\"25M\"',\n                          18: '\"25M\"',\n                          19: '\"25M\"'},\n                         'Sum': {0: 34,\n                          1: 60,\n                          2: 23,\n                          3: 67,\n                          4: -90,\n                          5: 100,\n                          6: 6,\n                          7: -100,\n                          8: 67,\n                          9: 450,\n                          10: 600,\n                          11: -9,\n                          12: 45,\n                          13: 67,\n                          14: 130,\n                          15: 45,\n                          16: 100,\n                          17: -90,\n                          18: 700,\n                          19: -9}})\n\ndf[\"Date\"]=pd.to_datetime(df[\"Date\"], format=(\"%Y-%m-%d\"))\ndf=df.sort_values([\"Date\",\"Category\",\"Sum\"],ascending=True)\ndf=round(df.groupby([\"Date\",\"Category\"]).agg({\"Sum\":\"sum\"}).reset_index(),1)\n\n\n\ndt_all = pd.date_range(start=df['Date'].iloc[0],end=df['Date'].iloc[-1])\ndt_obs = [d.strftime(\"%Y-%m-%d\") for d in df['Date']]\ndt_breaks = [d for d in dt_all.strftime(\"%Y-%m-%d\").tolist() if not d in dt_obs]\n\ndf=df.set_index('Date')\n\n#fig = px.bar(df, x=df.index.strftime(\"%Y/%m/%d\") , y='Sum',barmode=\"group\",color=\"Category\") \nfig = px.bar(df, x=df.index , y='Sum',barmode=\"group\",color=\"Category\")\n\nfig.update_xaxes(\n    rangebreaks=[dict(values=dt_breaks)] # hide dates with no values\n)\n\n\nfig.update_xaxes(\nrangeslider_visible=True,\nrangeselector=dict(\n    buttons=list([\n        dict(count=1, label=\"day\", step=\"day\", stepmode=\"todate\"),\n        dict(count=24, label=\"montly\", step=\"month\", stepmode=\"todate\"),\n        dict(count=1, label=\"year\", step=\"year\", stepmode=\"todate\"),\n        dict(step=\"all\")\n    ])\n   ))\n\n\nfig.show()\n"], ["def paranthesis(exprs):\n    stack = []\n    for char in exprs:\n        if char in [\"(\",\"{\",\"[\"]:\n            stack.append(char)\n        else:\n            currchar = stack.pop()\n            if currchar ==\"(\":\n                if char !=\")\":\n                    return False\n            if currchar == \"{\":\n                if char != \"}\":\n                    return False\n            if currchar == \"[\":\n                if char != \"]\":\n                    return False\n    if stack:\n        print(stack)\n        return False\n    return True\n\n\nif __name__ == \"__main__\":\n    exprs = \"({[]}]\"\n\n    if paranthesis:\n        print(\"Balanced\")\n    else:\n        print(\"Unbalanced\")\n}\n"], ["import re\ndef check_web_address(text):\n  pattern = r'^[A-Za-z._-][^/@]*$'\n  result = re.search(pattern, text)\n  return result != None\n\nprint(check_web_address(\"gmail.com\")) # True\nprint(check_web_address(\"www@google\")) # False\nprint(check_web_address(\"www.Coursera.org\")) # True\nprint(check_web_address(\"web-address.com/homepage\")) # False\nprint(check_web_address(\"My_Favorite-Blog.US\")) # True\n"], [], ["static int compute_refills(int dist, int tank, int stops[], int n) {\n    int current_refills=0;\n    int num_refills=0;\n    int last_refill=0;\n    while(current_refills<=n) {\n        last_refill = current_refills;\n        while ((current_refills !=stops.length-1) && (stops[current_refills + 1] - stops[last_refill]) <= tank) {\n            current_refills +=1 ;\n\n        }\n\n        if (current_refills == last_refill)\n            return -1;\n        if (current_refills <= n)\n            num_refills +=1;\n\n\n    }\n    return num_refills;\n}\n\n\n\n    public static void main (String[]args){\n        Scanner scanner = new Scanner(System.in);\n        int dist = scanner.nextInt();\n        int tank = scanner.nextInt();\n        int n = scanner.nextInt();\n        int stops[] = new int[n * n * n];// to solve array index out of bound exception increase the size of the array\n        for (int i = 0; i < n; i++) {\n            stops[i] = scanner.nextInt();\n        }\n\n        System.out.println(compute_refills(dist, tank, stops, n));\n\n    }\n}\n"], ["$ nano ~/.bashrc  \nalias notebook=\"jupyter notebook --notebook-dir=/mnt/r\" \n$ source ~/.bashrc  \n$ notebook\n", "$ jupyter notebook list\n"], [], ["args = parser.parser_args()\n\nprint(f\"Input directory: {args.input_directory}\")\nprint(f\"Output directory: {args.output_directory}\")\n", "print(\"Input directory: {}\".format(args.input_directory))\nprint(\"Output directory: {}\".format(args.output_directory))\n", "print(\"Input directory: \"+args.input_directory)\nprint(\"Output directory: \"+args.output_directory)\n"], ["import os\nimport cv2\nbad_list=[]\ndir=r'c:\\'PetImages'\nsubdir_list=os.listdir(dir) # create a list of the sub directories in the directory ie train or test\nfor d in subdir_list:  # iterate through the sub directories train and test\n    dpath=os.path.join (dir, d) # create path to sub directory\n    if d in ['test', 'train']:\n        class_list=os.listdir(dpath) # list of classes ie dog or cat\n       # print (class_list)\n        for klass in class_list: # iterate through the two classes\n            class_path=os.path.join(dpath, klass) # path to class directory\n            #print(class_path)\n            file_list=os.listdir(class_path) # create list of files in class directory\n            for f in file_list: # iterate through the files\n                fpath=os.path.join (class_path,f)\n                index=f.rfind('.') # find index of period infilename\n                ext=f[index+1:] # get the files extension\n                if ext  not in ['jpg', 'png', 'bmp', 'gif']:\n                    print(f'file {fpath}  has an invalid extension {ext}')\n                    bad_list.append(fpath)                    \n                else:\n                    try:\n                        img=cv2.imread(fpath)\n                        size=img.shape\n                    except:\n                        print(f'file {fpath} is not a valid image file ')\n                        bad_list.append(fpath)\n                       \nprint (bad_list)\n                    \n    \n  \n"], ["import os\nfrom PIL import Image\nfolder_path = 'data\\img'\nextensions = []\nfor fldr in os.listdir(folder_path):\n    sub_folder_path = os.path.join(folder_path, fldr)\n    for filee in os.listdir(sub_folder_path):\n        file_path = os.path.join(sub_folder_path, filee)\n        print('** Path: {}  **'.format(file_path), end=\"\\r\", flush=True)\n        im = Image.open(file_path)\n        rgb_im = im.convert('RGB')\n        if filee.split('.')[1] not in extensions:\n            extensions.append(filee.split('.')[1])\n    \n"], ["pip install --upgrade pip setuptools wheel\n", "pip install opencv-python\n"], ["def compute_min_refills(distance, tank, stops):\n\n    numrefill, currentrefill= 0,0\n    stops = [0] + stops + [distance] #include the start and end points in the stops list   \n    if distance <= tank:\n        return 0\n    else:\n        while currentrefill < len(stops)-1:\n            lastrefill = currentrefill\n            #print(currentrefill, lastrefill, len(stops))\n            while currentrefill < len(stops)-1 and stops[currentrefill+1] - stops[lastrefill]<=tank:\n           \n                currentrefill += 1\n\n            if currentrefill == lastrefill:\n                return -1\n            if currentrefill < len(stops)-1:\n                numrefill +=1\n\n        #print(numrefill)\n\n        return numrefill\n\nif __name__ == '__main__':\n    \n    #print(compute_min_refills(10, 3, [1,2,5,9]))\n"], [], ["def split_check(bill, people, tax = 0.15, tip = 0.09):\n    tax = bill * tax \n    tip = bill * tip\n    return (bill + tax + tip)/people\n    \nprint('Cost per diner:', split_check(25, 2))\n", "def split_check(bill, people, tax = 0.15, tip = 0.09):\n    return bill * (1.0 + tax + tip) / people\n    \nprint('Cost per diner:', split_check(25, 2))\n", "Cost per diner: 15.5\n"], ["def is_power_of(number, base):\n# Base case: when number is smaller than base.\nnumber= number/base\n if number < base:\n# If number is equal to 1, it's a power (base**0).\n  return False\n else: \n  return True\nreturn is_power_of(number, base)\n\n\nprint(is_power_of(8,2)) # Should be True\nprint(is_power_of(64,4)) # Should be True\nprint(is_power_of(70,10)) # Should be False\n"], [], ["def balanced(s):\n    if s.count('[') == s.count(']') and s.count('(') == s.count(')') and s.count('{') == s.count('}'):\n        return True\n    else:   \n        return False\n", "Prob_test_cases = ('}{', '][', ')(')\n", "def para_check(checkme):\n    open = ['(', '[', '{']\n    close = [')', ']', '}']\n    # assume that the result is true\n    result = True\n\n    # if the input is not a list then convert it to list\n    if type(checkme) is not list:\n        checkme = list(checkme)\n\n    # if it doesnt contain at least 2 elements then return false\n    if len(checkme) < 2:\n        result = False\n\n    # if number of closing and opening paranthesis is not the same then it is not balanced\n    count_check1 = checkme.count('[') == checkme.count(']')\n    count_check2 = checkme.count('(') == checkme.count(')')\n    count_check3 = checkme.count('{') == checkme.count('}')\n\n    # if not all of the above are true then it is unbalanced and thus...\n    if not all([count_check1, count_check2, count_check3]):\n        result = False\n\n    def recurser(checkme, first, last):\n        '''\n        here start can be '[,(,{' and end can be '],),}' respectively,\n        Check for a given type of bracket (any 1 of 3) see if the \n        index of the first closing bracket is greater than the first \n        opening bracket and if yes then remove them since they are a pair.\n        Repeat this forever for all 3 types of brackets.\n        '''            \n        if first in checkme and last in checkme:\n            open_index = checkme.index(first)\n            closed_index = checkme.index(last)\n            \n            if closed_index > open_index:\n                checkme.pop(closed_index)\n                checkme.pop(open_index)\n                # recursion\n                recurser(checkme, first, last)\n            else:\n                result = False\n\n    recurser(checkme, '[', ']')\n    recurser(checkme, '(', ')')\n    recurser(checkme, '{', '}')\n\n    if len(checkme) > 0:\n        result = False\n\n    return result\n"], ["if \"new_customer\" in Action._value2member_map_:  # works\n", "if \"new_customer\" in Action:  # doesn't work (i.e. TypeError)\n"], [">>> Action('new_customer')\nAction.NEW_CUSTOMER\n", "def is_action(obj):\n    try:\n        Action(obj)\n    except ValueError:\n        return False\n    return True\n"], ["def flatten(el):\n    flattened = [flatten(children) for children in el.children()]\n    res = [el]\n    for c in flattened:\n        res += c\n    return res\n\ncnn = nn.Sequential(Custom_block_1, Custom_block_2)\nlayers = flatten(cnn)\n"], [], ["function minfill(distance, miles, n, stations) {\n\n    //added final distance to last station for simplicity can simply push to array. \n    stations = [...stations, distance]\n\n    let refill = 0,\n        limit = miles,\n        dt = 0, //distance travelled\n        current = 0; //current station\n\n    while (current <= n) {\n\n        //check if next  or first station is unreachable\n        if ((Math.abs(stations[current] - stations[current + 1]) > limit) || stations[0] > limit) return -1\n\n        //check if we need to refuel or pass\n        if (Math.abs(dt - stations[current]) <= limit) { \n            current++\n        }\n\n        //if next distance was over limit we set distance tavelled to previous station ,current station was already pointed to next in above block\n        else {\n            dt = stations[current - 1]\n\n            refill++\n        }\n    }\n    return refill\n}\n"], ["def count_letters(text):\n    result = {}\n  # Go through each letter in the text\n    text=text.lower()\n    for letter in text:\n    # Check if the letter needs to be counted or not\n        if letter.isalpha():\n    # Add or increment the value in the dictionary\n            result[letter] = result.get(letter,0) + 1\n        else:\n            pass\n    return result\n\nprint(count_letters(\"AaBbCc\"))\n# Should be {'a': 2, 'b': 2, 'c': 2}\nprint(count_letters(\"Math is fun! 2+2=4\"))\n# Should be {'m': 1, 'a': 1, 't': 1, 'h': 1, 'i': 1, 's': 1, 'f': 1, 'u': 1, 'n': 1}\nprint(count_letters(\"This is a sentence.\"))\n# Should be {'t': 2, 'h': 1, 'i': 2, 's': 3, 'a': 1, 'e': 3, 'n': 2, 'c': 1}\n"], [], ["device = args.device # \"cuda\" / \"cpu\"\nif \"cuda\" in device and not torch.cuda.is_available():\n    device = \"cpu\"\ndata = data.to(device)\nmodel.to(device)\n"], ["def is_power_of(number, base):\n  # Base case: when number is smaller than base.\n  if number < base:\n    # If number is equal to 1, it's a power (base**0).\n    return number == 1\n  result = number//base\n  # Recursive case: keep dividing number by base.\n  return is_power_of(result, base)\n"], ["def car_refill(dist,cap,n,stops):\n    stops.insert(0,0)\n    stops.append(dist)\n    num_refill,curr_refill = 0,0\n    while curr_refill <= n:\n        last_refill = curr_refill\n        while (curr_refill <= n and stops[curr_refill + 1] - stops[last_refill] <= cap):\n            curr_refill += 1\n        if curr_refill == num_refill :\n            return -1\n        if curr_refill <= n:\n            num_refill +=1\n    return num_refill\n"], ["def summer_69(arr):\n        x = arr.count(6)\n        y = arr.count(9)\n        # to decide number of iteration required for loop\n        z = min(x,y)\n        k = 0\n        while k < (z) :\n            m = arr.index(6)\n            n = arr.index(9)\n            del arr[m:(n+1)]\n            k = k + 1\n        print(arr)\n        return sum(arr)\n"], ["def count_letters(text):\n  result = {}\n  text = text.lower()\n  # Go through each letter in the text\n  for letter in text:\n   \n    # Check if the letter needs to be counted or not\n    if letter.isalpha() :\n      # Add or increment the value in the dictionary\n      count = text.count(letter)\n      result[letter] = count\n  return result\n\nprint(count_letters(\"AaBbCc\"))\n# Should be {'a': 2, 'b': 2, 'c': 2}\n\nprint(count_letters(\"Math is fun! 2+2=4\"))\n# Should be {'m': 1, 'a': 1, 't': 1, 'h': 1, 'i': 1, 's': 1, 'f': 1, 'u': 1, 'n': 1}\n\nprint(count_letters(\"This is a sentence.\"))\n# Should be {'t': 2, 'h': 1, 'i': 2, 's': 3, 'a': 1, 'e': 3, 'n': 2, 'c': 1}\n"], ["def is_power_of(number, base):\n    return (math.log(number) / math.log(base)).is_integer()\n", "def is_power_of(number, base):\n    x = math.log(abs(number)) / math.log(abs(base))\n    return base ** x == number\n"], ["def is_power_of(number,base):\n    if number == base:\n        return True\n    elif number < base:\n        return False\n    return is_power_of(number / base, base)\n"], ["def count_letters(text):\n  result = {}\n  # Go through each letter in the text\n  for letter in text:\n    # Check if the letter needs to be counted or not\n    if letter.isalpha() == True:\n      if letter.lower() not in result:\n        result[letter.lower()] = 1\n    # Add or increment the value in the dictionary\n      else:\n        result[letter.lower()] += 1\n    \n  return result\n\nprint(count_letters(\"AaBbCc\"))\n# Should be {'a': 2, 'b': 2, 'c': 2}\n\nprint(count_letters(\"Math is fun! 2+2=4\"))\n# Should be {'m': 1, 'a': 1, 't': 1, 'h': 1, 'i': 1, 's': 1, 'f': 1, 'u': 1, 'n': 1}\n\nprint(count_letters(\"This is a sentence.\"))\n# Should be {'t': 2, 'h': 1, 'i': 2, 's': 3, 'a': 1, 'e': 3, 'n': 2, 'c': 1}\n"], ["from shapely.geometry import Polygon\nimport matplotlib.pyplot as plt\nimport geopandas as gpd\n\npolygon1 = Polygon([(0,5),\n                    (1,1),\n                    (3,0),\n                    ])\n\n p = gpd.GeoSeries(polygon1)\n p.plot()\n plt.show()\n"], ["def count_letters(text):\n  result = {}\n  # Go through each letter in the text\n  for letter in text:\n    # Check if the letter needs to be counted or not\n    \n    if letter.isalpha() and letter not in result:\n      letter=letter.lower()\n      result[letter]=1\n    elif letter.isalpha()==False:\n      pass\n    else:\n      result[letter]+=1\n\n    ___\n    # Add or increment the value in the dictionary\n    ___\n  return result\n\nprint(count_letters(\"AaBbCc\"))\n# Should be {'a': 2, 'b': 2, 'c': 2}\n\nprint(count_letters(\"Math is fun! 2+2=4\"))\n# Should be {'m': 1, 'a': 1, 't': 1, 'h': 1, 'i': 1, 's': 1, 'f': 1, 'u': 1, 'n': 1}\n\nprint(count_letters(\"This is a sentence.\"))\n# Should be {'t': 2, 'h': 1, 'i': 2, 's': 3, 'a': 1, 'e': 3, 'n': 2, 'c': 1}\n"], ["TOKENIZERS_PARALLELISM=false\n", "import os\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n"], [], ["dfx=pd.DataFrame(columns=[\"A\",\"B\",\"C\"],data=np.random.randint(0,5,size=(10,3)))\n#dfx\n#\n#   A  B  C\n#0  4  4  1\n#1  2  4  4\n#2  1  3  3\n#3  2  4  3\n#4  1  2  1\n#5  0  4  2\n#6  2  3  4\n#7  1  0  2\n#8  2  1  4\n#9  3  0  3\n", "aggdict = {\"A\":lambda x: x.iloc[0], \"B\": lambda x: x.iloc[-1], \"C\" : \"mean\" , \"D\":lambda x: \"mean\"}\n", "gb_col=\"C\"\ngbc = dfx.groupby(gb_col).agg(**{k:(k,v) for k,v in aggdict.items() if k in dfx.columns and k != gb_col})\n#       A  B\n#C      \n#1  4  2\n#2  0  0\n#3  1  4\n#4  2  3\n", "mygb = lambda gb_col: dfx.groupby(gb_col).agg(**{k:(k,v) for k,v in aggdict.items() if k in dfx.columns and k != gb_col})\nallgb = [mygb(c) for c in dfx.columns]\n"], ["def summer_69(arr):\n    a = 0\n    for nums in arr: \n        if nums == 6:\n            for items in arr[arr.index(6):]:\n                a = a+ items\n                if items == 9:\n                    break\n    return sum(arr)-a\n"], ["In [87]: arr = np.array([[1, 0, 1], \n    ...:                   [0, 0, 1], \n    ...:                   [1, 1, 0], \n    ...:                   [0, 0, 0], \n    ...:                   [1, 0, 1]])                                                  \nIn [88]: x = np.array([1,0,1])                                                          \n", "In [89]: arr == x                                                                       \nOut[89]: \narray([[ True,  True,  True],\n       [False,  True,  True],\n       [ True, False, False],\n       [False,  True, False],\n       [ True,  True,  True]])\n", "In [90]: (arr == x).all(axis=1)                                                         \nOut[90]: array([ True, False, False, False,  True])\n", "In [96]: arr[(arr == x).all(axis=1)]                                                    \nOut[96]: \narray([[1, 0, 1],\n       [1, 0, 1]])\n", "In [97]: arr[(arr == x).all(axis=1)]=[1,1,1]                                            \nIn [98]: arr                                                                            \nOut[98]: \narray([[1, 1, 1],\n       [0, 0, 1],\n       [1, 1, 0],\n       [0, 0, 0],\n       [1, 1, 1]])\n"], ["array[(array == [1, 0, 1]).all(axis=1)] = [1, 1, 1]\n"], ["np.sign([1,0,1] - [1,0,1])  # returns 0\n"], [], ["def count_letters(text):\n  result = {}\n  # Go through each letter in the text\n  text=text.lower()\n  for letter in text:\n    if letter in 'abcdefghijklmnopqrtsuvwxyz':\n\n      if letter in result:\n        result[letter]+=1\n      \n      else:\n        result[letter]=1\n  return result\n\nprint(count_letters(\"AaBbCc\"))\n# Should be {'a': 2, 'b': 2, 'c': 2}\n\nprint(count_letters(\"Math is fun! 2+2=4\"))\n# Should be {'m': 1, 'a': 1, 't': 1, 'h': 1, 'i': 1, 's': 1, 'f': 1, 'u': 1, 'n': 1}\n\nprint(count_letters(\"This is a sentence.\"))\n# Should be {'t': 2, 'h': 1, 'i': 2, 's': 3, 'a': 1, 'e': 3, 'n': 2, 'c': 1}\n"], ["approved = temp[col2]\ntemp = pd.DataFrame(project_data.groupby(col1)[col2].agg([('Avg','mean'),('total','count')]).reset_index())\ntemp[col2] = approved\n"], ["# Install python/pip\nENV PYTHONUNBUFFERED=1\nRUN apk add --update --no-cache python3 && ln -sf python3 /usr/bin/python\nRUN python3 -m ensurepip\nRUN pip3 install --no-cache --upgrade pip setuptools\n"], [], [], [], ["WARNING: Upgrading ipython, ipykernel, tornado, prompt-toolkit or pyzmq can\ncause your runtime to repeatedly crash or behave in unexpected ways and is not\nrecommended\n", "!pip install ipydex\n%load_ext ipydex.displaytools\n", "a = 4\nc = 5 ##:\n", "c := 5\n\n---\n"], ["!pip install -U ipython \n"], ["x = 5\nx\ny = 7\ny\n\nOut[]:\n5\n7\n", "Out[]:\n57\n", "meter = UNITS.meter\nsecond = UNITS.second\na = 9.8 * meter / second**2\na\n"], ["print(meter)\nprint(second)\nprint(a)\n", "from IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = \"all\"\n"], [], [], ["  if torch.cuda.is_available():\n      device = 'cuda'\n  else:\n      device = 'cpu'\n", "  checkpoint = torch.load('./generator_release.pth', map_location=device)\n  G = Generator().to(device)\n", "if torch.cuda.is_available():\n  data = data.cuda()\nresult = G(data)\n", "if torch.cuda.is_available():\n    result = result.cpu()\n"], ["import re\n\ntext = \"Life is beautiful\"\npattern = r\"\\b(?=[a-z]*[aeiou]{3})[a-z]+\\b\"\nresult = re.findall(pattern, text, re.I)\nprint(result)\n", "['beautiful']\n"], ["import requests\nimport wget\nimport zipfile\nimport os\n\n# get the latest chrome driver version number\nurl = 'https://chromedriver.storage.googleapis.com/LATEST_RELEASE'\nresponse = requests.get(url)\nversion_number = response.text\n\n# build the donwload url\ndownload_url = \"https://chromedriver.storage.googleapis.com/\" + version_number +\"/chromedriver_win32.zip\"\n\n# download the zip file using the url built above\nlatest_driver_zip = wget.download(download_url,'chromedriver.zip')\n\n# extract the zip file\nwith zipfile.ZipFile(latest_driver_zip, 'r') as zip_ref:\n    zip_ref.extractall() # you can specify the destination folder path here\n# delete the zip file downloaded above\nos.remove(latest_driver_zip)\n"], [], ["def summer_69(arr):\nsum = 0\nFlag = False\nif 6 not in arr:\n    for num in arr:\n        sum = sum + num\n    return sum\nelse:\n    for num in arr:\n        if num != 6 and Flag == False:\n            sum = sum + num                \n        elif num == 6:\n            Flag = True\n            continue\n        elif Flag == True and num != 9:\n            continue\n        elif num == 9:\n            Flag = False\n    return sum\n"], ["def count_letters(text):\n  result = {}\n  # Go through each letter in the text\n  for letter in text.lower():\n    # Check if the letter needs to be counted or not\n    if letter.isalpha() and letter not in result:\n    # Add or increment the value in the dictionary\n      result[letter] = text.lower().count(letter) \n  return result\n\nprint(count_letters(\"AaBbCc\"))\n# Should be {'a': 2, 'b': 2, 'c': 2}\n\nprint(count_letters(\"Math is fun! 2+2=4\"))\n# Should be {'m': 1, 'a': 1, 't': 1, 'h': 1, 'i': 1, 's': 1, 'f': 1, 'u': 1, 'n': 1}\n\nprint(count_letters(\"This is a sentence.\"))\n# Should be {'t': 2, 'h': 1, 'i': 2, 's': 3, 'a': 1, 'e': 3, 'n': 2, 'c': 1}\n"], ["def count_letters(text):\n  result = {}\n  # Go through each letter in the text\n  for letter in text:\n    # Check if the letter needs to be counted or not\n    if (letter.lower() not in result ) :\n      if not letter.isalpha():\n        continue\n      result[letter.lower()] = 0\n             # Add or increment the value in the dictionary\n    result[letter.lower()] += 1\n    continue\n  return result\n\nprint(count_letters(\"AaBbCc\"))\n# Should be {'a': 2, 'b': 2, 'c': 2}\n\nprint(count_letters(\"Math is fun! 2+2=4\"))\n# Should be {'m': 1, 'a': 1, 't': 1, 'h': 1, 'i': 1, 's': 1, 'f': 1, 'u': 1, 'n': 1}\n\nprint(count_letters(\"This is a sentence.\"))\n# Should be {'t': 2, 'h': 1, 'i': 2, 's': 3, 'a': 1, 'e': 3, 'n': 2, 'c': 1}\n"], ["def count_letters(text):\n  result = {}\n  text = text.lower()\n  # Go through each letter in the text\n  for letter in text:\n    # Check if the letter needs to be counted or not\n    if letter in \"abcdefghijklmnopqrstuvwxyz\":\n      #\n      if letter not in result:\n        result[letter] = 1\n      # Add or increment the value in the dictionary\n      else:\n        result[letter] += 1\n  return result\n\n  print(count_letters(\"AaBbCc\"))\n\n  # Should be {'a': 2, 'b': 2, 'c': 2}\n\n  print(count_letters(\"Math is fun! 2+2=4\"))\n  # Should be {'m': 1, 'a': 1, 't': 1, 'h': 1, 'i': 1, 's': 1, 'f': 1, 'u': \n  1, 'n': 1}\n\n  print(count_letters(\"This is a sentence.\"))\n  # Should be {'t': 2, 'h': 1, 'i': 2, 's': 3, 'a': 1, 'e': 3, 'n': 2, 'c': \n  1}\n"], ["def count_letters(text):\n r = {}\n  # Go through each letter in the text\n for letter in text:\n    # Check if the letter needs to be counted or not\n     for letter in text:\n# Check if the letter needs to be counted or not\n for alp in letter:\n  # To check the letters are alphabets or not\n  if alp in ascii_letters:\n   #Converting into lowercase as python is case sensitive\n    if alp.lower() in r and alp!=' ':\n      r[alp.lower()]+=1\n    elif alp.lower() not in r and alp!=' ':\n      r[alp.lower()]=1\n  # Add or increment the value in the dictionary\n  return r\n\nprint(count_letters(\"AaBbCc\"))\nprint(count_letters(\"Math is fun! 2+2=4\"))\nprint(count_letters(\"This is a sentence.\"))\n"], [], [], ["Make a row from a given bit string or with the given number of columns.\n", "Makes a row from a given bit string or with the given number of columns.\n", "makes a row from a given bit string or with the given number of columns\n"], ["def car_fueling(dist,miles,n,gas_stations):\n    num_refill, curr_refill, limit = 0,0,miles\n    while limit < dist:  # While the destination cannot be reached with current fuel\n        if curr_refill >= n or gas_stations[curr_refill] > limit:\n            # Cannot reach the destination nor the next gas station\n            return -1\n        # Find the furthest gas station we can reach\n        while curr_refill < n-1 and gas_stations[curr_refill+1] <= limit:\n            curr_refill += 1\n        num_refill += 1  # Stop to tank\n        limit = gas_stations[curr_refill] + miles  # Fill up the tank \n        curr_refill += 1\n    return num_refill\n\n# Test cases\nprint(car_fueling(950, 400, 4, [200, 375, 550, 750]))  # 2\nprint(car_fueling(10, 3, 4, [1, 2, 5, 9]))  # -1\n"], ["def car_fueling(dist,miles,n,gas_stations):\n    num_refill, curr_refill, last_refill = 0,0,0\n\n    while curr_refill <= n:\n        last_refill = curr_refill\n\n        while (curr_refill <= n-1) & (gas_stations[curr_refill + 1] - gas_stations[last_refill] <= miles):\n            curr_refill += 1\n        if curr_refill == last_refill:  \n            return -1\n        if curr_refill <= n:\n            num_refill += 1\n\n        n+=1 # Increment\n\n  return num_refill\n"], [], [], [], ["import yfinance as yf\ndata = yf.download(\"ABEV3.SA\", start=\"2020-03-01\", end=\"2020-03-30\")\n"], ["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: FutureWarning: using a dict on a Series for aggregation\nis deprecated and will be removed in a future version. Use                 named aggregation instead.\n\n    >>> grouper.agg(name_1=func_1, name_2=func_2)\n\n  \"\"\"Entry point for launching an IPython kernel.\n", "grouper.agg(name_1=func_1, name_2=func_2)\n"], [">>> from collections import Counter\n>>> from string import ascii_letters\n>>> def count_letters(s) :\n...     filtered = [c for c in s.lower() if c in ascii_letters]\n...     return Counter(filtered)\n... \n>>> count_letters('Math is fun! 2+2=4')\nCounter({'a': 1, 'f': 1, 'i': 1, 'h': 1, 'm': 1, 'n': 1, 's': 1, 'u': 1, 't': 1})\n>>> \n"], ["conda update --all\n"], [], [], ["def my_func(*args):\n", "fire_runner.py my_func one two\n"], [], ["temp['total'] = pd.DataFrame(project_data.groupby(col1)[col2].agg({'total':'count'})).reset_index()['total']\n", "temp['total'] = project_data.groupby(col1)[col2].agg(total=('total','count')).reset_index()['total']\n"], ["def make_matrix(board): #type(board) == chess.Board()\n    pgn = board.epd()\n    foo = []  #Final board\n    pieces = pgn.split(\" \", 1)[0]\n    rows = pieces.split(\"/\")\n    for row in rows:\n        foo2 = []  #This is the row I make\n        for thing in row:\n            if thing.isdigit():\n                for i in range(0, int(thing)):\n                    foo2.append('.')\n            else:\n                foo2.append(thing)\n        foo.append(foo2)\n    return foo\n", "[['r', 'n', 'b', 'q', 'k', 'b', 'n', 'r'], \n['p', 'p', 'p', 'p', 'p', 'p', 'p', 'p'], \n['.', '.', '.', '.', '.', '.', '.', '.'], \n['.', '.', '.', '.', '.', '.', '.', '.'], \n['.', '.', '.', '.', '.', '.', '.', '.'], \n['.', '.', '.', '.', '.', '.', '.', '.'], \n['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P'], \n['R', 'N', 'B', 'Q', 'K', 'B', 'N', 'R']]\n"], [], [], ["  \"\"\"D401: First line should be in imperative mood: 'Do', not 'Does'.\n\n   [Docstring] prescribes the function or method's effect as a command:\n    (\"Do this\", \"Return that\"), not as a description; e.g. don't write\n    \"Returns the pathname ...\".\n"], [], ["# connect to s3 - assuming your creds are all set up and you have boto3 installed\ns3 = boto3.resource('s3')\n\n# identify the bucket - you can use prefix if you know what your bucket name starts with\nfor bucket in s3.buckets.all():\n    print(bucket.name)\n\n# get the bucket\nbucket = s3.Bucket('my-s3-bucket')\n\n# use loop and count increment\ncount_obj = 0\nfor i in bucket.objects.all():\n    count_obj = count_obj + 1\nprint(count_obj)\n"], ["import time\nimport datetime\n\nWEEK  = 20 - 1 # as it starts with 0 and you want week to start from sunday\nstartdate = time.asctime(time.strptime('2019 %d 1' % WEEK, '%Y %W %w')) \nstartdate = datetime.datetime.strptime(startdate, '%a %b %d %H:%M:%S %Y') \ndates = [startdate.strftime('%Y-%m-%d')] \nfor i in range(1, 7): \n    day = startdate + datetime.timedelta(days=i)\n    dates.append(day.strftime('%Y-%m-%d'))\nprint(dates)\n"], [], [], ["import matplotlib.pyplot as plt\n\nx,y = polygon1.exterior.xy\nplt.plot(x,y)\n", "plt.plot(*polygon1.exterior.xy)\n"], [], [], [], [], ["FROM python:3.7-slim\n\nWORKDIR /app\n\n# both files are explicitly required!\nCOPY Pipfile Pipfile.lock ./\n\nRUN pip install pipenv && \\\n  apt-get update && \\\n  apt-get install -y --no-install-recommends gcc python3-dev libssl-dev && \\\n  pipenv install --deploy --system && \\\n  apt-get remove -y gcc python3-dev libssl-dev && \\\n  apt-get autoremove -y && \\\n  pip uninstall pipenv -y\n\nCOPY app ./\n\nCMD [\"python\", \"app.py\"]\n"], [], [], [], [], ["def yield_non_summer(series):\n  in_summer = False\n  def stateful_summer_predicate(v):\n    nonlocal in_summer\n    if in_summer and v == 9:\n      in_summer = False\n      return True  # 9 is still in summer\n    elif not in_summer and v == 6:\n      in_summer = True\n    return in_summer\n  return (v for v in series if not stateful_summer_predicate(v))\n\ndef summer_69(series):\n  return sum(yield_non_summer(series))\n", "def yield_non_summer(series):\n  in_summer = False\n  def stateful_summer_predicate(v):\n    nonlocal in_summer\n    in_summer = (in_summer or v == 6) and v != 9\n    return in_summer\n  return (v for v in series if not stateful_summer_predicate(v))\n\ndef summer_69(series):\n  return sum(yield_non_summer(series))\n"], ["def summer_69(lst):\n  \"\"\"Return the sum of the numbers in the array, \n     except ignore sections of numbers starting with a 6 and extending to the next 9 \n     (every 6 will be followed by at least one 9). Return 0 for no numbers\n  \"\"\"\n  if not lst:\n    return 0\n  else:\n    _sum = 0\n    active = True\n    for x in lst:\n      if active: \n        if x != 6:\n          _sum += x\n        else:\n          active = False\n      else:\n        if x == 9:\n          active = True\n    return _sum\n\nprint(summer_69([1, 3, 5]))\nprint(summer_69([4, 5, 6, 7, 8, 9]))\nprint(summer_69([2, 1, 6, 9, 11]))\n", "9\n9\n14\n"], ["def summer_69(series):\n  in_summer = False\n  cur_sum = 0\n  for v in series:\n    if in_summer:\n      if v == 9:\n        in_summer = False\n    else:\n      if v == 6:\n        in_summer = True\n      else:\n        cur_sum += v\n  return cur_sum\n"], ["FROM python:3.7-alpine\n\nWORKDIR /myapp\n\nCOPY Pipfile* ./\n\nRUN pip install --no-cache-dir pipenv && \\\n    pipenv install --system --deploy --clear\n\nCOPY src .\nCMD [\"python3\", \"app.py\"]\n"], ["python -m spacy download en_core_web_sm\n", "nlp = spacy.load(\"en_core_web_sm\")\n"], ["import os\nfrom azure.storage.blob import BlockBlobService\n\nroot_path = '<your root path>'\ndir_name = 'images'\npath = f\"{root_path}/{dir_name}\"\nfile_names = os.listdir(path)\n\naccount_name = '<your account name>'\naccount_key = '<your account key>'\ncontainer_name = '<your container name, such as `test` for me>'\n\nblock_blob_service = BlockBlobService(\n    account_name=account_name,\n    account_key=account_key\n)\n\nfor file_name in file_names:\n    blob_name = f\"{dir_name}/{file_name}\"\n    file_path = f\"{path}/{file_name}\"\n    block_blob_service.create_blob_from_path(container_name, blob_name, file_path)\n"], ["def defA() :\n    return \"yes\"\n\nflag = True\n\nvalue = [defA() if flag else 'No' for x in range(4)]  #If you need to use else\nvalue = [defA() for x in range(4) if flag]            #If there is no need for else\n"], [], [], ["acpt = driver.find_element_by_xpath(\"//*[contains(@class, 'aOOlW   HoLwm ')]\")\nacpt.click()\n"], ["\"python.dataScience.sendSelectionToInteractiveWindow\": false\n"], ["import string\ntext = input(\"Enter: \")\ncorrect = string.ascii_letters + string.digits\nstatus = True\nfor char in text:\n    if char not in correct:\n        status = False\nif status:\n    print('Correct')\nelse:\n    print('InCorrect')\n"], ["import re\npattern = re.compile(\"[A-Za-z0-9]+\")\npattern.fullmatch(string)\n", "import re\n\nif __name__ == '__main__':\n    string = \"YourString123\"\n    pattern = re.compile(\"[A-Za-z0-9]+\")\n\n    # if found match (entire string matches pattern)\n    if pattern.fullmatch(string) is not None:\n        print(\"Found match: \" + string)\n    else:\n        # if not found match\n        print(\"No match\")\n"], ["import string\ncorrect = {char for char in string.ascii_letters + string.digits}\ndef is_correct(text):\n    return {char for char in text}.issubset(correct)\nprint(is_correct('letters123')) # True\nprint(is_correct('???')) # False\nprint(is_correct('\\n')) # False\n"], ["abcDEF123 -> Success\nhello! -> Failure\n"], [" import re\n text = input(\"enter:\")\n regex = r\"([0-9a-zA-Z]+)\"\n\n match = re.match(regex, string)\n\n if match != None:\n    print(\"success\")\n"], [], ["brew install openssl\nLDFLAGS=-L/usr/local/opt/openssl/lib pip install mysqlclient\n"], ["sudo apt-get install python3.7-dev libmysqlclient-dev\n", "pipenv install\n"], ["fire_runner.py my_func [one,two]\n"], ["RUN chown dockuser:dockuser -R /app/\n"], ["alias python='/usr/bin/python3'\n"], [], ["def is_matched(expr):\n    expr = re.sub(\"[^][}{)(]+\", \"\", expr)\n    while expr:\n        expr1 = re.sub(r\"\\(\\)|\\[\\]|\\{\\}\", \"\", expr)\n        if expr1 == expr:\n            return not expr1\n        expr = expr1\n    return True\n\n>>> is_matched(\"{[()]}\")\nTrue\n>>> is_matched(\"{[(])}\")\nFalse\n>>> is_matched(\"{{[[(())]]}}\")\nTrue\n"], ["def balanced(s):\n    pairs = {\"{\": \"}\", \"(\": \")\", \"[\": \"]\"}\n    stack = []\n    for c in s:\n        if c in \"{[(\":\n            stack.append(c)\n        elif stack and c == pairs[stack[-1]]:\n            stack.pop()\n        else:\n            return False\n    return len(stack) == 0\n\n\ntest_cases = (\"{[()]}\", \"{[(])}\", \"{{[[(())]]}}\")\nfor s in test_cases:\n    print(s, balanced(s))\n", "{[()]} True\n{[(])} False\n{{[[(())]]}} True\n"], [">>> from functools import reduce\n>>> def f(s): return reduce(lambda acc, x: acc[:-1] if acc and acc[-1]+x in ('{}', '[]', '()') else acc+x, s)\n", ">>> f('{[()]}')\n'' # balanced\n>>> f('{[(])}')\n'{[(])}' # unbalanced\n", ">>> s = '{[()]}'\n>>> len(s) % 2\n0\n", ">>> t, u = s[:len(s)//2], s[len(s)//2:]\n>>> t, u\n('{[(', ')]}')\n>>> t, \"\".join(reversed(u))\n('{[(', '}])')\n>>> [o+c for o,c in zip(t, reversed(u))]\n['{}', '[]', '()']\n", ">>> [o+c for o,c in zip(t, reversed(u)) if o+c not in ('{}', '[]', '()')]\n[] # balanced\n"], ["def isBalanced(s):\n    opened = [0] # {}=3/-3, []=2/-2, ()=1/-1, others:0/-4\n    for n in [3-(\"{[( )]}\"+c).index(c) for c in s]:\n        if not n&3 : continue\n        elif n>0   : opened.append(n)\n        elif opened.pop() != -n: return False\n    return opened == [0]\n"], [], ["def is_matched(expression):\n    \"\"\"\n    Finds out how balanced an expression is.\n    With a string containing only brackets.\n\n    >>> is_matched('[]()()(((([])))')\n    False\n    >>> is_matched('[](){{{[]}}}')\n    True\n    \"\"\"\n    opening = tuple('({[')\n    closing = tuple(')}]')\n    mapping = dict(zip(opening, closing))\n    queue = []\n\n    for letter in expression:\n        if letter in opening:\n            queue.append(mapping[letter])\n        elif letter in closing:\n            if not queue or letter != queue.pop():\n                return False\n    return not queue\n\nif __name__ == '__main__':\n    import doctest\n    doctest.testmod()\n\n"], [], [], [], ["print(df['col1'].tail(1).item())\n", "3\n"], ["print (df['col1'].iloc[-1])\n3\nprint (df['col1'].iat[-1])\n3\n", "print (df['col1'].values[-1])\n3\n", "print (df.iloc[-1, df.columns.get_loc('col1')])\n3\nprint (df.iat[-1, df.columns.get_loc('col1')])\n3\n", "print (df.loc[df.index[-1], 'col1'])\n3\n"], ["import datetime\ntheday = datetime.date.today()\nweekday = theday.isoweekday()\n# The start of the week\nstart = theday - datetime.timedelta(days=weekday)\n# build a simple range\ndates = [start + datetime.timedelta(days=d) for d in range(7)]\n", "dates = [str(d) for d in dates]\n"], ["weekdates = []\nweek_number = datetime.datetime.now().isocalendar()[1]\nfor day in range(7):\n    week_date = datetime.datetime.strptime(\"2019-W{}\".format(week_number)+ '-{}'.format(day), \"%Y-W%W-%w\")\n    weekdates.append(week_date)\n"], ["import datetime\n\n# Starts with knowing the day of the week\nweek_day=datetime.datetime.now().isocalendar()[2]\n\n# Calculates Starting date (Sunday) for this case by subtracting current date with time delta of the day of the week\nstart_date=datetime.datetime.now() - datetime.timedelta(days=week_day)\n\n# Prints the list of dates in a current week\ndates=[str((start_date + datetime.timedelta(days=i)).date()) for i in range(7)]\ndates\n", ">>> dates\n['2019-05-12', '2019-05-13', '2019-05-14', '2019-05-15', '2019-05-16', '2019-05-17', '2019-05-18']\n"], ["WEEK  = 20 - 2 # as it starts with 0 and you want week to start from sunday\nstartdate = time.asctime(time.strptime('2019 %d 0' % WEEK, '%Y %W %w')) \nstartdate = datetime.datetime.strptime(startdate, '%a %b %d %H:%M:%S %Y') \ndates = [startdate.strftime('%Y-%m-%d')] \nfor i in range(1, 7): \n    day = startdate + datetime.timedelta(days=i)\n    dates.append(day.strftime('%Y-%m-%d')) \n", "dates = ['2019-05-12',\n         '2019-05-13',\n         '2019-05-14',\n         '2019-05-15',\n         '2019-05-16',\n         '2019-05-17',\n         '2019-05-18']\n"], [], ["epislon = 5 \n\ndef extract_nested_values(it):\n    if isinstance(it, list):\n        for sub_it in it:\n            yield from extract_nested_values(sub_it)\n    elif isinstance(it, dict):\n        for value in it.values():\n            yield from extract_nested_values(value)\n    else:\n        yield it\n\n\nd = {\"foo\": {\"bar\": 0.30000001}}\n#[0.30000001]\ne = {\"foo\": {\"bar\": 0.30000002}}\n#[0.30000002]\n\nd_value = list(extract_nested_values(d))\ne_value = list(extract_nested_values(e))\n\nif set(d.keys()) == set(e.keys()) and abs(e_value[0] - d_value[0]) < epislon:\n    print('Close Enough')\nelse:\n    print(\"not the same\")\n", "Close Enough\n"], [], ["numbers = [1, 3, 11,  12,  14,  15,  16, 3, 4, 6]\n\ndef getMaxConsecutiveInd(index):\n    if numbers[index] + 1 == numbers[index + 1]:\n        # call the functions if values are cosecutive to check next value\n        return getMaxConsecutiveInd(index + 1)\n    # return last index for cosecutive numbers\n    return index\n\n\nmax_length, start_index, end_index = 0,0,0\n\ni = 0\nwhile i < len(numbers) - 1:\n    con_index = getMaxConsecutiveInd(i)\n    # if available max_length is less than new_max_length(con_index - i)\n    # then change start_index and end_index  \n    if max_length < con_index - i:\n        max_length = con_index - i\n        start_index = i\n        end_index = con_index\n    # change value of i to latest con_index if i != con_index\n    if i == con_index:\n        i = i + 1\n    else:\n        i = con_index\n\nprint(start_index, end_index, max_length)\nOutput: (4,6,2)\n\nnumbers = [1, 2, 3, 4, 5, 6, 7, 11, 12, 14, 15, 16, 17, 18, 3, 4, 6]\nOutput: (0,6,6)\n\n\n"], ["numbers = [  1, 3, 11,  12,  14,  15,  16, 3, 4, 6]\n\ndef longest(numbers):\n    max, count_ = 1, 1\n    start_idx, end_idx = 0, 0\n    for i in range(len(numbers)-1):\n        # if difference between number and his follower is 1,they are in sequence\n        if numbers[i+1]-numbers[i] ==1:\n            count_ = count_+1\n        else:\n            if count_ > max :\n                max = count_\n                end_idx = i\n                start_idx = i+1 - max\n            # Reset counter\n            count_ = 1\n    return (start_idx,end_idx,max)\n\n\nprint (longest(numbers))\n", "(4, 6, 3) #start_idx, end_idx, len\n"], ["import numpy as np\nfrom itertools import groupby\nfrom operator import itemgetter\n\ndef get_longest_consecutive_numbers(numbers):\n    idx = max(\n        (\n            list(map(itemgetter(0), g)) \n            for i, g in groupby(enumerate(np.diff(numbers)==1), itemgetter(1)) \n            if i\n        ), \n        key=len\n    )\n    return (idx[0], idx[-1]+1)\n\nprint(get_longest_consecutive_numbers(numbers))\n#(4,6)\n"], ["def longest_weird(numbers):\n    delta = list(set(range(max(numbers))).symmetric_difference(numbers))\n    start,end = 0,0\n    maxi = 0\n    for i,x in enumerate(delta[:-1]):\n        aux = max(maxi,delta[i+1]-x)\n        if aux != maxi:\n            start,end = (x+1,delta[i+1]-1)\n            maxi = aux\n    return numbers.index(start),numbers.index(end)\n"], [], [], ["str.replace(old, new[, count])\n", "def manual_replace(s, char, index):\n    return s[:index] + char + s[index +1:]\n\nstring = '11234'\nprint(manual_replace(string, 'I', 0))\n"], [">>> import re\n>>> string = \"11234\"\n>>> re.sub('1', 'I', string, 1)\n'I1234'\n>>> \n", "re.sub('1', 'I', string, 1)\n"], ["string = \"11234\"\nstring.replace('1', 'I', 1)\n"], ["    screen.fill(GREEN) #first fill the screen with green\n    pygame.draw.rect(screen,(78,203,245),(0,0,250,500),5) #and after that draw the rectangle\n"], [], ["import pygame\nimport pygame.font\npygame.init()\n\n# Colours\nBLACK   = (  0,  0,  0)\nWHITE   = (255,255,255)\nGREEN   = (  0,255,  0)\nRED     = (255,  0,  0)\nBLUE    = (  0,  0,255)\n\n# Dimensions of screen\nsize = (400,500)\nWIDTH = 500\nHEIGHT = 400\nscreen = pygame.display.set_mode(size)\n\n# Loop Switch\ndone = False\n\n# Screen Update Speed (FPS)\nclock = pygame.time.Clock()\n\n# ------- Main Program Loop -------\nwhile not done:\n    # --- Main Event Loop ---\n    for event in pygame.event.get():\n        if event.type == pygame.QUIT:\n            done = True\n    screen.fill(GREEN)\n    pygame.draw.rect(screen,(78,203,245),(0,0,250,500),5)\n\n\n    pygame.display.flip()\n    pygame.display.update()\n\n    #Setting FPS\n    clock.tick(60)\n\n#Shutdown\npygame.quit()\n"], [], ["html = \"<p>\" + text.replace(\"\\n\", \"<br>\") + \"</p>\"\n"], ["for line in text:\n   for char in line:\n      if char == \"/n\":\n         text.replace(char, \"<br>\")\n"], ["my_string.replace('\\n', '<br>')\n"], [], ["pygame.draw.rect(screen,(78,203,245),(0,0,250,500),5)\nscreen.fill(GREEN)\n"], ["from tika import parser\n\nfilename = 'myfile.pdf'\n\n# Parse the PDF\nparsedPDF = parser.from_file(filename)\n\n# Extract the text content from the parsed PDF\npdf = parsedPDF[\"content\"]\n\n# Convert double newlines into single newlines\npdf = pdf.replace('\\n\\n', '\\n')\n\n#####################################\n# Do something with the PDF\n#####################################\nprint (pdf)\n"], ["content = content.replace(\"\\\\r\\\\n\", \"\")\n"], [], [], [], ["from collections import UserList\n\n\nclass JavaLike(UserList):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.iter = None\n\n    def stream(self):\n        self.iter = None\n\n        return self\n\n    def filter(self, function):\n        self.iter = filter(function, self if self.iter is None else self.iter)\n\n        return self\n\n    def map(self, function):\n        self.iter = map(function, self if self.iter is None else self.iter)\n\n        return self\n\n    def collect(self, collection_class=None):\n        if collection_class is None:\n            if self.iter is not None:\n                ret = JavaLike(self.iter)\n                self.iter = None\n\n                return ret\n\n            return JavaLike(self)\n\n        return collection_class(self if self.iter is None else self.iter)\n", ">>> JavaLike(range(10)).stream().filter(lambda x: x % 2 == 0).map(str).collect(tuple)\n('0', '2', '4', '6', '8')\n"], ["from selenium.webdriver.support import ui\nfrom selenium.webdriver.support import expected_conditions as EC\nfrom selenium.webdriver.common.by import By\n\n\nui.WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.CSS_SELECTOR, \".aOOlW.HoLwm\"))).click()\n"], [" cap = cv2.VideoCapture(0)\n"], ["cap.set(CV_CAP_PROP_FRAME_WIDTH, 640)\ncap.set(CV_CAP_PROP_FRAME_WIDTH, 480)\n"], ["# Use urllib to get the image and convert into a cv2 usable format\ncap = cv2.VideoCapture(0)\n\nwidth = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nhiegh = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n"], ["python -m pip install opencv-python\n", "> import cv2\n> sift = cv2.xfeatures2d.SIFT_create()\n"], [], ["from queue import PriorityQueue\n\nclass CompareError(ValueError): pass\n\nclass O:\n    def __init__(self,n):\n        self.n = n\n\n    def __lq__(self):\n        raise CompareError\n\n    def __repr__(self): return str(self)\n    def __str__(self): return self.n\n\ndef add(prioqueue,prio,item):\n    \"\"\"Adds the 'item' with 'prio' to the 'priorqueue' adding a unique value that\n    is stored as member of this method 'add.n' which is incremented on each usage.\"\"\"\n    prioqueue.put( (prio, add.n, item))\n    add.n += 1\n\n# no len() on PrioQueue - we ensure our unique integer via method-param\n# if you forget to declare this, you get an AttributeError\nadd.n = 0\n\nh = PriorityQueue()\n\nadd(h, 7, O('release product'))\nadd(h, 1, O('write spec 3'))\nadd(h, 1, O('write spec 2'))\nadd(h, 1, O('write spec 1'))\nadd(h, 3, O('create tests'))\n\nfor _ in range(4):\n    item = h.get()\n    print(item)\n", "TypeError: '<' not supported between instances of 'O' and 'int'`\n", "(1, 2, write spec 3)\n(1, 3, write spec 2)\n(1, 4, write spec 1)\n(3, 5, create tests)\n"], ["class PriorityElem:\n    def __init__(self, elem_to_wrap):\n        self.wrapped_elem = elem_to_wrap\n\n    def __lt__(self, other):\n        return self.wrapped_elem.priority < other.wrapped_elem.priority\n", "class PriorityElem:\n    def __init__(self, elem_to_wrap, priority):\n        self.wrapped_elem = elem_to_wrap\n        self.priority = other.priority\n\n    def __lt__(self, other):\n        return self.priority <  other.priority\n", "queue = PriorityQueue()\nqueue.put(PriorityElem(my_custom_class1, 10))\nqueue.put(PriorityElem(my_custom_class2, 10))\nqueue.put(PriorityElem(my_custom_class3, 30))\n\nfirst_returned_elem = queue.get()\n# first_returned_elem is PriorityElem(my_custom_class1, 10)\nsecond_returned_elem = queue.get()\n# second_returned_elem is PriorityElem(my_custom_class2, 10)\nthird_returned_elem = queue.get()\n# third_returned_elem is PriorityElem(my_custom_class3, 30)\n", "elem = queue.get().wrapped_elem\n"], ["from functools import total_ordering\n\n@total_ordering\nclass PrioritizedItem:\n    # ...\n\n    def __eq__(self, other):\n        return self.priority == other.priority\n\n    def __lt__(self, other):\n        return self.priority < other.priority\n"], ["from scipy.misc import face\nimport matplotlib.pyplot as plt\nimport torch\n\nnp_image = face()\nprint(type(np_image), np_image.shape)\ntensor_image = torch.from_numpy(np_image)\nprint(type(tensor_image), tensor_image.shape)\n# reshape to channel first:\ntensor_image = tensor_image.view(tensor_image.shape[2], tensor_image.shape[0], tensor_image.shape[1])\nprint(type(tensor_image), tensor_image.shape)\n\n# If you try to plot image with shape (C, H, W)\n# You will get TypeError:\n# plt.imshow(tensor_image)\n\n# So we need to reshape it to (H, W, C):\ntensor_image = tensor_image.view(tensor_image.shape[1], tensor_image.shape[2], tensor_image.shape[0])\nprint(type(tensor_image), tensor_image.shape)\n\nplt.imshow(tensor_image)\nplt.show()\n", "<class 'numpy.ndarray'> (768, 1024, 3)\n<class 'torch.Tensor'> torch.Size([768, 1024, 3])\n<class 'torch.Tensor'> torch.Size([3, 768, 1024])\n<class 'torch.Tensor'> torch.Size([768, 1024, 3])\n"], ["import torch\nt = torch.randn(3, 3)\nixs = torch.arange(3, dtype=torch.int64)\nzeroed = torch.where(ixs[None, :] == 1, torch.tensor(0.), t)\n\nzeroed\ntensor([[-0.6616,  0.0000,  0.7329],\n        [ 0.8961,  0.0000, -0.1978],\n        [ 0.0798,  0.0000, -1.2041]])\n\nt\ntensor([[-0.6616, -1.6422,  0.7329],\n        [ 0.8961, -0.9623, -0.1978],\n        [ 0.0798, -0.7733, -1.2041]])\n"], ["            inputs_reg = Variable(data, requires_grad=True)\n            output_reg = self.model.forward(inputs_reg)\n            num_classes = output.size()[1]\n\n            jacobian_list = []\n            grad_output = torch.zeros(*output_reg.size())\n\n            if inputs_reg.is_cuda:\n                grad_output = grad_output.cuda()\n\n            for i in range(5):\n                zero_gradients(inputs_reg)\n\n                grad_output_curr = grad_output.clone()\n                grad_output_curr[:, i] = 1\n                jacobian_list.append(torch.autograd.grad(outputs=output_reg,\n                                                         inputs=inputs_reg,\n                                                         grad_outputs=grad_output_curr,\n                                                         only_inputs=True,\n                                                         retain_graph=True,\n                                                         create_graph=True)[0])\n\n            jacobian = torch.stack(jacobian_list, dim=0)\n            loss3 = jacobian.norm()\n            loss3.backward()\n"], ["from selenium import webdriver\nfrom selenium.webdriver.chrome.options import Options\nfrom selenium.webdriver.support.ui import WebDriverWait\nfrom selenium.webdriver.support import expected_conditions as EC\nfrom selenium.webdriver.common.by import By\n\noptions = Options()\noptions.add_argument(\"start-maximized\")\noptions.add_argument(\"disable-infobars\")\noptions.add_argument(\"--disable-extensions\")\ndriver = webdriver.Chrome(chrome_options=options, executable_path=r'C:\\WebDrivers\\chromedriver.exe')\ndriver.get(\"https://www.instagram.com/accounts/login/?source=auth_switcher\")\ndriver.find_element_by_name('username').send_keys(\"Giacomo\")\ndriver.find_element_by_name('password').send_keys(\"Maraglino\")\ndriver.find_element_by_tag_name('form').submit()\nWebDriverWait(driver, 20).until(EC.element_to_be_clickable((By.XPATH, \"//button[contains(.,'Non ora')]\"))).click()\n"]]