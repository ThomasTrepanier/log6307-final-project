[["def solution(s): # 's' should be a binary input (011100)\n    while s[0] == \"0\":\n        s = s[1:]\n    ones = s.count('1')\n    zeros = s.count('0')\n    return ones*2+zeros-1\n"], [], ["docker pull selenium/standalone-chrome:95.0-chromedriver-95.0-20211102\ndocker run -d -p 4444:4444 --shm-size=\"2g\" selenium/standalone-chrome:95.0-chromedriver-95.0-20211102\n", "from selenium import webdriver\n\noptions = webdriver.ChromeOptions()\noptions.add_argument('--lang=en')\nprefs = {\n    \"translate_whitelists\": {\"es\": \"en\"},\n    \"translate\": {\"enabled\": \"true\"}\n}\noptions.add_experimental_option(\"prefs\", prefs)\n\ndriver = webdriver.Remote(command_executor='http://localhost:4444/wd/hub', options=options)\ndriver.get(\"https://www.amazon.es/\")\n"], ["seq = ['a', 'SEP', 'b', 'c', 'SEP', 'SEP', 'd']\n[seq[a + 1 : b]\n for (a, b) in itertools.pairwise(\n     [-1] + [i for i in range(len(seq)) if seq[i] == 'SEP'] + [len(seq)])]\n", "[['a'], ['b', 'c'], [], ['d']]\n"], ["cd ~/.pyenv/plugins/python-build && git pull\n"], [], ["  lft rel rgt  num\n0  t3  r3  z2    3\n1  t1  r3  x1    9\n2  x2  r3  t2    8\n3  x4  r1  t2    4\n4  t1  r1  z3    1\n5  x1  r1  t2    2\n6  x2  r2  t4    4\n7  z3  r2  t4    5\n8  t4  r3  x3    4\n9  z1  r2  t3    4\n  lft rel rgt  num new\n0  t3  r3  z2    3  T1\n1  t1  r3  x1    9  T1\n2  x2  r3  t2    8  X1\n3  x4  r1  t2    4  X1\n4  t1  r1  z3    1  T1\n5  x1  r1  t2    2  X1\n6  x2  r2  t4    4  X1\n7  z3  r2  t4    5  Z1\n8  t4  r3  x3    4  T1\n9  z1  r2  t3    4  Z1\n"], ["df1.drop_duplicates().groupby([\"Student\", \"Subject\"], sort=False).apply(lambda x \n: \nx if len(x) == 1 else x.dropna(subset= \n['Checked'])).drop_duplicates().reset_index(drop=True)\n"], [], [], ["str = 'testing'\n''.join([y.upper() if x%2 ==0 else y.lower() for x,y in enumerate(str)])\n"], [], ["with dag:\n\n    task_1 = DummyOperator(\n        task_id = 'real_operation_1'\n    )\n\n    task_2 = DummyOperator(\n        task_id = 'real_operation_2'\n    )\n\n    task_3 = DummyOperator(\n        task_id = 'dummy_operation'\n    )\n\n    task_4 = DummyOperator(\n        task_id = 'real_operation_3'\n    )\n\n    task_5 = DummyOperator(\n        task_id = 'real_operation_4'\n    )\n\n    [task_1, task_2] >> task_3 >> [task_4, task_5]\n"], [], [], [], ["from nltk.corpus import stopwords\nfrom nltk import PorterStemmer\nfrom nltk import LancasterStemmer\n\ndef performStemAndLemma(textcontent):\n    pattern =r'\\w+'\n    tokenizewords=nltk.regexp_tokenize(textcontent,pattern)\n    tokenizewords = [w.lower() for w in set(tokenizewords)]\n    stopper = stopwords.words(\"english\")\n    filteredwords = [w for w in tokenizewords if w not in stopper]\n    porter = nltk.PorterStemmer()\n    lancaster = nltk.LancasterStemmer()\n    porterstemmedwords = [porter.stem(w) for w in filteredwords]\n    lancasterstemmedwords = [lancaster.stem(w) for w in filteredwords]\n    wnl = nltk.WordNetLemmatizer()\n    lemmatizedwords = [wnl.lemmatize(word) for word in filteredwords]\n    return porterstemmedwords, lancasterstemmedwords, lemmatizedwords\n"], ["def remove_duplicate_dataframes(dfs: list) -> list:\n    if len(dfs) < 2:\n        return dfs\n\n    unique_dfs = []\n    for idx, df in enumerate(dfs):\n        if len(unique_dfs) == 0:\n            unique_dfs.append(df)\n            continue\n\n        dfs_copy = deepcopy(dfs)\n        dfs_copy.pop(idx)\n        if any([df_.equals(df) for df_ in dfs_copy]):\n            continue\n        else:\n            unique_dfs.append(df)\n\n    return unique_dfs\n"], ["from tensorflow.keras import optimizers\n", "optimisers.RMSprop(...)\n"], ["arr1 = np.arange(20000).reshape(-1,2)\narr2 = arr1.copy()\nnp.random.shuffle(arr2)\nprint(len(arr1)) #10000\n", "%%timeit\nres= np.array([x\n   for x in set(tuple(x) for x in arr1) & set(tuple(x) for x in arr2)\n])\n"], ["!pip install prophet\nfrom prophet import Prophet\n", "model = Prophet()\nmodel.fit(df)\n"], ["import re\nfrom parsec import *\n\nspaces = regex(r'\\s*', re.MULTILINE)\n\n@generate\ndef getHeader():\n  s1 = yield string (\"DateGroup\") \n  s2 = ''.join( (yield many1(digit())))\n  return (s1 + s2)\n\n@generate\ndef getDataLine():\n  s1 = yield digit()\n  s2 = ''.join((yield many1 (none_of (\"\\r\\n\"))))\n  yield spaces\n  return (s1 + s2)\n\n@generate\ndef getChunk():\n  yield spaces\n  header = yield getHeader\n  yield spaces\n  dataList = yield many1 (getDataLine)\n  return (header,dataList)\n\n@generate\ndef getData():\n  yield spaces\n  parsedData = yield many1(getChunk)\n  yield eof()\n  return parsedData\n\ninputText = \"\"\"DateGroup1\n20191129\n20191127\n20191126\nDateGroup2\n20191129\n20191127\n20191126\nDateGroup3\n2019-12-02\nDateGroup4\n2019-11-27\nDateGroup5\n2019-11-27\"\"\"\n\n\nresult = getData.parse(inputText)\nfor p in result:\n  print(p)\n", "('DateGroup1', ['20191129', '20191127', '20191126'])\n('DateGroup2', ['20191129', '20191127', '20191126'])\n('DateGroup3', ['2019-12-02'])\n('DateGroup4', ['2019-11-27'])\n('DateGroup5', ['2019-11-27'])\n"], [], ["tokenizedwords = [x.lower() for x in tokenizedword if x != '']\n\nstop_words = set(stopwords.words('english')) \nfilteredwords = [x for x in set(tokenizedwords) if x not in stop_words]\n\nps = PorterStemmer()\nls = LancasterStemmer()\nwnl = WordNetLemmatizer()\nporterstemmedwords =[ps.stem(x) for x in filteredwords]\nlancasterstemmedwords = [ls.stem(x) for x in filteredwords]\nlemmatizedwords = [wnl.lemmatize(x) for x in filteredwords]\n\nreturn porterstemmedwords, lancasterstemmedwords, lemmatizedwords\n"], ["def nametag(first_name, last_name):\nreturn '{} {:>2s}.'.format(first_name, last_name[0])\n"], ["import pandas as pd\n\nurl = 'https://github.com/lukes/ISO-3166-Countries-with-Regional-Codes/blob/master/all/all.csv?raw=true'\ndf = pd.read_csv(url,index_col=0)\nprint(df.head(5))\n"], ["mkvirtualenv projectname --python=python3.10\n"], ["location /api {\n    include proxy_params;\n    proxy_pass http://localhost:8000;\n}\n"], [], [], [" list(filter(lambda x: x['text']=='abc', listpost))\n"], ["import datetime\nfirst_date = datetime.datetime(1970, 1, 1)\ntime_since = datetime.datetime.now() - first_date\nseconds = int(time_since.total_seconds())\n"], [], [], [], ["python manage.py shell\nfrom django.contrib.auth.models import\nu=User.objects.get(username=\"user.name\")\nu\nu.set_password(\"mynewpasssword\")\nu.save\n"], [], [], [], ["from pathlib import Path\nfile = Path.cwd().parent / 'data' / 'sales.csv'\n", "from pathlib import Path\nfile = Path(__file__).parent.parent / 'data' / 'sales.csv'\n"], ["\"'\"+DataFram.Column.map(lambda x: \nx.strip()).to_string(index=False).replace('\\n',\"','\")+\"'\"\n"], ["from fastapi import FastAPI, Depends, Header\n\napp = FastAPI()\n\n@app.get('/')\ndef index(real_ip: str = Header(None, alias='X-Real-IP')):\nreturn real_ip\n", "HTTP/1.1 200 OK\ncontent-length: 17 \ncontent-type: application/json\nserver: uvicorn\n"], [], [], ["  lft rel rgt  num\n0  X1  r1  t2    6\n1  X1  r2  t4    4\n2  X1  r3  t2    8\n3  t1  r3  X1    9\n4  t4  r3  X1    4\n"], ["#reverse dict to dissolve the lists as values\nreversed_dict = {v:k for k,val in replacement_dict.items() for v in val}\n\n# replace the values\ncols = ['lft', 'rel', 'rgt']\ndf[cols] = df[cols].replace(reversed_dict)\n\n# filter rows where X1 is anywhere in the columns\ndf = df[df.eq('X1').any(axis=1)]\n\n# sum the duplicate rows\nout = df_filtered.groupby(cols).sum().reset_index()\nprint(out)\n"], [], ["keys = replacement_dict.keys()\n\n# Loop through every value in our dictionary and get the replacements\n\nfor key in keys:\n  DF = DF.replace(to_replace=replacement_dict[key], value=key)\n"], ["def groups_per_user(group_dictionary):\n    user_groups = {}\n    # Go through group_dictionary\n    for key,value in group_dictionary.items():\n        # Now go through the users in the group\n        for letter in value:\n            if letter in user_groups:\n                user_groups[letter] += [key]             \n            else :\n                user_groups[letter] = [key]\n            \n    return(user_groups)\n\nprint(groups_per_user({\"local\": [\"admin\", \"userA\"],\n    \"public\":  [\"admin\", \"userB\"],\n    \"administrator\": [\"admin\"] }))\n"], ["int_array = np.frompyfunc(int, 2, 1) #Can be used, for example, to add broadcasting to a built-in Python function \nint_array(hexArray,16).astype(np.uint32)\n"], ["x += 3\nlst.append(x)\n", "lst = [3*x for x in range(1, 100)]\n"], ["x = 0 \n\nlst = []\n\nfor i in range (1,100):\n    y = x+i*3\n    lst.append(y) \nprint(list)\n"], [], ["largest_smallest = -1\nfor i in arr: \n  if i < x: \n     if i > largest_smallest: \n        largest_smallest = i \n        \n     \n"], ["def checkargs(func):\n    def inner(*args, **kwargs):\n        if 'y' in kwargs:\n            print('y passed with its keyword!')\n        else:\n            print('y passed positionally.')\n        result = func(*args, **kwargs)\n        return result\n    return inner\n\n>>>  @checkargs\n...: def foo(x, y):\n...:     return x + y\n\n>>> foo(2, 3)\ny passed positionally.\n5\n\n>>> foo(2, y=3)\ny passed with its keyword!\n5\n", "def checkargs(param_to_check):\n    def inner(func):\n        def wrapper(*args, **kwargs):\n            if param_to_check in kwargs:\n                print('y passed with its keyword!')\n            else:\n                print('y passed positionally.')\n            result = func(*args, **kwargs)\n            return result\n        return wrapper\n    return inner\n\n>>>  @checkargs(param_to_check='y')\n...: def foo(x, y):\n...:     return x + y\n\n>>> foo(2, y=3)\ny passed with its keyword!\n5\n", "from functools import wraps\nfrom inspect import signature\n\ndef checkargs(func):\n    @wraps(func)\n    def inner(*args, **kwargs):\n        for param in signature(func).parameters:\n            if param in kwargs:\n                print(param, 'passed with its keyword!')\n            else:\n                print(param, 'passed positionally.')\n        result = func(*args, **kwargs)\n        return result\n    return inner\n\n>>>  @checkargs\n...: def foo(x, y, z) -> int:\n...:     return x + y\n\n>>> foo(2, 3, z=4)\nx passed positionally.\ny passed positionally.\nz passed with its keyword!\n9\n\n>>> inspect.getfullargspec(foo)\nFullArgSpec(args=[], varargs='args', varkw='kwargs', defaults=None, \nkwonlyargs=[], kwonlydefaults=None, annotations={'return': <class 'int'>})\n                                             _____________HERE____________\n", "from functools import wraps\nfrom inspect import signature\nfrom typing import Callable, ParamSpec, TypeVar, TYPE_CHECKING\n\nT = TypeVar(\"T\")\nP = ParamSpec(\"P\")\n\n\ndef check_args(func: Callable[P, T]) -> Callable[P, T]:\n    \"\"\"\n    Decorator to monitor whether an argument is passed\n    positionally or with its keyword, during function call.\n    \"\"\"\n\n    @wraps(func)\n    def inner(*args: P.args, **kwargs: P.kwargs) -> T:\n        for param in signature(func).parameters:\n            if param in kwargs:\n                print(param, 'passed with its keyword!')\n            else:\n                print(param, 'passed positionally.')\n        return func(*args, **kwargs)\n\n    return inner\n"], [], [], [], [], ["import torch\nimport torch.nn.functional as F\n\nclass Conv2dSame(torch.nn.Conv2d):\n\n    def calc_same_pad(self, i: int, k: int, s: int, d: int) -> int:\n        return max((math.ceil(i / s) - 1) * s + (k - 1) * d + 1 - i, 0)\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        ih, iw = x.size()[-2:]\n\n        pad_h = self.calc_same_pad(i=ih, k=self.kernel_size[0], s=self.stride[0], d=self.dilation[0])\n        pad_w = self.calc_same_pad(i=iw, k=self.kernel_size[1], s=self.stride[1], d=self.dilation[1])\n\n        if pad_h > 0 or pad_w > 0:\n            x = F.pad(\n                x, [pad_w // 2, pad_w - pad_w // 2, pad_h // 2, pad_h - pad_h // 2]\n            )\n        return F.conv2d(\n            x,\n            self.weight,\n            self.bias,\n            self.stride,\n            self.padding,\n            self.dilation,\n            self.groups,\n        )\n\nconv_layer_s2_same = Conv2dSame(in_channels=3, out_channels=64, kernel_size=(7, 7), stride=(2, 2), groups=1, bias=True)\nout = conv_layer_s2_same(torch.zeros(1, 3, 224, 224)) \n"], ["from itertools import cycle, islice\n\ndef intersection(inputs):\n    \"Yield the intersection of elements from multiple sorted inputs.\"\n    # intersection(['ABBCD', 'BBDE', 'BBBDDE']) --> B B D\n    n = len(inputs)\n    iters = cycle(map(iter, inputs))\n    try:\n        candidate = next(next(iters))\n        while True:\n            for it in islice(iters, n-1):\n                while (value := next(it)) < candidate:\n                    pass\n                if value != candidate:\n                    candidate = value\n                    break\n            else:\n                yield candidate\n                candidate = next(next(iters))\n    except StopIteration:\n        return\n", ">>> data = [[1,3,5,7], [1,1,3,5,7], [1,4,7,9]]\n>>> list(intersection(data))\n[1, 7]\n\n>>> data = [[1,1,2,3], [1,1,4,4]]\n>>> list(intersection(data))\n[1, 1]\n", "def intersection(inputs):\n    \"Yield the intersection of elements from multiple sorted inputs.\"\n    # intersection(['ABBCD', 'BBDE', 'BBBDDE']) --> B B D\n    n = len(inputs)\n    iters = list(map(iter, inputs))\n    curr_iter = 0\n    try:\n        it = iters[curr_iter]\n        curr_iter = (curr_iter + 1) % n\n        candidate = next(it)\n        while True:\n            for i in range(n - 1):\n                it = iters[curr_iter]\n                curr_iter = (curr_iter + 1) % n\n                while (value := next(it)) < candidate:\n                    pass\n                if value != candidate:\n                    candidate = value\n                    break\n            else:\n                yield candidate\n                it = iters[curr_iter]\n                curr_iter = (curr_iter + 1) % n\n                candidate = next(it)\n    except StopIteration:\n        return\n"], [], ["gethostbyname(gethostname()+'.')\n"], ["Flask==2.1.2\nflask-restx==0.5.1\nWerkzeug==2.1.2\n"], [" python3 -m alembic.config upgrade head\n"], ["class YourModel(Model):\n    your_field = JSONField(default=list, null=False, blank=True)\n"], ["[tool.black]\nextend-exclude = '''\n/(\n  | migrations\n)/\n'''\n"], ["FROM python:3.9 as builder\nRUN pip install --target /tmp/site-packages \"git+GIT_URL\"\n\nFROM public.ecr.aws/lambda/python:3.9\nCOPY --from=builder /tmp/site-packages /var/lang/lib/python3.9/site-packages\n"], [], ["pip install movecolumn\n", "import movecolumn as mc\nmc.MoveToLast(df,'date')\n"], ["class Solution:\n    def searchInsert(self, nums: List[int], target: int) -> int:\n        \"\"\"\n        :type nums: List[int]\n        :type target: int\n        :rtype: int\n        \"\"\"\n\n        if target not in nums:\n            nums.append(target)\n            nums.sort()\n        return nums.index(target)\n"], ["result = %sql SELECT COMMUNITY_AREA_NUMBER, \\\n    COUNT(*) AS COUNTING_CRIMES FROM CRIME_DATA \\\n    GROUP BY COMMUNITY_AREA_NUMBER ORDER BY COUNTING_CRIMES DESC LIMIT 1\nresult = result[0][0]\n\ncomunity_area_name = %sql SELECT COMMUNITY_AREA_NAME \\\n    FROM CENSUS_DATA WHERE COMMUNITY_AREA_NUMBER =:result\ncomunity_area_name\nOUTPUT: Austin\n"], [], ["from matplotlib import pyplot as plt\nimport pandas as pd\nfrom sklearn.datasets import load_wine as load_data\nfrom psynlig import plot_correlation_heatmap\nplt.style.use('seaborn-talk')\n\ndata_set = load_data()\ndata = pd.DataFrame(data_set['data'], columns=data_set['feature_names'])\n#data = df_corr_selected\n\nkwargs = {\n    'heatmap': {\n        'vmin': -1,\n        'vmax': 1,\n        'cmap': 'viridis',\n    },\n    'figure': {\n        'figsize': (14, 10),\n    },\n}\n\nplot_correlation_heatmap(data, bubble=True, annotate=False, **kwargs)\nplt.show()\n"], ["def end_zeros(a: int) -> int:  \n    count = 0 \n    list = [int(x) for x in str(a)]\n    list.reverse()\n    list.append(1)\n    for x in list:\n        if x == 0:\n            count += 1            \n        else:\n            return count\n"], [], ["from setuptools import setup\n\nsetup(name=\"pandasmodule\",\n        version=\"0.1\",\n        packages=[],\n        install_requires=['pandas==0.25.1']\n    )\n\n# use pandas\nimport numpy as np\nimport pandas as pd\n\ns = pd.Series([1, 3, 5, np.nan, 6, 8])\n\nprint(s)\n"], ["FROM ubuntu:20.04\nRUN set -ex && \\\n    apt install -y \\\n        software-properties-common && \\\n    add-apt-repository -y ppa:deadsnakes/ppa && \\\n    apt install -y \\\n        python3.9 \\\n        python3.9-distutils \\\n        python3.9-venv && \\\n    python3.9 --version && \\\n    python3.9 -m ensurepip && \\\n    pip3.9 --version\nENTRYPOINT []\n"], ["import numpy as np\n\ndf1['to_drop'] = np.where(\n    (df1['Student'].isin(df1[df1[['Student','Subject']].duplicated()]['Student'].tolist())\n     ) & (df1['Checked'].isnull()),1,0)\n\ndf1.loc[df1.to_drop==0].drop('to_drop',axis=1)\n", "   Student Subject Checked\n0        A     Law     Bob\n1        A     Law   James\n3        B   Maths    Jack\n4        C   Maths   Laura\n5        D     Law   Laura\n6        E   Maths     NaN\n8        F   Music     Tim\n9        G   Music     Tim\n10       H     Art     Tim\n"], ["# is the group containing more than one row?\nm1 = df1.duplicated(['Student', 'Subject'], keep=False)\n# is the row a NaN in \"Checked\"?\nm2 = df1['Checked'].isna()\n# both conditions True\nm = m1&m2\n\n# keep if either condition is False \ndf1[~m]\n\n# to get dropped duplicates\n# keep if both are True\ndf1[m]\n", "   Student Subject Checked\n0        A     Law     Bob\n1        A     Law   James\n3        B   Maths    Jack\n4        C   Maths   Laura\n5        D     Law   Laura\n6        E   Maths     NaN\n8        F   Music     Tim\n9        G   Music     Tim\n10       H     Art     Tim\n"], ["s_idx = ~(df1[(df1.duplicated(subset=['Student','Subject'],keep=False))])['Checked'].isna()\n\nidx = [x for x in df1.index.values if x not in s_idx[~s_idx].index]\n\ndf1.iloc[idx]\n", "   Student Subject Checked\n0        A     Law     Bob\n1        A     Law   James\n3        B   Maths    Jack\n4        C   Maths   Laura\n5        D     Law   Laura\n6        E   Maths     NaN\n8        F   Music     Tim\n9        G   Music     Tim\n10       H     Art     Tim\n"], ["df.groupby(\"Student\", sort=False).apply(lambda x : x if len(x) == 1 else x.dropna(subset=['Checked'])).reset_index(drop=True)\n", "  Student Subject Checked\n0       A     Law     Bob\n1       A     Law   James\n2       B   Maths    Jack\n3       C   Maths   Laura\n4       D     Law   Laura\n5       E   Maths     NaN\n6       F   Music     Tim\n7       G   Music     Tim\n8       H     Art     Tim\n"], [], ["# workaround to suppress color logging in werkzeug\ntry:\n    import click\n    old_color = click.style\n\n    def _color(text, fg=None, bg=None, bold=None, dim=None, underline=None, blink=None, reverse=None, reset=True):\n        return click.unstyle(text)\n\n    click.style = _color\nexcept:\n    pass\n"], ["conda activate my_env\nconda update --all\n", "conda install -c anaconda zeromq\n"], [], ["import os.path\nimport base64\nimport json\nimport re\nimport time\nfrom google.auth.transport.requests import Request\nfrom google.oauth2.credentials import Credentials\nfrom google_auth_oauthlib.flow import InstalledAppFlow\nfrom googleapiclient.discovery import build\nimport logging\nimport requests\n\nSCOPES = ['https://www.googleapis.com/auth/gmail.readonly','https://www.googleapis.com/auth/gmail.modify']\n\ndef readEmails():\n    \"\"\"Shows basic usage of the Gmail API.\n    Lists the user's Gmail labels.\n    \"\"\"\n    creds = None\n    # The file token.json stores the user's access and refresh tokens, and is\n    # created automatically when the authorization flow completes for the first\n    # time.\n    if os.path.exists('token.json'):\n        creds = Credentials.from_authorized_user_file('token.json', SCOPES)\n    # If there are no (valid) credentials available, let the user log in.\n    if not creds or not creds.valid:\n        if creds and creds.expired and creds.refresh_token:\n            creds.refresh(Request())\n        else:\n            flow = InstalledAppFlow.from_client_secrets_file(               \n                # your creds file here. Please create json file as here https://cloud.google.com/docs/authentication/getting-started\n                'my_cred_file.json', SCOPES)\n            creds = flow.run_local_server(port=0)\n        # Save the credentials for the next run\n        with open('token.json', 'w') as token:\n            token.write(creds.to_json())\n    try:\n        # Call the Gmail API\n        service = build('gmail', 'v1', credentials=creds)\n        results = service.users().messages().list(userId='me', labelIds=['INBOX'], q=\"is:unread\").execute()\n        messages = results.get('messages',[]);\n        if not messages:\n            print('No new messages.')\n        else:\n            message_count = 0\n            for message in messages:\n                msg = service.users().messages().get(userId='me', id=message['id']).execute()                \n                email_data = msg['payload']['headers']\n                for values in email_data:\n                    name = values['name']\n                    if name == 'From':\n                        from_name= values['value']                \n                        for part in msg['payload']['parts']:\n                            try:\n                                data = part['body'][\"data\"]\n                                byte_code = base64.urlsafe_b64decode(data)\n\n                                text = byte_code.decode(\"utf-8\")\n                                print (\"This is the message: \"+ str(text))\n\n                                # mark the message as read (optional)\n                                msg  = service.users().messages().modify(userId='me', id=message['id'], body={'removeLabelIds': ['UNREAD']}).execute()                                                       \n                            except BaseException as error:\n                                pass                            \n    except Exception as error:\n        print(f'An error occurred: {error}')\n"], ["10 ** length(big_int_str_var)\n", "echo 23958699683561808518065081866850688652086158016508618152865101851111111111111 | \ntee >( gpaste | gcat -n >&2; ) | gcat - |\n \npython3 -c '\\\nimport sys; [ print(\"1\"+\"0\"*len(_.strip(\"\\n\"))) for _ in sys.stdin ]' \n  \n  or   '... [ print(  10 ** len(_.strip(\"\\n\"))) for _ in sys.stdin ]' \n", "1 23958699683561808518065081866850688652086158016508618152865101851111111111111\n\n1 100000000000000000000000000000000000000000000000000000000000000000000000000000\n"], ["STATICFILES_STORAGE = 'whitenoise.storage.CompressedManifestStaticFilesStorage'\n", "STATICFILES_STORAGE = 'django.contrib.staticfiles.storage.StaticFilesStorage'\n"], ["source env/bin/activate\npython manage.py runserver\n"], ["sed -i -e 's/=python /=python3 /g' ~/Library/Arduino15/packages/esp32/hardware/esp32/*/platform.txt\n"], ["pd.Categorical(['A', 'B', 'C', 'A', 'C']).codes\n", "array([0, 1, 2, 0, 2], dtype=int8)\n"], [], [], ["df['Size_Numerical'] = pd.factorize(df['Size'])[0] + 1\n", "     Size  Size_Numerical\n0     Big               1\n1  Medium               2\n2   Small               3\n"], ["from sklearn import preprocessing\nle = preprocessing.LabelEncoder()\nle.fit(df['Sizes'])\ndf['Category'] = le.transform(df['Sizes']) + 1\n", "    Sizes  Category\n0   Small         3\n1  Medium         2\n2   Large         1\n"], ["   a  b\n0  1  3\n1  2  4\n   a  b\n"], [], ["# rename df columns by position (as opposed to index)\n# mapper is a dict where keys = ordinal column position and vals = new titles\n# unclear that using the native df rename() function produces the correct results when renaming by position\ndef rename_df_cols_by_position(df, mapper):\n    new_cols = [df.columns[i] if i not in mapper.keys() else mapper[i] for i in range(0, len(df.columns))]\n    df.columns = new_cols\n    return\n"], ["element = WebDriverWait(driver, 20).until(EC.element_to_be_clickable((By.CSS_SELECTOR, \"div[data-testid='pluggable-input-body'][role='textbox']\")))\n", "element = WebDriverWait(driver, 20).until(EC.element_to_be_clickable((By.XPATH, \"//div[@data-testid='pluggable-input-body' and @role='textbox']\")))\n", "from selenium.webdriver.support.ui import WebDriverWait\nfrom selenium.webdriver.common.by import By\nfrom selenium.webdriver.support import expected_conditions as EC\n"], ["element = WebDriverWait(driver, 20).until(EC.presence_of_element_located((By.CSS_SELECTOR, '._13NKt.copyable-text.selectable-text')))\n", "from selenium.webdriver.support.ui import WebDriverWait\nfrom selenium.webdriver.support import expected_conditions as EC\n"], [], ["driver.find_element(By.CLASS_NAME, \"_13NKt.copyable-text.selectable-text\")\n", "driver.find_element(By.CSS_SELECTOR, \"._13NKt.copyable-text.selectable-text\")\n"], ["element = driver.find_element(By.CSS_SELECTOR, \"._13NKt.copyable-text.selectable-text\")\n", "element = driver.find_element(By.CSS_SELECTOR, \"[data-testid='pluggable-input-body']\")\n"], ["import tensorflow\nfrom tensorflow.keras import optimizers\noptimizer = tensorflow.keras.optimizers.RMSprop(lr=0.0003,decay=1e-6)\n"], ["edge_path=\"C:\\Windows\\SystemApps\\Microsoft.MicrosoftEdge_8wekyb3d8bbwe\\MicrosoftEdge.exe\n", "edge_path=\"C:\\Windows\\SystemApps\\Microsoft.MicrosoftEdge_8wekyb3d8bbwe\\msedge.exe\n"], ["driver.execute_script(\"window.scrollTo(0, 300);\")\n"], ["def tree_to_tuple(node):\n\nif node is None:\n    return None \nif node.left is None and node.right is None:\n    return node.key\n\n\ntreeTuple = tree_to_tuple(node.left),node.key,tree_to_tuple(node.right)\n\nreturn treeTuple\n"], ["pip install Werkzeug==2.0.0\n"], ["def tree_to_tuple(node):\n    if isinstance(node, TreeNode):\n        if node.left is None and node.right is None:\n            return node.key;\n    else: return node;\n    return (tree_to_tuple(node.left), node.key, tree_to_tuple(node.right));\n"], [], ["from selenium.webdriver.chrome.options import Options\n\nchrome_options = Options()\nchrome_options.add_experimental_option(\"detach\", True)\n\ndriver = webdriver.Chrome(options=chrome_options)\n"], [], ["measure   uid location   unit  price  vol\n0        U100       US  unit1     10  100\n1        U100       US  unit2     10  200\n2        U100       US  unit3      0    0\n3        U200       US  unit1     20  150\n4        U200       US  unit2     25  200\n5        U200       US  unit3      0    0\n6        E100       EU  unit1     15  100\n7        E100       EU  unit2     30  150\n8        E100       EU  unit3      0    0\n9        E200       EU  unit1     10  200\n10       E200       EU  unit2     20  300\n11       E200       EU  unit3     20  500\n12       E300       EU  unit1     10  150\n13       E300       EU  unit2     10  300\n14       E300       EU  unit3     20  500\n15       A100     Asia  unit1     10  150\n16       A100     Asia  unit2     10  200\n17       A100     Asia  unit3     20  500\n18       A200     Asia  unit1     20  100\n19       A200     Asia  unit2     10  150\n20       A200     Asia  unit3     20  500\n21       A300     Asia  unit1     20  200\n22       A300     Asia  unit2     10  225\n23       A300     Asia  unit3     20  500\n24       A400     Asia  unit1     25  200\n25       A400     Asia  unit2     20  225\n26       A400     Asia  unit3     20  500\n27       A500     Asia  unit1     25  200\n28       A500     Asia  unit2     20  250\n29       A500     Asia  unit3     20  500\n"], [], [], ["python3 -m  pip install pystan\npython3 -m  pip install prophet\n", "pip install pystan\npip install prophet\n"], [], [], ["df_price = df.set_index(['uid','location']).filter(\n    regex='price$').stack().rename_axis(\n    ['uid', 'location', 'price_unit']).rename('price').reset_index()\n\ndf_vol = df.filter(regex='vol$').stack().rename_axis(\n    ['', 'vol_unit']).rename('volume').reset_index(level=1).reset_index(drop=True)\n\ndf2 = pd.concat([df_price, df_vol], axis=1)\ndf2['unit'] = df2['price_unit'].apply(lambda x:x.split('_')[0])\ndf2.drop(['price_unit', 'vol_unit'],axis=1, inplace=True)\n", "     uid location  price  volume   unit\n0   U100       US     10     100  unit1\n1   U100       US     10     200  unit2\n2   U100       US      0       0  unit3\n3   U200       US     20     150  unit1\n4   U200       US     25     200  unit2\n5   U200       US      0       0  unit3\n6   E100       EU     15     100  unit1\n7   E100       EU     30     150  unit2\n8   E100       EU      0       0  unit3\n9   E200       EU     10     200  unit1\n10  E200       EU     20     300  unit2\n11  E200       EU     20     500  unit3\n12  E300       EU     10     150  unit1\n13  E300       EU     10     300  unit2\n14  E300       EU     20     500  unit3\n15  A100     Asia     10     150  unit1\n16  A100     Asia     10     200  unit2\n17  A100     Asia     20     500  unit3\n18  A200     Asia     20     100  unit1\n19  A200     Asia     10     150  unit2\n20  A200     Asia     20     500  unit3\n21  A300     Asia     20     200  unit1\n22  A300     Asia     10     225  unit2\n23  A300     Asia     20     500  unit3\n24  A400     Asia     25     200  unit1\n25  A400     Asia     20     225  unit2\n26  A400     Asia     20     500  unit3\n27  A500     Asia     25     200  unit1\n28  A500     Asia     20     250  unit2\n29  A500     Asia     20     500  unit3\n"], ["df1 = df.melt(id_vars=['uid', 'location'], value_vars=['unit1_price', 'unit2_price', 'unit3_price'],var_name='unit',value_name='price')\n\ndf2 = df.melt(id_vars=['uid', 'location'], value_vars=['unit1_vol', 'unit2_vol', 'unit3_vol'],var_name='unit', value_name=\"volume\")\n\nddf = pd.concat([df1,df2['volume']],axis=1).sort_values(by=['uid','unit'],ignore_index=True)\n\nddf['unit']=ddf['unit'].str.split('_',expand=True)[0]\n"], ["import pandas as pd\ndf = pd.DataFrame(\n    {\n        'uid': ['U100', 'U200', 'E100', 'E200', 'E300', 'A100', 'A200', 'A300', 'A400', 'A500'],\n        'location': ['US', 'US', 'EU', 'EU', 'EU', 'Asia', 'Asia', 'Asia', 'Asia', 'Asia'],\n        'unit1_price': [10, 20, 15, 10, 10, 10, 20, 20, 25, 25],\n        'unit1_vol': [100, 150, 100, 200, 150, 150, 100, 200, 200, 200],\n        'unit2_price': [10, 25, 30, 20, 10, 10, 10, 10, 20, 20],\n        'unit2_vol': [200, 200, 150, 300, 300, 200, 150, 225, 225, 250],\n        'unit3_price': [0, 0, 0, 20, 20, 20, 20, 20, 20, 20],\n        'unit3_vol': [0, 0, 0, 500, 500, 500, 500, 500, 500, 500]\n    }\n)\n\nprice = pd.melt(\n    df, id_vars=['uid', 'location', 'unit2_vol', 'unit1_vol', 'unit3_vol'], value_vars=['unit1_price', 'unit3_price', 'unit2_price'], var_name=\"price\", value_name=\"price_value\"\n)\n\nres = pd.melt(\n    price, id_vars=['uid', 'location', 'price', 'price_value'], value_vars=['unit2_vol', 'unit1_vol', 'unit3_vol'], var_name=\"vol\", value_name=\"vol_value\"\n)\nprint(res)\n", "     uid location        price  price_value        vol  vol_value\n0   U100       US  unit1_price           10  unit2_vol        200\n1   U200       US  unit1_price           20  unit2_vol        200\n2   E100       EU  unit1_price           15  unit2_vol        150\n3   E200       EU  unit1_price           10  unit2_vol        300\n4   E300       EU  unit1_price           10  unit2_vol        300\n..   ...      ...          ...          ...        ...        ...\n85  A100     Asia  unit2_price           10  unit3_vol        500\n86  A200     Asia  unit2_price           10  unit3_vol        500\n87  A300     Asia  unit2_price           10  unit3_vol        500\n88  A400     Asia  unit2_price           20  unit3_vol        500\n89  A500     Asia  unit2_price           20  unit3_vol        500\n"], ["s = df.melt(['uid','location'])\ns[['unit','type']] = \n\ns['variable'].str.split('_',expand=True)\ns = s.pivot(index = ['uid','location','unit'],columns = ['type'],values = 'value').reset_index()\ns\nOut[967]: \ntype   uid location   unit  price  vol\n0     A100     Asia  unit1     10  150\n1     A100     Asia  unit2     10  200\n2     A100     Asia  unit3     20  500\n3     A200     Asia  unit1     20  100\n4     A200     Asia  unit2     10  150\n"], [], ["import threading as th\nimport time\n\nclass CTask(object):\n\n    once  = 1\n    loop  = 8\n\n    def __init__(self, foo, args, kwargs, type):\n        self.__kwargs = kwargs\n        self.__args = args\n        self.__foo = foo\n        self.__ret = None\n\n        self.task_type = type\n        self.terminated = False\n\n    def pool_call(self):\n        self.__ret = self.__foo(\n            *self.__args,\n            **self.__kwargs\n        )\n        if self.task_type == self.once:\n            self.terminated = True\n\n    def __call__(self):\n        return self.__ret\n\n    def terminate(self):\n        self.terminated = True\n\nclass Worker_Pool:\n\n    def push_task(self, type=CTask.once):\n        def func_wraper(func):\n            def varg_wraper(*a, **b):\n                ntask = CTask(func, a, b, type)\n                self.__lock.acquire(True, -1)\n                self.__ref.append(ntask)\n                self.__lock.release()\n                return ntask\n            return varg_wraper\n        return func_wraper\n\n    def __init__(self, n_work):\n        self.__lock = th.Lock()\n        self.__pool = []\n        self.__ref = []\n        self.alive = True\n\n        for _ in range(n_work):\n            self.__pool.append(\n                th.Thread(target=self.__run)\n            )\n        for w in self.__pool:\n            w.start()\n\n    def __run(self):\n        while self.alive:\n            wtask = None\n            if self.__lock.acquire(True, 0.1):\n                if len(self.__ref) > 0:\n                    wtask = self.__ref.pop(0)\n                self.__lock.release()\n\n            if wtask is None or wtask.terminated:\n                continue\n\n            wtask.pool_call()\n\n            if wtask.task_type == CTask.loop:\n                self.__lock.acquire(True, -1)\n                self.__ref.append(wtask)\n                self.__lock.release()\n\n    def terminate(self):\n        self.alive = False\n        for w in self.__pool:\n            w.join()\n\nbg = Worker_Pool(3)\n\nclass Some_App:\n\n    @bg.push_task(CTask.loop)\n    def do_task(self):\n        print(f'[{self.id}] -> {self.num}')\n        time.sleep(0.5)\n\n    @bg.push_task()\n    def do_mult(self):\n        self.num *= self.mul\n\n    def __init__(self, id, imul):\n        self.mul = imul\n        self.num = 1\n        self.id = id\n\n        self.bg_task = self.do_task()\n\n    def __del__(self):\n        # you should make sure that the the \n        # function is no longer in execution\n        # before continuing this function\n        self.bg_task.terminate()\n\nif __name__ == '__main__':\n    inst_a = Some_App(1, 2)\n    task_a = inst_a.do_task()\n    inst_b = Some_App(5, 6)\n    task_b = inst_b.do_task()\n\n    print('')\n    inst_a.do_mult()\n    inst_b.do_mult()\n    time.sleep(0.6)\n\n    print('')\n    inst_a.do_mult()\n    inst_b.do_mult()\n    time.sleep(1.2)\n\n    bg.terminate()\n"], [], [], [], [], [], [], [], [], [], [], [], ["RUN apt-get update && apt-get install -y git\n"], ["import PyPDF2\n\nreader = PyPDF2.PdfReader(\"mypdf.pdf\")\nfor page in reader.pages:\n    print(page.extract_text())\n"], [], [], [], ["location /api/ {\n    proxy_pass http://backend:8000/;\n    proxy_set_header   Host             $host;\n    proxy_set_header   X-Real-IP        $remote_addr;\n    proxy_set_header   X-Forwarded-For  $proxy_add_x_forwarded_for;\n}\n"], ["uvicorn launch1:app --port 5010 --host 0.0.0.0 --root-path /site1\n", "    ProxyPreserveHost On\n\n    ProxyPass /site1/ http://127.0.0.1:5010/\n    ProxyPassReverse /site1/ http://127.0.0.1:5010/\n", "a2enmod proxy_http\nsystemctl restart apache2\n"], [], ["# class for creating binary tree (that has key(node), left(node), right(node)) \nclass TreeNode:\n    def __init__(self, key):\n        self.key = key\n        self.left = None\n        self.right = None\n\n\n# instead of linking nodes one by one, we can represent nodes in the form of tuple\n# and we can use recursion technique to automate linking process.  \n  \ndef parse_tuple(data):\n\n    # check if the parameter passed is of type tuple and it's length is 3 (left node, key, right node)\n    if isinstance(data, tuple) and len(data) == 3:\n        node = TreeNode(data[1])\n        node.left = parse_tuple(data[0])\n        node.right = parse_tuple(data[2])\n    \n    # if it is the leaf node(last node) and it is also == None, then assign node = None\n    elif data is None:\n        node = None\n    \n    # if it is a leaf node(last node) and not != to None, then assign node = current value\n    else:\n        node = TreeNode(data)\n    \n    return node\n\n\ndef tree_to_tuple(node):\n    if isinstance(node, TreeNode):\n        # check if left and right node are equal to None if so, then it means it has no child nodes\n        # and simply just return key node\n        if node.left is None and node.right is None:\n            return node.key\n        \n        # use recursion to iterate through each sub tree and get the left , key and right nodes\n        return (\n            tree_to_tuple(node.left),\n            node.key,\n            tree_to_tuple(node.right)\n        )\n    # else simply return node\n    else:\n        return node\n\n    \ntree_tuple = ((1,3,None), 2, ((None, 3, 4), 5, (6, 7, 8)))\ntree2 = parse_tuple(tree_tuple)\nprint(tree_to_tuple(tree2))\n\n\nOutput\n ((1, 3, None), 2, ((None, 3, 4), 5, (6, 7, 8)))\n"], ["In [274]: arr = np.array([1,2,np.nan, 4,np.nan])\nIn [275]: arr\nOut[275]: array([ 1.,  2., nan,  4., nan])\nIn [277]: arr[[2,4]]\nOut[277]: array([nan, nan])\n", "In [278]: arr[[2,4]] = ' '\nTraceback (most recent call last):\n  Input In [278] in <cell line: 1>\n    arr[[2,4]] = ' '\nValueError: could not convert string to float: ''\n", "In [279]: sarr = arr.astype(str)\nIn [280]: sarr\nOut[280]: array(['1.0', '2.0', 'nan', '4.0', 'nan'], dtype='<U32')\nIn [281]: sarr[[2,4]] = ' '\nIn [282]: sarr\nOut[282]: array(['1.0', '2.0', ' ', '4.0', ' '], dtype='<U32')\n", "In [283]: np.isnan(arr)\nOut[283]: array([False, False,  True, False,  True])\nIn [284]: np.nonzero(np.isnan(arr))\nOut[284]: (array([2, 4]),)\n", "In [285]: sarr = arr.astype(str)\nIn [286]: sarr == 'nan'\nOut[286]: array([False, False,  True, False,  True])\n", "In [287]: S = pd.Series(arr)\nIn [288]: S\nOut[288]: \n0    1.0\n1    2.0\n2    NaN\n3    4.0\n4    NaN\ndtype: float64\nIn [289]: S.replace?\nIn [290]: S.replace(np.nan, ' ')\nOut[290]: \n0    1.0\n1    2.0\n2       \n3    4.0\n4       \ndtype: object\n", "In [292]: _.to_numpy()\nOut[292]: array([1.0, 2.0, ' ', 4.0, ' '], dtype=object)\n"], ["a = np.array([[nan, 2], [3, nan]])\na = np.where(np.isnan(a), '', a)\nprint(a)\n", "[['' '2.0']\n ['3.0' '']]\n\nProcess finished with exit code 0\n", "a = np.array([[nan, 2], [3, nan]])\na = np.nan_to_num(a, nan=0)\nprint(a)\n", "[[0. 2.]\n [3. 0.]]\n\nProcess finished with exit code 0\n"], ["df2 = df.fillna(\"\")\n", "df = pd.DataFrame(numpy_array)\n"], ["import numpy as np\n\narr = np.array((np.nan, 1, 0, np.nan, -42))\n\narr[np.isnan(arr)] = -100\n\nprint(arr)\n", "array([-100.,    1.,    0., -100.,  -42.])\n"], ["dfCopy = df.replace(np.nan, '', regex=True)\n"], ["brew install python-tk\n"], ["def nametag(first_name, last_name):\n    return(\"{} {}.\".format(first_name, last_name[0]))\n\nprint(nametag(\"Jane\", \"Smith\")) \n# Should display \"Jane S.\" \nprint(nametag(\"Francesco\", \"Rinaldi\")) \n# Should display \"Francesco R.\" \nprint(nametag(\"Jean-Luc\", \"Grand-Pierre\")) \n# Should display \"Jean-Luc G.\" \n"], ["import pyautogui\n\nfrom selenium import webdriver\nfrom selenium.webdriver import ActionChains\nfrom selenium.webdriver.chrome.options import Options\n\n\nurl = 'https://ifconfig.me/'\n\noptions = Options()\noptions.add_argument('--lang=fr')  # set your language here\n\nbrowser = webdriver.Chrome(options=options)\n\nbrowser.get(url)\n\nactionChains = ActionChains(browser)\nactionChains.context_click().perform()\n\n# here maybe problem. Debug it:\nfor i in range(3):\n    pyautogui.sleep(1)\n    pyautogui.press('up')\n\npyautogui.press('enter')\n"], [], [], ["import json\n\njsonpath = '/path/to/json/file.json'\n\nwith open(jsonpath) as file:\n    j = json.loads(file.read())\n\nnames_to_remove = ['XY_MAGIC#1111']\n\nfor element in j['names']:\n    if element['name'] in names_to_remove:\n        j['names'].remove(element)\n        \nwith open(jsonpath, 'w') as file:\n    file.write(json.dumps(j, indent=4))\n"], ["import json\nwith open(\"test.json\",'r') as f:\n   data = json.loads(f.read())\n   names=data.get('names')\n   for idx,name in enumerate(names):\n      if name['name']=='XY_MAGIC#1111':\n         del names[idx]\n         break\n   print(names)\n"], ["# importing the module\nimport ast\n  \n# reading the data from the file\nwith open('dictionary.txt') as f:\n    data = f.read()\n  \nprint(\"Data type before reconstruction : \", type(data))\n      \n# reconstructing the data as a dictionary\na_dict = ast.literal_eval(data)\n\n{\"names\":[a for a in a_dict[\"names\"] if a.get(\"name\") !=\"XY_MAGIC#1111\"]}\n"], ["def tree_to_tuple(node):\n    if isinstance(node, TreeNode):\n       return(tree_to_tuple(node.left), node.key, tree_to_tuple(node.right))\n    else:return node\n"], [], [], [], ["# First digit, requires two steps:\n   |\n1001\n\n# Second digit, requires one step:\n  |\n1001\n\n# Third digit, requires one step:\n |\n1001\n\n# S[0] is 1, but requires only one step:\n|\n1001\n\n=> total of 5 steps:\n\n0:  1001    # (-1)\n1:  1000    # (/2)\n2:   100    # (/2)\n3:    10    # (/2)\n4:     1    # (-1)\n5:     0\n"], [], [], ["from keras.optimizers import rmsprop_v2\nmodel.compile(loss='binary_crossentropy', optimizer='rmsprop')\n"], ["conda install -c conda-forge gcc\nconda install -c conda-forge pystan\nconda install -c conda-forge fbprophet\n"], ["from django.apps import AppConfig\n\nclass MyAppConfig(AppConfig):\n    default_auto_field = 'django.db.models.AutoField'\n    name = 'my_app'\n", "from django.db import models\n\nclass MyModel(models.Model):\n    id = models.AutoField(primary_key=True)\n"], ["import itertools\n\ndef apple():\n  print(\"In apple\")\ndef mango():\n   print(\"In mango\")\ndef orange():\n   print(\"In orange\")\n\nfruits = ['apple','mango','orange']\nprint(type(fruits))\nfunc = '[%s]'%','.join(map(str,fruits))\nprint(func) ## [apple,mango,orange]\nhehe = eval(func)\nprint(type(hehe))\n\nn = len(hehe)\nfunc_it = itertools.cycle(hehe)\nfor i in range(n):\n   next(func_it)()\n", "<class 'list'>\n[apple,mango,orange]\n<class 'list'>\nIn apple\nIn mango\nIn orange\n\n"], [], [], ["from django.contrib.sessions.models import Session\nSession.objects.all().delete()\n"], ["def groups_per_user(group_dictionary):\n    user_groups = {}\n    for key,users in group_dictionary.items():\n        for user in users:\n            user_groups[user]=[]\n    for key in user_groups.keys():\n        for ke,value in group_dictionary.items():\n            for i in value:\n                if(key==i):\n                    user_groups[key].append(ke)\n    return(user_groups)\nprint(groups_per_user({\"local\": [\"admin\", \"userA\"],\"public\"[\"admin\",\"userB\"],\"administrator\": [\"admin\"] }))\n"], [" location / {\n  proxy_set_header   Host             $host;\n  proxy_set_header   X-Real-IP        $remote_addr;\n  proxy_set_header   X-Forwarded-For  $proxy_add_x_forwarded_for;\n  proxy_pass http://localhost:8000;\n}\n", "EXPOSE 8000\n\nCMD [\"uvicorn\", \"app.main:app\", \"--host\", \"0.0.0.0\"]\n", "version: \"3.7\"\nservices:\n  app:\n    build: ./fastapi\n    container_name: ipinfo\n    restart: always\n    ports:\n      - \"8000:8000\"\n    network_mode: host\n\n  nginx:\n    build: ./nginx\n    container_name: nginx\n    restart: always\n    ports:\n      - \"80:80\"\n      - \"443:443\"\n    network_mode: host\n"], ["Internal Server Error: /admin\nTraceback (most recent call last):\n  File \"C:\\Users\\Public\\django2.2\\lib\\site-packages\\django\\contrib\\sessions\\backends\\base.py\", line 189, in _get_session\n    return self._session_cache\nAttributeError: 'SessionStore' object has no attribute '_session_cache'\nDuring handling of the above exception, another exception occurred:\nTraceback (most recent call last):\n  File \"C:\\Users\\Public\\django2.2\\lib\\site-packages\\django\\core\\handlers\\exception.py\", line 34, in inner\n    response = get_response(request)\n  File \"C:\\Users\\Public\\django2.2\\lib\\site-packages\\django\\core\\handlers\\base.py\", line 115, in _get_response\n    response = self.process_exception_by_middleware(e, request)\n  File \"C:\\Users\\Public\\django2.2\\lib\\site-packages\\django\\core\\handlers\\base.py\", line 113, in _get_response\n    response = wrapped_callback(request, *callback_args, **callback_kwargs)\n  File \"C:\\Users\\Public\\django2.2\\lib\\site-packages\\django\\contrib\\admin\\sites.py\", line 241, in wrapper\n    return self.admin_view(view, cacheable)(*args, **kwargs)\n  File \"C:\\Users\\Public\\django2.2\\lib\\site-packages\\django\\utils\\decorators.py\", line 142, in _wrapped_view\n    response = view_func(request, *args, **kwargs)\n  File \"C:\\Users\\Public\\django2.2\\lib\\site-packages\\django\\views\\decorators\\cache.py\", line 44, in _wrapped_view_func\n    response = view_func(request, *args, **kwargs)\n  File \"C:\\Users\\Public\\django2.2\\lib\\site-packages\\django\\contrib\\admin\\sites.py\", line 212, in inner\n    if not self.has_permission(request):\n  File \"C:\\Users\\Public\\django2.2\\lib\\site-packages\\django\\contrib\\admin\\sites.py\", line 186, in has_permission\n    return request.user.is_active and request.user.is_staff\n  File \"C:\\Users\\Public\\django2.2\\lib\\site-packages\\django\\utils\\functional.py\", line 256, in inner\n    self._setup()\n  File \"C:\\Users\\Public\\django2.2\\lib\\site-packages\\django\\utils\\functional.py\", line 392, in _setup\n    self._wrapped = self._setupfunc()\n  File \"C:\\Users\\Public\\django2.2\\lib\\site-packages\\django\\contrib\\auth\\middleware.py\", line 24, in <lambda>\n    request.user = SimpleLazyObject(lambda: get_user(request))\n  File \"C:\\Users\\Public\\django2.2\\lib\\site-packages\\django\\contrib\\auth\\middleware.py\", line 12, in get_user\n    request._cached_user = auth.get_user(request)\n  File \"C:\\Users\\Public\\django2.2\\lib\\site-packages\\django\\contrib\\auth\\__init__.py\", line 182, in get_user\n    user_id = _get_user_session_key(request)\n  File \"C:\\Users\\Public\\django2.2\\lib\\site-packages\\django\\contrib\\auth\\__init__.py\", line 59, in _get_user_session_key\n    return get_user_model()._meta.pk.to_python(request.session[SESSION_KEY])\n  File \"C:\\Users\\Public\\django2.2\\lib\\site-packages\\django\\contrib\\sessions\\backends\\base.py\", line 54, in __getitem__\n    return self._session[key]\n  File \"C:\\Users\\Public\\django2.2\\lib\\site-packages\\django\\contrib\\sessions\\backends\\base.py\", line 194, in _get_session\n    self._session_cache = self.load()\n  File \"C:\\Users\\Public\\django2.2\\lib\\site-packages\\django\\contrib\\sessions\\backends\\db.py\", line 44, in load\n    return self.decode(s.session_data) if s else {}\n  File \"C:\\Users\\Public\\django2.2\\lib\\site-packages\\django\\contrib\\sessions\\backends\\base.py\", line 100, in decode\n    encoded_data = base64.b64decode(session_data.encode('ascii'))\n"], [], [], [], ["server {\n  # the port your site will be served on\n    listen 80;\n  # the domain name it will serve for\n    server_name <your_host_name>; # substitute your machine's IP address or FQDN\n\n#    add_header Access-Control-Allow-Origin *;\n    # add_header Access-Control-Allow-Credentials: true;\n    add_header Access-Control-Allow-Headers Content-Type,XFILENAME,XFILECATEGORY,XFILESIZE;\n    add_header access-control-allow-headers authorization;\n    # Finally, send all non-media requests to the Django server.\n    location / {\n        proxy_pass http://127.0.0.1:8000/; # the uvicorn server address\n        proxy_set_header   Host             $host;\n        proxy_set_header   X-Real-IP        $remote_addr;\n        proxy_set_header   X-Forwarded-For  $proxy_add_x_forwarded_for;\n    }\n}\n\n"], [], [], ["(n+d)/d = (n/d)+1\n(-n)/d = -(n/d)\n"], [], [], [], [], ["from tensorflow import keras\nfrom keras import optimizers\noptimizer=keras.optimizers.RMSprop(learning_rate=0.01)\n"], ["export PYTHON_VERSION_SHORT=3.9\napt-get install -y python${PYTHON_VERSION_SHORT} python3-pip && \\\nln -s -f /usr/bin/python${PYTHON_VERSION_SHORT} /usr/bin/python3 && \\\nln -s -f /usr/bin/python${PYTHON_VERSION_SHORT} /usr/bin/python && \\\nln -s -f /usr/bin/pip3 /usr/bin/pip\n"], [], [], [" 0   1  2018     80\n 1   2  2018     70,    ID  Year  Score\n 0   1  2017     77\n 1   3  2017     62]\n"], ["class CustomJSONField(JSONField):\nempty_values = [None, '', [], ()]\n\ndef formfield(self, **kwargs):\n    result = super().formfield(**kwargs)\n    result.empty_values = self.empty_values\n    return result\n"], [], ["<div style=style=\"font-size: 12px\">\n   \n     //your stuffs here\n\n</div>\n"], [], ["def tree_to_tuple(node):\n    if isinstance(node, TreeNode):\n\n        if node.left is not None and node.right is not None:\n            node_mid = node.key\n            node_left = tree_to_tuple(node.left)\n            node_right = tree_to_tuple(node.right)\n\n            return (node_left, node_mid, node_right)\n\n        elif node.left is None and node.right is None:\n            return node.key\n\n        elif node.left is None and node.right is not None:\n            node_mid = node.key\n            node_right = tree_to_tuple(node.right)\n            node_left = None\n\n            return (node_left, node_mid, node_right)\n\n        elif node.left is not None and node.right is None:\n            node_mid = node.key\n            node_right = None\n            node_left = tree_to_tuple(node.left)\n\n            return (node_left, node_mid, node_right)\n\n    else:\n        print(\"It's not a tree\")\n"], [], ["circles = [plt.Circle((j,i), radius=R[j][i]) for j, i in zip(x.flat, y.flat)]\n"], ["$ python3.9 -m ensurepip\n"], [], [], [], [], ["columns_list = df.columns.values.tolist()\n", "columns_df = pd.DataFrame([columns_list], columns=columns_list)\ncolumns_dict = dict(zip(columns_list, columns_list))\ncolumns_series = pd.Series(columns_list, index=columns_list)\ncolumns_dict_manual = {\"column_1\":\"column_1\", \"column_2\":\"column_2\", \"column3\":\"column_3\"}\n", "df = df.append(columns_df, ignore_index=True) # append dataframe\ndf = df.append(columns_dict, ignore_index=True) # append dictionary\ndf = df.append(columns_series, ignore_index=True) # append series\n", "df = pd.concat([df, columns_df], ignore_index=True, axis=0)\n", "df.loc[len(df)] = columns_list # insert list row to the bottom\ndf.loc[len(df)] = columns_series # insert series row to the bottom\n\n# Insert a row to the top\ndf.loc[-1] = columns_list # inserting a row\ndf.index = df.index + 1 # shifting index\ndf = df.sort_index() # sorting by index\n", "df = df.append(pd.Series(), ignore_index=True) # Insert empty row\ndf.iloc[len(df) - 1] = columns_series # Insert columns to existing empty row\n", "df = df.append(df.sum(numeric_only=True), ignore_index=True)\n"], [], [], ["select COMMUNITY_AREA_NUMBER, COMMUNITY_AREA_NAME FROM ChicagoCensusData WHERE COMMUNITY_AREA_NUMBER IN (SELECT TOP 2 COMMUNITY_AREA_NUMBER FROM ChicagoCrimeData GROUP BY COMMUNITY_AREA_NUMBER ORDER BY COUNT(*) DESC);\n"], ["sudo rm -rf /Library/Developer/CommandLineTools\nsudo xcode-select --install\n"], [], ["PYTHONPATH={your python path} {your alembic cmd}\n"], ["fname = input(\"Enter file name:\")\nfh = open(fname)\ncount = 0\ns=0\nfor line in fh:\n    if not line.startswith(\"X-DSPAM-Confidence:\"):\n        continue\n    count = count+1\n    pos = line.find('0')\n    floatingP = float(line[pos:])\n    s += floatingP\nprint(s/count)\n"], ["import pandas as pd\nimport sqlalchemy\nimport uuid\nimport os\n\ndef upsert_df(df: pd.DataFrame, table_name: str, engine: sqlalchemy.engine.Engine):\n    \"\"\"Implements the equivalent of pd.DataFrame.to_sql(..., if_exists='update')\n    (which does not exist). Creates or updates the db records based on the\n    dataframe records.\n    Conflicts to determine update are based on the dataframes index.\n    This will set unique keys constraint on the table equal to the index names\n    1. Create a temp table from the dataframe\n    2. Insert/update from temp table into table_name\n    Returns: True if successful\n    \"\"\"\n\n    # If the table does not exist, we should just use to_sql to create it\n    if not engine.execute(\n        f\"\"\"SELECT EXISTS (\n            SELECT FROM information_schema.tables \n            WHERE  table_schema = 'public'\n            AND    table_name   = '{table_name}');\n            \"\"\"\n    ).first()[0]:\n        df.to_sql(table_name, engine)\n        return True\n\n    # If it already exists...\n    temp_table_name = f\"temp_{uuid.uuid4().hex[:6]}\"\n    df.to_sql(temp_table_name, engine, index=True)\n\n    index = list(df.index.names)\n    index_sql_txt = \", \".join([f'\"{i}\"' for i in index])\n    columns = list(df.columns)\n    headers = index + columns\n    headers_sql_txt = \", \".join(\n        [f'\"{i}\"' for i in headers]\n    )  # index1, index2, ..., column 1, col2, ...\n\n    # col1 = exluded.col1, col2=excluded.col2\n    update_column_stmt = \", \".join([f'\"{col}\" = EXCLUDED.\"{col}\"' for col in columns])\n\n    # For the ON CONFLICT clause, postgres requires that the columns have unique constraint\n    query_pk = f\"\"\"\n    ALTER TABLE \"{table_name}\" DROP CONSTRAINT IF EXISTS unique_constraint_for_upsert;\n    ALTER TABLE \"{table_name}\" ADD CONSTRAINT unique_constraint_for_upsert UNIQUE ({index_sql_txt});\n    \"\"\"\n    engine.execute(query_pk)\n\n    # Compose and execute upsert query\n    query_upsert = f\"\"\"\n    INSERT INTO \"{table_name}\" ({headers_sql_txt}) \n    SELECT {headers_sql_txt} FROM \"{temp_table_name}\"\n    ON CONFLICT ({index_sql_txt}) DO UPDATE \n    SET {update_column_stmt};\n    \"\"\"\n    engine.execute(query_upsert)\n    engine.execute(f\"DROP TABLE {temp_table_name}\")\n\n    return True\n"], ["((1, 3, None), 2, ((None, 3, 4), 5, (6, 7, 8)))\n"], [], ["    abcdefgh\n    hgfedcba\n    \n    x      x  => (a+h) < 10\n    \n    if both ends are same in n, strip both sides by one digit and recurse\n    \n", "    1    \n    abcdefgh\n    hgfedcba\n    \n   (x+1)......(x)  => (a+h+1) < 10\n\n   if left end is 1 greater than right end in n, strip both sides by one digit, add digit 1 on the left and recurse\n", "   1      1\n    abcdefgh\n    hgfedcba\n    \n   1x      x   => (a+h) >= 10\n   \n strip -  if second and last digit are same, strip two digits from left and one from right, from the remaining number minus 1 and recurse.\n", "        11    \n         abcdefgh\n         hgfedcba\n\n        10......9\n        \n    strip - two from left and one from right and recurse.\n        \n", "        11     1\n         abcdefgh\n         hgfedcba\n\n        1(x+1)......x\n        \n    strip - two from left and one from right and subtract 1 from number and recurse.\n"], ["brew update && brew upgrade pyenv\n"], [], [], ["i = 0   # iterator\nwhile i < len(LIST_OF_OPS):   # list of operators which I have aggregated beforehand\n    LIST_OF_OPS[i] >> LIST_OF_OPS[i+1:i+8] # one task queues up seven more\n    i += 7 # in order not to start all of them in parallel, I increase the iterator to one less than the number of tasks started just now; a chain is formed.\n"], ["pip install --upgrade Pillow\n"], [], [], [], ["@app.post('/my-endpoint')\nasync def my_endpoint(stats: Stats, request: Request):\n    x = 'x-forwarded-for'.encode('utf-8')\n    for header in request.headers.raw:\n        if header[0] == x:\n            print(\"Find out the forwarded-for ip address\")\n            origin_ip, forward_ip = re.split(', ', header[1].decode('utf-8'))\n            print(f\"origin_ip:\\t{origin_ip}\")\n            print(f\"forward_ip:\\t{forward_ip}\")\n    return {'status': 1, 'message': 'ok'}\n"], ["def nametag(first_name, last_name):\n    return(\"{} {:.1}.\".format(first_name, last_name))\nprint(nametag(\"Jane\", \"Smith\"))\n"], ["for c in range(1, 12): # check the list start from 0 or 1 \n    time.sleep(5)  # Give time to loading the information\n    element = driver.find_element_by_xpath(f'//*[@id=\"grid-search-results\"]/ul/li[{c}]') # variable c refer to next item\n    driver.execute_script(\"arguments[0].scrollIntoView();\", element)\n"], ["class NoEscape(logging.Filter):\n    def __init__(self):\n        self.regex = re.compile(r'(\\x9B|\\x1B\\[)[0-?]*[ -\\/]*[@-~]')\n    def strip_esc(self, s):\n        try: # string-like \n            return self.regex.sub('',s)\n        except: # non-string-like\n            return s\n    def filter(self, record: logging.LogRecord) -> int:\n        record.msg = self.strip_esc(record.msg)\n        if type(record.args) is tuple:\n            record.args = tuple(map(self.strip_esc, record.args))\n        return 1\n"], ["[15292:18896:0820/144926.111:ERROR:device_event_log_impl.cc(214)] [14:49:26.110] USB: usb_device_handle_win.cc:1048 Failed to read descriptor from node connection: A device attached to the system is not functioning. (0x1F)\n"], ["    %%sql select community_area_name \n    from CENSUS_DATA \n    where community_area_number = (select A.community_area_number from CHICAGO_CRIME_DATA as A \n    GROUP BY A.community_area_number \n    ORDER BY COUNT (A.community_area_number) DESC LIMIT 1)\n"], ["filtered_list = [e for e in listpost if e['text'] == 'abc']\n"], ["new_list = [el for el in listpost if el[\"text\"]==\"abc\"]\n", "new_list = [el for el in listpost if el[\"text\"].startswith(\"abc\")]\n", "new_list = [el for el in listpost if \"abc\" in el[\"text\"]]\n"], [], [], ["def nametag(first_name, last_name):\n    name = '{}.{}'.format(first_name, last_name)\n    location = name.find('.')\n    name = name[:location + 2].replace('.', ' ') + '.'\n    return name\n"], ["<link rel=\"icon\" href=\"{% static 'images/favicon.png' %}\">\n", "<link rel=\"icon\" href=\"{% static 'blog/images/favicon.png' %}\">\n"], [], [], ["driver = webdriver.Chrome(resource_path(\"C:\\\\webdriver\\\\chromedriver.exe\"))  # to open the chromebrowser\ndriver.get(\"https://web.whatsapp.com\")\n", "driver = webdriver.Chrome(executable_path=r'C:\\webdriver\\chromedriver.exe')  # to open the chromebrowser\ndriver.get(\"https://web.whatsapp.com\")\n", "pip install pywin32\n"], ["n = 12.43564\nresult = n % int(n)\nwhile not int(result) or int(result) % 10:\n    result *= 10\nresult = int(result / 10)\n"], ["def digits(x,N):\n    return int((abs(x) % 1) * 10**N)\n    \nprint(digits(1.23456,2))\nprint(digits(-1.23456,3))\nprint(digits(1.23,5))\n", "23\n234\n23000\n"], ["> np.modf(d)\n(0.43563999999999936, 12.0)\n\n> int(np.modf(d)[0] * 1e3)\n435\n"], [">>> x = 1.23456789\nstr(x)\n>>> str(x)\n'1.23456789'\n>>> str(x).split('.')\n['1', '23456789']\n>>> str(x).split('.')[1][:4]\n'2345'\n", ">>> (x - int(x)) * 10000\n2345.678899999999\n>>> int((x - int(x)) * 10000)\n2345\n"], ["x = 12.43564\nprint(str(x).split(\".\")[1][:3])\n", "str(x).split(\".\")[1][:1000]\n"], [], ["l = 'YourString'\nli=[]\nfor index,i in enumerate(l):\n    if index % 2 == 0:\n        i=i.lower()\n        li.append(i)\n    elif index % 2 == 1:\n        i=i.upper() \n        li.append(i)\nprint(''.join(li))\n"], ["c = {0: 'a', 1: 'b'}\nm = dict(zip(df.columns[list(c.keys())], c.values()))\n", ">>> m\n{'A': 'a', 'B': 'b'}\n\n>>> df.rename(columns=m)\n   a  b\n0  1  3\n1  2  2\n2  3  1\n"], ["names = iter(['a', 'b'])\n\ndef renamer(col):\n    return next(names)\n\n\ndf.rename(renamer, axis='columns', inplace=True)\n"], ["import pandas as pd\ndf = pd.DataFrame({'A':[1, 2, 3],'B':[3, 2, 1]})\ndf.columns = [\"X\",\"Y\"]\nprint(df)\n", "   X  Y\n0  1  3\n1  2  2\n2  3  1\n"], ["df.rename(columns={ df.columns[0]: 'a', df.columns[1]: 'b',}, inplace = True)\ndf\n", "    a   b\n0   1   3\n1   2   2\n2   3   1\n"], ["update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.9 1\n"], ["def count_zeros(num: int) -> int:\n    return len(str(num)) - len(str(num).rstrip('0'))\n\n    \n\nprint(count_zeros(0))       #1\nprint(count_zeros(1))       #0\nprint(count_zeros(10))      #1\nprint(count_zeros(245))     #0\nprint(count_zeros(101))     #0\nprint(count_zeros(100100))  #2\n"], ["apt install python-is-python3\n"], ["apt update\napt install software-properties-common\nadd-apt-repository ppa:deadsnakes/ppa -y\napt update\napt install python3.9\nupdate-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.9 1\ncurl https://bootstrap.pypa.io/get-pip.py -o get-pip.py\npython3.9 get-pip.py\n"], ["int immediateSmaller(int arr[], int n, int x)\n    {\n        // your code here\n        int smaller=-1;\n        for(int i=0;i<n;i++)\n        {\n            if(arr[i]>smaller && arr[i]<x)\n            smaller=arr[i];\n            \n        }return smaller;\n    }\n};\n"], [], [], ["import matplotlib.pyplot as plt\n\nhelp (plt)\n", "python newfile.py\n"], ["String chromeProfilePath = \"C:\\\\Users\\\\shah\\\\Documents\\\\\";\nChromeOptions chroOption = new ChromeOptions();\nchroOption.addArguments(\"user-data-dir=\" + chromeProfilePath);\n", "chroOption.addArguments(\"profile-directory=Profile 2\");\nWebDriver driver = new ChromeDriver(chroOption);\ndriver.get(\"https://facebook.com\");\n"], ["import traceback, ast, re\ndef get_fun(name, ast_obj):\n    if isinstance(ast_obj, ast.Call) and ast_obj.func.id == name:\n        yield from [i.arg for i in getattr(ast_obj, 'keywords', [])]\n    for a, b in getattr(ast_obj, '__dict__', {}).items():\n        yield from (get_fun(name, b) if not isinstance(b, list) else \\\n                        [i for k in b for i in get_fun(name, k)])\n\ndef passed_positionally(stack):\n    *_, [_, co], [trace, _] = [re.split('\\n\\s+', i.strip()) for i in stack] \n    f_name = re.findall('(?:line \\d+, in )(\\w+)', trace)[0]\n    return list(get_fun(f_name, ast.parse(co)))\n\ndef foo(x, y):\n    if 'y' in passed_positionally(traceback.format_stack()):\n        print('y was passed with its keyword')\n    else:\n        print('y was passed positionally')\n\nfoo(1, y=2)\n", "y was passed with its keyword\n"], ["%%sql \nSELECT COMMUNITY_AREA_NAME, COMMUNITY_AREA_NUMBER AS MOST_CRIMES FROM CENSUS_DATA\nWHERE COMMUNITY_AREA_NUMBER IN (SELECT COUNT(COMMUNITY_AREA_NUMBER) FROM CRIME_DATA GROUP BY COMMUNITY_AREA_NUMBER) ;\n"], [], ["id = models.AutoField(primary_key=True)\n", "class Contact(models.Model):\n    sno = models.AutoField(primary_key=True)\n    name = models.CharField(max_length=25, blank=True)\n    email = models.EmailField(max_length=40, blank=True)\n    phone = models.IntegerField()\n"], ["#!/usr/bin/env python3\n\nfruits = ['apple','mango','orange']\n\ndef apple():\n  print(\"In apple\")\ndef mango():\n   print(\"In mango\")\ndef orange():\n   print(\"In orange\")\n\nfor func in fruits:\n    exec(func + '()')  \n", "In apple\nIn mango\nIn orange\n"], ["func = [globals()[fun] for fun in fruits]\nfunc_it = itertools.cycle(func)\nfor i in range(len(func)):\n   next(func_it)()\n", "In apple\nIn mango\nIn orange\n"], ["import itertools\nfruits = ['apple','mango','orange']\ndef apple():\n  print(\"In apple\")\ndef mango():\n   print(\"In mango\")\ndef orange():\n   print(\"In orange\")\nfuncs = {'apple':apple()}\nfuncs['apple']\n", "In apple\n"], ["import itertools\n\ndef apple():\n  print(\"In apple\")\ndef mango():\n   print(\"In mango\")\ndef orange():\n   print(\"In orange\")\n\nfunc = [apple, mango, orange]  # list of functions\nn = len(func)\nfunc_it = itertools.cycle(func)\nfor i in range(n):\n    x = next(func_it)\n    print(type(x))  # check the type\n    x()\n", "<class 'function'>\nIn apple\n<class 'function'>\nIn mango\n<class 'function'>\nIn orange\n", "s = '[apple, mango, orange]'\nfunc = eval(s)\nprint(func)\n", "[<function apple at 0x000001FB9E7CF040>, <function mango at 0x000001FB9ECB7940>, <function orange at 0x000001FB9ECB7DC0>]\n"], ["def foo(x, y):\n    if passed_positionally(y):\n        raise Exception(\"You need to pass 'y' as a keyword argument\")\n    else:\n        process(x, y)\n", "def foo(x, *, y):\n    pass\n\n>>> foo(1, 2)\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nTypeError: foo() takes 1 positional argument but 2 were given\n\n>>> foo(1, y=2) # works\n", "def foo(x, y, /):\n    pass\n\n>>> foo(x=1, y=2)\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nTypeError: foo() got some positional-only arguments passed as keyword arguments: 'x, y'\n\n>>> foo(1, 2) # works\n"], ["yum search tkinter\nyum install python39-tkinter.x86_64\n", "yum install tk-devel\n", "make install\n"], ["$ mypy t.py \nt.py:27: note: Revealed type is 'builtins.int'\n", "$ python t.py \nx passed positionally.\ny passed positionally.\nx passed positionally.\ny passed with its keyword!\n"], ["def foo(x, y=None, /, **kwargs):\n \n    if y is None: \n        y = kwargs.pop(y)\n        received_as_positional = False\n    else:\n        received_as_positional = True\n\n"], ["def find_welfare_crook(f, g, h, i, j, k):\n    \"\"\"f, g, and h are \"ascending functions,\" i.e.,\ni <= j implies f[i] <= f[j] or, equivalently,\nf[i] < f[j] implies i < j, and the same goes for g and h.\ni, j, k define where to start the search in each list.\n\"\"\"\n    # This is an implementation of a solution to the Welfare Crook\n    # problems presented in David Gries's book, The Science of Programming.\n    # The surprising and beautiful thing is that the guard predicates are\n    # so few and so simple.\n    i , j , k = i , j , k\n    while True:\n        if f[i] < g[j]:\n            i += 1\n        elif g[j] < h[k]:\n            j += 1\n        elif h[k] < f[i]:\n            k += 1\n        else:\n            break\n    return (i,j,k)\n    # The other remarkable thing is how the negation of the guard\n    # predicates works out to be:  f[i] == g[j] and g[j] == c[k].\n", "def findIntersectionLofL(lofl):\n    \"\"\"Generalized findIntersection function which operates on a \"list of lists.\" \"\"\"\n    K = len(lofl)\n    indices = [0 for i in range(K)]\n    result = []\n    #\n    try:\n        while True:\n            # idea is to maintain the indices via a construct like the following:\n            allEqual = True\n            for i in range(K):\n                if lofl[i][indices[i]] < lofl[(i+1)%K][indices[(i+1)%K]] :\n                    indices[i] += 1\n                    allEqual = False\n            # When the above iteration finishes, if all of the list\n            # items indexed by the indices are equal, then another\n            # item common to all of the lists must be added to the result.\n            if allEqual :\n                result.append(lofl[0][indices[0]])\n                while lofl[0][indices[0]] == lofl[1][indices[1]]:\n                    indices[0] += 1\n    except IndexError as e:\n        # Eventually, the foregoing iteration will advance one of the\n        # indices past the end of one of the lists, and when that happens\n        # an IndexError exception will be raised.  This means the algorithm\n        # is finished.\n        return result\n", "def findIntersectionLofLunRolled(lofl):\n    \"\"\"Generalized findIntersection function which operates on a \"list of lists.\"\nAccepts a list-of-lists, lofl.  Each of the lists must be ordered.\nReturns the list of each element which appears in all of the lists at least once.\n\"\"\"\n    K = len(lofl)\n    indices = [0] * K\n    result = []\n    lt = [ (i, (i+1) % K) for i in range(K) ] # avoids evaluation of index exprs inside the loop\n    #\n    try:\n        while True:\n            allUnEqual = True\n            while allUnEqual:\n                allUnEqual = False\n                for i,j in lt:\n                    if lofl[i][indices[i]] < lofl[j][indices[j]]:\n                        indices[i] += 1\n                        allUnEqual = True\n            # Now all of the lofl[i][indices[i]], for all i, are the same value.\n            # Store that value in the result, and then advance all of the indices\n            # past that common value:\n            v = lofl[0][indices[0]]\n            result.append(v)\n            for i,j in lt:\n                while lofl[i][indices[i]] == v:\n                    indices[i] += 1\n    except IndexError as e:\n        # Eventually, the foregoing iteration will advance one of the\n        # indices past the end of one of the lists, and when that happens\n        # an IndexError exception will be raised.  This means the algorithm\n        # is finished.\n        return result\n"], ["def foo(x,y1=None,y=None):\n  if y1 is not None:\n    print('y was passed positionally!')\n  else:\n    print('y was passed with its keyword')\n"], ["def nametag(first_name, last_name):\n    return(\"{}{}{}.\".format(first_name,\" \",last_name[0]))\n"], ["def intersection(iterables):\n    target, count = None, 0\n    for it in itertools.cycle(map(iter, iterables)):\n        for value in it:\n            if count == 0 or value > target:\n                target, count = value, 1\n                break\n            if value == target:\n                count += 1\n                break\n        else:  # exhausted iterator\n            return\n        if count >= len(iterables):\n            yield target\n            count = 0\n", "def intersection(seqs):\n    seq = min(seqs, key=len)\n    if not seq:\n        return\n    pivot = seq[len(seq) // 2]\n    lows, counts, highs = [], [], []\n    for seq in seqs:\n        start = bisect.bisect_left(seq, pivot)\n        stop = bisect.bisect_right(seq, pivot, start)\n        lows.append(seq[:start])\n        counts.append(stop - start)\n        highs.append(seq[stop:])\n    yield from intersection(lows)\n    yield from itertools.repeat(pivot, min(counts))\n    yield from intersection(highs)\n"], ["from heapq import merge\nfrom itertools import groupby, chain\n\nls = [[1, 3, 5, 7], [1, 1, 3, 5, 7], [1, 4, 7, 9]]\n\n\ndef index_groups(lst):\n    \"\"\"[1, 1, 3, 5, 7] -> [(1, 0), (1, 1), (3, 0), (5, 0), (7, 0)]\"\"\"\n    return chain.from_iterable(((e, i) for i, e in enumerate(group)) for k, group in groupby(lst))\n\n\niterables = (index_groups(li) for li in ls)\nflat = merge(*iterables)\nres = [k for (k, _), g in groupby(flat) if sum(1 for _ in g) == len(ls)]\nprint(res)\n", "[1, 7]\n", "ls = [[1, 1, 3, 5, 7], [1, 1, 3, 5, 7], [1, 1, 4, 7, 9]]\n", "[1, 1, 7]\n"], ["class Solution(object):\n    def searchInsert(self, nums, target):\n        \"\"\"\n        :type nums: List[int]\n        :type target: int\n        :rtype: int\n        \"\"\"\n        if target in nums:\n            return (nums.index(target))\n        else:\n            nums.append(target)\n            nums.sort()\n            return(nums.index(target))\n"], ["pip3 install --upgrade djangorestframework-simplejwt\n"], ["def counter(my_list):\n    my_list = sorted(my_list)\n    first_val, *all_val = my_list\n    p_index = my_list.index(first_val)\n    my_counter = {}\n    for item in all_val:\n         c_index = my_list.index(item)\n         diff = abs(c_index-p_index)\n         p_index = c_index\n         my_counter[first_val] = diff \n         first_val = item\n    c_index = my_list.index(item)\n    diff = len(my_list) - c_index\n    my_counter[first_val] = diff \n    return my_counter\n\ndef my_func(data):\n    if not data or not isinstance(data, list):\n        return\n    # get the first value\n    first_val, *all_val = data\n    if not isinstance(first_val, list):\n        return\n    # count items in first value\n    p = counter(first_val) # counter({1: 2, 3: 1, 5: 1, 7: 1})\n    # collect all common items and calculate the minimum occurance in intersection\n    for val in all_val:\n        # collecting common items\n        c = counter(val)\n        # calculate the minimum occurance in intersection\n        inner_dict = {}\n        for inner_val in set(c).intersection(set(p)):\n            inner_dict[inner_val] = min(p[inner_val], c[inner_val])\n        p = inner_dict\n    # >>>p\n    # {1: 2, 7: 1}\n    # Sort by keys of counter\n    sorted_items = sorted(p.items(), key=lambda x:x[0]) # [(1, 2), (7, 1)]\n    result=[i[0] for i in sorted_items for _ in range(i[1])] # [1, 1, 7]\n    return result\n", ">>> data = [[1,3,5,7],[1,1,3,5,7],[1,4,7,9]]\n>>> my_func(data=data)\n[1, 7]\n>>> data = [[1,1,3,5,7],[1,1,3,5,7],[1,1,4,7,9]]\n>>> my_func(data=data)\n[1, 1, 7]\n"], [], [], ["arrays = [[1,3,5,7],[1,1,3,5,7],[1,4,7,9]]\ncounts = {}\n\nfor ar in arrays:\n  last = None\n  for i in ar:\n    if (i != last):\n      counts[i] = counts.get(i, 0) + 1\n    last = i\n\nN = len(arrays)\nintersection = [i for i, n in counts.iteritems() if n == N]\nprint intersection\n"], ["import heapq\n\n\ndef mergeArys(srtd_arys):\n    heap = []\n    srtd_iters = [iter(x) for x in srtd_arys]\n\n    # put the first element from each srtd array onto the heap\n    for idx, it in enumerate(srtd_iters):\n        elem = next(it, None)\n        if elem:\n            heapq.heappush(heap, (elem, idx))\n\n    res = []\n\n    # the number of tims that the current number has been seen\n    times_seen = 0\n\n    # the lowest number from the heap - currently checking if the first numbers in all sub-lists are equal to this\n    lowest = heap[0][0] if heap else None\n\n    # collect results in nlogK time\n    while heap:\n        elem, ary = heap[0]\n        unbench_all = True\n\n        if lowest != elem or ary != times_seen:\n            if lowest == elem:\n                heapq.heappop(heap)\n                it = srtd_iters[ary]\n                nxt = next(it, None)\n                if nxt:\n                    heapq.heappush(heap, (nxt, ary))\n        else:\n            heapq.heappop(heap)\n            times_seen += 1\n\n            if times_seen == len(srtd_arys):\n                res.append(elem)\n            else:\n                unbench_all = False\n\n        if unbench_all:\n            for unbenched in range(times_seen):\n                unbenched_it = srtd_iters[unbenched]\n                nxt = next(unbenched_it, None)\n                if nxt:\n                    heapq.heappush(heap, (nxt, unbenched))\n            times_seen = 0\n            if heap:\n                lowest = heap[0][0]\n\n    return res\n\n\nif __name__ == '__main__':\n    a1 = [[1, 3, 5, 7], [1, 1, 3, 5, 7], [1, 4, 7, 9]]\n    a2 = [[1, 1], [1, 1, 2, 2, 3]]\n    for arys in [a1, a2]:\n        print(mergeArys(arys))\n", "def mergeArys(srtd_arys):\n    heap = []\n    srtd_iters = [iter(x) for x in srtd_arys]\n\n    # put the first element from each srtd array onto the heap\n    for idx, it in enumerate(srtd_iters):\n        elem = next(it, None)\n        if elem:\n            heapq.heappush(heap, (elem, idx))\n\n    res = []\n\n    # collect results in nlogK time\n    while heap:\n        elem, ary = heap[0]\n        lowest = elem\n        keep_elem = True\n        for i in range(len(srtd_arys)):\n            elem, ary = heap[0]\n            if lowest != elem or ary != i:\n                if ary != i:\n                    heapq.heappop(heap)\n                    it = srtd_iters[ary]\n                    nxt = next(it, None)\n                    if nxt:\n                        heapq.heappush(heap, (nxt, ary))\n\n                keep_elem = False\n                i -= 1\n                break\n            heapq.heappop(heap)\n\n        if keep_elem:\n            res.append(elem)\n\n        for unbenched in range(i+1):\n            unbenched_it = srtd_iters[unbenched]\n            nxt = next(unbenched_it, None)\n            if nxt:\n                heapq.heappush(heap, (nxt, unbenched))\n\n        if len(heap) < len(srtd_arys):\n            heap = []\n\n    return res\n\n"], ["problem = [[1,3,5,7],[1,1,3,5,8,7],[1,4,7,9]];\n\ndebruijn = [0, 1, 28, 2, 29, 14, 24, 3, 30, 22, 20, 15, 25, 17, 4, 8,\n    31, 27, 13, 23, 21, 19, 16, 7, 26, 12, 18, 6, 11, 5, 10, 9];\nu32 = accum = (1 << 32) - 1;\nfor vec in problem:\n    maxterm = 0;\n    for v in vec:\n        maxterm |= 1 << v;\n    accum &= maxterm;\n\n# https://graphics.stanford.edu/~seander/bithacks.html#IntegerLogDeBruijn\nresult = [];\nwhile accum:\n    power = accum;\n    accum &= accum - 1; # Peter Wegner CACM 3 (1960), 322\n    power &= ~accum;\n    result.append(debruijn[((power * 0x077CB531) & u32) >> 27]);\n\nprint result;\n"], ["  inter = []\n\n  for n in range(len(arrays[0])):\n    if indexes[0] >= len(arrays[0]):\n        return inter\n    for i in range(1,k):\n      if indexes[i] >= len(arrays[i]):\n        return inter\n      while indexes[i] < len(arrays[i]) and arrays[i][indexes[i]] < arrays[0][indexes[0]]:\n        indexes[i] += 1\n      while indexes[i] < len(arrays[i]) and indexes[0] < len(arrays[0]) and arrays[i][indexes[i]] > arrays[0][indexes[0]]:\n        indexes[0] += 1\n    if indexes[0] < len(arrays[0]):\n      inter.append(arrays[0][indexes[0]])\n    indexes = [idx+1 for idx in indexes]\n  return inter\n"], [], ["from functools import reduce\n\na = [[1,3,5,7],[1,1,3,5,7],[1,4,7,9]] \nreduce(lambda x, y: x & set(y), a[1:], set(a[0]))\n {1, 7}\n"], [], ["path('admin/', admin.site.urls)\n"], [], ["models.py:\n       class Topic(models.Model):\n           id = models.AutoField(primary_key=True)\n", "settings.py:\nDEFAULT_AUTO_FIELD = 'django.db.models.AutoField'\n"], [], [], [], ["import pandas as pd\n\nurl_data = (r'https://raw.githubusercontent.com/oderofrancis/rona/main/Countries-Continents.csv')\n\ndata_csv = pd.read_csv(url_data)\n\ndata_csv.head()\n"], ["WHITENOISE_AUTOREFRESH = True\n"], [], ["def myfunc(a):\n    newString = ''\n    for count, ele in enumerate(a, 0):\n        if count %2 == 0:\n            newString += (a[count].lower())\n        else:\n            newString += ((a[count].upper()))\n    return newString\n"], [], ["dataframe = dataframe.append(pd.Series(name='col'))\ndataframe.iloc[ len(dataframe) - 1 ] = dataframe.columns\n", "      A   B   C   D   E   F   G   H\n12   ||  ||  ||  ||  ||  ||  ||  ||\n11   ||  ||  ||  ||  ||  ||  ||  ||\n10   ||  ||  ||  ||  ||  ||  ||  ||\n9    ||  ||  ||  ||  ||  ||  ||  ||\n8    ||  ||  ||  ||  ||  ||  ||  ||\n7    ||  ||  ||  ||  ||  ||  ||  ||\n6    ||  ||  ||  ||  ||  ||  ||  ||\n5    ||  ||  ||  ||  ||  ||  ||  ||\n4    ||  ||  ||  ||  ||  ||  ||  ||\n3    ||  ||  ||  ||  ||  ||  ||  ||\n2    ||  ||  ||  ||  ||  ||  ||  ||\n1    ||  ||  ||  ||  ||  ||  ||  ||\ncol   A   B   C   D   E   F   G   H\n"], [], ["..\n\n# Default primary key field type\n# https://docs.djangoproject.com/en/3.2/ref/settings/#default-auto-field\n\nDEFAULT_AUTO_FIELD = 'django.db.models.BigAutoField'\n"], ["class Topic(models.Model):\n    id = models.AutoField(primary_key=True)\n    ...\n"], ["tf.compat.v1.train.AdamOptimizer()\n"], [], ["yes, by brute force\nloop_check function took 29209.069 ms\nYes\ncheck function took 0.000 ms\n"], [], ["def reverse(n):\n    r = 0\n    while n != 0:\n        r = r*10 + int(n%10)\n        n = int(n/10)\n    return r\n\ndef f(n):\n    for i in range(n + 1):\n        if i + reverse(i) == n:\n            return True\n    return False\n\nprint('Yes' if f(101) else 'No')\n#Yes\n"], [], ["i = 0\nj = num\nposs = 0\nwhile(i<=j):\n   if(str(i)==str(j)[::-1]):\n       poss = 1\n       break\n   i+=1 \n   j-=1\nif(poss):\n    print(\"Yes\")\nelse:\n    print(\"No\")\n"], [], ["select cps.community_area_number, cps.community_area_name \nfrom CHICAGO_PUBLIC_SCHOOLS cps\nwhere cps.community_area_number = (select ccd.community_area_number \n                                   from CHICAGO_CRIME_DATA ccd\n                                   order by ccd.num_crimes desc \n                                   limit 1\n                                  ) ccd;\n"], ["options = webdriver.ChromeOptions()\noptions.add_experimental_option('excludeSwitches', ['enable-logging'])\ndriver = webdriver.Chrome(options=options)\n"], ["conda remove Pillow\npip install Pillow\n"], [], [], ["[tool.black]\n...\nexclude = '''\n\n(\n  /(\n    ...\n    | .+/migrations\n  )/\n)\n'''\n"], [], [], ["element = driver.find_element_by_xpath('//div[@id=\"container1\"]')\ntime.sleep(10)\n\nverical_ordinate = 100\nfor i in range(0, 50):\n   print(verical_ordinate)\n   driver.execute_script(\"arguments[0].scrollTop = arguments[1]\", element, verical_ordinate)\n   verical_ordinate += 100\n   time.sleep(1)\n"], ["while True:\n    time.sleep(1)\n    driver.execute_script(\"arguments[0].scrollTop = arguments[0].scrollHeight\", element)\n    if no_new_data_available():\n        break\n"], ["# Use this line in a loop, accordingly how much screen to be scrolled down\n# this just scrolls down to the height of browser screen, hence loop.\n\ndriver.execute_script(\"window.scrollTo(0,document.body.scrollHeight)\")\n", "# Now if the website needs time to load its data after scroll, add this in the loop..\n\ntime.sleep(5)\n"], ["    SCROLL_PAUSE_TIME = 0.5\n\n# Get scroll height\nlast_height = driver.execute_script(\"return document.body.scrollHeight\")\n\nwhile True:\n    # Scroll down to bottom\n    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n\n    # Wait to load page\n    time.sleep(SCROLL_PAUSE_TIME)\n\n    # Calculate new scroll height and compare with last scroll height\n    new_height = driver.execute_script(\"return document.body.scrollHeight\")\n    if new_height == last_height:\n        break\n    last_height = new_height\n", "label.sendKeys(Keys.PAGE_DOWN);\n"], ["l = []\nfor no in arr:\n    if no < x:\n        l.append(no)\nif l == []:\n    return -1\nreturn max(l)\n"], ["import requests, time, datetime, os, threading, sys, configparser\nimport glob\nimport pdfplumber\n\nfor filename in glob.glob(\"*.pdf\"):\n    pdf = pdfplumber.open(filename)\n    OutputFile = filename.replace('.pdf','.txt')\n    fx2=open(OutputFile, \"a+\")\n    for i in range(0,10000,1):\n        try:\n            page = pdf.pages[i]\n            text = page.extract_text()\n            print(text)\n            fx2.write(text)\n        except Exception as e: \n            print(e)\n    fx2.close()\n    pdf.close()\n"], [], ["_, contours, _ = cv.findContours()\n", "contours, _ = cv.findContours()\n", "conda install -c conda-forge opencv=4.1.0 \n\npip install opencv-contrib-python  \n"], [], [], ["from sqlalchemy import Table\nfrom sqlalchemy.engine.base import Engine as sql_engine\nfrom sqlalchemy.dialects.postgresql import insert\nfrom sqlalchemy.ext.automap import automap_base\nimport pandas as pd\n\n\ndef upsert_database(list_input: pd.DataFrame, engine: sql_engine, table: str, schema: str) -> None:\n    if len(list_input) == 0:\n        return None\n    flattened_input = list_input.to_dict('records')\n    with engine.connect() as conn:\n        base = automap_base()\n        base.prepare(engine, reflect=True, schema=schema)\n        target_table = Table(table, base.metadata,\n                             autoload=True, autoload_with=engine, schema=schema)\n        chunks = [flattened_input[i:i + 1000] for i in range(0, len(flattened_input), 1000)]\n        for chunk in chunks:\n            stmt = insert(target_table).values(chunk)\n            update_dict = {c.name: c for c in stmt.excluded if not c.primary_key}\n            conn.execute(stmt.on_conflict_do_update(\n                constraint=f'{table}_pkey',\n                set_=update_dict)\n            )\n"], ["def myfunc(str):\n    rstr = ''\n    for i in range(len(str) ):\n        if i % 2 == 0 :\n            # str[i].upper()\n            rstr = rstr + str[i].upper()\n        else:  \n            #str[i].lower()\n            rstr = rstr + str[i].lower()\n    return rstr        \n"], ["import re\n\ndef count_zeros(number: int) -> int:\n    count = re.search(r'0+$', str(number))\n    return len(count[0]) if count else 0\n\nprint(count_zeros(1))\nprint(count_zeros(123))\nprint(count_zeros(0))\nprint(count_zeros(10))\nprint(count_zeros(12300))\nprint(count_zeros(123000))\n", "0\n0\n1\n1\n2\n3\n"], ["    if number ==0:\n        return 1\n", "def count_zeros(number:int) -> int:\n\n    if number==0:\n        return 1\n\n    number_list = list(str(number))\n\n    is_zero = True\n    zero_count = 0\n\n    while is_zero:\n        if int(number_list.pop())==0:\n            zero_count += 1\n        else:\n            is_zero = False\n\n    return zero_count\n"], [], [], ["from fastapi import FastAPI, Request\n\napp = FastAPI()\n\n\n@app.get(\"/items/{item_id}\")\ndef read_root(item_id: str, request: Request):\n    client_host = request.client.host\n    return {\"client_host\": client_host, \"item_id\": item_id}\n"], ["import seaborn as sns\nimport matplotlib.pyplot as plt\n\n%matplotlib inline\n"], ["def nametag(first_name, last_name):\n\n    return \"{} {last_name}.\".format(first_name, last_name=last_name[0])\n\n\nprint(nametag(\"Jane\", \"Smith\"))\n\nout put:\nJane S.\n"], ["return(\"{first_name} {last_name[0]}.\".format(first_name= first_name, last_name=last_name[0]))\n"], ["static int activityNotifications(int[] expenditure, int d) {\n    int count = 0;\n    int days = expenditure.length;\n    int[]tempArr = Arrays.copyOfRange(expenditure,0,d);\n    Arrays.sort(tempArr);//\n\n    for(int i=0;d+i<days;i++){\n        \n       if(i>0 ){\n      //rearrange them based on outgoing and incoming into the window\n       int outgo = expenditure[i-1];\n       int income = expenditure[i+d-1];\n       rearrange(outgo,income,tempArr);}\n\n    //get medain\n     float median;\n     int size= d;\n     if(size%2==0){\n        int mid = size/2;\n       median = (float)(tempArr[mid-1]+tempArr[mid])/2;          \n     }\n    else{\n        median = tempArr[size/2];\n    }\n   \n    //checking notification         \n\n        if(expenditure[d+i]>=2*median){\n            count++;\n        }\n\n    }\nreturn count;\n}\n\n\n  public static void rearrange(int outgo,int income,int[]arr){\n  \n  int len = arr.length;\n  int i=0;\n  for( i=0;i<len;i++){\n      if(arr[i]==outgo){\n          arr[i]=income;\n          break;\n      }          \n  }\n  \n\nif(i==0){        \n if(arr[i+1]>=income){return;}\n else{\n      while(i+1<len  && arr[i+1]<income){\n         arr[i]=arr[i+1];\n         i++;\n     }\n     arr[i]=income;\n }\n}\nelse if(i==len-1){\n    if(arr[i-1]<=income){return;}\n else{\n     while( i>=1 & arr[i-1]>income ){\n         arr[i]=arr[i-1];\n         i--;\n     }\n     arr[i]=income;\n }\n }\n\n\nelse{\n    if(arr[i+1]<income){\n         while(i+1<len  && arr[i+1]<income){\n         arr[i]=arr[i+1];\n         i++;\n     }\n     arr[i]=income;\n    }\n     if(arr[i-1]>income){\n\n         while( i>=1 && arr[i-1]>income ){\n         arr[i]=arr[i-1];\n         i--;\n     }\n     arr[i]=income;            \n    }\n}\n"], ["def sum_divisors(n):\n    x = 1\n    a = 0\n    while n!=0 and x<n:\n        if n%x == 0:\n        a = a + x\n        x += 1  \n    #Return the sum of all divisors of n, not including n\n    return a\n\nprint(sum_divisors(0)) #0\n\nprint(sum_divisors(3)) # Should sum of 1\n\nprint(sum_divisors(36)) # Should sum of 1+2+3+4+6+9+12+18\n\nprint(sum_divisors(102)) # Should be sum of 2+3+6+17+34+51\n"], [], [], [], ["> C:\\Users\\MY\\PycharmProjects\\pythonProject>py -m venv venv\n> C:\\Users\\MY\\PycharmProjects\\pythonProject>cd venv\\Scripts\n> C:\\Users\\MY\\PycharmProjects\\pythonProject\\venv\\Scripts>activate\n"], [], ["from selenium import webdriver\nimport chromedriver_binary  # Adds chromedriver binary to path\nimport time\n\noptions = webdriver.ChromeOptions() \noptions.add_argument(\"start-maximized\")\ndriver = webdriver.Chrome(options=options)\n\ndriver.get('https://www.google.com/')\ntime.sleep(3600) # let the browser die after 1 hour\n"], ["python3.9 -m pip --version\n", "curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py\npython3.9 get-pip.py\n"], [], [], ["0   2015-02-04\n1   2016-03-05\ndtype: datetime64[ns]\n", "0   2015-02-04\n1   2016-03-05\ndtype: datetime64[ns]\n"], ["from django.contrib import admin\nfrom .models.models import User\nfrom django.contrib.auth.admin import UserAdmin\n\nadmin.site.register(User, UserAdmin)\n"], [], ["[14432:11656:1120/161059.539:ERROR:device_event_log_impl.cc(211)] [16:10:59.539] USB: usb_device_handle_win.cc:1020 Failed to read descriptor from node connection: A device attached to the system is not functioning. (0x1F)\n", "void UsbDeviceHandleWin::GotDescriptorFromNodeConnection(\n    TransferCallback callback,\n    scoped_refptr<base::RefCountedBytes> request_buffer,\n    scoped_refptr<base::RefCountedBytes> original_buffer,\n    Request* request_ptr,\n    DWORD win32_result,\n    size_t bytes_transferred) {\n  std::unique_ptr<Request> request = UnlinkRequest(request_ptr);\n  if (win32_result != ERROR_SUCCESS) {\n    SetLastError(win32_result);\n    USB_PLOG(ERROR) << \"Failed to read descriptor from node connection\";\n    std::move(callback).Run(UsbTransferStatus::TRANSFER_ERROR, nullptr, 0);\n    return;\n  }\n", "webdriver.Chrome(executable_path=r'C:\\webdriver\\chromedriver.exe') # to open the chromebrowser \ndriver.get(\"https://web.whatsapp.com\")\n"], [], ["from django.contrib.auth.models import User\nu = User.objects.get(username='john')\nu.set_password('new password')\nu.save()\n"], ["from django.contrib.auth.admin import UserAdmin as DjangoUserAdmin\nfrom django.contrib import admin\nfrom <my-app> import models    \n\n@admin.register(models.User)\nclass UserAdmin(DjangoUserAdmin):\n    \n    # extra logic:\n    ...\n"], [], ["self.features = nn.Sequential(\n            nn.Conv2d(3, 64, kernel_size=3,\n                      bias=False),\n            nn.BatchNorm2d(64),\n            nn.ReLU(inplace=True),\n            nn.Dropout(0.3),\n            nn.Conv2d(64, 64, kernel_size=3, padding = 1\n                      bias=False),\n            nn.BatchNorm2d(64),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=3, stride=2, padding = 32),\n        )\n"], [], ["import pandas as pd\nfrom sqlalchemy import create_engine, text\n\nengine = create_engine(postgresql://username:pass@host:port/dbname)\nquery = text(f\"\"\" \n                INSERT INTO schema.table(name, title, id)\n                VALUES {','.join([str(i) for i in list(df.to_records(index=False))])}\n                ON CONFLICT (id)\n                DO  UPDATE SET name= excluded.name,\n                               title= excluded.title\n         \"\"\")\nengine.execute(query)\n", "import pandas as pd\nfrom sqlalchemy import create_engine, text\n\ndf.name = df.name.str.replace(\"'\", \"''\")\ndf.title = df.title.str.replace(\"'\", \"''\")\nengine = create_engine(postgresql://username:pass@host:port/dbname)\nquery = text(\"\"\" \n            INSERT INTO author(name, title, id)\n            VALUES %s\n            ON CONFLICT (id)\n            DO  UPDATE SET name= excluded.name,\n                           title= excluded.title\n     \"\"\" % ','.join([str(i) for i in list(df.to_records(index=False))]).replace('\"', \"'\"))\nengine.execute(query)\n"], ["def nametag(first_name, last_name):\n    return(\"{} {[0]}.\".format(first_name,last_name))\n\nprint(nametag(\"Jane\", \"Smith\")) \nprint(nametag(\"Francesco\", \"Rinaldi\")) \n\nprint(nametag(\"Jean-Luc\", \"Grand-Pierre\")) \n"], [], [], [], [], [], ["  public static int immediateSmaller(int arr[], int n, int x){\n    // Your code here\n    int ele = -1;\n    int diff = Integer.MAX_VALUE;\n\n    for (int i = 0; i < n; i++)\n        if (arr[i] < x && (x - arr[i]) < diff){\n                ele = arr[i];\n                diff = x - arr[i];\n        }\n        \n    return ele;\n}\n"], ["driver = webdriver.Chrome(resource_path=\"C:\\webdriver\\chromedriver.exe\") # to open the chromebrowser \ndriver.get(\"https://web.whatsapp.com\")\n"], [], ["conda deactivate\n", "conda update anaconda-navigator\n"], ["def split(seq, sep):\n    from itertools import takewhile\n    iterator = iter(seq)\n    while subseq := list(takewhile(lambda x: x != sep, iterator)):\n        yield subseq\n"], [], [], [], ["BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\nsys.path.append(BASE_DIR)\n"], ["def sum_divisors(n):\n  sum = 0\n  x = 1\n  while n != 0 and x < n :\n      \n    if n % x == 0  :\n      sum += x\n    else:\n      sum += 0\n    x += 1    \n  return sum\n"], ["y = 0\nmylist = []\nfor i in range (1,100):\n  y += 3\n  mylist.append(y)\nprint (mylist)\n", "x = 0\nmylist = []\nfor i in range (1,100):\n  y = x + 3\n  x += 3 #update the x variable\n  mylist.append(y)\nprint (mylist)\n"], ["[x for x in range(1, 100) if x % 3 == 0]\n", "[x*3 for x in range(1, 100)]\n"], [], [], ["x = 0\nl = []\nfor i in range(1, 100):\n    x += 3\n    l.append(x)\n\nprint(l)\n"], [], ["if click:\n    color = click.style\n\n    if code[0] == \"1\":  # 1xx - Informational\n        msg = color(msg, bold=True)\n    ...\nself.log(\"info\", '\"%s\" %s %s', msg, code, size)\n", "import logging\n\nimport click\n    \n\nclass RemoveColorFilter(logging.Filter):\n    def filter(self, record):\n        if record and record.msg and isinstance(record.msg, str):\n            record.msg = click.unstyle(record.msg) \n        return True\n\nremove_color_filter = RemoveColorFilter()\nfile_handler_access_log.addFilter(remove_color_filter)\n"], ["import re\nfrom nltk.corpus import stopwords \ndef performStemAndLemma(textcontent):\n    # Write your code here\n    lancaster = nltk.LancasterStemmer()\n    porter = nltk.PorterStemmer()\n    wnl = nltk.WordNetLemmatizer()\n    tokens2_3 = nltk.regexp_tokenize(textcontent,  r'\\w+')\n    stop_words = set(stopwords.words('english'))\n    tokenisedwords=[words for words in set(tokens2_3) if not words.lower() in  stop_words ]\n    #print(tokenizedwords)\n    return [porter.stem(word.lower()) for word in set(tokenisedwords)],[lancaster.stem(word.lower()) for word in set(tokenisedwords)],[wnl.lemmatize(word.lower()) for word in set(tokenisedwords)]\n"], [], [], ["https://github.com/mwaskom/seaborn-data/blob/master/iris.csv\n", "import pandas as pd\n\npd.read_csv('https://raw.githubusercontent.com/mwaskom/seaborn-data/master/iris.csv')\n"], ["def split(sequence, sep):\n    chunk = []\n    for val in sequence:\n        if val == sep:\n            yield chunk\n            chunk = []\n        else:\n            chunk.append(val)\n    yield chunk\n"], ["#plt.show() // just comment out as it may not display from Pydroid Terminal anyway \n\nplt.savefig('yourplot.jpg') // save plot as Jpeg file for Android \n\nplt.close() // close matlab plotting \n"], ["[tool.black]\nexclude = '''\n/(\n  | migrations\n)/\n\n'''\n"], [" (x, y, w, h) = cv2.boundingRect(contour.astype(np.int))\n"], ["def sum_divisors(n):\n  sum = 0\n  accum = 1\n  # Return the sum of all divisors of n, not including n\n  while n != 0 and accum < n:\n    if n % accum == 0:\n      sum += accum\n    accum += 1\n  return sum\n\nprint(sum_divisors(0))\n# 0\nprint(sum_divisors(3)) # Should sum of 1\n# 1\nprint(sum_divisors(36)) # Should sum of 1+2+3+4+6+9+12+18\n# 55\nprint(sum_divisors(102)) # Should be sum of 2+3+6+17+34+51\n# 114\n"], ["brew uninstall --ignore-dependencies openssl@1.1\npyenv uninstall 3.5.2  # deinstall old versions compiled with the wrong version of openssl\npyenv install 3.5.2\n", "brew upgrade openssl\npyenv uninstall 3.7.4 # deinstall old versions compiled with the wrong version of openssl\npyenv install 3.7.4\n"], [], [], [], ["def sum_divisors(n):\n  sum = 0\n  accum = 1\n  while n != 0 and accum < n:\n    if n % accum == 0:\n      sum += accum\n    accum += 1\n  return sum\n\n\n\nprint(sum_divisors(6)) # prints 6\nprint(sum_divisors(12)) # prints 16\n"], ["conda install cython\n"], [], ["sudo ln -s /usr/bin/python3 /usr/bin/python\n"], ["python code_file_name.py\n"], ["def groups_per_user(group_dictionary):\n    user_groups = {}\n    # Go through group_dictionary\n    for group in group_dictionary:\n        # Now go through the users in the group\n        for user in group_dictionary[group]:\n            try:\n                user_groups[user].append(group)\n            except KeyError:\n                user_groups[user] = [group]\n            # Now add the group to the list of\n# groups for this user, creating the entry\n# in the dictionary if necessary\n\n    return(user_groups)\n"], [], ["def findMedian(counter, d):\n    count = 0\n    median = 0\n\n    if d%2 != 0:\n        for i in range(len(counter)):\n            count += counter[i]\n\n            if count > d//2:\n                median = i\n                break\n            \n    else:\n        first = 0\n        second = 0\n\n        for i, _ in enumerate(counter):\n            count += counter[i]\n            \n            if first == 0 and count >= d//2:\n                first = i\n                \n            if second == 0 and count >= d//2 + 1:\n                second = i\n                break\n            \n        median = (first+second) / 2\n        \n    return median\n\n\ndef activityNotifications(expenditure, d):\n    count = 0\n    counter = [0]*201\n    \n    for exp in range(d):\n        counter[expenditure[exp]] += 1\n\n    for i in range(d, len(expenditure)):\n        new = expenditure[i]\n        old = expenditure[i-d]\n        median = findMedian(counter, d)\n        \n        if new >= 2*median:\n            count += 1\n            \n        counter[old] -= 1\n        counter[new] += 1\n        \n    return count\n", "import pandas as pd\n\ndef activityNotifications(expenditure, d):\n    df = pd.DataFrame(expenditure)\n    return (df.shift(-1) > 2 * df.rolling(d).median())[0].sum()\n"], [], ["#pip install pdfminer.six\nimport io\n\nfrom pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\nfrom pdfminer.converter import TextConverter\nfrom pdfminer.layout import LAParams\nfrom pdfminer.pdfpage import PDFPage\n\n\ndef convert_pdf_to_txt(path):\n    '''Convert pdf content from a file path to text\n\n    :path the file path\n    '''\n    rsrcmgr = PDFResourceManager()\n    codec = 'utf-8'\n    laparams = LAParams()\n\n    with io.StringIO() as retstr:\n        with TextConverter(rsrcmgr, retstr, codec=codec,\n                           laparams=laparams) as device:\n            with open(path, 'rb') as fp:\n                interpreter = PDFPageInterpreter(rsrcmgr, device)\n                password = \"\"\n                maxpages = 0\n                caching = True\n                pagenos = set()\n\n                for page in PDFPage.get_pages(fp,\n                                              pagenos,\n                                              maxpages=maxpages,\n                                              password=password,\n                                              caching=caching,\n                                              check_extractable=True):\n                    interpreter.process_page(page)\n\n                return retstr.getvalue()\n\n\nif __name__ == \"__main__\":\n    print(convert_pdf_to_txt('C:\\\\Path\\\\To\\\\Test_PDF.pdf'))\n"], [], ["ifconfig | grep 255.255.255.0\n", "inet 192.168.43.248  netmask 255.255.255.0  broadcast 192.168.43.255\n", "#!/usr/bin/env python\nimport subprocess\ncmd = \"ifconfig | grep 255.255.255.0\"\ninet = subprocess.check_output(cmd, shell = True)\ninet = wlan.decode(\"utf-8\")\ninet = wlan.split(\" \")\ninet_addr = inet[inet.index(\"inet\")+1]\nprint(inet_addr)\n"], ["RUN python -m pip install git+URL_OF_GIT_REPO\n"], ["def performStemAndLemma(textcontent):\n    from nltk.corpus import stopwords\n"], [], [], ["import requests\nfrom bs4 import BeautifulSoup\nhtml_doc='''\n<table callspacing=\"0\" cellpadding=\"0\">\n    <tbody><tr>\n    <td>1text&nbsp;2text</td>\n    <td>3text&nbsp;</td>\n    </tr>\n    <tr>\n    <td>4text&nbsp;5text</td>\n    <td>6text&nbsp;</td>\n    </tr>\n</tbody></table>\n'''\n\nsoup = BeautifulSoup(html_doc, 'lxml')\nsoup1 = soup.select('tr')\n\nfor i in soup1:\n    print(i.select_one('td:nth-child(2)').text)\n", "trs = soup.find('table').find_all('tr')\n\nfor i in trs:\n    tds = i.find_all('td')\n    print(tds[1].text)\n", "3text \n6text \n"], ["from bs4 import BeautifulSoup\n\nhtml=\"\"\"\n<table callspacing=\"0\" cellpadding=\"0\">\n    <tbody><tr>\n    <td>1text&nbsp;2text</td>\n    <td>3text&nbsp;</td>\n    </tr>\n    <tr>\n    <td>4text&nbsp;5text</td>\n    <td>6text&nbsp;</td>\n    </tr>\n</tbody></table>\"\"\"\n\nsoup = BeautifulSoup(html, 'html.parser')\n\nfor tr_soup in soup.find_all('tr'):\n    td_soup = tr_soup.find_all('td')\n    print(td_soup[1].text.strip())\n"], [], ["from bs4 import BeautifulSoup\n\nhtml_doc='''\n<table callspacing=\"0\" cellpadding=\"0\">\n    <tbody><tr>\n    <td>1text&nbsp;2text</td>\n    <td>3text&nbsp;</td>\n    </tr>\n    <tr>\n    <td>4text&nbsp;5text</td>\n    <td>6text&nbsp;</td>\n    </tr>\n</tbody></table>\n'''\n\n\nsoup = BeautifulSoup(html_doc, \"html.parser\")\n\n# finds all tr tags\nfor i in soup.find_all(\"tr\"):\n    # finds all td tags in tr tags\n    for k in i.find_all(\"td\"):\n        # prints all td tags with a text format\n        print(k.text)\n", "# finds all tr tags\nfor i in soup.find_all(\"tr\"):\n    # finds all td tags in tr tags\n    print(i.find_all(\"td\")[1].text)\n"], ["from html.parser import HTMLParser\n\nclass MyHTMLParser(HTMLParser):\n    def __init__(self):\n        super().__init__()\n        self.in_cell = False\n        self.cell_index = -1\n\n    def handle_starttag(self, tag, attrs):\n        if tag == 'tr':\n            self.cell_index = -1\n        if tag == 'td':\n            self.in_cell = True\n            self.cell_index += 1\n        # print(\"Encountered a start tag:\", tag)\n\n    def handle_endtag(self, tag):\n        if tag == 'td':\n            self.in_cell = False\n        # print(\"Encountered an end tag :\", tag)\n\n    def handle_data(self, data):\n        if self.in_cell and self.cell_index == 1:\n            print(data.strip())\n\nparser = MyHTMLParser()\nparser.feed('''<table callspacing=\"0\" cellpadding=\"0\">\n    <tbody><tr>\n    <td>1text&nbsp;2text</td>\n    <td>3text&nbsp;</td>\n    </tr>\n    <tr>\n    <td>4text&nbsp;5text</td>\n    <td>6text&nbsp;</td>\n    </tr>\n</tbody></table>''')\n", "> python -u \"html_parser_test.py\"\n3text\n6text\n"], ["In [8]: import pandas as pd\n\nIn [9]: df =  pd.read_html(html_table)[0]\n\nIn [10]: df[1]\nOut[10]:\n0    3text\n1    6text\nName: 1, dtype: object\n"], ["task_1 >> [task_2 , task_3]\ntask_2 >> [task_4, task_5]\ntask_3 >> [task_4, task_5]\n[task_4 , task_5 ] >> task_6\n"], [" ftype Python.File\n", "set PYLAUNCH_DEBUG=1\n", "Computer\\HKEY_LOCAL_MACHINE\\SOFTWARE\\Python\\PythonCore\\3.7\\InstallPath\n"], [], ["fname = input(\"Enter file name: \")\nfh = open(fname)\nval = 0\ncount = 0\nfor line in fh:\n    if line.startswith(\"X-DSPAM-Confidence:\") :\n        count = count + 1\n        val=val + float(line[line.find('0'):])\n    elif not line.startswith(\"X-DSPAM-Confidence:\") :\n        continue\nprint(\"Average spam confidence:\",val/count)\n"], ["$ flatpak run --command=ls cc.arduino.arduinoide -l /usr/bin/|grep python\nlrwxrwxrwx  1 nfsnobody nfsnobody       9 Feb  5 16:30 python3 -> python3.7\n-rwxr-xr-x  2 nfsnobody nfsnobody   14512 Jan  1  1970 python3.7\nlrwxrwxrwx  1 nfsnobody nfsnobody      17 Feb  5 16:30 python3.7-config -> python3.7m-config\nlrwxrwxrwx  1 nfsnobody nfsnobody       9 Feb  5 16:30 python3.7m -> python3.7\n-rwxr-xr-x  2 nfsnobody nfsnobody    3309 Jan  1  1970 python3.7m-config\nlrwxrwxrwx  1 nfsnobody nfsnobody      16 Feb  5 16:30 python3-config -> python3.7-config\n", "$ cd /var/lib/flatpak/runtime/org.freedesktop.Platform/x86_64/19.08/active/files/bin\n$ sudo ln -s python3 python\n"], ["fname = input(\"Enter file name: \")\nfh = open(fname)\ncount = 0\npos = 0\nans = None\ntotal = 0\nfor line in fh:\n    if not line.startswith(\"X-DSPAM-Confidence:\") : \n        continue\n    else :\n        count = count + 1\n        pos = line.find(':')\n        ans = line[pos+1 : ]\n        total = total + float(ans)\navg = total/count\n"], ["int median(int arr[], int d)\n{\n    int med;\n    \n    int sum = 0;\n    for(int i = 0; i <= 200; i++)\n    {\n        sum = sum + arr[i];\n        if(sum>=d)\n        {\n            med = i;\n            break;\n        }\n    }\n    return med;\n}\n\nint activityNotifications(vector<int> expenditure, int d) {\n    int count  = 0;\n    int n = expenditure.size();\n    if(n==d)\n    {\n        return 0;\n    }\n    int temp[201]={0};\n    for(int i = 0; i < d; i++)\n    {\n        temp[expenditure[i]]++;\n    }\n    \n    int med = median(temp, d/2+d%2);\n    for(int i = d; i < n; i++)\n    {\n        if(d%2==0)\n        {\n            int temp_med = median(temp, d/2+1);\n            if(expenditure[i]>=med+temp_med)\n            {\n                count++;\n            }\n        }\n        else\n        {\n            if(expenditure[i]>=med*2)\n            {\n                count++;\n            }\n        }\n        \n        temp[expenditure[i-d]]--;\n        temp[expenditure[i]]++;\n        med = median(temp,d/2+d%2);\n    }\n    return count;\n}\n"], ["total = [0]\ndivisors = 1\nwhile divisors < n:\n    if n % divisors == 0:\n        result.append(divisors)\n    else:\n        pass\n    divisors += 1\nreturn sum(total)\n"], ["Python (3.6, 3.7, 3.8)\nDjango (2.0, 2.1, 2.2, 3.0)\nDjango REST Framework (3.8, 3.9, 3.10)\n", "pip uninstall django\npip uninstall djangorestframework\npip install --upgrade django==3.0\npip install --upgrade djangorestframework==3.10\npip install djangorestframework-simplejwt\n"], ["class Solution:\n  def searchInsert(self, array: List[int], target: int) -> int:\n      low = 0\n      high = len(array)\n\n      while low < high:\n          middle = (high + low) // 2\n\n          if array[middle] == target:\n              return middle\n\n          if array[middle] < target:\n             low = middle + 1\n\n          if array[middle] > target:\n             high = middle - 0\n    return low\n"], [], [], ["import math\n\n\nnumber = int(input('Enter a number: '))\nnext_pow_ten = round(10 ** math.ceil(math.log10(number)))\nprint(str(10) + ' power ' + str(round(math.log10(number))) + ' = '\\\n      + str(next_pow_ten))\n"], [">>> i = 0.04123\n>>> print i, 10 ** len(str(int(i))) if int(i) > 1 else 10 if i > 1.0 else 1 if i > 0.1 else 10 ** (1 - min([(\"%.100f\" % i).replace('.', '').index(k) for k in [str(j) for j in xrange(1, 10) if str(j) in \"%.100f\" % i]]))               \n0.04123 0.1\n>>> i = 0.712\n>>> print i, 10 ** len(str(int(i))) if int(i) > 1 else 10 if i > 1.0 else 1 if i > 0.1 else 10 ** (1 - min([(\"%.100f\" % i).replace('.', '').index(k) for k in [str(j) for j in xrange(1, 10) if str(j) in \"%.100f\" % i]]))                 \n0.712 1\n>>> i = 1.1\n>>> print i, 10 ** len(str(int(i))) if int(i) > 1 else 10 if i > 1.0 else 1 if i > 0.1 else 10 ** (1 - min([(\"%.100f\" % i).replace('.', '').index(k) for k in [str(j) for j in xrange(1, 10) if str(j) in \"%.100f\" % i]]))                   \n1.1 10\n>>> i = 90\n>>> print i, 10 ** len(str(int(i))) if int(i) > 1 else 10 if i > 1.0 else 1 if i > 0.1 else 10 ** (1 - min([(\"%.100f\" % i).replace('.', '').index(k) for k in [str(j) for j in xrange(1, 10) if str(j) in \"%.100f\" % i]]))                    \n90 100\n"], ["_, contours, hierarchy = cv2.findContours(img,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_NONE)\n", "_, contours, _ = cv2.findContours(img,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_NONE)\n"], [], ["if(num==0):\nreturn result;\n"], ["arr = [4, 67, 13, 12, 15]\nX = 16\n\nsmaller = -1\n\nfor i in arr:\n    if 0 < X - i < X - smaller:\n        smaller = i\n\nprint(smaller)  # or return if it's a function\n", "15\n"], [], [], ["model.compile(optimizer=tf.optimizers.Adam(), loss=\"sparse_categorical_crossentropy\")\n"], ["def grab(x, y, w, h):\n    screen = np.array(ImageGrab.grab(x, y, w, h)) # Throws XCB error\n    ...\n    return screen\n", "def grab(x, y, w, h):\n    screen = np.array(ImageGrab.grab(bbox=(x, y, w, h))) # Throws no errors\n    # screen = np.array(ImageGrab.grab()) # Alternative that grabs full screen\n    ...\n    return screen\n"], [" brew uninstall pyenv pyenv-virtualenv\n brew install pyenv pyenv-virtualenv\n pyenv uninstall 3.6.5\n pyenv install 3.6.5\n"], [], ["from selenium import webdriver\nchrome_path = \"D:\\chromedriver_win32\\chromedriver\"\ncustom_options = webdriver.ChromeOptions()\nprefs = {\n  \"translate_whitelists\": {\"ru\":\"en\"},\n  \"translate\":{\"enabled\":\"true\"}\n}\ncustom_options.add_experimental_option(\"prefs\", prefs)\ndriver=webdriver.Chrome(chrome_path, options=custom_options)\n"], ["from sqlalchemy import create_engine\n#create a connection from Postgre URI\ncnxn = create_engine(\"postgresql+psycopg2://username:password@host:port/database\")\n#write dataframe to database\ndf.to_sql(\"my_table\", con=cnxn, schema=\"myschema\")\n"], [], ["contours, _ = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n"], ["y = math.ceil(x)\nz = y + (10 - (y % 10))\n"], ["tf.train.AdamOptimizer() \n", "tf.optimizers.Adam()\n"], [], ["def nametag(first_name, last_name):\n    return '{} {}.'.format(first_name, last_name[0])\n"], ["def nextpow10(n):\n    return 10 ** math.ceil(math.log10(n))\n", ">>> import math\n>>> from numpy import nextafter\n>>> n = 1\n>>> while (10 ** math.ceil(math.log10(nextafter(n,math.inf)))) > n:\n...     n *= 10\n... \n>>> n\n10\n>>> nextafter(n,math.inf)\n10.000000000000002\n>>> 10 ** math.ceil(math.log10(10.000000000000002))\n10\n", "def nextpow10(n):\n    p = round(math.log10(n))\n    r = 10 ** p\n    if r < n:\n        r = 10 ** (p+1) \n    return r;\n", "n = -323 # 10**-324 == 0\nwhile n < 1000:\n    v = 10 ** n\n    if v != nextpow10(v): print(str(v)+\" bad\")\n    try:\n        v = min(nextafter(v,math.inf),v+1)\n    except:\n        v += 1\n    if v > nextpow10(v): print(str(v)+\" bad\")\n    n += 1\n"], ["def ceiling10(x):\n    if (x > 10):\n        return ceiling10(x / 10) * 10\n    else:\n        if (x <= 1):\n            return ceiling10(10 * x) / 10\n        else:\n            return 10\nfor x in [1 / 1235, 0.5, 1, 3, 10, 125, 12345]:\n    print(x, ceiling10(x))\n"], [">>> 10 ** math.ceil(math.log10(0.04))\n0.1\n>>> 10 ** math.ceil(math.log10(0.7))\n1\n>>> 10 ** math.ceil(math.log10(1.1))\n10\n>>> 10 ** math.ceil(math.log10(90))\n100\n", ">>> 10 ** math.ceil(math.log10(0.1))\n0.1\n>>> 10 ** math.ceil(math.log10(1))\n1\n>>> 10 ** math.ceil(math.log10(10))\n10\n"], ["def groups_per_user(group_dictionary):\n    user_groups = {}\n    for grp, users in group_dictionary.items():\n        for user in users:\n            if user in user_groups:\n                user_groups[user].append(grp)\n            else:\n                user_groups[user] = [grp]\n\n    return (user_groups)\n", "{'admin': ['local', 'public', 'administrator'], 'userA': ['local'], 'userB': ['public']}\n"], ["def groups_per_user(group_dictionary):\n    user_groups = {}\n    for group in group_dictionary:\n        for user in group_dictionary[group]:\n            if user not in user_groups:\n                user_groups[user] = []\n            if group not in user_groups[user]:\n                user_groups[user].append(group)\n    return user_groups\n\nmylist = {\"local\": [\"admin\", \"userA\"],\n          \"public\":  [\"admin\", \"userB\"],\n          \"administrator\": [\"admin\"] }\n\nprint(groups_per_user(mylist))\n# {'admin': ['local', 'public', 'administrator'], 'userA': ['local'], 'userB': ['public']}\n\n"], [], ["fig, ax = plt.subplots()\n", "first = plt.plot(ratios, final_z_scores[0])\nsecond = plt.plot(ratios, final_z_scores[1])\n", "first = plt.plot(ratios, final_z_scores[0], label='label1')\nsecond = plt.plot(ratios, final_z_scores[1], label='label2')\n...\nplt.legend()\nplt.plot()\n"], [], [], [], ["In [65]: v = hexArray.view(np.uint8)[::4]\n\nIn [66]: np.where(v>64,v-55,v-48)\nOut[66]: array([ 9, 10, 11], dtype=uint8)\n"], [], [" array1=[int(value, 16) for value in hexArray]\n print (array1)\n", "[9, 10, 11]\n"], ["[tool.black]\nline-length = 79\ninclude = '\\.pyi?$'\nexclude = '''\n/(\n    \\.git\n  | \\.hg\n  | \\.mypy_cache\n  | \\.tox\n  | \\.venv\n  | _build\n  | buck-out\n  | build\n  | dist\n  | migrations\n)/\n'''\n"], ["brew reinstall openssl\nbrew reinstall pyenv\nbrew reinstall pyenv-virtualenv\n", "brew uninstall pyenv pyenv-virtualenv\nbrew install pyenv pyenv-virtualenv\npyenv uninstall 3.x.x\npyenv install 3.x.x\npip install -r requirements.txt\n"], [], ["pyenv install 3.7.3\npyenv global 3.7.3\n"], ["training_images_labels_path\n"], ["mydir = 'C:/Users/Public/Desktop/project/data/generated'\nmyfile = 'training_images_labels.txt'\ntraining_images_labels_path = os.path.join(mydir, myfile)\n\nwith open(training_images_labels_path,'r') as file:\n    lines = file.readlines()\n", "with open('training_images_labels.txt','r') as file:\n        lines = file.readlines()\n"], [], ["class YourForm(forms.ModelForm):\n    media_data = SimpleArrayField(JSONField(), required=False, widget=forms.Textarea, delimiter='|')\n"], ["brew uninstall python\nrm -rf $(pyenv root)\nbrew uninstall pyenv-virtualenv   # you may not have this installed, but...\nbrew uninstall pyenv\n", "brew install pyenv\npyenv install 3.6.10  (or whatever version you want)\n"], [], ["pip install opencv-python-headless==3.4.9.31\n"], [], ["import math \ndef sum_divisors(num) : \n\n    # Final result of summation of divisors \n    result = 0\n\n    # find all divisors which divides 'num' \n    i = 2\n    while i<= (math.sqrt(num)) : \n\n        # if 'i' is divisor of 'num' \n        if (num % i == 0) : \n\n            # if both divisors are same then \n            # add it only once else add both \n            if (i == (num / i)) : \n                result = result + i; \n            else : \n                result = result +  (i + num//i); \n        i = i + 1\n\n    # Add 1 to the result as 1 is also  \n    # a divisor \n    return (result + 1); \n\nprint(sum_divisors(6))\nprint(sum_divisors(12))\n"], ["if n%divisor==0:\n      return divisor\n      divisor = divisor + 1 //<= this is actually dead code, since is after the return statement...\n", "divisor = divisor + 1\n", "accum = 0\nwhile divisor < n:\n    foo = n % divisor\n    if foo == 0:\n    accum = accum + divisor\n"], [], ["model.compile(optimizer = tf.keras.optimizers.Adam(),\n              loss = 'sparse_categorical_crossentropy',\n              metrics=['accuracy'])\n"], [], ["assoc .py=Python.File\n", "ftype Python.File=\"C:\\Path\\to\\pythonw.exe %1 %*\"\n"], ["    public static double findMedian(int a[]) {\n        int n = a.length;\n        if (n % 2 != 0)\n            return (double) a[n / 2];\n\n        return (double) (a[(n - 1) / 2] + a[n / 2]) / 2.0;\n    }\n\n    static void swap(int[] arr, int i, int j) {\n        int temp = arr[i];\n        arr[i] = arr[j];\n        arr[j] = temp;\n    }\n\n    static int activityNotifications(int[] expenditure, int d) {\n        if (d >= expenditure.length) return 0;\n\n        int numNotifications = 0;\n        int[] trailingArr = new int[d];\n        for (int i = 0; i < trailingArr.length; i++) {\n            trailingArr[i] = expenditure[i];\n        }\n        Arrays.sort(trailingArr);\n        for (int i = d; i < expenditure.length; i++) {\n            double median = findMedian(trailingArr);\n            if (expenditure[i] >= 2.0 * median) {\n                numNotifications += 1;\n            }\n            int nextToRemoveElement = expenditure[i - d];\n            int toInsertElement = expenditure[i];\n            adjustTrailingArray(trailingArr, nextToRemoveElement, toInsertElement);\n        }\n        return numNotifications;\n    }\n\n    //This whole thing is O(d) time. Note that we are not sorting again as trailing array was already sorted\n    // as preprocessing and now only one new element has to find its position in sorted array.\n\n    private static void adjustTrailingArray(int[] trailingArr, int elementToRemove, int elementToInsert) {\n        if (elementToInsert == elementToRemove) return;\n        int foundIndex = 0;\n\n        //The first element of unsorted trailing array will move out of the sliding window\n        //Since the trailing array was sorted by us, we have lost the position of its first element in original array.\n        //Hence, I search linearly for it and replace it with the new element.\n\n        while (foundIndex < trailingArr.length) {\n            if (trailingArr[foundIndex] != elementToRemove) {\n                foundIndex++;\n            } else {\n                trailingArr[foundIndex] = elementToInsert;\n                break;\n            }\n        }\n\n        //Now we bubble the new element just inserted using bubble sort to left/right based on whether it was bigger\n        //or smaller than the element that got removed.\n\n        if (elementToInsert > elementToRemove) {\n            int i = foundIndex;\n            while (i < trailingArr.length - 1) {\n                if (trailingArr[i] > trailingArr[i + 1]) {\n                    swap(trailingArr, i, i + 1);\n                    i += 1;\n                } else break;\n            }\n        } else {\n            int i = foundIndex;\n            while (i > 0) {\n                if (trailingArr[i] < trailingArr[i - 1]) {\n                    swap(trailingArr, i, i - 1);\n                    i -= 1;\n                } else break;\n            }\n        }\n    }\n"], ["from pdfreader import SimplePDFViewer, PageDoesNotExist\n\nfd = open(you_pdf_file_name, \"rb\")\nviewer = SimplePDFViewer(fd)\n\nplain_text = \"\"\npdf_markdown = \"\"\n\ntry:\n    while True:\n        viewer.render()\n        pdf_markdown += viewer.canvas.text_content\n        plain_text += \"\".join(viewer.canvas.strings)\n        viewer.next()\nexcept PageDoesNotExist:\n    pass\n\n"], [], ["import numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.collections import PatchCollection\n\nN = 10\nM = 11\nylabels = [\"\".join(np.random.choice(list(\"PQRSTUVXYZ\"), size=7)) for _ in range(N)]\nxlabels = [\"\".join(np.random.choice(list(\"ABCDE\"), size=3)) for _ in range(M)]\n\nx, y = np.meshgrid(np.arange(M), np.arange(N))\ns = np.random.randint(0, 180, size=(N,M))\nc = np.random.rand(N, M)-0.5\n\nfig, ax = plt.subplots()\n\nR = s/s.max()/2\ncircles = [plt.Circle((j,i), radius=r) for r, j, i in zip(R.flat, x.flat, y.flat)]\ncol = PatchCollection(circles, array=c.flatten(), cmap=\"RdYlGn\")\nax.add_collection(col)\n\nax.set(xticks=np.arange(M), yticks=np.arange(N),\n       xticklabels=xlabels, yticklabels=ylabels)\nax.set_xticks(np.arange(M+1)-0.5, minor=True)\nax.set_yticks(np.arange(N+1)-0.5, minor=True)\nax.grid(which='minor')\n\nfig.colorbar(col)\nplt.show()\n"], ["import pdfplumber\npdf = pdfplumber.open('pdffile.pdf')\npage = pdf.pages[0]\ntext = page.extract_text()\nprint(text)\npdf.close()\n"], ["import pandas as pd\nfrom bokeh.palettes import RdBu\nfrom bokeh.models import LinearColorMapper, ColumnDataSource, ColorBar\nfrom bokeh.models.ranges import FactorRange\nfrom bokeh.plotting import figure, show\nfrom bokeh.io import output_notebook\n\nimport numpy as np\n\noutput_notebook()\n\nd = dict(x = ['A','A','A', 'B','B','B','C','C','C','D','D','D'], \n         y = ['B','C','D', 'A','C','D','B','D','A','A','B','C'], \n         corr = np.random.uniform(low=-1, high=1, size=(12,)).tolist())\n\ndf = pd.DataFrame(d)\n\ndf['size'] = np.where(df['corr']<0, np.abs(df['corr']), df['corr'])*50\n#added a new column to make the plot size\n\ncolors = list(reversed(RdBu[9]))\nexp_cmap = LinearColorMapper(palette=colors, \n                             low = -1, \n                             high = 1)\n\n\np = figure(x_range = FactorRange(), y_range = FactorRange(), plot_width=700, \n           plot_height=450, title=\"Correlation\",\n           toolbar_location=None, tools=\"hover\")\n\np.scatter(\"x\",\"y\",source=df, fill_alpha=1,  line_width=0, size=\"size\", \n          fill_color={\"field\":\"corr\", \"transform\":exp_cmap})\n\np.x_range.factors = sorted(df['x'].unique().tolist())\np.y_range.factors = sorted(df['y'].unique().tolist(), reverse = True)\n\np.xaxis.axis_label = 'Values'\np.yaxis.axis_label = 'Values'\n\nbar = ColorBar(color_mapper=exp_cmap, location=(0,0))\np.add_layout(bar, \"right\")\n\nshow(p)\n\n"], [], [], [], ["WorkspaceFolder:\n    SubFolder:\n      MyScript.py\n      ImportMe.py\n", "from importme import * since the file location is added to the path\n", "from SubFolder.importme import *\n"], ["from ttp import ttp\n\ndata_to_parse = \"\"\"\nDateGroup1\n20191129\n20191127\n20191126\nDateGroup2\n20191129\n20191127\n20191126\nDateGroup3\n2019-12-02\nDateGroup4\n2019-11-27\nDateGroup5\n2019-11-27\n\"\"\"\n\nttp_template = \"\"\"\n<group name=\"date_groups.date_group{{ id }}\">\nDateGroup{{ id }}\n{{ dates | to_list | joinmatches() }}\n</group>\n\"\"\"\n\nparser = ttp(data=data_to_parse, template=ttp_template)\nparser.parse()\nprint(parser.result(format=\"json\")[0])\n", "[\n    {\n        \"date_groups\": {\n            \"date_group1\": {\n                \"dates\": [\n                    \"20191129\",\n                    \"20191127\",\n                    \"20191126\"\n                ]\n            },\n            \"date_group2\": {\n                \"dates\": [\n                    \"20191129\",\n                    \"20191127\",\n                    \"20191126\"\n                ]\n            },\n            \"date_group3\": {\n                \"dates\": [\n                    \"2019-12-02\"\n                ]\n            },\n            \"date_group4\": {\n                \"dates\": [\n                    \"2019-11-27\"\n                ]\n            },\n            \"date_group5\": {\n                \"dates\": [\n                    \"2019-11-27\"\n                ]\n            }\n        }\n    }\n]\n"], ["import sys\nfrom io import StringIO  # allows treating some lines in editor as if they were from a file)\n\ndat=StringIO(\"\"\"DateGroup1\n20191129\n20191127\n20191126\nDateGroup2\n20191129\n20191127\n20191126\nDateGroup3\n2019-12-02\nDateGroup4\n2019-11-27\nDateGroup5\n2019-11-27\"\"\")\n\nlines=[ l.strip() for l in dat.readlines()]    \nprint(lines) \n", "   ['DateGroup1', '20191129', '20191127', '20191126', 'DateGroup2', '20191129', '20191127', '20191126', 'DateGroup3', '2019-12-02', 'DateGroup4', '2019-11-27', 'DateGroup5', '2019-11-27']\n", "from datetime import datetime\nb=[]\nfor i,line in enumerate(lines):\n    try:             # try first dateformat\n        do = datetime.strptime(line, '%Y%m%d')\n        a.append(datetime.strftime(do,'%Y-%m-%d'))\n    except:\n        try:         # try second dateformat\n            do=datetime.strptime(line,'%Y-%m-%d')\n            a.append(datetime.strftime(do,'%Y-%m-%d'))\n        except:       # if neither date, append old list to list of lists  & make a new list\n            if a!=None:\n                b.append(a)\n            a=[]\n    if i==len(lines)-1:\n        b.append(a)\n\nb\n", " [['2019-11-27'],\n ['2019-11-29', '2019-11-27', '2019-11-26'],\n ['2019-11-29', '2019-11-27', '2019-11-26'],\n ['2019-12-02'],\n ['2019-11-27'],\n ['2019-11-27']]\n"], ["DATE_GROUP_SEPARATOR = 'DateGroup'\nsorted_data = {}\n\nwith open('test.txt') as file:\n    last_group = None\n    for line in file.readlines():\n        line = line.replace('\\n', '')\n        if DATE_GROUP_SEPARATOR in line:\n            sorted_data[line] = []\n            last_group = line\n        else:\n            sorted_data[last_group].append(line)\n\nfor date_group, dates in sorted_data.items():\n    print(f\"{date_group}: {dates}\")\n"], ["file = open(\"dates.txt\")\ntext = file.read()\nfile.close()\n\namountGroups = text.count(\"DateGroup\")\n\nlist = []\n\nindex = 0\ni = 0\nfor i in range(amountGroups):\n    list.append([])\n\n    index = text.find(\"DateGroup\", index)\n    index = text.find(\"\\n\", index) + 1\n    indexEnd = text.find(\"DateGroup\", index)\n    if(indexEnd == -1):\n        indexEnd = len(text)\n    while(index < indexEnd):\n        indexNewline = text.find(\"\\n\", index)\n        list[i].append(text[index:indexNewline])\n        index = indexNewline + 1\n\nprint(list)\n"], ["import os\n\n#read file\nlineList = 0\nwith open(\"test.txt\") as f:\n  lineList = f.readlines()\n\n#make new list to hold variables\nlists = []\n\n#loop through and check for numbers and strings\ny=-1\nfor x in range(len(lineList)):\n    #check if it is a number or a string\n    if(lineList[x][0] is not None and not lineList[x][0].isdigit()):\n        #if it is a string make a new list and push back the name\n        lists.append([lineList[x]])\n        y+=1\n    else:\n        #if it is the number append it to the current list\n        lists[y].append(lineList[x])\n\n#print the lists\nfor x in lists:\n    print(x)\n"], ["myproj/\n    setup.py\n    alembic/\n        env.py\n        migrations/\n    myapp/\n        __init__.py\n        alchemy/\n            __init__.py\n        models/\n            __init__.py\n"], ["setup(name=\"<module name>\",\n        version=\"0.1\",\n        packages=['<package name if any or ignore>'],\n        install_requires=['pandas==0.25.1']\n    )\n"], ["from setuptools import setup\n\nsetup(name=\"pandasmodule\",\n        version=\"0.1\",\n        packages=[],\n        install_requires=['pandas==0.25.1']\n    )\n", "python setup.py bdist_wheel\n"], ["Mac-Admin:~ admin$ python3\nPython 3.7.4 (default, Sep  7 2019, 18:27:02) \n[Clang 10.0.1 (clang-1001.0.46.4)] on darwin\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n>>> import ssl\n>>> ssl\n<module 'ssl' from '/usr/local/Cellar/python/3.7.4_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/ssl.py'>\n>>> import _ssl\n>>> _ssl\n<module '_ssl' from '/usr/local/Cellar/python/3.7.4_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/lib-dynload/_ssl.cpython-37m-darwin.so'>\n"], ["from bisect import bisect_left, insort_left\n\nn, d = map(int, input().split())\nt = list(map(int, input().split()))\nnoti = 0\n\nlistD = sorted(t[:d])\n\ndef median():\n  return listD[d//2] if d%2 == 1 else ((listD[d//2] + listD[d//2-1])/2)\n\nfor i in range(d,n):\n  if t[i] >= 2*median(): noti += 1\n  del listD[bisect_left(listD, t[i-d])]\n  insort_left(listD, t[i])\nprint(noti)\n"], ["#include <iostream>\n#include <cstring>\n#include <cmath>\n#include <cstring>\nusing namespace std;\nint maxlen=1,minlen=1,heapsize;\ndouble median=0,ct=0;\nvoid min_heapify(double arr[],int i)\n{\n    int l=(2*i);\n    int r=(2*i+1);\n    int smallest;\n    if(l<=heapsize && arr[l]<arr[i])\n    {\n        smallest=l;\n    }\n    else\n    {\n        smallest=i;\n    }\n    if(r<=heapsize && arr[r]<arr[smallest])\n    {\n        smallest=r;\n    }\n    if(smallest==i)\n        return;\n    if(smallest!=i)\n    {\n        double swap=arr[i];\n        arr[i]=arr[smallest];\n        arr[smallest]=swap;\n    }\n    min_heapify(arr,smallest);\n}\nvoid max_heapify(double arr[], int i)\n{\n    int l=(2*i);\n    int r=(2*i+1);\n    int largest;\n    if(l<=heapsize && arr[l]>arr[i])\n    {\n        largest=l;\n    }\n    else\n    {\n        largest=i;\n    }\n    if(r<=heapsize && arr[r]>arr[largest])\n    {\n        largest=r;\n    }\n    if(largest==i)\n        return;\n    if(largest!=i)\n    {\n        double swap=arr[i];\n        arr[i]=arr[largest];\n        arr[largest]=swap;\n    }\n    max_heapify(arr,largest);\n}\nvoid insert_valuein_minheap(double minh[], int i, double val)\n{\n    minh[i]=val;\n    while(i>1 && minh[i/2]>minh[i])\n    {\n        double temp=minh[i/2];\n        minh[i/2]=minh[i];\n        minh[i]=temp;\n        i=i/2;\n    }\n}\nvoid insert_valuein_maxheap(double maxh[], int i, double val)\n{\n    maxh[i]=val;\n    while(i>1 && maxh[i/2]<maxh[i])\n    {\n        double temp=maxh[i/2];\n        maxh[i/2]=maxh[i];\n        maxh[i]=temp;\n        i=i/2;\n    }\n}\nvoid insert_element(double maxh[], double minh[], double val, int size)\n{\n    if(val<=maxh[1])\n    {\n        maxlen+=1;\n        insert_valuein_maxheap(maxh,maxlen,val);\n    }\n    else\n    {\n        minlen+=1;\n        insert_valuein_minheap(minh,minlen,val);\n    }\n    if(maxlen==minlen)\n    {\n        median=(maxh[1]+minh[1])/2;\n        ct=1;\n        return;\n    }\n    if(maxlen<minlen)\n    {\n        maxlen+=1;\n        insert_valuein_maxheap(maxh,maxlen,minh[1]);\n        double temp=minh[1];\n        minh[1]=minh[minlen];\n        minh[minlen]=temp;\n        minlen-=1;\n        heapsize=minlen;\n        min_heapify(minh,1);\n    }\n    else\n    {\n        minlen+=1;\n        insert_valuein_minheap(minh,minlen,maxh[1]);\n        double temp=maxh[1];\n        maxh[1]=maxh[maxlen];\n        maxh[maxlen]=temp;\n        maxlen-=1;\n        heapsize=maxlen;\n        max_heapify(maxh,1);\n    }\n}\nint main()\n{\n    int n,td,notif=0;\n    cin>>n>>td;\n    double array[n+1],maxh[n+1]={},minh[n+1]={};\n    for(int i=1;i<=n;i++)\n    {\n        cin>>array[i];\n    }\n    double first,second;\n    for(int i=1,j;i<=n-td;i++)\n    {\n        int count=2;\n        first=array[i];\n        second=array[i+1];\n        if(first<=second)\n        {\n            maxh[1]=first;\n            minh[1]=second;\n        }\n        else\n        {\n            maxh[1]=first;\n            minh[1]=second;\n        }\n        maxlen=1;minlen=1;ct=0;\n        for(j=i+2;count!=td;j++)\n        {\n            insert_element(maxh,minh,array[j],j);\n            count++;\n        }\n        if(td%2!=0)\n        {\n            if(maxlen>minlen)\n                median=maxh[1];\n            else\n                median=minh[1];\n        }\n        else if(ct==0)\n        {\n            median=(maxh[1]+minh[1])/2;\n        }\n        float nota=array[j];\n        if(nota>=2*median)\n        {\n            notif++;\n        }\n    }\n    cout<<notif<<endl;\n}\n"], ["df.reindex(df.columns[df.columns != 'date'].union(['date']), axis=1) \n", "   A  B  C  D  E  F  G  H  I  date\n0  0  1  2  3  4  8  6  7  9     5\n"], ["original = df.columns\nnew_cols = original.delete(original.get_loc('date'))\ndf.reindex(columns=new_cols)\n"], ["df_new=df.loc[:,df.columns!='date']\ndf_new['date']=df['date']\n"], ["print(df)\n   col1  col2  col3\n0     1    11   111\n1     2    22   222\n2     3    33   333\n\ns = df.pop('col1')\nnew_df = pd.concat([df, s], 1)\nprint(new_df)\n", "   col2  col3  col1\n0    11   111     1\n1    22   222     2\n2    33   333     3\n"], ["new_cols = [col for col in df.columns if col != 'date'] + ['date']\ndf = df[new_cols]\n", "cols = ['A','B','C','D','E','date','G','H','F','I']\ndf = pd.DataFrame([np.arange(len(cols))],\n                  columns=cols)\n\nprint(df)\n#    A  B  C  D  E  date  G  H  F  I\n# 0  0  1  2  3  4     5  6  7  8  9\n", "   A  B  C  D  E  G  H  F  I  date\n0  0  1  2  3  4  6  7  8  9     5\n"], ["import string\n\n// returns a string of all the alphabets\n// abcdefghijklmnopqrstuvwxyz\"\n\n   result = string.ascii_letters \n\n// get the index of the input alphabet and return the next alphabet in the results string. \n// using the modulus to make sure when 'Z' is given as the input it returns to the first alphabet. \n\n   result[(result.index(alphabet.lower()) + 1) % 26].upper() \n"], ["alpha=input()\nif alpha =='Z': print('A')\nelse:print(chr(ord(alpha)+1))\n"], ["char_input = input()\nreturn chr((ord(char_input) - ord('A') + 1) % 26 + ord('A'))\n"], ["my_chr = ord(input())\nif my_chr == 90:\n        print('A')\nelse:\n    print(chr(my_chr+1))\n"], ["_chr = input('Enter character(A-Z): ')\nif _chr == 'Z':\n    print('A')\nelse:\n    print(chr(ord(_chr) + 1))\n"], ["from datetime import datetime\ndf['myDt'] = df.apply(lambda row: datetime.strptime(f\"{int(row.year)}-{int(row.month)}-{int(row.day)}\", '%Y-%m-%d'), axis=1)\n"], ["df['dateInt']=df['year'].astype(str) + df['month'].astype(str).str.zfill(2)+ df['day'].astype(str).str.zfill(2)\ndf['Date'] = pd.to_datetime(df['dateInt'], format='%Y%m%d')\n", "    year  month day dateInt     Date\n0   2015    5   20  20150520    2015-05-20\n1   2016    6   21  20160621    2016-06-21\n2   2017    7   22  20170722    2017-07-22\n3   2018    8   23  20180823    2018-08-23\n4   2019    9   24  20190924    2019-09-24\n"], ["tf.optimizers.Adam()\n"], [], [], ["import datetime\n\nnow = datetime.datetime.now()\ndelta = (now - datetime.datetime(1970,1,1))\nprint(delta.total_seconds())\n"], ["import time\nprint(time.time())\n", "1567532027.192546\n"], ["now = datetime.now()\n...\nreturn [len(removed_elts) == 0, score, now.timestamp()]\n"], ["sns.regplot(x=score,y=target,data=df)\nplt.show()\n"], [], ["var_name = ','.join(df[\"Name\"])\n"], [], ["','.join(dataframe['column'].tolist())\n", "dataframe['column'].to_csv(header=False)\n"], ["out = df['Name'].to_csv(path_of_buf=None, header=False, index=False)\n"], ["df[my_columns].tolist()\n", "','.join(df[my_columns].tolist())\n"], ["st = ','.join(df[\"Name\"])\n"], ["def myfunc(st):\nstr=''\nfor index, l in enumerate(st):\n    if index % 2 == 0:\n        str+=l.upper()\n    else:\n        str+=l.lower()\nreturn str\n"], ["host_name = socket.gethostname()`\nhost_addr = socket.gethostbyname(host_name)\n", "host_addr = socket.gethostbyname(host_name + \".local\")\n"], [], ["newstring = ''.join(map(lambda x: x if not x.isdigit() else \"\", string.split() ))\n", "newstring = ' '.join(map(lambda x: x if not x.isdigit() else \"\", string.split() )).replace('  ', ' ')\n"], [">>> string = \"these 5 sentences should not have 2 numbers in them\"\n>>> string.split()\n['these', '5', 'sentences', 'should', 'not', 'have', '2', 'numbers', 'in', 'them']\n>>> token = string.split()[3]\n>>> token\n'should'\n>>> token.isdigit()\nFalse\n>>> token is not token.isdigit()\nTrue\n>>> token = string.split()[1]\n>>> token\n'5'\n>>> token is not token.isdigit()\nTrue\n"], [], ["newString = \" \".join([x for x in string.split() if x.isdigit() == False])\n"], ["def upLow(s):\n    return \"\".join(c.lower() if i&1 else c.upper() for i,c in enumerate(s))\nupLow(\"HelloWorld\") # HeLlOwOrLd\n"], ["def my_func(st):\n\n    res = []\n    #Iterate over the character\n    for index in range(len(st)):\n        if index % 2 == 0:\n            #Refer to each character via index and append modified character to list\n            res.append(st[index].upper())\n        else:\n            res.append(st[index].lower())\n\n    #Join the list into a string and return\n    return ''.join(res)\n", "def my_func(st):\n\n    res = []\n    #Iterate over the characters\n    for index, c in enumerate(st):\n        if index % 2 == 0:\n            #Refer to each character via index and append modified character to list\n            res.append(c.upper())\n        else:\n            res.append(c.lower())\n\n    #Join the list into a string and return\n    return ''.join(res)\nprint(my_func('helloworld'))\n", "HeLlOwOrLd\n"], ["def my_func(st):\n    operations = (str.lower, str.upper)\n    return ''.join(operations[i%2](x) for i, x in enumerate(st))\n\nprint(my_func('austin'))\n# aUsTiN\n"], [], [], [], ["print(\n    Path(__file__).parent,  # the folder\n    Path(__file__).parent.parent,  # the folder's parent\n    sep='\\n'\n)\n\nprint(\n    Path(\n        Path(__file__).parent.parent, 'hello.py'\n    )\n)\n", "C:\\Users\\isik\\Desktop\\Python\\MessAround\\project\\module\nC:\\Users\\isik\\Desktop\\Python\\MessAround\\project\nC:\\Users\\isik\\Desktop\\Python\\MessAround\\project\\hello.py\n", "-project\n    -module\n        -__init__.py\n    -hello.py\n    -__init__.py\n"], ["import os\nfilePath = os.path.dirname(__file__)+'/../'+fileName\nfileDesc = open(filePath)\nfileData = fileDesc.read()\nfileDesc.close()\n...\n"], ["\n#decimalToBinary\n\nnum=int(input(\"Enter number\"))\noutput = []\nwhile num!=0:\n    bin=num%2\n    num=num//2\n    output.append(bin)\n\nprint (output[::-1])\n", "print (' '.join([str(o) for o in output[::-1]]))\n", "#decimalToBinary\n\nnum=int(input(\"Enter number\"))\noutput = ''\nwhile num!=0:\n    bin=num%2\n    num=num//2\n    output = str(bin) + output\n\nprint (output)\n"], ["    1) form.is_valid() \n       ->form.full_clean()\n        -->form._clean_fields()\n         ---> self.cleand_data[name] = field.clean(value)\n    2) field.clean(value)\n        -> self.to_python(value)\n        -> self.validate(value)\n", "# These values, if given to validate(), will trigger the self.required check.\nEMPTY_VALUES = (None, '', [], (), {})\n"], ["from __future__ import print_function\nnum=int(input(\"Enter number\"))\nbin = []\nwhile num!=0: \n    bin.append(num%2) \n    num=num//2\nprint(*bin[::-1], sep=' ')\n"], ["num = 13\nbin = \"\"\nwhile num!=0:\n    bin += str(num%2) + \" \"\n    num=num//2\n\nbin = bin.strip();\n\nprint(bin[::-1])\n"], ["num=int(input(\"Enter number\"))\ndigits = []\nwhile num!=0:\n    bin=num%2\n    num=num//2\n    digits.append(bin)\n", "print(digits[::-1]) #this will possibly need formatting.\n", "print(\" \".join(str(x) for x in L[::-1]))\n"], ["num=int(input(\"Enter number\"))\nlst=list()\nwhile num!=0:\n    bin=num%2\n    num=num//2\n    lst.append(bin)\n\nprint(lst,lst[::-1])\n", "Enter number13\n[1, 0, 1, 1] [1, 1, 0, 1]\n"], ["def replace_exception_chars(string):\n    exception_chars_dict = {'Old': 'New', 'old': 'new'}\n\n    #Iterate over key and value together\n    for key, value in exception_chars_dict.items():\n        #If key is found, replace key with value and assign to new string\n        if key in string:\n            string = string.replace(key, value)\n\n    return string\n\nprint(replace_exception_chars('Old, not old'))\n", "New, not new\n"], [" string.replace(exception_char, exception_chars_dict[exception_char])\n", "string = string.replace(exception_char, exception_chars_dict[exception_char])\n"], ["string.replace(exception_char, exception_chars_dict[exception_char])\n", "string = string.replace(exception_char, exception_chars_dict[exception_char])\n", "def replace_exception_chars(string):\n    exception_chars_dict = {'Old': 'New', 'old': 'new'}\n    exception_chars_keys = list(exception_chars_dict.keys())\n    for exception_char in exception_chars_keys:\n        if exception_char in string:\n            string = string.replace(exception_char, exception_chars_dict[exception_char])\n    return string\n\nprint(replace_exception_chars('Old, not old'))\n"], ["def replace_exception_chars(string):\n    exception_chars_dict = {'Old': 'New', 'old': 'new'}\n    exception_chars_keys = list(exception_chars_dict.keys())\n    for exception_char in exception_chars_keys:\n        if exception_char in string:\n            string = string.replace(\n                exception_char, exception_chars_dict[exception_char])\n    return string\n\n\nprint(replace_exception_chars('Old, not old'))\n# New, not new\n"], [], ["string = string.replace(exception_char, exception_chars_dict[exception_char])\n"], [], [], ["def check_arr_str(li):\n\n    #Filter out elements which are of type string\n    res = list(filter(lambda x: isinstance(x,str), li))\n\n    #If length of original and filtered list match, all elements are strings, otherwise not\n    return (len(res) == len(li) and isinstance(li, list))\n\n", "print(check_arr_str(['a','b']))\n#True\nprint(check_arr_str(['a','b', 1]))\n#False\nprint(check_arr_str(['a','b', {}, []]))\n#False\nprint(check_arr_str('a'))\n#False\n", "def check_arr_str(li):\n\n    res = list(filter(lambda x: isinstance(x,str), li))\n    if (len(res) == len(li) and isinstance(li, list)):\n        raise TypeError('I am expecting list of strings')\n", "def check_arr_str(li):\n\n    #Check if any instance of the list is not a string\n    flag = any(not isinstance(i,str) for i in li)\n\n    #If any instance of an item  in the list not being a list, or the input itself not being a list is found, throw exception\n    if (flag or not isinstance(li, list)):\n        raise TypeError('I am expecting list of strings')\n"], ["l = [\"abc\", \"def\", \"ghi\", \"jkl\"]  \nisinstance(l, list) and all(isinstance(i,str) for i in l)\n", "In [1]: a = [\"abc\", \"def\", \"ghi\", \"jkl\"]                                        \n\nIn [2]: isinstance(a, list) and all(isinstance(i,str) for i in a)               \nOut[2]: True\n\nIn [3]: a = [\"abc\", \"def\", \"ghi\", \"jkl\",2]                                      \n\nIn [4]: isinstance(a, list) and all(isinstance(i,str) for i in a)               \nOut[4]: False\n"], ["def foo(my_str_list):\n    is_list = isinstance(my_str_list, list) \n    are_strings = all(isinstance(x, str) for x in my_str_list)\n    if not is_list or not are_strings:\n        raise TypeError(\"Funtion argument should be a list of strings.\")\n    ...\n"], [">>> isinstance([\"abc\", \"def\", \"ghi\", \"jkl\"], list)\nTrue\n>>> isinstance(50, list)\nFalse\n"], ["def stepsToZero(N):\n    return N if N < 2 else 2 + stepsToZero(N//2-1)\n", "import math\ndef steps2Zero(N):\n    if N < 2: return N\n    d = int(math.log(N+2,2))-1\n    s = int(N >= 3*2**d-2)\n    return 2*d+s\n"], ["#test(1)\n1 // 2 = 0\n0 - 1 = -1\n...\n"], ["def test(x):\n    return x.count('1') + len(x) - 1\n"], ["import pdftables_api\nimport os\n\nc = pdftables_api.Client('MY-API-KEY')\n\nfile_path = \"C:\\\\Users\\\\MyName\\\\Documents\\\\PDFTablesCode\\\\\"\n\nfor file in os.listdir(file_path):\n    if file.endswith(\".pdf\"):\n        c.xlsx(os.path.join(file_path,file), file+'.xlsx')\n"], ["from tika import parser\n\nrawText = parser.from_file('January2019.pdf')\n\nrawList = rawText['content'].splitlines()\n"], ["    import pdftotext\n\n    pdfFileObj = open(\"January2019.pdf\", 'rb')\n\n\n    pdf = pdftotext.PDF(pdfFileObj)\n\n    # Iterate over all the pages\n    for page in pdf:\n        print(page)\n"], ["In [229]: desired_list = pd.Series(all_df_list).drop_duplicates().tolist()\n\nIn [230]: desired_list\nOut[230]:\n[   ID  Year  Score\n 0   1  2018     80\n 1   2  2018     70,    ID  Year  Score\n 0   1  2017     77\n 1   3  2017     62]\n", "In [231]: desired_list[0] == df1\nOut[231]:\n     ID  Year  Score\n0  True  True   True\n1  True  True   True\n\nIn [232]: desired_list[1] == df2\nOut[232]:\n     ID  Year  Score\n0  True  True   True\n1  True  True   True\n"], ["desired_list = [all_df_list[x] for x, _ in enumerate(all_df_list) if all_df_list[x].equals(all_df_list[x-1]) is False]\n\nprint(desired_list)\n[   ID  Year  Score\n0   1  2018     80\n1   2  2018     70,    ID  Year  Score\n0   1  2017     77\n1   3  2017     62]\n", "df1.equals(df1)\nTrue\n\ndf1.equals(df2)\nFalse\n"], ["_,idx=np.unique(np.array([x.values for x in all_df_list]),axis=0,return_index=True)\ndesired_list=[all_df_list[x] for  x in idx ]\ndesired_list\nOut[829]: \n[   ID  Year  Score\n 0   1  2017     77\n 1   3  2017     62,    ID  Year  Score\n 0   1  2018     80\n 1   2  2018     70]\n"], ["from functools import reduce\nreduced_df = reduce(lambda left, right: pd.merge(left, right, on=None, how='outer'),\n                    all_df_list)\nprint(reduced_df)\n#    ID  Year  Score\n# 0   1  2018     80\n# 1   2  2018     70\n# 2   1  2017     77\n# 3   3  2017     62\n"], ["import numpy_indexed as npi\nnpi.intersect(a, b)\n"], ["def array_intersect(a, b):\n    s = {tuple(x) for x in a}\n    return np.unique([x for x in b if tuple(x) in s], axis=0)\n"], ["In [31]: from scipy.spatial.distance import cdist\n\nIn [32]: np.unique(array1a[np.where(cdist(array1a, array1b) == 0)[0]], axis=0)\nOut[32]: \narray([[2],\n       [5]])\n\nIn [33]: np.unique(array2a[np.where(cdist(array2a, array2b) == 0)[0]], axis=0)\nOut[33]: \narray([[2, 1],\n       [3, 3]])\n"], ["import numpy as np\n\narray2a = np.array([[1, 2], [3, 3], [2, 1], [1, 3], [2, 1]])\narray2b = np.array([[2, 1], [1, 4], [3, 3]])\n\ntest = array2a[:, None] == array2b\nprint(array2b[np.all(test.mean(0) > 0, axis = 1)]) # [[2 1]\n                                                   # [3 3]]\n"], ["import numpy as np\n\narray2a = np.array([[1, 2], [3, 3], [2, 1], [1, 3], [2, 1]])\narray2b = np.array([[2, 1], [1, 4], [3, 3]])\n\n\na = set((tuple(i) for i in array2a))\nb = set((tuple(i) for i in array2b))\n\na.intersection(b) # {(2, 1), (3, 3)}\n"], ["app.config[\"SQLALCHEMY_DATABASE_URI\"] = os.getenv(\"postgresql://postgres:password@localhost/database1\")\n", "app.config[\"SQLALCHEMY_DATABASE_URI\"] = \"postgresql://postgres:password@localhost/database1\"\n", "export SQLALCHEMY_DATABASE_URI='postgresql://postgres:password@localhost/database1'\n", "app.config[\"SQLALCHEMY_DATABASE_URI\"] = os.environ.get('SQLALCHEMY_DATABASE_URI')\n"], ["app.config[\"SQLALCHEMY_DATABASE_URI\"] = os.getenv(\"DATABASE_URI\")\n", "app.config[\"SQLALCHEMY_DATABASE_URI\"] = \"postgresql://postgres:password@localhost/database1\"\n"], ["$ python\nPython 3.7.0 (default, Aug 20 2018, 15:06:39) \n[GCC 6.3.0 20170516] on linux\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n>>> import os  \n>>> editor = os.getenv('EDITOR')\n>>> print(editor)\nvi\n"], ["import operator\nimport functools\n\n\nif __name__ == \"__main__\":\n    nums = []\n\n    for i in range(10):\n        nums.append(functools.partial(operator.add, i))\n    for i in nums:\n        print(i(1))\n"], ["            nums = []\n            x=0\n            for i in range(10):\n                j = lambda x,i : x + i\n                nums.append(j)\n            for i in nums:\n                print(i(1,1))\n"], ["j = lambda x: x + i\n", "print(i(1))\n", "if __name__ == \"__main__\":\n  nums = []\n  for i in range(10):\n    def generate_lambda(i):\n      return lambda x: x + i\n    j = generate_lambda(i)\n    nums.append(j)\n  for i in nums:\n    print(i(1))\n"], [">>> i=1\n>>> a=lambda x:x+i\n>>> a(5)\n6\n>>> i=2\n>>> a(5)\n7\n", "nums = []\nfor i in range(10):\n    j = lambda x: x + i\n    nums.append(j)\nfor f in nums:\n    print(f(1))\n", "10\n10\n10\n10\n10\n10\n10\n10\n10\n10\n", "nums = []\nfor i in range(10):\n    j = lambda x,i=i: x + i\n    nums.append(j)\nfor f in nums:\n    print(f(1))\n", "1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n"], ["j = lambda x: x + i\n", "j = (lambda y: lambda x: x + y)(i)\n"], [], [], ["options = Options()\nprefs = {\n  \"translate_whitelists\": {\"fr\":\"en\"},\n  \"translate\":{\"enabled\":\"true\"}\n}\noptions.add_experimental_option(\"prefs\", prefs)\nbrowser = webdriver.Chrome(chrome_options=options)\n"], [], [], ["s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\ns.connect((\"8.8.8.8\", 80))\nprint s.getsockname()[0]\n"], ["IPAddr = socket.gethostbyname(socket.getfqdn())\n"], ["# makefile\ngit clone REPO\ncd REPO_DIR; python setup.py bdist_wheel\ncp REPO_DIR/dist/* .\nrm -rf REPO_DIR/\n", "# dockerfile\nRUN pip install REPO*.whl\n"], ["cd WORKING_DIRECTORY\npip install --target ./ GIT_URL\n"], ["import pandas as pd\n\nurl = 'https://raw.githubusercontent.com/lukes/ISO-3166-Countries-with-Regional-Codes/master/all/all.csv'\ndf = pd.read_csv(url, index_col=0)\nprint(df.head(5))\n"], [], ["    import numpy as np\n    import pandas as pd\n\n    column = [_ for _ in 'ABCDEFGH']\n    row = range(12, 0, -1)\n    # board = np.full((12, 8), 7) # to test dtype changes\n    board = np.full((12, 8), '||')\n    df0 = pd.DataFrame(board, index=row, \n    columns=column).sort_index(ascending=False)\n", "    footer = {'A':'A', 'B':'B', 'C':'C', 'D':'D', 'E':'E', 'F':'F', 'G':'G', 'H':'H'}\n", "    keys = list(df0.columns.values)\n    values = list(df0.columns.values)\n    footer = dict(zip(keys, values))\n", "    df1 = df0.append(footer, ignore_index=True)\n", "    df2 = df0.append(pd.Series((pd.Series(footer)), name='Footer'))  # Change 'Footer' to any text\n", "    df3 = df0.append(pd.Series((pd.Series(footer)), name=''))  # Same as df2 but blank name\n", "    df4 = df3\n    df4.columns = [''] * len(df4.columns)\n\n    print(df4)  # OP's solution\n"], ["String_4 = 'The price is 114 euros'\n"], ["import re\nString_1 = 'The price is 15 euros.'\nif float(re.findall(r'\\d+', String_1)[0]) > 14:\n    print(\"OK\")\n"], ["import re\np = re.compile('price\\sis\\s\\d\\d*')\nstring1 = 'The price is 15 euros'\nstring2 = 'The price is 14 euros'\n\nnumber = re.findall(p, string1)[0].split(\"price is \")\n\nif int(number[1]) > 14:\n    print('ok')\n", "ok\n"], ["str = \"price is 16 euros\"\nfor number in [int(s) for s in str.split() if s.isdigit()]:\n    if (number > 14):\n        print \"ok\"\n"], ["if int(s.split()[3]) > 14:\n    print('ok')\n"], ["from tabulate import tabulate\nimport pandas as pd\n\ndf = pd.DataFrame({'col_two' : [0.0001, 1e-005 , 1e-006, 1e-007],\n                   'column_3' : ['ABCD', 'ABCD', 'long string', 'ABCD']})\nprint(tabulate(df, headers='keys', tablefmt='psql'))\n\n+----+-----------+-------------+\n|    |   col_two | column_3    |\n|----+-----------+-------------|\n|  0 |    0.0001 | ABCD        |\n|  1 |    1e-05  | ABCD        |\n|  2 |    1e-06  | long string |\n|  3 |    1e-07  | ABCD        |\n+----+-----------+-------------+\n"], ["def split(seq, sep):\n    seq, peek = iter(seq), sep\n    while True:\n        try:\n            peek = next(seq)\n        except StopIteration:\n            break\n        yield list(it.takewhile(sep.__ne__, it.chain((peek,), seq)))\n    if peek == sep:\n        yield []\n"], ["def split(seq, sep):\n    start, stop = 0, -1\n    while start < len(seq):\n        try:\n            stop = seq.index(sep, start)\n        except ValueError:\n            yield seq[start:]\n            break\n        yield seq[start:stop]\n        start = stop + 1\n    else:\n        if stop == len(seq) - 1:\n            yield []\n"], ["from pprint import pprint\nmy_array = [\"a\", \"SEP\", \"SEP\", \"SEP\"]\nmy_temp = []\nmy_final = []\nfor item in my_array:\n  if item != \"SEP\":\n    my_temp.append(item)\n  else:\n    my_final.append(my_temp);\n    my_temp = []\npprint(my_final);\n"], ["l = ['a', 'SEP', 'b', 'c', 'SEP', 'SEP', 'd']\n\ndef sublist_with_words(word, search_list):\n    res = []\n    for i in range(search_list.count(word)):\n        index = search_list.index(word)\n        res.append(search_list[:index])\n        search_list = search_list[index+1:]\n    res.append(search_list)\n    return res\n", "print(sublist_with_words(word = 'SEP', search_list=l))\nprint(sublist_with_words(word = 'SEP', search_list=['a', 'b', 'c']))\nprint(sublist_with_words(word = 'SEP', search_list=['SEP']))\n", "[['a'], ['b', 'c'], [], ['d']]\n[['a', 'b', 'c']]\n[[], []]\n"], ["import re\n\ndef split_list(nums, n):\n    nums_str = str(nums)\n    splits = nums_str.split(f\"{n},\")\n\n    patc = re.compile(r\"\\d+\")\n    group = []\n    for part in splits:\n        group.append([int(v) for v in patc.findall(part)])\n\n    return group\n\nif __name__ == \"__main__\":\n    l = [1, 2, 3, 4, 3, 6, 7, 3, 8, 9, 10]\n    n = 3\n    split_l = split_list(l, n)\n    assert split_l == [[1, 2], [4], [6, 7], [8, 9, 10]]\n"], ["def mySplit(iterable, sep):\n    output = []\n    sepcount = 0\n    current_output = []\n    for i, elem in enumerate(iterable):\n        if elem != sep:\n            sepcount = 0\n            current_output.append(elem)\n            if (i==(len(iterable)-1)):\n                output.append(current_output)\n        else:\n            if current_output: \n                output.append(current_output)\n                current_output = []\n\n            sepcount+=1\n\n            if (i==0) or (sepcount > 1):\n                output.append([])\n            if (i==(len(iterable)-1)):\n                output.append([])\n\n    return output\n", "testLists = [\n    ['a', 'SEP', 'b', 'c', 'SEP', 'SEP', 'd'],\n    [\"a\", \"SEP\", \"SEP\", \"SEP\"],\n    [\"SEP\"],\n    [\"a\", \"b\", \"c\"]\n]\n\nfor tl in testLists:\n    print(mySplit(tl, sep=\"SEP\"))\n#[['a'], ['b', 'c'], [], ['d']]\n#[['a'], [], [], []]\n#[[], []]\n#[['a', 'b', 'c']]\n", "for tl in testLists:\n    print(\"\".join(tl).split(\"SEP\"))\n#['a', 'bc', '', 'd']\n#['a', '', '', '']\n#['', '']\n#['abc']\n", "for tl in testLists:\n    print([list(x) for x in \"\".join(tl).split(\"SEP\")])\n#[['a'], ['b', 'c'], [], ['d']]\n#[['a'], [], [], []]\n#[[], []]\n#[['a', 'b', 'c']]\n"], ["class Solution:\n    def searchInsert(self, nums, target):\n        \"\"\"\n        :type nums: List[int]\n        :type target: int\n        :rtype: int\n        \"\"\"\n        nums.append(target)         \n        nums.sort()                 \n        for i,j in enumerate(nums): \n            if target == j:         \n                return i            \n"], ["chrome_options = Options()\nchrome_options.add_argument(\"--lang=en\")\n"], ["class Solution(object):\n    def searchInsert(self, nums, target):\n        \"\"\"\n        :type nums: List[int]\n        :type target: int\n        :rtype: int\n        \"\"\"\n        try:\n            return nums.index(target)\n        except:\n            for i in range(len(nums)):\n                print i\n                if nums[i] - target > 0:\n                    return i\n\n            print \"hello\", len(nums)\n            return len(nums)\n", "from bisect import bisect_left\nprint(bisect_left([1,3,5,6],4))\n"], ["  for i in range(len(nums)):\n      if nums[i] - target > 0:\n          return i  # return if True\n      else: \n          return len(nums)  # return if False\n", "def searchInsert(self, nums, target):\n    try:\n        return nums.index(target)\n    except IndexError:  # best to use explicit except\n        for index, value in enumerate(nums):  # more pythonic than range(len(nums))\n             if value > target:\n                  return index\n        return len(nums)\n"], ["count = 0\nfname = input(\"Enter file name: \")\nfh = open(fname)\nfor line in fh:\n    if line.startswith(\"X-DSPAM-Confidence:\") :\n        print(line)\n        value = line[line.rfind(':'):]  # will take the last occurrence of : to slice the line\n        print(value)\n        count = count + 1\nprint(count)\n"], ["float(line.split(':')[1])\n"], ["count = 0\nfname = input(\"Enter file name: \")\nfh = open(fname)\nfor line in fh:\n    if line.startswith(\"X-DSPAM-Confidence:\") :\n        print(line)\n        value = line.split(':')[-1]  # will split line into 'X-DSPAM-Confidence' and 'value'\n        # if you have ',' at the end of the line, simply do this:\n        value = value.strip(',')\n        value = float(value)\n        print(value)\n        count = count + 1\nprint(count)\n"]]