[[">>> import pandas as pd\n>>> df = pd.DataFrame(pair_array)\n>>> pd.crosstab(df[0], df[1])\n1    69   183  254  267  382\n0\n18     1    0    0    0    0\n31     0    1    0    1    1\n183    0    0    0    1    1\n205    0    0    1    0    2\n254    0    0    0    0    1\n"], [], ["with open(filename) as f:\n    reader = csv.reader(f)\n    next(reader)\n\n    list_ = []\n\n    for row in reader:\n        list_.append(row)\n"], ["def broadcast(fun):\n    return lambda *x: numpy.broadcast_arrays(fun(*x), *x)[0]\n"], [">>> print (True) if set(range(1,100)) & set(range(90,150)) else print (False)\nTrue\n\n>>> print (True) if set(range(1,100)) & set(range(110,150)) else print (False)\nFalse\n", "def compare_ranges(x,y):\n    return True if set(x) & set(y) else False\n\ncompare_ranges(range(1,100),range(110,150))\ncompare_ranges(range(1,100),range(90,150))\n", "False\nTrue\n", "compare(['a','b','c','d'],['a','c','e','f'])\ncompare(['a','b','c','d'],['e','f','g','h'])\n", "True\nFalse\n"], ["readRegion=[*range(end,start,2)] #this list is always 600 in length\nrefRegion=[*range(600000,600500,1)] #this range will vary\nregionUnion = set(readRegion).intersection(set(refRegion))\nprint(len(regionUnion))\n"], ["a = range(end, start, 1)\nb = range(600000, 600500, 1)\noverlapping = (b.start <= a.start < b.stop) or (a.start <= b.start < a.stop)\n", "def ranges_overlap(a: range, b: range) -> bool:\n    if b.start <= a.start < b.stop:\n        return (a.start - b.start) % b.step == 0\n    if a.start <= b.start < a.stop:\n        return (b.start - a.start) % a.step == 0\n    return False\n"], [">>> def range_intersect(a: range, b:range) -> range:\n...     assert a.step == b.step == 1\n...     return range(max((a.start, b.start)), min((a.stop, b.stop)))\n...\n>>> range_intersect(range(1, 10), range(5, 20))\nrange(5, 10)\n", ">>> len(range_intersect(range(1, 3), range(5, 10)))\n0\n"], ["def overlaps(x, y):\n    return max(x.start,y.start) < min(x.stop,y.stop)\n\nprint(overlaps(range(10, 100), range(94, 200))\n"], ["df.sort_values(\n    by='bit', \n    key=lambda x: x.str.replace('bit_', '').astype(int),\n)\n\n    bit     val\n11  bit_0   40.9\n9   bit_1   49.6\n4   bit_2   50.5\n0   bit_3   37.7\n6   bit_4   52.0\n"], ["In [1038]: ix = df.bit.str.extract('(\\d+)', expand=False).astype(int).argsort().tolist()\n\nIn [1039]: df.loc[ix]\nOut[1039]: \n       bit   val\n11   bit_0  40.9\n9    bit_1  49.6\n4    bit_2  50.5\n0    bit_3  37.7\n6    bit_4  52.0\n19   bit_5  55.1\n2    bit_6  40.6\n8    bit_7  37.8\n16   bit_8  39.2\n14   bit_9  51.1\n3   bit_10  48.4\n18  bit_11  49.8\n17  bit_12  51.7\n10  bit_13  46.7\n5   bit_14  40.8\n15  bit_15  41.1\n1   bit_16  36.7\n7   bit_17  50.8\n13  bit_18  41.6\n12  bit_19  41.3\n"], ["df.sort_values('bit',key=lambda x: x.str.split(\"_\",expand=True)[1].astype(int))\n", "       bit   val\n11   bit_0  40.9\n9    bit_1  49.6\n4    bit_2  50.5\n0    bit_3  37.7\n6    bit_4  52.0\n19   bit_5  55.1\n2    bit_6  40.6\n8    bit_7  37.8\n16   bit_8  39.2\n14   bit_9  51.1\n3   bit_10  48.4\n18  bit_11  49.8\n17  bit_12  51.7\n10  bit_13  46.7\n5   bit_14  40.8\n15  bit_15  41.1\n1   bit_16  36.7\n7   bit_17  50.8\n13  bit_18  41.6\n12  bit_19  41.3\n", "df.sort_values('bit',key=lambda x: x.str.split(\"_\",expand=True)[1].astype(int)).reset_index(drop=True)\n", "       bit   val\n0    bit_0  40.9\n1    bit_1  49.6\n2    bit_2  50.5\n3    bit_3  37.7\n4    bit_4  52.0\n5    bit_5  55.1\n6    bit_6  40.6\n7    bit_7  37.8\n8    bit_8  39.2\n9    bit_9  51.1\n10  bit_10  48.4\n11  bit_11  49.8\n12  bit_12  51.7\n13  bit_13  46.7\n14  bit_14  40.8\n15  bit_15  41.1\n16  bit_16  36.7\n17  bit_17  50.8\n18  bit_18  41.6\n19  bit_19  41.3\n"], ["from natsort import index_natsorted\ndf = df.iloc[index_natsorted(df.bit)]\ndf\nOut[195]: \n       bit   val\n11   bit_0  40.9\n9    bit_1  49.6\n4    bit_2  50.5\n0    bit_3  37.7\n6    bit_4  52.0\n19   bit_5  55.1\n2    bit_6  40.6\n8    bit_7  37.8\n16   bit_8  39.2\n14   bit_9  51.1\n3   bit_10  48.4\n18  bit_11  49.8\n17  bit_12  51.7\n10  bit_13  46.7\n5   bit_14  40.8\n15  bit_15  41.1\n1   bit_16  36.7\n7   bit_17  50.8\n13  bit_18  41.6\n12  bit_19  41.3\n"], ["# create series of bit integers, sort them\nbit_vals = df.bit.str.split(\"_\", expand=True).loc[:, 1].astype(int)\nsort_series = bit_vals.sort_values()    \n\n# pass back to dataframe\ndf = df.iloc[sort_series.index]\n", "       bit   val\n11   bit_0  40.9\n9    bit_1  49.6\n4    bit_2  50.5\n0    bit_3  37.7\n6    bit_4  52.0\n19   bit_5  55.1\n2    bit_6  40.6\n8    bit_7  37.8\n16   bit_8  39.2\n14   bit_9  51.1\n3   bit_10  48.4\n18  bit_11  49.8\n17  bit_12  51.7\n10  bit_13  46.7\n5   bit_14  40.8\n15  bit_15  41.1\n1   bit_16  36.7\n7   bit_17  50.8\n13  bit_18  41.6\n12  bit_19  41.3\n"], ["def float_swap(x): # 2.5\n    a = x - int(x) # a = 2.5 - 2 = 0.5\n    b = int(x)     # b = 2\n    return str(b+a)# str(2 + 0.5)\n\nprint(float_swap(2.5))\n# 2.5 \n", "def float_swap(x): # 2.5\n    return '.'.join(str(float(x)).split('.')[::-1])\n\nprint(float_swap(2.5))\nprint(float_swap(37))\n", "5.2\n0.37\n"], ["x = \"a sequence of words\"\ny = x[0]\n", "z = x[0:10]\n"], ["x= \"a sequence of words\"\nprint(x.split(\" \",1)[0])\n"], ["x.split()[0]\n"], [], [], ["x = \"a sequence of words\"\nprint(x[0])\n"], ["def float_swap(x):\n    return f\"{x % 1 * 10:.0f}.{x:.0f}\"\n\nprint(float_swap(2.5))\nprint(float_swap(37))\n", "> python3 test.py\n5.2\n0.37\n>\n"], [], ["def float_swap(x):\n    ix = int(x)\n    if x == ix:\n        return f\"0.{ix}\"\n    return '.'.join(str(x).split(\".\")[::-1])\n\nprint(float_swap(2.5))\n\nprint(float_swap(37))\n", "5.2\n0.37\n"], ["def swap(num):\n  num = str(float(num))\n  a, b = num.split('.')\n  res = b + '.' + a\n  return res\n\n\nprint(swap(2)) # 0.2\nprint(swap(21.34)) # 34.21\n"], ["def float_swap(x):\n    a = float(x)\n    a, b = str(a).split('.')\n    return b + '.' + a\n"], ["def float_swap(x):\n    s=str(float(x))\n    return s[s.find('.')+1:]+'.'+ s[:s.find('.')]\n"], ["def repeat(string,number):\nfstring = \"\"\nfor var in range(1,number):\n     fstring+=fstring+string\nprint(fstring)\nrepeat(\"Hi\",3)\n"], ["    fstring = \"\"\n    for var in range(1,number+1):\n         fstring+=string\n    print(fstring)\nrepeat(\"Hi\",3)\n"], ["         fstring+=fstring+string\n", "def repeat(s, number):\n    result = ''\n    for _ in range(0, number):\n         result += s\n    return result\n\nprint(repeat(\"Hi\", 3))\n"], ["fstring=fstring+string\n", "fstring+=string\n"], ["def repeat(string,number):\n    fstring = \"\"\n    for var in range(1,number+1):\n         fstring+=string\n    return fstring\nrepeat(\"Hi\",3)\n", "print(repeat(\"Hi\",3))\n"], ["fstring+=fstring+string\n", "fstring = fstring + fstring + string\n", "fstring += string\n"], ["with open('file.txt') as reader, open('file.txt', 'r+') as writer:\n  for line in reader:\n    if line.strip():\n      writer.write(line)\n  writer.truncate()\n"], ["with open('path/to/file.txt', 'r') as f:\n    with open('path/to/target.txt', 'w') as <b>w</b>:\n    for line in f:\n        if line.strip():\n            <b>w.write(line)</b>", "with open('path/to/file.txt', 'r') as f:\n    with open('path/to/target.txt', 'w') as <b>w</b>:\n    for line in f:\n        line = line<b>.strip()</b>\n        if line:\n            w.write(line)\n            <b>w.write('\\n')</b>"], ["write_position = 0\nwith open('file.txt', 'rb+') as f:\n  for line in f:\n    if line.strip():\n      read_position = f.tell()\n      f.seek(write_position)\n      f.write(line)\n      write_position = f.tell()\n      f.seek(read_position)\n  f.truncate(write_position)\n"], ["with open('path/to/file.txt', 'r') as f: #this opens the file in read mode\n    lines = [line for line in f.readlines() if line.strip() != \"\"] #this puts all the lines of the file into a nice list, but removes every line that is empty. \n\nwith open('path/to/file.txt', 'w') as f: #this just clears the contents\n    pass \n\nfor line in lines: #this goes through the lines list\n    with open('path/to/file.txt', 'a') as f: #this opens the file append mode\n        f.write(f'{line.strip()}\\n') #this strips the line, and adds it at the end of the file and creates a new line\n"], ["with open(\"txt.txt\", \"r\") as f:\n  for l in f:\n    if l == \"\\n\":\n      l = l.replace(\"\\n\", \"\")\n    with open(\"output.txt\", \"a\") as f2:\n        f2.write(l)\n"], ["with open('path/to/file.txt', 'r+') as f:\n    lines = f.readlines()\n    lines = [line.strip() for line in lines]\n    f.writelines(line)\n"], ["with open('path/to/file.txt', 'r') as f:  \n    new_text = '\\n'.join([line.strip() for line in f.read().split('\\n')] if line.strip())\n    with open('path/to/file.txt','w') as in_file: \n        in_file.write(new_text)\n"], [], ["import functools\n\n\nclass reprable:\n    \"\"\"Decorates a function with a repr method.\n\n    Example:\n        >>> @reprable\n        ... def foo():\n        ...     '''Does something cool.'''\n        ...     return 4\n        ...\n        >>> foo()\n        4\n        >>> foo.__name__\n        'foo'\n        >>> foo.__doc__\n        'Does something cool.'\n        >>> repr(foo)\n        'foo: Does something cool.'\n        >>> type(foo)\n        <class '__main__.reprable'>\n    \"\"\"\n\n    def __init__(self, wrapped):\n        self._wrapped = wrapped\n        functools.update_wrapper(self, wrapped)\n\n    def __call__(self, *args, **kwargs):\n        return self._wrapped(*args, **kwargs)\n\n    def __repr__(self):\n        return f'{self._wrapped.__name__}: {self._wrapped.__doc__}'\n"], ["def beginning(lst):\n    new_list = []\n    start = 0\n    while start < 10 and lst[start] != 'bye':\n        new_list.append(lst[start])\n        start += 1\n        \n    return new_list\n\nlist1 = [\"Hello\", \"There\", \"bye\", \"Hi\", \"K\", \"EHEH\", \"Edkf\"]\nprint(beginning(list1))\n"], ["def display_function(func):\n    \"\"\" This decorator prints before and after running \"\"\"\n\n    @functools.wraps(func)\n    def function_wrapper(*args, **kwargs):\n        print(f'\\nNow: Calling {func.__name__}.')\n        entity = func(*args, **kwargs)\n        print(f'Done: Calling {func.__name__}.\\n')\n        return entity\n\n    return function_wrapper\n", "import retrying\n@retrying.retry(wait_exponential_multiplier=1000, wait_exponential_max=10000)\n"], ["class myfunction:\n    @staticmethod   # Avoids need to receive unused self\n    def __call__(your, args, here):\n        ... do stuff and return as if it were a function ...\n\n    @classmethod    # Know about class, but again, instance is useless\n    def __repr__(cls):\n        return f'{cls.__name__}(a, b, c)'\n", "myfunction = myfunction()\n"], ["class CustomReprFunc:\n\n    def __init__(self, f, custom_repr):\n        self.f = f\n        self.custom_repr = custom_repr\n\n    def __call__(self, *args, **kwargs):\n        return self.f(*args, **kwargs)\n\n    def __repr__(self):\n        return self.custom_repr(self.f)\n\n\ndef set_repr(custom_repr):\n    def set_repr_decorator(f):\n        return CustomReprFunc(f, custom_repr)\n    return set_repr_decorator\n\n\n@set_repr(lambda f: f.__name__)\ndef func(a):\n    return a\n\n\nprint(repr(func))\n"], [">>> repr(lambda x:x)\n'<function <lambda> at 0x1100f6ee0>'\n"], ["import requests\nfrom bs4 import BeautifulSoup as bs\n\nres = requests.get('https://finance.yahoo.com/quote/SQQQ/')   \nsoup = bs(res.content, 'lxml')\nfor stock in soup.find_all('span', class_='Trsdu(0.3s) Fw(b) Fz(36px) Mb(-4px) D(ib)'):\n    print(stock.get_text())\n"], ["nums = [6, 7, 11, 15, 3, 6, 5, 3,99,5,4,7,2]\ntarget = 27\nn = 0\n\nfor i in range(len(nums)):\n    \n    n+=1\n    if n == len(nums):\n      n == len(nums)\n      \n    else:\n        if nums[i]+nums[n] == target:\n          # to find the target position \n          print([nums.index(nums[i]),nums.index(nums[n])])\n          # to get the actual numbers to add print([nums[i],nums[n]])\n"], ["import networkx as nx\n\nG = nx.from_edgelist(pair_array, create_using=nx.MultiGraph)\nnx.to_pandas_adjacency(G, nodelist=sorted(G.nodes()), dtype='int')\n\n      18   31   69   183  205  254  267  382\n18     0    0    1    0    0    0    0    0\n31     0    0    0    1    0    0    1    1\n69     1    0    0    0    0    0    0    0\n183    0    1    0    0    0    0    1    1\n205    0    0    0    0    0    1    0    2\n254    0    0    0    0    1    0    0    1\n267    0    1    0    1    0    0    0    0\n382    0    1    0    1    2    1    0    0\n"], [], [], ["df['Name'] = df['Age'].astype(str).str.cat(df['Name'], sep=' ')\n\n        Name  Age\n0    10 Alex   10\n1     12 Bob   12\n2  13 Clarke   13\n"], ["df['Name'] = df['Age'].map(str) + ' ' + df['Name']\n"], ["In [2511]: df['Name'] = df[\"Age\"].astype(str) + \" \" + df[\"Name\"]\n\nIn [2511]: df['Name']\nOut[2511]: \n0      10 Alex\n1       12 Bob\n2    13 Clarke\n"], ["import os\n\ndct = {'apt-get'         : ['update', 'upgrade', 'other commands', 'etc.'],\n       'apt-get install' : ['libatlas-base-dev','libjasper-dev', 'libqtgui4', 'libhdf5-dev'],\n       'pip3 instal'     : ['flask', 'numpy', 'opencv-contrib-python', 'imutils', 'opencv-python']}\n\n# The below code shows how nested list comprehension works\n\nfor k,v in dct.items():\n    for i in v:\n        print (k,i)\n\n# which can be re-written to:\n\n[print (k,i) for k,v in dct.items() for i in v]\n", "import os\n\ndct = {'apt-get'         : ['update', 'upgrade', 'other commands', 'etc.'],\n       'apt-get install' : ['libatlas-base-dev','libjasper-dev', 'libqtgui4', 'libhdf5-dev'],\n       'pip3 instal'     : ['flask', 'numpy', 'opencv-contrib-python', 'imutils', 'opencv-python']}\n\n[os.system(f\"sudo {k} {i}\") for k,v in dct.items() for i in v]\n"], ["import pandas as pd\nfrom pathlib import Path\n\nsrc_path  = r\"C:\\Users\\SessionName\\FolderName\\FileName.csv\"\ncountries = ['United States', 'China', 'Russia', 'India']\n\nfor country in countries:\n    p = Path(src_path).parent.joinpath(f\"{country}_ranking.csv\")\n    df.to_csv(p,index=False)\n", "C:\\Users\\SessionName\\FolderName\\United States_ranking.csv\nC:\\Users\\SessionName\\FolderName\\China_ranking.csv\nC:\\Users\\SessionName\\FolderName\\Russia_ranking.csv\nC:\\Users\\SessionName\\FolderName\\India_ranking.csv\n", "print(p)\nWindowsPath('C:/Users/SessionName/FolderName/United States_ranking.csv')\nif not p.is_file():\n   df.to_csv(p,index=False)\nelse:\n    print('file exists')\n"], ["countries = ['United States', 'China', 'Russia', 'India']\nfor country in countries:\n    path = r\"C:\\Users\\SessionName\\FolderName\" + \"\\\\\" + country + \"_ranking.csv\"\n"], ["for country in countries:\n    path = r\"C:\\\\Users\\\\SessionName\\\\FolderName\\\\ {} _ranking.csv\".format(country)\n"], [], ["for country in countries:\n    path = r\"C:\\\\Users\\\\SessionName\\\\FolderName\\\\\" + country + \"_ranking.csv\"\n"], ["all_vals = np.r_[pair_array, pair_array[:, ::-1]]\npd.crosstab(all_vals[:, 0], all_vals[:, 1])\n\ncol_0  18   31   69   183  205  254  267  382\nrow_0                                        \n18       0    0    1    0    0    0    0    0\n31       0    0    0    1    0    0    1    1\n69       1    0    0    0    0    0    0    0\n183      0    1    0    0    0    0    1    1\n205      0    0    0    0    0    1    0    2\n254      0    0    0    0    1    0    0    1\n267      0    1    0    1    0    0    0    0\n382      0    1    0    1    2    1    0    0\n", "rev = pair_array[:, ::-1]\nm = (pair_array == rev)\nrev = rev[~np.all(m, axis=1)]\nall_vals = np.r_[pair_arr, rev]\n"], ["sudo apt-get update \nsudo apt-get upgrade\nsudo apt-get install libatlas-base-dev\nsudo apt-get install libjasper-dev\nsudo apt-get install libqtgui4 \nsudo apt-get install libqt4-test\nsudo apt-get install libhdf5-dev\nsudo pip3 install flask\nsudo pip3 install numpy\nsudo pip3 install opencv-contrib-python\nsudo pip3 install imutils\nsudo pip3 install opencv-python\n"], [], ["print(list(random.choices([1, 2, 3, 4, 5], k=100)))\n"], ["from random import choices\n\nrand_list = choices(range(1,6),k=100)\n"], ["values = [1,2,3,4,5]\nprint(random.choices(values,k=10))\n", "[2, 1, 4, 2, 2, 4, 1, 2, 1, 4]\n"], ["from random import choices\n\nrand_list = choices(range(1, 6), k=100)\n"], ["import numpy as np\nimport pandas as pd\n\npair_array = np.array([(205, 254), (205, 382), (254, 382), (18, 69), (205, 382),\n                       (31, 183), (31, 267), (31, 82), (183, 267), (183, 382)])\n\nvals = sorted(set(pair_array.flatten()))\nn = len(vals)\n\ndf = pd.DataFrame(np.zeros((n, n), dtype=np.int), columns=vals, index=vals)\n\nfor r, c in pair_array:\n    df.at[r, c] += 1\n    df.at[c, r] += 1\n\nprint(df)\n", "     18   31   69   82   183  205  254  267  382\n18     0    0    1    0    0    0    0    0    0\n31     0    0    0    1    1    0    0    1    0\n69     1    0    0    0    0    0    0    0    0\n82     0    1    0    0    0    0    0    0    0\n183    0    1    0    0    0    0    0    1    1\n205    0    0    0    0    0    0    1    0    2\n254    0    0    0    0    0    1    0    0    1\n267    0    1    0    0    1    0    0    0    0\n382    0    0    0    0    1    2    1    0    0\n"], ["pd.crosstab(pair_array[:,0], pair_array[:,1])\n", "col_0  69   82   183  254  267  382\nrow_0                              \n18       1    0    0    0    0    0\n31       0    1    1    0    1    0\n183      0    0    0    0    1    1\n205      0    0    0    1    0    2\n254      0    0    0    0    0    1\n"], ["posts = json.loads(open(file).read())\n\nfor post in posts:\n    if 'data' in post:\n        for data in post['data']:\n            if 'post' in data:\n                print(data['post'])\n"], ["for i in range(temp_df.shape[1]):\n    if temp_df.iloc[-1,i] == 'nan':\n        temp_df = temp_df.drop(i,1)\n", "for i in range(temp_df.shape[1]):\n    if temp_df.iloc[-1,i].isnull():\n        temp_df = temp_df.drop(i,1)\n"], ["any(0 in elem for elem in BOARD_EASY)\n"], ["df = pd.DataFrame({\"A\":[np.nan, 1,\"x\",4],  \n                   \"B\":[\"t\",2,\"y\",np.nan],\n                   \"C\":[\"x\",3,\"z\",6]})\n \ndf = df.loc[:,df.iloc[-1,:].notna()]\n"], ["df.loc[:, ~df.iloc[-1].isna()]\n", "    A   C\n0   NaN x\n1   1   3\n2   x   z\n3   4   6\n"], ["df = df.dropna(axis=1, subset=[df.index[-1]], how='any')\nOut[8]: \n     A  C\n0  NaN  x\n1    1  3\n2    x  z\n3    4  6\n"], ["df.drop(df.loc[:,df.iloc[-1].isna()], axis=1)\n", "     A  C\n0  NaN  x\n1    1  3\n2    x  z\n3    4  6\n"], ["BOARD_EASY = [\n  [7, 2, 5, 8, 1, 3, 6, 4, 9],\n  [4, 8, 6, 9, 2, 7, 1, 5, 3],\n  [3, 1, 9, 6, 5, 4, 8, 7, 2],\n  [5, 6, 4, 2, 7, 1, 3, 9, 8],\n  [8, 9, 1, 5, 3, 9, 4, 2, 7],\n  [2, 7, 3, 4, 8, 9, 5, 6, 1],\n  [6, 3, 8, 7, 9, 5, 2, 1, 4],\n  [9, 4, 2, 1, 6, 8, 7, 3, 5],\n  [0, 0, 7, 3, 4, 2, 9, 8, 6]\n]\n\nfor i, x in enumerate(BOARD_EASY):\n    print(i+1, x)\n", "1 [7, 2, 5, 8, 1, 3, 6, 4, 9]\n2 [4, 8, 6, 9, 2, 7, 1, 5, 3]\n3 [3, 1, 9, 6, 5, 4, 8, 7, 2]\n4 [5, 6, 4, 2, 7, 1, 3, 9, 8]\n5 [8, 9, 1, 5, 3, 9, 4, 2, 7]\n6 [2, 7, 3, 4, 8, 9, 5, 6, 1]\n7 [6, 3, 8, 7, 9, 5, 2, 1, 4]\n8 [9, 4, 2, 1, 6, 8, 7, 3, 5]\n9 [0, 0, 7, 3, 4, 2, 9, 8, 6]\n", "for i, l in enumerate(BOARD_EASY):\n    if 0 in l:\n        print(\"There's a zero in row \" + str(i + 1))\n", "There's a zero in row 9\n"], ["if any(0 in elem for elem in BOARD_EASY):\n    print ('0 is found in BOARD_EASY')\nelse:\n    print ('0 is NOT found in BOARD_EASY')\n"], ["# start of the script\nBOARD_EASY = np.array(BOARD_EASY)\n#\n#\nif 0 in np.concatenate(BOARD_EASY):\n  do the thing\n"], ["if 0 in itertools.chain(*BOARD_EASY):\n  do the thing\n"], ["BOARD_EASY = np.array(BOARD_EASY).flatten()\nprint(\"do the thing\") if 0 in BOARD_EASY else False\n\ndo the thing\n"], ["for count, i in enumerate(BOARD_EASY):\n    if 0 in i:\n        print(\"Found it in index\", count)\n"], [], [], ["Past_Tense = [ w + \"e\"*(w[-1]!=\"e\") + \"d\" for w in My_List ]\n", "Past_Tense = [ w + 'ed'[w[-1]==\"e\":] for w in My_List ]\n"], ["n = 7*a + 5*b + 3*c\nc = (7*a + 5*b - n) / -3\n", "import random\n\nn = 30;\nmax = 1000000;\nmin = -1000000;\n\nwhile True:\n  a = random.randint(min , max);\n  b = random.randint(min , max);\n  t = (7*a) + (5*b) - n;\n  if (t % 3 == 0) :\n    break;\n\nc = (t/-3);\n\nprint(\"A = \" + str(a));\nprint(\"B = \" + str(b));\nprint(\"C = \" + str(c));\nprint(\"7A + 5B + 3C =>\")\nprint(\"(7 * \" + str(a) + \") + (5 * \" + str(b) + \") + (3 * \" + str(c) + \") = \")\nprint((7*a) + (5*b) + (3*c));\n"], ["My_List = [\"adopt\", \"bake\", \"beam\"]\n\ndef ed(word): return word+\"d\" if word[-1]==\"e\" else word+\"ed\"\n\nPast_Tense = list(map(ed, My_List)) # ['adopted', 'baked', 'beamed']\n"], [], ["a = [[[['10.0.0.0-E', '10.0.0.0-B'], ['172.0.0.0-E', '172.0.0.0-B'], ['12.0.0.0-E', '12.0.0.0-B']]]]\nmain_list = a[0][0]\nfor i in range(len(main_list)):\n    print(main_list[i][0], '-' ,main_list[i][1])\n", "10.0.0.0-E - 10.0.0.0-B\n172.0.0.0-E - 172.0.0.0-B\n12.0.0.0-E - 12.0.0.0-B\n"], ["[ # <- first level\n    [ # <- second level\n        [ # <- third level\n            ['10.0.0.0-E', '10.0.0.0-B'],\n            ['172.0.0.0-E', '172.0.0.0-B'],\n            ['12.0.0.0-E', '12.0.0.0-B']\n        ]\n    ]\n]\n", "my_list = [[[['10.0.0.0-E', '10.0.0.0-B'], ['172.0.0.0-E', '172.0.0.0-B'], ['12.0.0.0-E', '12.0.0.0-B']]]]\nlist_of_pairs = my_list[0][0]\n", "for pair in list_of_pairs:\n    print(' - '.join(pair))\n", "my_list = [[[['10.0.0.0-E', '10.0.0.0-B'], ['172.0.0.0-E', '172.0.0.0-B'], ['12.0.0.0-E', '12.0.0.0-B']]]]\n\nfor pair in my_list[0][0]:\n    print(' - '.join(pair))\n", "my_list = [[[['10.0.0.0-E', '10.0.0.0-B'], ['172.0.0.0-E', '172.0.0.0-B'], ['12.0.0.0-E', '12.0.0.0-B']]]]\n\nprint('\\n'.join(' - '.join(pair) for pair in my_list[0][0]))\n"], ["for i in x[0][0]:                                                                                                      \n    print(i) \n\nResult                                                                                                                                                                                            \n['10.0.0.0-E', '10.0.0.0-B']                                                                                            \n['172.0.0.0-E', '172.0.0.0-B']                                                                                          \n['12.0.0.0-E', '12.0.0.0-B']\n", " for i in x[0][0]:\n    for j in I:                                                                                                       \n        print(j, end='')                                                                                               \n    print(end='\\n')                                                                                                   \n \n Result:\n  10.0.0.0-E10.0.0.0-B                                                                                                    \n  172.0.0.0-E172.0.0.0-B                                                                                                  \n  12.0.0.0-E12.0.0.0-B  \n"], ["from functools import reduce\na = [[[['10.0.0.0-E', '10.0.0.0-B'], ['172.0.0.0-E', '172.0.0.0-B'], ['12.0.0.0-E', '12.0.0.0-B']]]]\n\nif a:\n    while type(a[0]) == list:\n        a = reduce(lambda x,y:x+y,a)\n\nfor i in range(0,len(a),2):\n    print(a[i],a[i+1])\n"], ["result = [[[['10.0.0.0-E', '10.0.0.0-B'], ['172.0.0.0-E', '172.0.0.0-B'], ['12.0.0.0-E', '12.0.0.0-B']]]]\n\nfor item in result[0][0]:\n    print(f'{item[0]} - {item[1]}')\n", "10.0.0.0-E - 10.0.0.0-B\n172.0.0.0-E - 172.0.0.0-B\n12.0.0.0-E - 12.0.0.0-B\n"], [], ["from sympy.solvers.diophantine.diophantine import diop_linear\nfrom sympy import symbols\nfrom numpy.random import randint\n\nn = 30\nN = 8 # Number of solutions needed\n\n# Unknowns\na, b, c = symbols('a, b, c', integer=True)\n\n# Coefficients\nx, y, z = 7, 5, 3\n\n# Parameters of parametric equation of solution\nt_0, t_1 = symbols('t_0, t_1', integer=True)\n\nsolution = diop_linear(x * a + y * b + z * c - n)\n\nif not (None in solution):\n  for s in range(N):\n    # -10000 and 10000 (max and min for t_0 and t_1)\n    t_sub = [(t_0, randint(-10000, 10000)), (t_1, randint(-10000, 10000))]\n\n    a_val, b_val, c_val = map(lambda t : t.subs(t_sub), solution)\n\n    print('Solution #%d' % (s + 1))\n    print('a =', a_val, ', b =', b_val, ', c =', c_val)\nelse:\n  print('no solutions')\n", "Solution #1\na = -141 , b = -29187 , c = 48984\nSolution #2\na = -8532 , b = -68757 , c = 134513\nSolution #3\na = 5034 , b = 30729 , c = -62951\nSolution #4\na = 7107 , b = 76638 , c = -144303\nSolution #5\na = 4587 , b = 23721 , c = -50228\nSolution #6\na = -9294 , b = -106269 , c = 198811\nSolution #7\na = -1572 , b = -43224 , c = 75718\nSolution #8\na = 4956 , b = 68097 , c = -125049\n"], ["import numpy as np\n\n\ndef generate_answer(n: int, low_limit:int, high_limit: int):\n    while True:\n        a = np.random.randint(low_limit, high_limit + 1, 1)[0]\n        b = np.random.randint(low_limit, high_limit + 1, 1)[0]\n        c = (n - 7 * a - 5 * b) / 3.0\n        if int(c) == c and low_limit <= c <= high_limit:\n            break\n\n    return a, b, int(c)\n\n\nif __name__ == \"__main__\":\n    n = 30\n    ans = generate_answer(low_limit=-5, high_limit=50, n=n)\n    assert ans[0] * 7 + ans[1] * 5 + ans[2] * 3 == n\n    print(ans)\n", "def generate_all_answers(n: int, low_limit:int, high_limit: int):\n    results = []\n    for a in range(low_limit, high_limit + 1):\n        for b in range(low_limit, high_limit + 1):\n            c = (n - 7 * a - 5 * b) / 3.0\n            if int(c) == c and low_limit <= c <= high_limit:\n                results.append((a, b, int(c)))\n\n    return results\n"], [], ["s=input(\"Input the shape and number:\")\n# s=\"rect:5:3\"\n# s=\"cir:3.5\"\n# s=\"trapz:3 5 7\"\ncmd, para=s.split(':')[0], s.split(':')[1:]\nprint(cmd,\"->\",para)\n\nif cmd=='cir':\n    r = float(para[0])\n    print(f\"arear={r*r*3.14}\")\nelif cmd=='rect':\n    sw, sh =[int(x) for x in para]\n    print(f\"area={sw*sh}\")\nelif cmd=='trapz':\n    ul, bl, h = [int(x) for x in para]\n    print(f\"area={(ul+bl)*h/2}\")\nelse:\n    print(\"wrong input\")\n", "Input the shape and number:rect:5:3\nrect -> ['5', '3']\narea=15\n\nInput the shape and number:cir:3.5\ncir -> ['3.5']\narear=38.465\n\nInput the shape and number:trapz:3:5:7\ntrapz -> ['3', '5', '7']\narea=28.0\n"], ["s=input(\"Input the shape and number:\")\ns = s.split(':')\ncmd, para= s[0], s[1:] # <---- added this\nprint(cmd,\"->\",para)\n\nif cmd=='cir':\n    r = float(para[0])\n    print(f\"arear={r*r*3.14}\")\nelif cmd=='rect':\n    sw, sh =list(map(int, para)) #<---- added this\n    print(f\"area={sw*sh}\")\nelif cmd=='trapz':\n    ul, bl, h = list(map(int, para))\n    print(f\"area={(ul+bl)*h/2}\")\nelse:\n    print(\"wrong input\")\n", "Input the shape and number:trapz:3:5:7\ntrapz -> ['3', '5', '7']\narea=28.0\n\n\nInput the shape and number:rect:3:5\nrect -> ['3', '5']\narea=15\n\nInput the shape and number:cir:4.6\ncir -> ['4.6']\narear=66.44239999999999\n"], ["s=input(\"Input the shape and number:\")\n", "s=\"rect:5:3\"\ns=\"cir:3.5\"\ns=\"trapz:3 5 7\"\n"], ["s=input(\"Input the shape and number:\")\ncmd, para=s.split(\":\")\nprint(cmd,\"->\",para)\n\nif cmd=='cir':\n    r = float(para)\n    print(f\"arear={r*r*3.14}\")\nelif cmd=='rect':\n    sw, sh = (float(x) for x in para.split())\n    print(f\"area={sw*sh}\")\nelif cmd=='trapz':\n    ul, bl, h = (float(x) for x in para.split())\n    print(f\"area={(ul+bl)*h/2}\")\nelse:\n    print(\"wrong input\")\n"], ["if 7*a + 5*b + 3*c = n:\n    c.append(a)\n    k.append(b)\n    w.append(c)\n", "for c in range(n):\n    if 7*a + 5*b + 3*c = n:\n        c.append(a)\n        k.append(b)\n        w.append(c)\n", "for b in range(n):\n    for c in range(n):\n        if 7*a + 5*b + 3*c = n:\n            c.append(a)\n            k.append(b)\n            w.append(c)\n"], ["def firstShared(story,elementsToCheck,n=2):\n    overlap = set(i for i in elementsToCheck if i in story)\n    firstn = sorted(overlap,key=elementsToCheck.index)[:n]\n    indices = [story.index(i) for i in firstn]\n    return(indices)\n    \n    \nif __name__ == '__main__':\n    n = 2\n    story = ['a', 'b', 'c', 'd', 'b', 'c', 'c']\n    elementsToCheck = ['a', 'c', 'f', 'h']\n    # elementsToCheck = ['a', 'b', 'c', 'd', 'f', 'h']\n    for i in range(4):\n        print(firstShared(story,elementsToCheck,i))\n    # []\n    # [0]\n    # [0, 2]\n    # [0, 2]\n"], ["[i for i, x in enumerate(story) if x in elementsToCheck][:2]\n"], ["story = ['a', 'b', 'c', 'd', 'b', 'c', 'c']\nelementsToCheck = {'a', 'c', 'f', 'h', 'd'}\n\nidxs = {story.index(x) for x in elementsToCheck if x in story}\n\nprint(\n    min(idxs), min(idxs-{min(idxs)})\n)\n"], ["story = ['a', 'b', 'c', 'd', 'b', 'c', 'c']\nelementsToCheck = ['a', 'c', 'f', 'h']\ntmp=[]\nfor i in range(0,len(elementsToCheck)):\n    if elementsToCheck[i] in story and i<2:\n        tmp.append(story.index(elementsToCheck[i]))\nprint(tmp)\n"], ["story = ['a', 'b', 'c', 'd', 'b', 'c', 'c']\nelementsToCheck = ['a', 'c', 'f', 'h']\n\nout = []\nfor i, v in enumerate(story):\n    if v in elementsToCheck:\n        out.append(i)\n    if len(out) == 2:\n        break\n\nprint(out)\n", "[0, 2]\n"], [], ["dct = {1: ('a', 'b'), 2: ('c', 'd'), 3: ('e', 'f')}\ndct = dict(zip(dct, list(dct.values())[::-1]))\nprint(dct)\n", "{1: ('e', 'f'), 2: ('c', 'd'), 3: ('a', 'b')}\n"], ["class MyClass:\n\n    @classmethod\n    def my_method(cls):\n        return \"class method\"\n\n    @staticmethod\n    def my_other_method():\n        return \"static method\"\n\n    def yet_another_method(self):\n        return yet_another_method()\n\n# Class definition ends here. You can now define another function that\n# can be imported like you want to do it, and, if needed, used to define\n# a class method of the same name.\n\ndef yet_another_method():\n    return \"works too\"\n", "from test import MyClass, yet_another_method\n\nprint(MyClass.my_method())\nfunction = MyClass.my_method\nprint(function())\n\nprint(MyClass.my_other_method())\nfunction = MyClass.my_other_method\nprint(function())\n\nprint(yet_another_method())\n"], ["(base) fathead:tmp sholden$ cat module.py\nclass One:\n    def meth(self):\n        return 42\n\n(base) fathead:tmp sholden$ python\nPython 3.6.10 |Anaconda, Inc.| (default, Jan  7 2020, 15:01:53)\n[GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)] on darwin\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n>>> from module import One.meth\n  File \"<stdin>\", line 1\n    from module import One.meth\n                          ^\nSyntaxError: invalid syntax\n", "from module import One\n\nmy_func = One.meth\n"], ["from text_preprocessing import TextToTensor\n", "TextToTensor.clean_text(...)\n\n"], ["from text_preprocessing import TextToTensor.clean_text as clean_test\n"], [], [], ["smallestnum = [numbers[0]] # This will keep track of all smallest numbers we've found\nsecsmallest = [numbers[0]] # This will hold all second-smallest numbers we find\nfor element in numbers:\n    if element < smallestnum[0]:\n        # This is the new minimum\n        # So the old minimum is now the second-smallest\n        secsmallest = smallestnum\n        smallestnum = [element]\n    elif element == smallestnum[0]:\n        # Add this number to our list of smallests\n        smallestnum.append(element)\n    elif element < secsmallest[0]:\n        # This is the new second-smallest\n        secsmallest = [element]\n    elif element == secsmallest[0]:\n        # Add this to our list of 2nd smallest\n        secsmallest.append(element)\n    # else do nothing\n"], [">>> s = set(numbers)\n>>> s.remove(min(s))\n>>> x = min(s)\n>>> [x] * numbers.count(x)\n[15, 15]\n", ">>> x = min(numbers)\n>>> y = min(y for y in numbers if y != x)\n>>> [y] * numbers.count(y)\n[15, 15]\n"], ["numbers = [40, 40, 10, 10, 21, 21, 100,100, 400,400, 15, 15]\ndef second_lowest_number():\n        numbers.sort()\n        z = numbers[0]\nfor i in numbers:\n        if i > z:\n            print(i)\n            break\nsecond_lowest_number()\n"], ["sorted(set(numbers))[1]\n"], ["import pandas as pd\nimport numpy as np\nimport time\n\ndf=pd.DataFrame({'ID' : [i for i in range(1,1000)],\n                 'Area' : ['P' if (i & 1) else 'Q' for i in range(1,1000)],\n                 'Stage' : [ 'X' if (i & 2) else 'Y' for i in range(1,1000)]})\n\nt0=time.process_time()\nfor i in range(1,100):\n    df.loc[df['Stage']=='X', 'Area'] = df['Area'].replace('Q','q')\n    df.loc[df['Stage']=='X', 'Area'] = df['Area'].replace('q','Q')\n\nprint(\"Quang Hoang\", '%.2f' % (time.process_time() - t0))\n\nt0=time.process_time()\nfor i in range(1,100):\n    df.loc[df['Stage'] == 'X', 'Area'] = 'q'\n    df.loc[df['Stage'] == 'X', 'Area'] = 'Q'\n\nprint(\"Joe Ferndz\", '%.2f' % (time.process_time() - t0))\n\nt0=time.process_time()\nfor i in range(1,100):\n    df.loc[df['Area'].eq(\"Q\") & df['Stage'].eq('X'),'Area']='q'\n    df.loc[df['Area'].eq(\"q\") & df['Stage'].eq('X'),'Area']='Q'\n\nprint(\"anky 1\", '%.2f' % (time.process_time() - t0))\n\nt0=time.process_time()\nfor i in range(1,100):\n    df['Area'] = np.where(df['Area'].eq(\"Q\") & df['Stage'].eq('X'),'q',df['Area'])\n    df['Area'] = np.where(df['Area'].eq(\"q\") & df['Stage'].eq('X'),'Q',df['Area'])\n\nprint(\"anky 2\", '%.2f' % (time.process_time() - t0))\n\nt0=time.process_time()\nfor i in range(1,100):\n    df['Area']=np.where(df['Stage']=='X','q',df['Area'])\n    df['Area']=np.where(df['Stage']=='X','Q',df['Area'])\n\nprint(\"RavinderSingh13\", '%.2f' % (time.process_time() - t0))\n", "Quang Hoang 1.60\nJoe Ferndz 1.12\nanky 1 1.55\nanky 2 0.86\nRavinderSingh13 0.38\n", "Quang Hoang 10.79\nJoe Ferndz 6.61\nanky 1 10.91\nanky 2 9.64\nRavinderSingh13 4.75\n"], ["df.loc[df['Stage'] == 'X', 'Area'] = 'P'\n"], ["d = {1: ('a', 'b'), 3: ('e', 'f'), 2: ('c', 'd')}\nl = [v for k, v in sorted(d.items())]\n# [('a', 'b'), ('c', 'd'), ('e', 'f')]\n", "range(len(l))\n# range(0, 3)\n", "l[1] # Indices have been shifted. 2 is now 1\n# ('c', 'd')\n", ">>> dict(enumerate(l))\n{0: ('a', 'b'), 1: ('c', 'd'), 2: ('e', 'f')}\n>>> dict(enumerate(l, 1))\n{1: ('a', 'b'), 2: ('c', 'd'), 3: ('e', 'f')}\n", ">>> l[::-1]\n[('e', 'f'), ('c', 'd'), ('a', 'b')]\n>>> l[::-1][0]\n('e', 'f')\n", ">>> dict(list(enumerate(l[::-1])))\n{0: ('e', 'f'), 1: ('c', 'd'), 2: ('a', 'b')}\n>>> dict(list(enumerate(l[::-1], 1)))\n{1: ('e', 'f'), 2: ('c', 'd'), 3: ('a', 'b')}\n"], [], ["new_dict = dict(zip(old_dict, reversed(old_dict.values())))\n", "new_dict = dict(zip(old_dict, reversed(list(old_dict.values()))))\n"], ["def rev_keys(d: dict) -> dict:\n    '''Return dictionary structure with the \n        keys reasigned in opposite order'''\n    old_keys = list(d.keys())\n    new_keys = old_keys[::-1]\n    nd = {}\n    for ki in range(len(new_keys)):\n        nd[new_keys[ki]]= d[old_keys[ki]]\n    return nd\n", "dt = {'1': ('a','b'), '2': ('c','d'), '3': ('e','f')}\n\nrev_keys(dt)\n", "{'3': ('a', 'b'), '2': ('c', 'd'), '1': ('e', 'f')}\n"], ["import pandas as pd\nimport numpy as np\ndf['Area']=np.where(df['Stage']=='X','P',df['Area'])\n"], ["df.loc[df['Stage']=='X', 'Area'] = df['Area'].replace('Q','P')\n", "   ID Area Stage\n0   1    P     X\n1   2    P     X\n2   3    P     X\n3   4    Q     Y\n"], ["df.loc[df['Area'].eq(\"Q\") & df['Stage'].eq('X'),'Area']='P'\nprint(df)\n", "   ID Area Stage\n0   1    P     X\n1   2    P     X\n2   3    P     X\n3   4    Q     Y\n", "df['Area'] = np.where(df['Area'].eq(\"Q\") & df['Stage'].eq('X'),'P',df['Area'])\n"], [], ["myList = [4, 1, 88, 44, 3,-1,-7,-19,-0.5,-0.2]\n\ndef compute_closest_to_zero(myList):\n    positive = []\n    negative = []\n    if len(myList) == 0:\n        print('0')\n    else:\n        for i in myList:\n            if i >= 0:\n                positive.append(i)\n                #print(positive)\n            else:\n                negative.append(i)\n                #print(negative)\n                #print(min(positive))\n\n                \n    if min(positive) + max(negative) < 0:\n        print(min(positive))\n    else:\n        print(max(negative))\n    return\n\nBlockquote\n\ncompute_closest_to_zero(myList)\n"], [], ["def recursive_sum(n):\n    if n == 1:\n        return 1\n    else:\n        return n + recursive_sum(n - 1)\n\nprint(recursive_sum(10))  # -> 55\n"], ["n=int(input (\"Enter a number: \"))\ndef find_sum (n):\n    sum_num = (n * (n + 1)) / 2\n    return sum_num\nprint(\"The sum of first\" ,find_sum(n))\n"], ["def find_sum ():\n    n=int(input (\"Enter a number: \"))\n    sum_num = (n * (n + 1)) / 2\n    return sum_num\nsum = find_sum()\nprint(\"The sum of first\"+sum)\n"], ["def find_sum (n):\n    sum_num = (n * (n + 1)) / 2\n    return sum_num\n\nn=int(input (\"Enter a number: \"))\nresult = str(find_sum(n))\nprint(\"The sum of first \" + result)\n"], ["df.to_parquet(filename, use_deprecated_int96_timestamps=True)\n"], ["Label=pd.Series(['cluster1','cluster1','cluster2','cluster2'])\ndf['label']=Label\n"], ["import pandas as pd\ndf = pd.read_csv(\"dataset.csv\")\nlist1 = []\nfor i in range(len(df.name)):\n   if i < 2:\n      list1.append('cluster1')\n   else:\n      list1.append('cluster2')\nlabel = pd.Series(list1)\ndf['label'] = label\n"], ["import pandas as pd\ndf = pd.DataFrame({'name': ['john', 'mary', 'joseph', 'maria', 'john', 'mary', 'joseph', 'maria'],\n                   'age': [12, 13, 12, 14, 12, 13, 12, 14],\n                   'sex': ['m', 'f','m', 'f', 'm', 'f','m', 'f']})\n\ndf.index = df.index + 1\n\ndf['label'] = pd.Series()\ndef create_label(data, each_row):\n   i = 0\n   j = 1\n   while i <= len(data):\n      data['label'][i: i + each_row] = 'label' + str(j)\n      i += each_row\n      j += 1\n   return data\n\ndf_new = create_label(df, 2)\n"], ["import pandas as pd\ndata = {'name':['bob','sue','mary','steve'], 'age':[11, 23, 53, 44]}\n\ndf = pd.DataFrame(data)\nprint(df)\ndf['label'] = 0\ncluster1 = [0, 3]\ncluster2 = [1, 2]\ndf.loc[cluster1, 'label'] = 1\ndf.loc[cluster2, 'label'] = 2    \n#another way\n#df.iloc[cluster1, df.columns.get_loc('label')] = 1\n#df.iloc[cluster2, df.columns.get_loc('label')] = 2\nprint(df)\n", "    name  age\n0    bob   11\n1    sue   23\n2   mary   53\n3  steve   44\n    name  age  label\n0    bob   11      1\n1    sue   23      2\n2   mary   53      2\n3  steve   44      1\n"], ["import pandas as pd\n\ndf = pd.read_csv('test.txt',sep='\\+', engine = \"python\")\ndf[\"label\"] = \"\" # adds empty \"label\" column\ndf[\"label\"].iloc[0:2] = \"cluster1\"\ndf[\"label\"].iloc[2:4] = \"cluster2\"\n"], ["df[['Size','File']] = df[['Size','File']].replace('\\s+?TB','',regex=True)\n", "  Size ID File\n0  500  A  200\n1  200  B  100\n2  600  C  300\n"], [], ["df['Size'] = df['Size'].map(lambda x: x.lstrip('+-').rstrip('TB'))\ndf['File'] = df['File'].map(lambda x: x.lstrip('+-').rstrip('TB'))\n"], ["df[['Size','File']] = df[['Size','File']].apply(lambda x: x.str.strip(' TB'))\n"], ["df[['Size','File']] = df[['Size','File']].apply(lambda x: x.str.extract('^(\\d+)')[0])\n", "  Size ID File\n0  500  A  200\n1  200  B  100\n2  600  C  300\n"], [">>> from collections import defaultdict\n>>> list_of_dicts = [{\"a\": 1, \"b\": 2}, {\"a\": 1, \"b\": \"zz\"}, {\"a\": 1, \"b\": \"2\"}]\n>>> grouped_values = defaultdict(set)\n>>> for d in list_of_dicts:\n...     for k,v in d.items():\n...         grouped_values[k].add(v)\n...\n>>> [k for k,v in grouped_values.items() if len(v) == 1]\n['a']\n"], ["from functools import reduce\narray_of_dicts = [{\"a\": 1, \"b\": 2}, {\"a\": 1, \"c\": \"zz\"}, {\"a\": 1, \"d\": \"2\"}]\nresult = reduce(lambda a, b: a.intersection(b),list(map(lambda x: set(x.keys()), \n                array_of_dicts)))\n"], ["[list(x.keys())[0] for x in [{k:set([e[k] for e in list_of_dicts])} for k in list_of_dicts[0]] if len(list(x.values())[0]) == 1]\n", "['a']\n"], ["# all keys are the same, so get the list\nkeys = array_of_dicts[0].keys()\n\n# collapse values into a single dictionary\nvalue_dict = {k: set(d[k] for d in array_of_dicts) for k in keys}\n\n# get list of all single-valued keys\nprint([k for k, v in value_dict.items() if len(v) == 1])\n"], ["array_of_dicts = [{\"a\": 1, \"b\": 2}, {\"a\": 1, \"b\": \"zz\", \"c\": \"cc\"}, {\"a\": 1, \"b\": \"2\"}]\n\ndef get_same_vals(dicts):\n  keys = []\n  for key in dicts[0].keys():\n    is_same = True\n    for each_dict in array_of_dicts:\n      if not key in each_dict or  each_dict[key] != dicts[0][key]:\n        is_same = False\n    if is_same:\n      keys.append(key)\n  return keys\n\nprint(get_same_vals(array_of_dicts))  \n"], ["array_of_dicts = [{\"a\": 1, \"b\": 2}, {\"a\": 1, \"b\": \"zz\"}, {\"a\": 1, \"b\": \"2\"}]\n\ndef is_entry_in_all_dicts(key, value):\n    identical_entries_found = 0\n    for dict in array_of_dicts:\n        if key in dict:\n            if dict[key] == value:\n                identical_entries_found += 1\n    if identical_entries_found == len(array_of_dicts):\n        return True\n    return False\n                \nresult = []\nfor dict in array_of_dicts:\n    for key, value in dict.items():\n        if is_entry_in_all_dicts(key, value):\n            if key not in result:\n                result.append(key)\nprint(result)\n"], ["array_of_dicts = [{\"a\": 1, \"b\": 2}, {\"a\": 1, \"b\": \"zz\"}, {\"a\": 1, \"b\": \"2\"}]\n\ndef get_same_vals(dicts):\n  keys = []\n  for key in dicts[0].keys():\n    is_same = True\n    for each_dict in dicts:\n      if each_dict[key] != dicts[0][key]:\n        is_same = False\n    if is_same:\n      keys.append(key)\n  return keys\n\nprint(get_same_vals(array_of_dicts))\n# Prints ['a']\n"], ["giant_dict = collections.defaultdict(list)\nfor k, v in (e for d in list_of_dicts for e in d):\n    giant_dict[k].append(v)\nfor k, v in giant_dict.items():\n    if len(v) == len(list_of_dicts) and all(e == v[0] for e in v):\n        print(k)\n"], [], ["min = -1\nmax = 99999999  # put whatever you need\nJ = [min] + I + [max]\n[y for (x,y,z) in zip(J, J[1:], J[2:]) if x < y and y < z]\n"], ["l = [2, 3, 6, 6, 8, 9, 12, 12, 14]\ninset = set(l)\n\nfor i in inset:   # <-- usually the element to remove is in the front,\n    l.remove(i)   # <-- but in a worst case, this is slower than O(n)\n\nresult = list(inset - set(l))\n"], ["from itertools import groupby\n\ninputlist = [2, 3, 6, 6, 8, 9, 12, 12, 14]\n\noutputlist = [x for _, (x, *extra) in groupby(inputlist) if not extra]\n", "outputlist = [x for x, grp in groupby(inputlist) if ilen(grp) == 1]\n", "def more_than_one(it):\n    next(it)  # Assumes at least once, which is already the case with groupby groups\n    try:\n        next(it)\n    except StopIteration:\n        return True\n    return False\n\noutputlist = [x for x, grp in groupby(inputlist) if not more_than_one(grp)]\n"], [], ["Inputlist = [2, 3, 6, 6, 8, 9, 12, 12, 14]\n\nseen = set()\nans = set()\n\nfor el in Inputlist:\n    if el not in seen:\n        seen.add(el)\n        ans.add(el)\n    else:\n        ans.discard(el)\n\nprint(list(ans))\n", "from timeit import timeit\n\n\nfirst = \"\"\"\ndef get_from_two_sets():\n    seen = set()\n    ans = set()\n\n    for el in (2, 3, 6, 6, 8, 9, 12, 12, 14):\n        if el not in seen:\n            seen.add(el)\n            ans.add(el)\n        else:\n            ans.discard(el)\"\"\"\n\n\nsecond = \"\"\"\n\ndef get_from_counter():\n    return [el for el, cnt in Counter((2, 3, 6, 6, 8, 9, 12, 12, 14)).items() if cnt == 1]\n    \"\"\"\n\n\nprint(timeit(stmt=first, number=10000000))\nprint(timeit(stmt=second, number=10000000, setup=\"from collections import Counter\"))\n", "0.3130729760000577\n0.46127468299982866\n"], [">>> from collections import Counter\n>>> l = [2, 3, 6, 6, 8, 9, 12, 12, 14]\n>>> res = [el for el, cnt in Counter(l).items() if cnt==1]\n>>> res\n[2, 3, 8, 9, 14]\n"], [], ["list_tuples = (([ 24, 126,  33, 106]),([ 98, 135, 330, 339]))\n\n\npoints = [(x, y) for x,y in zip(list_tuples[0], list_tuples[1])]\n\n\nprint(points)\n"], ["import numpy as np\n\ntop_4 = (np.array([ 24, 126,  33, 106]), np.array([ 98, 135, 330, 339]))\n\nresult = list(zip(top_4[0], top_4[1]))\nprint(result)\n", "[(24, 98), (126, 135), (33, 330), (106, 339)]\n"], ["points = list(zip(max[0], max[1]))\n"], ["top_4 = ([ 24, 126,  33, 106], [ 98, 135, 330, 339])\n\nm = [(top_4[0][i],top_4[1][i]) for i in range(len(top_4[0]))]\nprint(m)\n", "[(24, 98), (126, 135), (33, 330), (106, 339)]\n"], [], ["s = '1974-11-27T00:00:00'\ns = s[:10].replace('-','')\n"], ["from datetime import datetime\n\ns = '1974-11-27T00:00:00'\nd = datetime.fromisoformat(s)\n", "print(d.strftime(\"%Y%m%d\"))\n19741127\n"], ["import datetime\nstr = '1974-11-27T00:00:00'\ndatetime.strptime(str,\"%Y-%m-%dT%H:%M:%S\")\n"], ["import datetime\nexample = '1974-11-27T00:00:00'\nd = datetime.datetime.fromisoformat(example)\n", "print(d.strftime('%Y%m%d'))\n>> 19741127\n"], ["import datetime\nthis_date = '1974-11-27T00:00:00'\n# transform the string you have to a datetime type\nyour_date = datetime.datetime.strptime(this_date, '%Y-%m-%dT%H:%M:%S')\n# print it in the format you want to\nprint(your_date.strftime(\"%Y%m%d\"))\n19741127\n"], ["def strict_int(x):\n    if x.is_integer():\n        return int(x)\n    raise ValueError\n", "int(x) if x.is_integer() else 'Error'\n"], ["import ast,sys\ninput_str = sys.stdin.read()\nvotes = ast.literal_eval(input_str)\nmy_dict = {}\n# Loop to count occurenec of food items\nfor i in set(votes):\n    my_dict[i] = votes.count(i)\n\n# Finding out max votes\nmax_votes = max(my_dict.values())\n\n# Checking if max votes > half the votes\nif max_votes > len(my_dict)//2:\n    # Checking if there is no conflicting max votes\n    if list(my_dict.values()).count(max_votes) < 2:\n        print(list(my_dict.keys())[list(my_dict.values()).index(max_votes)])\n    else:\n        print('NOTA')\n# Default value\nelse:\n    print('NOTA')\n"], ["listOrig = [\"0.txt\", \"1.txt\", ..., \"100.txt\"]\nlistNew = [\"10.txt\", \"11.txt\", ..., \"110.txt\"]\n\n# Reverse the lists\nlistOrig = listOrig.reverse() # [\"100.txt\" ... \"0.txt\"]\nlistNew = listNew.reverse() # [\"110.txt\" ... \"10.txt\"]\n"], [], [], [], [], ["G_undirected = G_projected.to_undirected()\n", "G_edges_as_gdf = ox.graph_to_gdfs(G_undirected, nodes=False, edges=True)\n", "block_faces = list(polygonize(G_edges_as_gdf['geometry']))\nblocks = gpd.GeoDataFrame(geometry=block_faces)\n", "ax = G_edges_as_gdf.plot(figsize=(10,10), color='red', zorder=0)\nblocks.plot(ax=ax, facecolor='gainsboro', edgecolor='k', linewidth=2, alpha=0.5, zorder=1)\n", "from libpysal.weights import Rook # Queen, KNN also available\nw_rook = Rook.from_dataframe(blocks)\n", "block = 18\nneighbors = w_rook.neighbors[block]\nneighbors.append(block)\nneighbors\n", "ax = blocks.plot(figsize=(10,10), facecolor='gainsboro', edgecolor='black')\nblocks[blocks.index.isin(neighbors)].plot(ax=ax, color='red', alpha=0.5)\n"], ["numlist.extend(numbers)\n", "the_sum = sum(int(n) for n in numlist)\n"], ["# if you want the sum per string in the list\nsums = [sum(map(int, filter(str.isnumeric, s.split()))) for s in df]\n# [19653, 7449]\n\n# if you simply want the sum of all numbers of all strings\nsum(sum(map(int, filter(str.isnumeric, s.split()))) for s in df)\n# 27102\n"], ["numlist = list()\nfor item in df:\n  for word in item.split():\n    if word.isnumeric():\n      numlist.append(int(word))\n\nprint(numlist)\nprint(sum(numlist))\n", "[4497, 6702, 8454, 7449]\n27102\n", "print(sum([int(word) for item in df for word in item.split() if word.isnumeric()]))\n>>> 27102\n"], ["my_sum = sum(map(int, numbers_list))\n"], ["sum(sum(int(i) for i in s.split() if i.isnumeric()) for s in df)\n# 27102\n", "from itertools imprt chain \nsum(chain.from_iterable((int(i) for i in s.split() if i.isnumeric()) for s in df))\n# 27102\n"], [], ["assert set(map(type, a)) == {int}\n"], ["a = [1,2,3,4,5]\nassert all(isinstance(i, int) for i in a)\n"], [], ["assert all(type(i) is int for i in a)\n"], ["a = [1,2,3,4,5]\nassert all(isinstance(i, int) for i in a)\n\na = [1,2,3,4,5.5]\nassert all(isinstance(i, int) for i in a)\n# AssertionError\n"], ["old_len = len(original)\nnew_len = 10\nresult = original * new_len // old_len\nif new_len % old_len != 0:\n    result += original[:new_len % old_len]\n"], ["x = [1,2,3,4]\n\nlength = 10\n\nfor i in range(length - len(x)):\n    x.append(x[i])\n\nprint(x)\n", "[1, 2, 3, 4, 1, 2, 3, 4, 1, 2]\n"], ["from itertools import cycle, islice\n\ninput = [1, 2, 3, 4]\noutput = list(islice(cycle(input), 10))\n", "[1, 2, 3, 4, 1, 2, 3, 4, 1, 2]\n"], ["NumOfValues = int(input(\"Number of Values: \"))\nList1 = [1,2,3,4]\nList2 = []\nCount = 0\nwhile len(List2) < NumOfValues:\n    List2.append(List1[Count])\n    Count += 1\n    if Count > len(List1) - 1:\n        Count = 0\nprint(List2)\n"], ["from itertools import cycle\n\nlst = [1, 2, 3, 4]\nmyiter = cycle(lst)\nprint([next(myiter) for _ in range(10)])\n", "[1, 2, 3, 4, 1, 2, 3, 4, 1, 2]\n", "from itertools import cycle\n\nlst = [1, 2, 3, 4]\nmyiter = cycle(lst)\nfor _ in range(6):\n    lst.append(next(myiter))\nprint(lst)\n", "[1, 2, 3, 4, 1, 2, 3, 4, 1, 2]\n"], [], ["n = 10\nlst =[1,2,3,4]\nnew_lst = [lst[i%len(lst)] for i in range(n)]\nprint(new_lst)\n", "[1, 2, 3, 4, 1, 2, 3, 4, 1, 2]\n"], [], ["# scripts.py\nfrom foo import Foo\nFoo().run()\n"], [], [], ["def fibonacci(n):\n    ls = []\n    for i in range(0,n):\n        if (i==0) or (i==1):\n            n=1\n            ls.append(n)\n        elif i>=2:\n            ls.append(ls[-1]+ls[-2])\n            n=ls[-2] + ls[-3]\n    print(n)\n\n\nwhile(True):\n    x = int(input())\n    fibonacci(x)\n"], ["def fibonacci(a):\n    ls = [1, 1]\n    for i in range(2, a):\n        ls.append(ls[i - 1] + ls[i - 2])\n    return ls[-1]\n\n# 21\nprint(fibonacci(8))\n", "import math\n\nSQRT_5 = math.sqrt(5)\n\ndef fibonacci(n):\n    return int(((((1 + SQRT_5) / 2) ** n) / SQRT_5) + 0.5 )\n"], [], ["n = 1\n", "ls.append(1)\n", "return ls[-1]\n", "print ls[-1]\n", "def fib(n):\n    a, b = 1, 1\n\n    for i in range(n-1):\n        a, b = b, a+b\n\n    return a\n"], [], ["def fib(n):\n    a, b = 0, 1\n    for i in range(n):\n        a, b = b, a + b\n    return a\n"], [], ["import fnmatch\n\nnames = ['uqqur', 'lxzev', 'ydfgs']\npatterns = ['?z???', '???i?', '???e?', '???f?', '?z???']\n[sum(fnmatch.fnmatch(name, pattern) for name in names) for pattern in patterns]\n\n# [0, 0, 1, 0, 0]\n"], [], [], [], ["lst = [('kol_id', '101152'), ('jnj_id', '7124166'), ('thrc_nm', 'VIR')]\ndef get_values(l):\n    for idx, item in enumerate(l, start=1):\n        yield f\"input_v{idx} = {item}\"\n    \nfor _input in get_values(lst):\n    print(_input)\n", "input_v1 = ('kol_id', '101152')\ninput_v2 = ('jnj_id', '7124166')\ninput_v3 = ('thrc_nm', 'VIR')\n"], ["lst = [('kol_id', '101152'), ('jnj_id', '7124166'), ('thrc_nm', 'VIR')]\n\nd = {}\n\nfor i, element in enumerate(lst, 1):\n    d[f'input_v{i}'] = element\n", "{'input_v1': ('kol_id', '101152'), 'input_v2': ('jnj_id', '7124166'), 'input_v3': ('thrc_nm', 'VIR')}\n"], ["import sys\nimport os.path\n\nparent_directory = os.path.split(os.path.dirname(__file__))[0]\nif parent_directory not in sys.path:\n    #sys.path.insert(0, parent_directory) # the first entry is directory of the running script, so maybe insert after that at index 1\n    sys.append(parent_directory)\n"], ["list(zip(animal,sound))\n>>>[('cow', 'moo'),\n ('pig', 'oink'),\n ('horse', 'neigh'),\n ('chick', 'cluck'),\n ('sheep', 'bahh')]\n"], ["lyrics = oldMacdonald() + \"And on his farm he had a \" + animal + \", Ee-igh, Ee-igh, Oh!\\n\" \\\n        \"With a \" + sound[0] + \", \" + sound[1] + \" here and a \" + sound[2] + \", \" \\\n        \"\" + sound[3] + \".\\nHere a \" + sound[4] + \", there a \" + sound[5] + \", \" \\\n        \"everywhere a \" + sound[6] + \", \" + sound[7] + \"\\n\" + oldMacdonald()\n"], ["def main():\n    sound = [\"moo\", \"oink\", \"neigh\", \"cluck\", \"bahh\"]\n    for animal in [\"cow\", \"pig\", \"horse\", \"chick\", \"sheep\"]:\n        print(verseFor(animal, sound))\n", "def main():\n    animals = [ [\"cow\", \"moo\"], [\"pig\", \"neigh\"], [\"sheep\", \"bahh\"] ]\n    for animal in animals:\n        print(verseFor(animal[0], animal[1]))\n", "def main():\n    animals = [\n        {\n            \"name\" : \"cow\",\n            \"sound\": \"moe\"\n        },\n        {\n            \"name\" : \"pig\",\n            \"sound\": \"haha\"\n        },\n        {\n            \"name\" : \"dog\",\n            \"sound\": \"lol\"\n        }\n    ]\n    for animal in animals:\n        print(verseFor(animal[\"name\"], animal[\"sound\"))\n"], ["def oldMacdonald():\n    return \"Old MacDonald had a farm, Ee-igh, Ee-igh, Oh!\"\n\ndef a(thing):\n    if thing[0] in 'aeiou':\n        return f'an {thing}'\n    else:\n        return f'a {thing}'\n\ndef verseFor(animal, sound):\n    an_animal = a(animal)\n    a_sound = a(sound)\n\n    lyrics = f\"\"\"{oldMacdonald()}\nAnd on his farm he had {an_animal}, Ee-igh, Ee-igh, Oh!\nWith {a_sound}, {sound} here and {a_sound}, {sound} there.\nHere {a_sound}, there {a_sound}, everywhere {a_sound}, {sound}.\n{oldMacdonald()}\n\"\"\"\n    return lyrics\n\ndef main():\n    sounds = [\"moo\", \"oink\", \"neigh\", \"cluck\", \"bahh\"]\n    animals = [\"cow\", \"pig\", \"horse\", \"chick\", \"sheep\"]\n\n    for animal, sound in zip(animals, sounds):\n        print(verseFor(animal, sound))\n\nmain()\n"], [], ["def oldMacdonald():\n    return \"Old MacDonald had a farm, Ee-igh, Ee-igh, Oh!\\n\"\n\ndef verseFor(animal, sound):\n    lyrics = oldMacdonald() + \"And on his farm he had a \" + animal + \", Ee-igh, Ee-igh, Oh!\\n\" \\\n                                                                        \"With a \" + sound + \", \" + sound + \" here and a \" + sound + \", \" \\\n                                                                                                                                             \"\" + sound + \".\\nHere a \" + sound + \", there a \" + sound + \", \" \\\n                                                                                                                                                                                                                 \"everywhere a \" + sound + \", \" + sound + \"\\n\" + oldMacdonald()\n\n    return lyrics\n\ndef main():\n    for animal,sound in zip([\"cow\", \"pig\", \"horse\", \"chick\", \"sheep\"],[\"moo\", \"oink\", \"neigh\", \"cluck\", \"bahh\"]):\n        print(verseFor(animal, sound))\n\nmain()\n"], [], [], ["r'(?<=[a-z])(?=[A-Z])'\n", "(?<=[a-z])  : use a positive lookbehind to assert that the match is preceded\n              by a lowercase letter\n(?=[A-Z])   : use a positive lookahead to assert that the match is followed\n              by an uppercase letter\n"], ["re.findall(\"[A-Z][a-z]+\", \"RegularExpression\")\n", "['Regular', 'Expression']\n"], ["import re\n\ns = \"RegularExpression\"\nprint(re.sub(r\"(?<=[a-z])([A-Z])\", r\" \\1\", s))\n", "Regular Expression\n"], ["In [1]: s = 'RegularExpression'\n\nIn [2]: answer = []\n\nIn [3]: breaks = [i for i,char in enumerate(s) if char.isupper()]\n\nIn [4]: breaks = breaks[1:]\n\nIn [5]: answer.append(s[:breaks[0]])\n\nIn [6]: for start,end in zip(breaks, breaks[1:]):\n   ...:     answer.append(s[start:end])\n   ...:\n\nIn [7]: answer.append(s[breaks[-1]:])\n\nIn [8]: answer\nOut[8]: ['Regular', 'Expression']\n\nIn [9]: print(' '.join(answer))\nRegular Expression\n"], ["import re\n\ns = \"RegularExpression\"\nre.sub(r\"([A-Z][a-z]+)([A-Z][a-z]+)\", r\"\\1 \\2\", s)\n"], [], ["class User(dict):\n    def __init__(self, *args, **kwargs):\n        super(User, self).__init__(*args, **kwargs)\n        self.__dict__ = self\n", "userObj  = User(dictionary)\n", "[setattr(userObj, key, item) for key,item in dict.items()]\n"], ["import inspect\nimport numpy as np\nmembers = inspect.getmembers(User)\n", "allowed = [\"__\" not in a[0] for a in members]\n", "members = np.array(members)[\"__\" not in a[0] for a in members]\n", "user = User(1)\ndic = {\"name\":\"test\", \"id\": 2, \"dob\" : \"any\"}\n", "for m in members:\nsetattr(user, m[0], dic[m[0]])\n"], ["class Foo:\n   bar: int # This actually creates a class member, not an instance member\n   ...\n", "d = {\n  'prop1': 'value1',\n  'prop2': 'value2',\n  'prop2': 'value2'\n}\n\nx = Foo()\n\nfor prop in d.keys():\n  setattr(x, prop, d[prop])\n"], ["class User:\n    name = None\n    id = None\n    dob = None\n\n    def __init__(self, id):\n        self.id = id\n\n    def map_dict(self, user_info):\n        for k, v in user_info.items():\n            setattr(self, k, v)\n\n", "\nuserObj = User(id=12)\nuser_dict = {\n    'name': 'Bob',\n    'dob': '11-20-1993',\n    'something': 'blah'\n}\n\nuserObj.map_dict(user_dict)\n"], [], [], ["export SETUPTOOLS_USE_DISTUTILS=stdlib\n"], ["$ rm -r /home/isaac/.virtualenvs/foobar #Remove the content\n$ /usr/bin/python3 -m venv /home/isaac/.virtualenvs/foobar #Recreate your environment\n$ cd /home/isaac/.virtualenvs/foobar\n$ source bin/activate #Activate the environment\n$ pip -V #(my version is 8.1.1 -> 20.x ==current version)\n$ pip install django==1.9 #That version did not give an teh error\n$ django-admin startproject yourprojectname #(worked nicely)\n"], [], ["index = [\n  {\"c\": 0b00001, \"m\": 0b00010, ...}  # first query letter\n  {\"a\": 0b01111, \"e\": 0x10000}       # second query letter\n]\n"], ["/usr/bin/python3 -m venv /home/isaac/.virtualenvs/foobar\n/home/isaac/.virtualenvs/foobar/bin/pip install django\n"], ["a = *[1, 2, 3],\n", "(1, 2, 3)\n", "1, 2, 3\n", "[1, 2, 3]\n", "(1, 2, 3)\n", "a = [1, 2, 3]\n", "*a, b = [1, 2, 3]\n", ">>> *a, = {1,2,3}\n>>> a\n[1, 2, 3]\n>>> *a, = (1,2,3)\n>>> a\n[1, 2, 3]\n>>> \n", "a, *b = 'hello'\n", "print(b)\n", "'ello'\n", "print([*a])\n", "print((*a))\n", "print({*a})\n"], [], ["pip install pandas_read_xml\n", "import pandas_read_xml as pdx\n\ndf = pdx.read_xml('filename.xml')\n", "df = pdx.flatten(df)\n", "df = pdx.fully_flatten(df)\n"], ["dict = {\n    \"apples.1\": \"aaaaaaappplllllleeeeeeeeees\",\n    \"bananas.1\": \"baaaanaaaaanaaaaaaaaaaasssssssss\",\n    \"strawberries.1\": \"straaaawwwwwbeeeeerriiiiies\"\n}\n\nfor val in dict.values():\n    first, tenth, fifteenth = val[0], val[9], val[14]\n    print(first, tenth, fifteenth)\n"], ["dict[x][:2]\n", "dict[x][n]\n", "dict['apples.1'][2]\n"], ["dict = {\"apples\" : \"aaaaaaappplllllleeeeeeeeees\", \"bananas\" : \"baaaanaaaaanaaaaaaaaaaasssssssss\", \"strawberries\" : \"straaaawwwwwbeeeeerriiiiies\"}\n\nx = list(d.values())  # I transformed dict values into list to be able to slice them\nprint(x[0][0], x[0][10], x[0][15])\nprint(x[1][0], x[1][10], x[1][15])\nprint(x[2][0], x[2][10], x[2][15])\n", "a l l\nb a a\ns w e\n"], ["d = {\n    'apples.1': 'aaaaaaappplllllleeeeeeeeees',\n    'bananas.1': 'baaaanaaaaanaaaaaaaaaaasssssssss',\n    'strawberries.1': 'straaaawwwwwbeeeeerriiiiies'\n}\n\nfor key, value in d.items():\n    a, b, c = value[0], value[9], value[14]\n    print(f'{key}: {a}, {b}, {c}')\n", "apples.1: a, p, l\nbananas.1: b, a, a\nstrawberries.1: s, w, e\n"], ["Dic[apples]=Dic[apples][5]\nDic[bananas]=Dic[bananas][5]\nDic[bananas]=Dic[bananas][0:5]\n\nprint(Dic)\n", "{\n        apples: 'a',\n        bananas: 'a',\n        strawberries: 'straa'\n    }\n"], ["def fill_in_numbers(lst):\n    i=0\n    while True:\n        if lst[i+1] != lst[i] + 1:\n             lst.insert(i+1, lst[i]+1)\n        i+=1\n        if lst[-1] - lst[i]== 1:\n            break\n    return lst\n"], ["        if lst[-1] - lst[i] !=1:\n", "lst = [12,15,19]\nfill_in_numbers(lst)\nprint(lst)\n"], ["def fill_in_numbers(lst):\n    return [*range(lst[0], lst[-1]+1)]\n", "def fill_in_numbers(lst):\n    start = lst[0]\n    end = lst[-1]\n    return [*range(start, end + 1)]\n", "print(fill_in_numbers([12, 15, 19])) # Output: [12, 13, 14, 15, 16, 17, 18, 19]\nprint(fill_in_numbers([-5, 0, 5])) # Output: [-5, -4, -3, -2, -1, 0, 1, 2, 3, 4, 5]\n"], ["def fill_in_numbers(lst):\n    i=0\n    while True:\n        if lst[-1] - lst[i] !=1:\n            if lst[i]+1 not in lst:\n                lst.insert(i+1, lst[i]+1)\n        i+=1\n        if lst[-1] - lst[i]== 1:\n            break\n    return lst\n", "def fill_in_numbers(lst):\n    return list(range(lst[0], lst[-1]+1))\n"], [">>> def fill_in_numbers(lst):\n...     #n1 = min(lst)\n...     n1 = lst[0]\n...     #n2 = max(lst)\n...     n2 = lst[-1]\n...     lst[:] = range(n1, n2 + 1)\n...     return lst\n...\n\n>>> fill_in_numbers([3, 8 , 12])\n[3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n"], [" def fill_in_numbers(lst):\n        i=0\n        lst = [a for a in range(lst[i],lst[-1]+1)]\n    \n        return lst\n    \n  print(fill_in_numbers([12,15,19]))\n"], ["def fill_in_numbers(lst):\n  new_list = []\n  for i in range(len(lst)):\n    new_list.append(lst[i])\n    if i+1 < len(lst):\n      [new_list.append(k) for k in range(lst[i]+1, lst[i+1])]\n  return new_list\n\n\nprint(fill_in_numbers([12,15,19])) # --- Output --->>> [12, 13, 14, 15, 16, 17, 18, 19] \nprint(fill_in_numbers([ -5,0, 5])) # --- Output --->>> [-5, -4, -3, -2, -1, 0, 1, 2, 3, 4, 5]\n"], ["class Node:\n\ndef __init__(self, letter):\n    self.letter = letter\n    self.chidren = {}\n\n@classmethod\ndef construct(cls):\n    return cls(letter=None)\n\ndef add_word(self, word):\n    current = self\n\n    for letter in word:\n        if letter not in current.chidren:\n            node = Node(letter)\n            current.chidren[letter] = node\n        else:\n            node = current.chidren[letter]\n        current = node\n\ndef lookup_word(self, word, m):\n    def _lookup_next_letter(_letter, _node):\n        if _letter == '?':\n            for node in _node.chidren.values():\n                q.put((node, i))\n\n        elif _letter in _node.chidren:\n            q.put((_node.chidren[_letter], i))\n\n    q = SimpleQueue()\n    count = 0\n    i = 0\n    current = self\n\n    letter = word[i]\n    i += 1\n\n    _lookup_next_letter(letter, current)\n\n    while not q.empty():\n        current, i = q.get()\n        if i == m:\n            count += 1\n            continue\n\n        letter = word[i]\n        i += 1\n        _lookup_next_letter(letter, current)\n\n    return count\n\ndef __eq__(self, other):\n    return self.letter == other.letter if isinstance(other, Node) else other\n\ndef __hash__(self):\n    return hash(self.letter)\n"], ["import operator\n\ndef get_overlaps(end, remaining):\n    output = []\n    for r in remaining:\n        if r[0] < end:\n            # starts before the end\n            output.append(r[2])\n            continue\n        break\n    return output\n\ndef get_all_overlaps(lst):\n    # thanks @Elan-R for this simplification\n    for i, (start, end, name) in enumerate(lst):        \n        overlaps = get_overlaps(end, lst[i+1:])\n        if overlaps:\n            print(name, \"overlaps\", \" & \".join(overlaps))\n\n\na = [(0, 98, '122:R'), (100, 210, '124:R'), (180, 398, '125:R'), (200, 298, '123:R')]\n\n# sort by start time\na.sort(key=operator.itemgetter(0)) # thanks to @moonGoose\nget_all_overlaps(a)\n", "124:R overlaps 125:R & 123:R\n125:R overlaps 123:R\n"], ["from itertools import combinations\nfrom intspan import intspan\n\na = [(0, 98, '122:R'), (100, 210, '124:R'), (180, 398, '125:R'), (200, 298, '123:R')]\n\nd = {}\nfor one, two in combinations(a,2):\n    # if the 2 ranges intersect\n    if intspan.from_range(*one[0:2]) & intspan.from_range(*two[0:2]):\n        d.setdefault(one[2], []).append(two[2])\n\nfor key, v in d.items():\n    print(key + ',' + ','.join(v))\n", "124:R,125:R,123:R\n125:R,123:R\n"], [], ["items = [(0, 98, '122:R'), (100, 210, '124:R'), (180, 398, '125:R'), (200, 298, '123:R')]\n    \nsorted(items, key=lambda x: x[0])\n\noverlaps = []\nwhile items:\n  overlap = list(takewhile(lambda item:item[0] < items[0][1],items))\n  overlaps.append(overlap)\n  items = items[len(overlap):]\n", "[\n   [(0, 98, '122:R')],\n   [(100, 210, '124:R'), (180, 398, '125:R'), (200, 298, '123:R')]\n]\n"], ["    a = [(0, 98, '122:R'), (100, 210, '124:R'), (180, 398, '125:R'), (200, 298, '123:R')]\n    \n    for i in range(len(a)-1):\n        i_low, i_high, i_id = a[i]\n        for j in range(i+1, len(a)):\n            j_low, j_high, j_id = a[j]\n            if i_low < j_low < i_high or j_low < i_low < j_high:\n                print(i_id, \" overlaps with \", j_id)\n", "    a = [(0, 98, '122:R'), (100, 210, '124:R'), (180, 398, '125:R'), (200, 298, '123:R')]\n    \n    for i in range(len(a)-1):\n        i_low, i_high, i_id = a[i][0], a[i][1], a[i][2]\n        for j in range(i+1, len(a)):\n            j_low, j_high, j_id =a[j][0], a[j][1], a[j][2]\n            if i_low < j_low < i_high or j_low < i_low < j_high:\n                print(i_id, \" overlaps with \", j_id)\n"], ["import re\nfor q in queries:\n    p = re.compile(q.replace(\"?\", \".\"))\n    print(sum(1 for w in words if p.match(w)))\n", "from collections import defaultdict\nfrom functools import reduce\n\nM = 3\nwords = [\"cat\", \"map\", \"bat\", \"man\", \"pen\"]\nqueries = [\"?at\", \"ma?\", \"?a?\", \"??n\"]\n\nsets = defaultdict(set)\nfor word in words:\n    for i, c in enumerate(word):\n        sets[i,c].add(word)\n\nall_words = set(words)\nfor q in queries:\n    possible_words = (sets[i,c] for i, c in enumerate(q) if c != \"?\")\n    w = reduce(set.intersection, possible_words, all_words)\n    print(q, len(w), w)\n"], ["t = int(input())\nfor j in range(t):\n    n,b = map(int,input().split())\n    n = list(map(int, input().split()))\n    n.sort()\n    s=0\n    ans=[]\n    for i in n:\n        s = s+i\n        if s<=b:\n            ans.append(s)\n    print(\"Case #{}: {}\".format(j+1,len(ans)))\n"], [], ["import java.util.regex.Matcher;\nimport java.util.regex.Pattern;\n\npublic class WordSearch {\n\nprivate void matchCount(int N, int M, int Q, String[] words,  String[] queries) {\n    \n    Pattern p = null;\n    Matcher m = null;\n    int count = 0;\n    \n    for (int i=0; i<Q; i++) {\n        \n        p = Pattern.compile(queries[i].replace('?','.'));\n        for (int j=0; j<N; j++) {\n            m = p.matcher(words[j]);\n            if (m.find()) {\n                count++;    \n            }\n        }\n        System.out.println(\"For query word '\"+ queries[i] + \"', the count is: \" + count) ;\n        count=0;\n    }\n    System.out.println(\"\\n\");\n    \n}\n\n\npublic static void main(String[] args) {\n    \n    WordSearch ws = new WordSearch();\n    int N = 5; int M=3; int Q=4;\n    String[] w = new String[] {\"cat\", \"map\", \"bat\", \"man\", \"pen\"};\n    String[] q = new String[] {\"?at\", \"ma?\", \"?a?\", \"??n\" };\n    ws.matchCount(N, M, Q, w, q); \n    \n    w = new String[] {\"uqqur\", \"1xzev\", \"ydfgz\"}; \n    q = new String[] {\"?z???\", \"???i?\", \"???e?\", \"???f?\", \"?z???\"};\n    N=3; M=5; Q=5;\n    ws.matchCount(N, M, Q, w, q);\n    \n}\n"], ["\"\"\"\nInput: db whic is a list of words\nchk :  str to find\n\"\"\"\n\ndef check(db,chk):\n    \n    seen = collections.defaultdict(list)\n    for i in db:\n        for j in range(len(i)):\n            temp = i[:j] + \"?\" + i[j+1:]\n            seen[temp].append(i)\n            \n    return len(seen[chk])\n    \nprint check([\"cat\",\"bat\"], \"?at\")\n"], [], ["import java.util.*;\nimport java.io.*;\nimport java.lang.*;\n\npublic class Main {\n\n    static class TrieNode \n    {\n        TrieNode []children = new TrieNode[26];\n        boolean endOfWord;\n        TrieNode() \n        { \n            this.endOfWord = false; \n            for (int i = 0; i < 26; i++) { \n                this.children[i] = null; \n            } \n        }\n\n        void addWord(String word) \n        { \n            // Crawl pointer points the object \n            // in reference \n            TrieNode pCrawl = this; \n    \n            // Traverse the given array of words \n            for (int i = 0; i < word.length(); i++) { \n                int index = word.charAt(i) - 'a'; \n                if (pCrawl.children[index]==null) \n                    pCrawl.children[index] \n                        = new TrieNode(); \n    \n                pCrawl = pCrawl.children[index]; \n            } \n            pCrawl.endOfWord = true; \n        }\n        public static int ans2 = 0;\n        void search(String word, boolean found, String curr_found, int pos) \n        { \n            TrieNode pCrawl = this; \n    \n            if (pos == word.length()) { \n                if (pCrawl.endOfWord) { \n                    \n                    found = true; \n                    ans2++;\n                } \n                return; \n            } \n    \n            if (word.charAt(pos) == '?') { \n    \n                // Iterate over every letter and \n                // proceed further by replacing \n                // the character in place of '.' \n                for (int i = 0; i < 26; i++) { \n                    if (pCrawl.children[i] != null) { \n                     pCrawl.children[i].search(word,found,curr_found + (char)('a' + i),pos + 1); \n                    } \n                } \n            } \n            else {  // Check if pointer at character \n                // position is available, \n                // then proceed \n                if (pCrawl.children[word.charAt(pos) - 'a'] != null) { \n                    pCrawl.children[word.charAt(pos) - 'a'] \n                        .search(word,found,curr_found + word.charAt(pos),pos + 1); \n                } \n            } \n            return; \n        } \n    \n        // Utility function for search operation \n        int searchUtil(String word) \n        { \n            TrieNode pCrawl = this; \n    \n            boolean found = false; \n            ans2 = 0;\n            pCrawl.search(word, found,\"\",0); \n            return ans2;\n        }   \n    }\n\n    static int searchPattern(String arr[], int N,String str) \n    { \n        // Object of the class Trie \n        TrieNode obj = new TrieNode(); \n    \n        for (int i = 0; i < N; i++) { \n            obj.addWord(arr[i]); \n        } \n    \n        // Search pattern \n        return obj.searchUtil(str); \n    } \n\n    \n\n    public static void ans(String []arr , int n, int m,String [] query, int q){\n        \n\n        for(int i=0;i<q;i++)\n        System.out.println(searchPattern(arr,n,query[i]));\n\n\n    }\n\n\n\n\n    public static void main(String args[]) {\n        Scanner scn = new Scanner();\n        \n            int n = scn.nextInt();\n            int m = scn.nextInt();\n            String []arr = new String[n];\n\n            for(int i=0;i<n;i++){\n                arr[i] = scn.next();\n            }\n            int q = scn.nextInt();\n\n            String []query = new String[q];\n\n            for(int i=0;i<q;i++){\n                query[i] = scn.next();\n            }\n\n            ans(arr,n,m,query,q);\n\n        \n    }\n}\n"], [], [], ["class Trie {\npublic:\nbool isEnd;\nvector<Trie*> children;\nTrie() {\n    this->isEnd = false;\n    this->children = vector<Trie*>(26, nullptr);\n}\n};\nTrie* root;\n\nvoid insert(string& str) {\n    int n = str.size(), idx, i = 0;\n    Trie* node = root;\n    while(i < n) {\n        idx = str[i++] - 'a';\n        if (node->children[idx] == nullptr) {\n            node->children[idx] = new Trie();\n        }\n        node = node->children[idx];\n    }\n    node->isEnd = true;\n}\n\nint getMatches(int i, string& str, Trie* node) {\n    int idx, n = str.size();\n    while(i < n) {\n        if (str[i] >= 'a' && str[i] <='z')\n            idx = str[i] - 'a';\n        else {\n            int res = 0;\n            for(int j = 0;j<26;j++) {\n                if (node->children[j] != nullptr)\n                    res += getMatches(i+1, str, node->children[j]);\n            }\n            return res;\n         }\n        \n        if (node->children[idx] == nullptr) return 0;\n        node = node->children[idx];\n        ++i;\n    }\n    return node->isEnd ? 1 : 0;\n}\n\nint main() {\n    int n, m;\n    cin>>n>>m;\n    string str;\n    root = new Trie();\n    while(n--) {\n        cin>>str;\n        insert(str);\n    }\n    int q;\n    cin>>q;\n    while(q--) {\n        cin>>str;\n        cout<<(str.size() == m ? getMatches(0, str, root) : 0)<<\"\\n\";\n    }\n}\n"], ["def Narcissistic(x):\n        y = sum([int(i)**(len(x)) for i in (x)])\nreturn Narcissistic(x)\n"], ["   group val    animal occurred\n0      A   3       fox        2\n1      A   3       cat        1\n2      A   3       dog        1\n3      A   3    rabbit        0\n4      A   3       eel        0\n5      A   3  elephant        0\n6      B   2       dog        1\n7      B   2    rabbit        1\n8      B   2       eel        1\n9      B   2       fox        0\n10     B   2       cat        0\n11     B   2  elephant        0\n12     C   6       fox        1\n13     C   6  elephant        1\n14     C   6       cat        0\n15     C   6       dog        0\n16     C   6    rabbit        0\n17     C   6       eel        0\n\n   group val val2    animal occurred\n0      A   3    4       fox        2\n1      A   3    4       cat        1\n2      A   3    4       dog        1\n3      A   3    4    rabbit        0\n4      A   3    4       eel        0\n5      A   3    4  elephant        0\n6      B   2    3       dog        1\n7      B   2    3    rabbit        1\n8      B   2    3       eel        1\n9      B   2    3       fox        0\n10     B   2    3       cat        0\n11     B   2    3  elephant        0\n12     C   6    7       fox        1\n13     C   6    7  elephant        1\n14     C   6    7       cat        0\n15     C   6    7       dog        0\n16     C   6    7    rabbit        0\n17     C   6    7       eel        0\n"], ["mux = pd.MultiIndex.from_product([df['group'].unique(), df['animal'].unique()], names=('group','animal'))\ndf = df.set_index(['group','animal']).reindex(mux).reset_index()\ndf['occurred'] = df['val'].notnull().astype(int)\ndf['val'] = df.groupby('group')['val'].transform('first')\n", "   group    animal  val  occurred\n0      A       fox  3.0         1\n1      A       cat  3.0         1\n2      A       dog  3.0         1\n3      A    rabbit  3.0         0\n4      A       eel  3.0         0\n5      A  elephant  3.0         0\n6      B       fox  2.0         0\n7      B       cat  2.0         0\n8      B       dog  2.0         1\n9      B    rabbit  2.0         1\n10     B       eel  2.0         1\n11     B  elephant  2.0         0\n12     C       fox  6.0         1\n13     C       cat  6.0         0\n14     C       dog  6.0         0\n15     C    rabbit  6.0         0\n16     C       eel  6.0         0\n17     C  elephant  6.0         1\n", "val_cols = ['val1', 'val2']\n\nmux = pd.MultiIndex.from_product([df['group'].unique(), df['animal'].unique()], names=('group','animal'))\ndf = df.set_index(['group','animal']).reindex(mux).reset_index()\ndf['occurred'] = df[val_cols[0]].notnull().astype(int)\ndf[val_cols ] = df.groupby('group')[val_cols].transform('first')\n"], [], [], ["df = pd.DataFrame([['A', 3, 4, 'fox'], ['A', 3, 4, 'cat'], ['A', 3, 4,'dog'],\n                   ['B', 2, 3, 'rabbit'], ['B', 2, 3, 'dog'], ['B', 2, 3,'eel'],\n                   ['C', 6, 7, 'fox'], ['C', 6, 7, 'elephant']],\n                  columns=['group', 'val1', 'val2', 'animal'])\n\n\ndfi = df.set_index(['group', 'animal']).assign(occurred=1)\nindx = pd.MultiIndex.from_product(dfi.index.levels)\ndfi = dfi.reindex(indx, fill_value=0)\ndfi[['val1', 'val2']]  = dfi.groupby(level=0)[['val1','val2']].transform('max')\nprint(dfi.reset_index().sort_values(['group', 'occurred'], ascending=[True, False]))\n", "   group    animal  val1  val2  occurred\n0      A       cat     3     4         1\n1      A       dog     3     4         1\n4      A       fox     3     4         1\n2      A       eel     3     4         0\n3      A  elephant     3     4         0\n5      A    rabbit     3     4         0\n7      B       dog     2     3         1\n8      B       eel     2     3         1\n11     B    rabbit     2     3         1\n6      B       cat     2     3         0\n9      B  elephant     2     3         0\n10     B       fox     2     3         0\n15     C  elephant     6     7         1\n16     C       fox     6     7         1\n12     C       cat     6     7         0\n13     C       dog     6     7         0\n14     C       eel     6     7         0\n17     C    rabbit     6     7         0\n", "dfi = df.set_index(['group', 'animal']).assign(occurred=1)\nindx = pd.MultiIndex.from_product(dfi.index.levels)\ndfi = dfi.reindex(indx, fill_value=0)\ndfi['val']  = dfi.groupby(level=0)['val'].transform('max')\ndfi.reset_index().sort_values(['group', 'occurred'], ascending=[True, False])\n", "   group    animal  val  occurred\n0      A       fox    3         1\n1      A       cat    3         1\n2      A       dog    3         1\n3      A    rabbit    3         0\n4      A       eel    3         0\n5      A  elephant    3         0\n8      B       dog    2         1\n9      B    rabbit    2         1\n10     B       eel    2         1\n6      B       fox    2         0\n7      B       cat    2         0\n11     B  elephant    2         0\n12     C       fox    6         1\n17     C  elephant    6         1\n13     C       cat    6         0\n14     C       dog    6         0\n15     C    rabbit    6         0\n16     C       eel    6         0\n"], ["#count how many words in Words list match a single query \ndef DoQuery(Words, OneQuery):\n    count = 0\n    #for each word in the Words list\n    for i in range(Words.size()):\n        word = Words.at(i)\n        #compare each letter to the query\n        match = true\n        for j in range(word.size()):\n            wordLetter = word.at(j)\n            queryLetter = OneQuery.at(j)\n            #if the letters do not match and are not ?, then skip to next word\n            if queryLetter != '?' and queryLetter != wordLetter:\n                match = false\n                break\n        #if we did not skip, the words match. Increase the count\n        if match == true\n            count = count + 1\n    #we have now checked all the words, return the count\n    return count\n"], ["ModuleNotFoundError: No module named 'skbuild'\n", "pip install --upgrade pip\n"], ["    from rest_framework.renderers import JSONRenderer\n    \n    class CustomRenderer(JSONRenderer):\n          \n          def render(self, data, accepted_media_type=None, renderer_context=None):\n              response = {\n                 'error': False,\n                 'message': 'Success',\n                 'data': data\n              }\n\n              return super(CustomRenderer, self).render(response, accepted_media_type, renderer_context)\n", "    from rest_framework.renderers import BrowsableAPIRenderer\n    from api.renderers import CustomRenderer\n\n    class MyViewSet(viewsets.ModelViewSet):\n          renderer_classes = [CustomRenderer, BrowsableAPIRenderer]\n          \n          ...\n"], ["df2 = pd.DataFrame(list(product(df.group.unique(), df.animal.unique())), columns=['group', 'animal'])\ndf2['val'] = df2['group'].map(df.set_index('group')['val'].to_dict())\ndf2.merge(df.drop('val', axis=1).assign(occurred=1), how='outer').fillna(0, downcast='infer')\n"], [], ["e = Environment(\"custom\")\ne.docker.base_dockerfile = \"path/to/your/dockerfile\"\n", "e.register(ws).build(ws).wait_for_completion()\n"], ["def model_map(row):\n    if row['x'] >= max(df.maxValue_1, maxValue_2):\n        return True\n    else:\n        return False\n    \ndf['result'] = df.apply(lambda row : model_map(row), axis=1)\n"], [], ["np.where(condition, value if condition is true, value if condition is false)\n", "df['result'] = np.where(df['x']>= np.maximum(df['maxValue_1'], maxValue_2) , True, False)\n", "    A  x  maxValue_1  result\n0  C1  2           2    True\n1  C2  2           1    True\n2  C3  3           2    True\n3  C4  2           3   False\n4  C5  3           4   False\n5  C6  1           2   False\n6  C7  3           1    True\n\n"], ["df['result'] = df['x'] >= np.maximum(df['maxValue_1'], maxValue_2)\nprint(df)\n", "    A  x  maxValue_1  result\n0  C1  2           2    True\n1  C2  2           1    True\n2  C3  3           2    True\n3  C4  2           3   False\n4  C5  3           4   False\n5  C6  1           2   False\n6  C7  3           1    True\n"], ["df['result'] = df.apply(lambda row: row.x >= max(row.maxValue_1, maxValue_2), axis=1)\n"], ["FROM nvidia/cuda:10.0-cudnn7-runtime-ubuntu18.04\n\nRUN apt-get update -y\nRUN apt-get install -y vim curl iputils-ping python3-dev python3-pip libsm6 \nlibxext6 libxrender-dev python3.6\nRUN pip3 install -r /requirements.txt\n...\n", "...\nopencv-python\n...\n", " Traceback (most recent call last):\n   File \"<string>\", line 1, in <module>\n   File \"/tmp/pip-build-acog3xol/opencv-python/setup.py\", line 9, in <module>\n     import skbuild\n ModuleNotFoundError: No module named 'skbuild'\n", "...\nopencv-python==4.2.0.34\n...\n"], ["import random as rand\n\nrandom_list = []\nlength = 0\na = -20\nb = 20\n\nwhile length < 10:\n    number = rand.randint(a,b)\n    if number > 0:\n        random_list.append(number)\n    else:\n        random_list.append(None)\n    k += 1\n\n\nprint(random_list)\n"], [], ["df['mean']=['%.2f'%row for row in mean]\n"], [], ["import numpy as np\nimport pandas as pd\ndf = pd.DataFrame(np.array([[0, 0.030, 0.031, 0.032], [10, 0.153, 0.155, 0.154], [20, 0.393, 0.397, 0.395]]), columns=['Y0','Y1', 'Y2', 'Y3'], dtype=float)\nXa=df.loc[:,\"Y1\":]\nmean=Xa.mean(axis=1)\ndf['mean']=mean.map(lambda x: '%.2f' % x)\ndf\n", "    Y0      Y1      Y2      Y3      mean\n0   0.0     0.030   0.031   0.032   0.03\n1   10.0    0.153   0.155   0.154   0.15\n2   20.0    0.393   0.397   0.395   0.40\n"], [], [">>> from itertools import tee\n>>> from operator import itemgetter\n\n>>> iterable1, iterable2 = 'abcde', 'xyz' \n\n>>> it1, shadow1 = tee(iterable1)\n>>> it2 = iter(iterable2)\n>>> combined = map(itemgetter(0, 1), zip(it1, it2, shadow1))\n \n>>> list(combined)\n[('a', 'x'), ('b', 'y'), ('c', 'z')]\n>>> next(shadow1)\n'd'\n"], ["a=np.array([r for r in a if any(r)])\n"], ["import numpy as np\nx    = np.array([ [1.0, 0.0, 2.0], [0.0, 0.0, 0.0], [2.0, 1.0, 0.0] ])\nm, n = x.shape\nrows = [row for row in range(m) if not all(x[row] == 0)]\nx    = x[rows]\nprint(x)\n"], ["a = np.array([[1.0, 0.0, 2.0], [0.0, 0.0, 0.0], [2.0, 1.0, 0.0]])\n\nprint(a[a.any(axis=1)])\n"], [">>> import numpy as np\n>>> x = np.array([ [1.0, 0.0, 2.0], [0.0, 0.0, 0.0], [2.0, 1.0, 0.0] ])\n>>> x\narray([[1., 0., 2.],\n       [0., 0., 0.],\n       [2., 1., 0.]])\n>>> sumrow = np.abs(x).sum(-1)\n>>> x[sumrow>0]\narray([[1., 0., 2.],\n       [2., 1., 0.]])\n", ">>> x = np.array([ [1.0, 0.0, 2.0], [0.0, 0.0, 0.0], [2.0, 1.0, 0.0] ])\n>>> x[~np.all(x == 0, axis=1)]\narray([[1., 0., 2.],\n       [2., 1., 0.]])\n"], [">>> bar = np.array ([ [1.0, 0.0, 2.0], [0.0, 0.0, 0.0], [2.0, 1.0, 0.0] ] )\n>>> mask = bar.sum(axis=1)==0\n>>> bar[mask]\narray([[1., 0., 2.],\n       [2., 1., 0.]])\n"], ["for row_position in range(1, row):\n            for col_position in range(1, col):\n                self.map = np.concatenate(\n                    [[row_position], [col_position]])  # Concatenate the index from row and col together to get indices\n                if row_position == col_position:\n                    self.slots[row_position][col_position] = None\n                else:\n                    ...\n"], ["import random\n\ndef get_random_number(minval, maxval, none_probability):\n    if random.random() < none_probability:\n        return None\n    else:\n        return random.randint(minval, maxval)\n\ndef get_random_list(length, minval, maxval, none_probability):\n    return [get_random_number(minval, maxval, none_probability)\n            for _ in range(length)]\n\n    \nprint(get_random_list(20, 0, 100, 0.2))\n", "[72, 33, 3, 70, None, 75, 49, 89, 100, 25, None, 55, 85, 95, 75, 9, None, 37, 37, None]\n"], ["def random_list(amount, minval, maxval, none_rate):\n    from random import choice\n    from numpy import linspace\n    arr = linspace(minval, maxval, amount)\n    none_count = round(float(amount * none_rate))\n    rep = []\n    col = [d for d in range(amount)]\n    while none_count > 0:\n        gen = choice(col)\n        if gen not in rep:\n            arr[gen] = None\n            none_count -= 1\n            rep.append(gen)\n    return arr\n\n\nprint(random_list(10, 0, 100, 0.3))\n"], ["import random\n\nr = random.choices(range(10), k=10)   # Get list of numbers\nprint('Before:', r)\nr[:] = [x if x not in range(2) else None for x in r]  # Replace 0-1 with None\nprint('After:', r)\n", "Before: [0, 1, 4, 6, 2, 9, 0, 6, 9, 5]\nAfter: [None, None, 4, 6, 2, 9, None, 6, 9, 5]\n"], ["from random import randint as r\nrandomlist=[r(0, 100) if r(0,100)>r(0,100) else None for i in range(15)]\n"], ["python3.7 -m pip install opencv-python==4.3.0.38\n"], ["n = int(input())\nif ((n>=1 and n<=100) or (n>=1 and n<=10**5)):\n    z = []\n    for i in range(0, n):\n      x = [int(w) for w in input().split()]\n      y = [int(j) for j in input().split()]\n      y.sort()\n      a = 0\n      count = 0\n      if sum(y) > x[1]:\n        for k in range(0, len(y)):\n          if (a == 0 and y[k]>x[1]):\n            break\n          elif (a <= x[1]):\n            a+= y[k]\n            count+=1\n            if (a + y[k+1] > x[1]):\n              break\n        z.append(count)\n      else:\n        z.append(len(y))\n    for i in range(0, n):\n      print(\"Case #\"+ str(i+1) +\": \" + str(z[i]))\n"], [], [], [], ["pip install --upgrade pip\n", "pip install opencv-python\n"], ["items = second_df.index\ndates = []\n\nfor pivot in first_df.date:\n    dates.append(getNearestDate(items, pivot))\n    \nfirst_df['new_date'] = dates\n", "first_df = first_df.drop(columns=\"date\")\n", "first_df.set_index(\"new_date\", inplace =True)\n", "second_df = second_df.merge(first_df, how = \"left\",left_index=True, right_index=True)\n", "second_df.importance = second_df.importance.fillna(0)\n"], ["# note the method and the tolerance. Change them to whatever works best for your actual data\nnew_df = df2.merge(df.reindex(df2.index, method='nearest', limit=1, tolerance='2T'),\n                   left_index=True, right_index=True)\n\n\n                         value importance\nindex                                    \n2006-12-05 08:03:01.985      6        NaN\n2006-12-05 08:11:34.130      7        NaN\n2006-12-05 08:20:05.959      6        NaN\n2006-12-05 08:28:38.104      6        NaN\n2006-12-05 08:37:02.995      6        NaN\n2006-12-05 08:45:35.140      5        NaN\n2006-12-05 08:54:06.969      6        NaN\n2006-12-05 09:02:59.928      6        NaN\n2006-12-05 09:11:32.072      6        NaN\n2006-12-05 09:20:03.901      6        NaN\n2006-12-05 09:28:36.046      5        NaN\n2006-12-05 09:37:00.937      5        NaN\n2006-12-05 09:45:33.082      6        NaN\n2006-12-05 09:54:04.911      6        NaN\n2006-12-05 10:02:04.889      6        NaN\n2006-12-05 10:10:37.034      5        NaN\n2006-12-05 10:19:08.863      6        NaN\n2006-12-05 10:27:41.008      5        NaN\n2006-12-05 10:36:04.953      5       HIGH\n2006-12-05 10:44:37.098      5        NaN\n2006-12-13 02:06:00.898      1        NaN\n2006-12-13 02:14:33.043      1        NaN\n2006-12-13 02:23:04.872      1        NaN\n2006-12-13 02:31:03.904      1        NaN\n2006-12-13 02:39:36.048      1        LOW\n2006-12-13 02:48:07.878      2        NaN\n2006-12-13 02:56:40.022      5        NaN\n2006-12-13 03:05:04.914      2        NaN\n2006-12-13 03:13:37.058      3        NaN\n2006-12-13 03:22:08.888      6        NaN\n2006-12-13 03:31:03.108      1        NaN\n2006-12-13 03:39:34.937      1        NaN\n2006-12-13 03:48:07.081      1        NaN\n2006-12-13 03:56:38.911      2        NaN\n2006-12-13 04:05:04.117      3        NaN\n"], ["loc=[]\n\n    def getNearestDate(items, pivot):\n        return min(items, key=lambda x: abs(x - pivot))\n    \n    items = second_df.index\n    for pivot in first_df.date:\n        d = getNearestDate(items, pivot)\n        loc.append(second_df.set_index('index').index.get_loc(d))\n    \n    ## Adding Data to your second df   \n    second_df['importance']=[]\n    for index,locations in enumerate(loc):\n        df['importance'][int(location)]=first_df['importance'][index]\n"], ["mask = False\nfor pivot in first_df.date:\n    mask |= second_df.index == getNearestDate(second_df.index, pivot)\nsecond_df['new_value'] = mask\n", "mask = False\nfor pivot in first_df.date:\n    mask |= second_df.index == getNearestDate(second_df.index, pivot)\nsecond_df['new_value'] = mask.apply(lambda x: 'X' if bool(x) else '')\n", "first_df['index'] = first_df.apply(\n    lambda x: getNearestDate(second_df.index, x.date),\n    axis = 1,\n    result_type = 'reduce'\n)\nsecond_df = second_df.merge(first_df, how='left', on='index')\n"], [], ["k_val = 'K'\nm_val = 'M'\nmy_list = ['389.3K', '2M' , '1.9M' , '6.9M' , '4.3M' , '251.5K' , '3.6M']\nkilos = []\nmegas = []\nentire = []\n\nfor val in my_list:\n    if val[-1] == k_val:\n        fval = float(val[:-1]) * 1000\n        kilos.append(fval)\n    elif val[-1] == m_val:\n        fval = float(val[:-1]) * 1000000\n        megas.append(fval)\n    else:\n        print(\"detected invalid value: \" + val)\n        continue\n    entire.append(fval)\n\nprint(str(kilos))\nprint(str(megas))\nprint(str(entire))\n"], ["my_list = ['389.3K', '2M' , '1.9M' , '6.9M' , '4.3M' , '251.5K' , '3.6M']\n\nk_list = [float(i[:-1])*1000 for i in my_list if i.endswith('K')]\nm_list = [float(i[:-1])*1000000 for i in my_list if i.endswith('M')]\n\n\nk_list_strings = [f'{num:,}' for num in k_list]\nm_list_strings = [f'{num:,}' for num in m_list]\n", "[389300.0, 251500.0]\n[2000000.0, 1900000.0, 6900000.0, 4300000.0, 3600000.0]\n", "['389,300.0', '251,500.0']\n['2,000,000.0', '1,900,000.0', '6,900,000.0', '4,300,000.0', '3,600,000.0']\n"], ["my_list = ['389.3K', '2M' , '1.9M' , '6.9M' , '4.3M' , '251.5K' , '3.6M']\ne_list = [i.replace('K','e3').replace('M','e6') for i in my_list]\nvalues = [float(i) for i in e_list]\nmy_new_list = [f'{int(i):,}' for i in values]\nprint(my_new_list)\n", "['389,300', '2,000,000', '1,900,000', '6,900,000', '4,300,000', '251,500', '3,600,000']\n"], [">>> [float(s.replace('K', 'e3').replace('M', 'e6')) for s in my_list]\n[389300.0, 2000000.0, 1900000.0, 6900000.0, 4300000.0, 251500.0, 3600000.0]\n"], ["my_list = ['389.3K', '2M' , '1.9M' , '6.9M' , '4.3M' , '251.5K' , '3.6M']\ndata = {\"K\": 1000, \"M\": 1000000}\nresult = [float(i[:-1])*data.get(i[-1], 0) for i in my_list]\nprint(result)\n", "import re\nimport locale    #https://stackoverflow.com/a/5180615/532312\n\nlocale.setlocale(locale.LC_ALL, '')\n\nmy_list = ['389.3K', '2M' , '1.9M' , '6.9M' , '4.3M' , '251.5K' , '3.6M']\ndata = {\"K\": 1000, \"M\": 1000000}\n\nresult = []\nfor i in my_list:\n    m = re.match(r\"(\\d+\\.?\\d*)([A-Z])\", i)\n    if m:\n        value, key = m.groups()\n        result.append(locale.currency(float(value) * data.get(key, 0), symbol=False, grouping=True))\nprint(result)\n", "['389,300.00', '2,000,000.00', '1,900,000.00', '6,900,000.00', '4,300,000.00', '251,500.00', '3,600,000.00']\n"], ["k_list = [val for val in my_list if k_val in val]\nm_list = [val for val in my_list if m_val in val]\n"], [], ["exit()\n"], [], [">>>\n"], [], [], ["pd.DataFrame(index=df2.squeeze(), columns=df1.squeeze()).apply(lambda x: x.name.astype(str)+':'+x.index)\n", "            1        2        3        4                                        \none      1:one    2:one    3:one    4:one\ntwo      1:two    2:two    3:two    4:two\nthree  1:three  2:three  3:three  4:three\nfour    1:four   2:four   3:four   4:four\n"], ["import csv\n\nmy_new_row = [6, 'abc6', 'xyz6']\nx, y = ',', ', '\n\nwith open('data.csv', 'r', newline='') as original_file:\n    original_reader = csv.reader(original_file)\n    with open('new_file.csv', 'w', newline='') as new_file:\n        new_writer = csv.writer(new_file, delimiter=',')\n        for line in original_reader:\n            new_writer.writerow(line)\n        with open('temp_file.csv', 'w+', newline='') as temp_file:\n            temp_reader = csv.reader(temp_file)\n            temp_writer = csv.writer(temp_file, delimiter=',')\n            temp_writer.writerow(my_new_row)\n            temp_file.seek(0)\n            data = temp_file.read()\n            temp_file.seek(0)\n            temp_file.write(data.replace(x, y))\n            temp_file.seek(0)\n            for line in temp_reader:\n                new_writer.writerow(line)\n"], ["import csv\n\nclass CSV_Translater(object):\n    \"\"\" Output file-like object that translates characters. \"\"\"\n    def __init__(self, f, old, new):\n        self.f = f\n        self.old = old\n        self.new = new\n    def write(self, s):\n        self.f.write(s.replace(self.old, self.new))\n    def close(self):\n        self.f.close()\n    def flush(self):\n        self.f.flush()\n\nmy_new_row = ['6', 'abc6', 'xyz6']\n\n\nwith open('data.csv', \"r+\") as filehandle:\n    reader = csv.reader(filehandle)\n    with open('out_test.csv', \"w\") as opfile:\n        translater = CSV_Translater(opfile, ',', ', ')\n        writer = csv.writer(translater, delimiter=',')\n        for row in reader:\n            writer.writerow(row)\n        writer.writerow(my_new_row)\n"], ["import csv\nmy_new_row = [6, 'abc6', 'xyz6']\nwith open('data.csv', 'a') as filehandle:\n    writer = csv.writer(filehandle, delimiter=',')\n    writer.writerow([' ' + str(i) if isinstance(i, str) else i for i in my_new_row])\n"], ["def readAndWriteFile(read_file_path,write_file_path):\n    with open(read_file_path,\"r\") as fin:\n        output = [\", \".join(element.split(',')) for element in fin.readlines()]\n    print(\"output:\",output)\n    \n    with open(write_file_path,'w') as fout:\n        fout.writelines(output)\n"], [], ["pd.DataFrame(np.tile(df1[0][:,None],df2.shape[0])).astype(str).add(\":\"+df2[0]).T\n", "pd.DataFrame(np.repeat(df1[0].astype(str)[None,:],df2.shape[0],axis=0)).add(':'+df2[0])\n", "         0        1        2        3\n0    1:one    2:one    3:one    4:one\n1    1:two    2:two    3:two    4:two\n2  1:three  2:three  3:three  4:three\n3   1:four   2:four   3:four   4:four\n", "def my_function(x, y):\n    return f\"{x}:{y}\"\n\nu = df1.assign(k=1).merge(df2.assign(k=1),on='k').drop('k',1).to_numpy()\narr = (np.array([*map(lambda x: my_function(*x),u)])\n         .reshape((df1.shape[0],df2.shape[0]),order='F'))\n", "print(arr,\"\\n---------------------------------------------------\\n\",pd.DataFrame(arr))\n\n[['1:one' '2:one' '3:one' '4:one']\n ['1:two' '2:two' '3:two' '4:two']\n ['1:three' '2:three' '3:three' '4:three']\n ['1:four' '2:four' '3:four' '4:four']] \n---------------------------------------------------\n         0        1        2        3\n0    1:one    2:one    3:one    4:one\n1    1:two    2:two    3:two    4:two\n2  1:three  2:three  3:three  4:three\n3   1:four   2:four   3:four   4:four\n"], [], ["pd.DataFrame(df1.astype(str).to_numpy().ravel() + ':' + df2.to_numpy())\n\n         0        1        2        3\n0    1:one    2:one    3:one    4:one\n1    1:two    2:two    3:two    4:two\n2  1:three  2:three  3:three  4:three\n3   1:four   2:four   3:four   4:four\n"], ["df = pd.DataFrame(np.add.outer(df1[0].astype(str).values,':'+df2[0].values).T)\nOut[258]: \n         0        1        2        3\n0    1:one    2:one    3:one    4:one\n1    1:two    2:two    3:two    4:two\n2  1:three  2:three  3:three  4:three\n3   1:four   2:four   3:four   4:four\n"], [], ["import datetime\nimport random\nimport numpy as np\n", "minute_range = np.arange(0,59,5)\n", "hour_range = np.arange(0,24,1)\n", "a = datetime.time(random.choice(hour_range),random.choice(minute_range))\n", "print(a.strftime(\"%H:%M\"))\n", "for _ in range(5):\n    a = datetime.time(random.choice(hour_range),random.choice(minute_range))\n    print(a.strftime(\"%H:%M\"))\n", "05:25\n09:55\n07:05\n08:05\n11:05\n"], ["import random\n\nfor RECORD in range(100):\n  print(\n    #generate random int between 0 and 23 convert to string and pad by '0'\n    str(random.randint(0,23)).rjust(2,'0') \n    # add devider\n    + ':' + \n    # random int between 0 and 55 with step 5\n    str(random.randint(0,11)*5).rjust(2,'0') \n  )\n"], ["In [15]: import pandas as pd\n\nIn [16]: [i.strftime(\"%H:%M\") for i in pd.date_range(\"01:13\", \"01:57\", freq=\"5min\").time]\nOut[16]:\n['01:13',\n '01:18',\n '01:23',\n '01:28',\n '01:33',\n '01:38',\n '01:43',\n '01:48',\n '01:53']\n"], ["import datetime\nimport time\nimport random\n\nMINTIME = datetime.datetime(2020,7,1,0,0,0)\nMAXTIME = datetime.datetime(2020,7,31,0,0,0)\n\nmintime_ts = int(time.mktime(MINTIME.timetuple())) #convert date into int\nmaxtime_ts = int(time.mktime(MAXTIME.timetuple())) #convert date into int\n\nnb_slots = (maxtime_ts - mintime_ts)//(5*60)  # number of 5 minutes slots\nfor RECORD in range(10):\n    random_slot = random.randint(0, nb_slots)\n    random_ts = mintime_ts + 5*60 * random_slot\n    RANDOMTIME = datetime.datetime.fromtimestamp(random_ts)\n    print(datetime.datetime.strftime(RANDOMTIME, '%H:%M'))\n    \n", "11:20\n15:20\n11:25\n02:10\n13:30\n08:30\n00:45\n06:10\n17:05\n01:00\n"], ["import datetime\nimport time\nimport random\n\nMINTIME = datetime.datetime(2020,7,1,0,0,0)\nMAXTIME = datetime.datetime(2020,7,31,0,0,0)\n\nmintime_ts = int(time.mktime(MINTIME.timetuple())) #convert date into int\nmaxtime_ts = int(time.mktime(MAXTIME.timetuple())) #convert date into int\n\nscale = 5*60\n\nfor RECORD in range(100):\n    random_ts = random.randint(mintime_ts//scale, maxtime_ts//scale)*scale\n    RANDOMTIME = datetime.datetime.fromtimestamp(random_ts)\n    print(RANDOMTIME.strftime('%H:%M'))\n"], ["import re\ncheck = re.match(r'^(?:[0-9]{1,3}\\.){3}[0-9]{1,3}$', YOUR_STRING)\nif check:\n    print('IP valid')\nelse:\n    print('IP not valid')\n", "wanip = str(input(\"please key in WAN IP address:\"))\nif not re.match(r'^(?:[0-9]{1,3}\\.){3}[0-9]{1,3}$', wanip):\n    # Throw error here\n# Continue with your code\n", "import re\n\nip = None\nwhile True:\n    ip = str(input(\"please key in WAN IP address:\"))\n    if re.match(r'^(?:[0-9]{1,3}\\.){3}[0-9]{1,3}$', ip):\n        # Say something to user\n        break\n    else:\n        # Say something to user\n        continue\nprint(ip)\n"], ["import ipaddress\n\nwhile True:\n    try:\n        a = ipaddress.ip_address(input('Enter IP address: '))\n        break\n    except ValueError:\n        continue\n\nprint(a)\n", "Enter IP address: s\nEnter IP address: a\nEnter IP address: 1.1.1.1\n1.1.1.1\n"], ["def isValid(ip):\n    ip = ip.split(\".\")\n\n    for number in ip:\n        if not number.isnumeric() or int(number) > 255:\n            return False\n    \n    return True\n"], ["def validIPAddress(self, IP):\n        \n        def isIPv4(s):\n            try: return str(int(s)) == s and 0 <= int(s) <= 255\n            except: return False\n            \n        def isIPv6(s):\n            if len(s) > 4: return False\n            try: return int(s, 16) >= 0 and s[0] != '-'\n            except: return False\n\n        if IP.count(\".\") == 3 and all(isIPv4(i) for i in IP.split(\".\")): \n            return \"IPv4\"\n        if IP.count(\":\") == 7 and all(isIPv6(i) for i in IP.split(\":\")): \n            return \"IPv6\"\n        return \"Neither\"\n"], ["import ipaddress\n\ntry:\n    user_ip = input(\"Enter adress: \")\n    ip = ipaddress.ip_address(user_ip)\n    print(f'{ip} is correct. Version: IPv{ip.version}')\nexcept ValueError:\n    print('Adress is invalid')\n", "Enter adress: 23\nAdress is invalid\n\nEnter adress: 154.123.1.34\n154.123.1.34 is correct. Version: IPv4\n"], [], ["def beginning(list1):\n    sub_list = []\n    final_list = []\n    if len(list1) > 10:\n        sub_list = list1[:10]\n        count = 0\n    while (count<len(sub_list)) and (sub_list[count] != \"bye\"):\n        final_list.append(sub_list[count])\n        count = count + 1\n    return final_list\n"], [], ["mx=[max(l) for l in list_name]\nmx=max(mx)\n", "for i in range(len(list_name)):\n  if mx==ps[i]:\n    print(\"The digit is \"+str(i))\n    break\n"], ["no_list = [22,68,90,78,90,88]\n\ndef average(x):\n       #complete the function's body to return the average\n\n    \nprint(average(no_list))\n"], ["testDf.replace(regex=r'([.](?=\\s))', value=r'')\n\n\n                  strings\n0     this is a. test stence\n1  for which is ? was a time\n"], [], ["testDf['strings'].str.replace('\\?.|\\..', '.')\n", "testDf['strings'].str.replace('\\..', '.')\n", "testDf['strings'].str.replace('\\?.', '.')\n"], ["testDF.replace(regex=r'([.?])\\.', value=r'\\1')\n"], ["testDf['strings'].str.replace('..', '.',regex=False).str.replace('?.', '?',regex=False)\n", "                     strings\n0     this is a. test stence\n1  for which is ? was a time\n"], [], ["while list.pop() != 'durian':\n    pass\nprint(len(list))\n", "i = 0\nwhile list[i] != 'durian':\n    i = random.randrange(len(list))\nprint(i)\n"], ["list_sample = ['apple', 'orange', 'durian', 'blackberry']\n\nfor i in range(len(list_sample)):\n    if list_sample[i] == 'durian':\n        print(\"Index Position of 'durian' in the list is \" + str(i))\n    else:\n        pass\n", "list_sample = ['apple', 'orange', 'durian', 'blackberry']  # apple is at the\n\nfor i, value in enumerate(list_sample):\n    if value == 'durian':\n        print(\"Index Position of 'durian' in the list is \" + str(i))\n    else:\n        pass\n\n"], ["def getindex(l: list, element) -> int:\n    for i, e in enumerate(l):\n        if e == element:\n            return i\n    raise ValueError(f\"{element} is not in list\")\n"], ["lst = ['apple', 'orange', 'durian', 'blackberry']\n\nfor idx, value in enumerate(lst):\n    if value == \"durian\":\n        print(idx)\n"], ["def beginning(lst):\n    ten=10\n    a=0\n    new_list=[]\n    while a<len(lst) and lst[a]!='bye':\n        new_list.append(lst[a])\n        a+=1\n    if len(new_list)>10 or len(new_list)==10:\n        return new_list[:10]\n    else:\n        return new_list\n"], [], ["x=[[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n\nout = []\nfor arr in x:\n    out.append([arr[0], arr[-1]])\n\nprint(out)\n", "[[1, 3], [4, 6], [7, 9]]\n", "out = [[arr[0], arr[-1]] for arr in x]\n"], [], [], ["next_vowel_index = vowels.index(letter) + 1\nif next_vowel_index >= len(vowels):\n    next_vowel_index = 0\nnew_message += vowels[next_vowel_index]\n"], ["import random\nvowels = {\"a\":\"e\", \"e\":\"i\", \"i\":\"o\", \"o\":\"u\", \"u\":\"a\"}\n\nmessage = input(\"Enter a string : \")\n\nnew_message = \"\"\n\nfor letter in message:\n    if letter not in vowels:\n        new_message += letter\n    else:\n        new_message += vowels[letter]\n        \nprint(\"Converted text : \" + new_message)\n", "Enter a string : hello sir\nConverted text : hillu sor\n"], [">>> v = \"aeiou\"\n>>> vDict = {v[i]: v[(i+1)%len(v)] for i in range(len(v))}\n>>> vDict\n{'a': 'e', 'e': 'i', 'i': 'o', 'o': 'u', 'u': 'a'}\n>>> \"This is a test-string. hope it works!\".translate(str.maketrans(vDict))\n'Thos os e tist-strong. hupi ot wurks!'\n"], ["vowels = [\"a\", \"e\", \"i\", \"o\", \"u\"]\n\nmapper = dict(zip(vowels, vowels[1:] + [vowels[0]])\nmessage = input(\"Enter a string\")\n\nnew_message = \"\"\n\nfor letter in message:\n    new_message += mapper.get(letter, letter)\n        \nprint(new_message)\n", "import re\n\nnew_message = re.sub(\"\\S\", lambda x: mapper.get(x.group(0), x.group(0)))\n"], ["for letter in message:\n    if letter not in vowels:\n        new_message += letter\n    else:\n        i = vowels.index(letter)\n        i+=1\n        new_message += vowels[i]\n"], ["$OriginalArray = @(\"1\",\"8\",\"8\",\"8\",\"1\",\"3\",\"3\",\"8\") \n$NewArray = New-ObjectSystem.Collections.ArrayList\n$ArrayGroup = $OriginalArray | Group-Object | Select-Object Count,Name\n\nForEach ($EachNumber in $ArrayGroup) {\n    $HalfTheCount = (1..([Math]::Round($EachNumber.Count / 2)))\n    ForEach ($Item in $HalfTheCount) {$NewArray.Add($EachNumber.Name) | Out-Null}   \n    } \n$NewArray\n", "$OriginalArray = @(\"1\",\"8\",\"8\",\"8\",\"1\",\"3\",\"3\",\"8\") \n\n$NewArray = New-Object System.Collections.ArrayList\n\n$OddOrEven = \"Even\"\nForEach ($SortedItem in ($OriginalArray | Sort-Object)) {\n    If ($OddOrEven -eq \"Even\") {$NewArray.Add($SortedItem);$EvenNumber = $True}\n    If ($OddOrEven -eq \"Odd\") {$EvenNumber = $False}\n    If ($EvenNumber -eq $True) {$OddOrEven = \"Odd\"} Else {$OddOrEven = \"Even\"} \n}\n$NewArray\n"], [], ["from pgmpy.models.BayesianModel import BayesianModel\nfrom pgmpy.factors.discrete import TabularCPD\nfrom pgmpy.sampling import BayesianModelSampling\n\nstudent = BayesianModel([('diff', 'grade'), ('intel', 'grade')])\n\ncpd_d = TabularCPD('diff', 2, [[0.6], [0.4]])\ncpd_i = TabularCPD('intel', 2, [[0.7], [0.3]])\ncpd_g = TabularCPD('grade', 3, [[0.3, 0.05, 0.9, 0.5], [0.4, 0.25, 0.08, 0.3], [0.3, 0.7, 0.02, 0.2]], ['intel', 'diff'], [2, 2])\n\nstudent.add_cpds(cpd_d, cpd_i, cpd_g)\ninference = BayesianModelSampling(student)\ndf_samples = inference.forward_sample(size=20, return_type='recarray')\n\nprint(df_samples)\n"], ["val headers = spark.read.format(\"xml\").option(\"rowTag\", \"integrationEntityHeader\").load(\"stackOverflowRafaXML.xml\")\n\nheaders.write.csv(<headerFilename>) // Create CSV from the header file\n\nval details = spark.read.format(\"xml\").option(\"rowTag\", \"integrationEntityDetails\").load(\"stackOverflowRafaXML.xml\")\n\n// The details need further unnesting. To get suppliers, for instance, you can do\nval supplier = spark.read.format(\"xml\").option(\"rowTag\", \"supplier\").load(\"stackOverflowRafaXML.xml\")\n\nsupplier.show\n\n+--------------------+--------------------+--------------------+--------------------+--------------------+------------+--------------------+-------+--------------------+---------+------+------------+----------+---------------------+\n|        allLocations|         bankDetails|      companyDetails|      contactDetails|        controlBlock|facilityCode|               forms|     id|          myLocation|requestId|status|supplierType|systemCode|systemFacilityDetails|\n+--------------------+--------------------+--------------------+--------------------+--------------------+------------+--------------------+-------+--------------------+---------+------+------------+----------+---------------------+\n|[[HQ, 2501 GRANT ...|[[[[LOW_BANK_KEY,...|[No, SUPPLIER, 25...|[[[1704312142, SI...|[[[MODE, Onboardi...|           1|[[[CATEGORY_PRODS...|1647059|[[1704342, false,...|  2614352|ACTIVE| Operational|         1|     [[ACTIVE, 1, 1]]|\n+--------------------+--------------------+--------------------+--------------------+--------------------+------------+--------------------+-------+--------------------+---------+------+------------+----------+---------------------+\n\n\n\n\n"], ["import itertools\n\nst=time.time()\nlst = [1,8,8,8,1,3,3,8]\nlist(itertools.chain.from_iterable(itertools.repeat(x, int(lst.count(x)/2)) for x in list(set(lst)) if lst.count(x)%2==0))\n"], ["def set_impl(l):\n  bag = set()\n  res = []\n  for i in l:\n    if i in bag:\n      res.append(i)\n      bag.remove(i)\n    else:\n      bag.add(i)\n", "import random\nimport statistics as stats\nfrom collections import Counter as counter\nfrom timeit import Timer\n\ndef slice_impl(l):\n  l.sort()\n  res = l[::2]\n\ndef dict_impl(l):\n  count={}\n  res=[]\n  for i in l:\n    if i in count:\n      count[i] += 1\n    else:\n      count[i] = 1\n    if count[i] % 2:\n      res.append(i)\n\ndef counter_impl(l):\n  count = counter(l)\n  res = []\n  for key, val in count.items():\n    res.extend(val//2 * [key])\n\ndef set_impl(l):\n  bag = set()\n  res = []\n  for i in l:\n    if i in bag:\n      res.append(i)\n      bag.remove(i)\n    else:\n      bag.add(i)\n\ndef timed_run():\n  for name, func in {\"Sort and Slice\": slice_impl, \n                     \"Dictionary\": dict_impl, \n                     \"Counter\": counter_impl, \n                     \"Set\": set_impl}.items():\n    seq = list(range(50))*2\n    results = []\n    print(f\"{name} Implementation Results\")\n    for i in range(50):\n      if len(results) % 10: random.shuffle(seq) # shuffle after 10 runs\n      results.append(Timer(lambda: func(seq)).timeit(10**4))\n      # print(f\"Run {i+1:02}: {results[i]:.6f}\")\n    print(\"\")\n    print(f\"Median:  {stats.median(results):.6f}\")\n    print(f\"Mean:    {stats.mean(results):.6f}\")\n    print(f\"Std Dev: {stats.stdev(results):.6f}\")\n    print(\"\\n\\n\")\n\ntimed_run()\n"], ["<?xml version=\"1.0\"?><Company><Employee><FirstName>Hal</FirstName><LastName>Thanos</LastName><ContactNo>122131</ContactNo><Email>hal.thanos@xyz.com</Email><Addresses><Address><City>Bangalore</City><State>Karnataka</State><Zip>560212</Zip><forms><form><id>ID1</id><value>LIC</value></form><form><id>ID2</id><value>PAS</value></form></forms></Address></Addresses></Employee><Employee><FirstName>Iron</FirstName><LastName>Man</LastName><ContactNo>12324</ContactNo><Email>iron.man@xyz.com</Email><Addresses><Address><type>Permanent</type><City>Bangalore</City><State>Karnataka</State><Zip>560212</Zip><forms><form><id>ID3</id><value>LIC</value></form></forms></Address><Address><type>Temporary</type><City>Concord</City><State>NC</State><Zip>28027</Zip><forms><form><id>ID1</id><value>LIC</value></form><form><id>ID2</id><value>PAS</value></form><form><id>ID3</id><value>SSN</value></form><form><id>ID2</id><value>CC</value></form></forms></Address></Addresses></Employee></Company>\n<?xml version=\"1.0\"?><Company><Employee><FirstName>Captain</FirstName><LastName>America</LastName><ContactNo>13322</ContactNo><Email>captain.america@xyz.com</Email><Addresses><Address><City>Trivandrum</City><State>Kerala</State><Zip>28115</Zip><forms><form><id>ID1</id><value>LIC</value></form><form><id>ID2</id><value>PAS</value></form></forms></Address></Addresses></Employee><Employee><FirstName>Sword</FirstName><LastName>Man</LastName><ContactNo>12324</ContactNo><Email>sword.man@xyz.com</Email><Addresses><Address><type>Permanent</type><City>Bangalore</City><State>Karnataka</State><Zip>560212</Zip><forms><form><id>ID3</id><value>LIC</value></form></forms></Address><Address><type>Temporary</type><City>Concord</City><State>NC</State><Zip>28027</Zip><forms><form><id>ID1</id><value>LIC</value></form><form><id>ID2</id><value>PAS</value></form><form><id>ID3</id><value>SSN</value></form><form><id>ID2</id><value>CC</value></form></forms></Address></Addresses></Employee></Company>\n<?xml version=\"1.0\"?><Company><Employee><FirstName>Thor</FirstName><LastName>Odison</LastName><ContactNo>156565</ContactNo><Email>thor.odison@xyz.com</Email><Addresses><Address><City>Tirunelveli</City><State>TamilNadu</State><Zip>36595</Zip><forms><form><id>ID1</id><value>LIC</value></form><form><id>ID2</id><value>PAS</value></form></forms></Address></Addresses></Employee><Employee><FirstName>Spider</FirstName><LastName>Man</LastName><ContactNo>12324</ContactNo><Email>spider.man@xyz.com</Email><Addresses><Address><type>Permanent</type><City>Bangalore</City><State>Karnataka</State><Zip>560212</Zip><forms><form><id>ID3</id><value>LIC</value></form></forms></Address><Address><type>Temporary</type><City>Concord</City><State>NC</State><Zip>28027</Zip><forms><form><id>ID1</id><value>LIC</value></form><form><id>ID2</id><value>PAS</value></form><form><id>ID3</id><value>SSN</value></form><form><id>ID2</id><value>CC</value></form></forms></Address></Addresses></Employee></Company>\n<?xml version=\"1.0\"?><Company><Employee><FirstName>Black</FirstName><LastName>Widow</LastName><ContactNo>16767</ContactNo><Email>black.widow@xyz.com</Email><Addresses><Address><City>Mysore</City><State>Karnataka</State><Zip>12478</Zip><forms><form><id>ID1</id><value>LIC</value></form></forms></Address></Addresses></Employee><Employee><FirstName>White</FirstName><LastName>Man</LastName><ContactNo>5634</ContactNo><Email>white.man@xyz.com</Email><Addresses><Address><type>Permanent</type><City>Bangalore</City><State>Karnataka</State><Zip>560212</Zip><forms><form><id>ID3</id><value>LIC</value></form></forms></Address><Address><type>Temporary</type><City>Concord</City><State>NC</State><Zip>28027</Zip><forms><form><id>ID1</id><value>LIC</value></form><form><id>ID2</id><value>PAS</value></form><form><id>ID3</id><value>SSN</value></form><form><id>ID2</id><value>CC</value></form></forms></Address></Addresses></Employee></Company>\n", "XPATH,ColumName,CSV_File_Name\n/Company/Employee[]/FirstName,FirstName,Name.csv\n/Company/Employee[]/LastName,LastName,Name.csv\n/Company/Employee[]/ContactNo,ContactNo,Name.csv\n/Company/Employee[]/Email,Email,Name.csv\n/Company/Employee[]/FirstName,FirstName,Address.csv\n/Company/Employee[]/LastName,LastName,Address.csv\n/Company/Employee[]/ContactNo,ContactNo,Address.csv\n/Company/Employee[]/Email,Email,Address.csv\n/Company/Employee[]/Addresses/Address[]/City,City,Address.csv\n/Company/Employee[]/Addresses/Address[]/State,State,Address.csv\n/Company/Employee[]/Addresses/Address[]/Zip,Zip,Address.csv\n/Company/Employee[]/Addresses/Address[]/type,type,Address.csv\n/Company/Employee[]/FirstName,FirstName,Form.csv\n/Company/Employee[]/LastName,LastName,Form.csv\n/Company/Employee[]/ContactNo,ContactNo,Form.csv\n/Company/Employee[]/Email,Email,Form.csv\n/Company/Employee[]/Addresses/Address[]/type,type,Form.csv\n/Company/Employee[]/Addresses/Address[]/forms/form[]/id,id,Form.csv\n/Company/Employee[]/Addresses/Address[]/forms/form[]/value,value,Form.csv\n", "import json\nimport xmltodict\nimport json\nimport os\nimport csv\nimport numpy as np\nimport pandas as pd\nimport sys\nfrom collections import defaultdict\nimport numpy as np\n\ndef getMatches(L1, L2):\n    R = set()\n    for elm in L1:\n        for pat in L2:\n            if elm.find(pat) != -1:\n                if elm.find('.', len(pat)+1) != -1:\n                    R.add(elm[:elm.find('.', len(pat)+1)])\n                else:\n                    R.add(elm)\n    return list(R)\n\ndef xml_parse(xml_file_name):\n    try:\n        process_xml_file = xml_file_name\n        with open(process_xml_file) as xml_file:\n            for xml_string in xml_file:\n                \"\"\"Converting the xml to Dict\"\"\"\n                data_dict = xmltodict.parse(xml_string)\n                \"\"\"Converting the dict to Pandas DF\"\"\"\n                df_processing = pd.json_normalize(data_dict)\n                xml_parse_loop(df_processing)\n            xml_file.close()\n    except Exception as e:\n        s = str(e)\n        print(s)\n\ndef xml_parse_loop(df_processing_input):\n    CSV_File_Name = []\n    \"\"\"Getting the list of csv Files to be created\"\"\"\n    with open(process_config_csv, newline='') as csvfile:\n        DataCaptured = csv.DictReader(csvfile)\n        for row in DataCaptured:\n            if row['CSV_File_Name'] not in CSV_File_Name:\n                CSV_File_Name.append(row['CSV_File_Name'])\n    \"\"\"Iterating the list of CSV\"\"\"\n    for items in CSV_File_Name:\n            df_processing = df_processing_input\n            df_subset_process = []\n            df_subset_list_all_cols = []\n            df_process_sub_explode_Level = []\n            df_final_column_name = []\n            print('Parsing the xml file for creating the file - ' + str(items))\n            \"\"\"Fetching the field list for processs from the confic File\"\"\"\n            with open(process_config_csv, newline='') as csvfile:\n                    DataCaptured = csv.DictReader(csvfile)\n                    for row in DataCaptured:\n                        if row['CSV_File_Name'] in items:\n                                df_final_column_name.append(row['ColumName'])\n                                \"\"\"Getting the columns until the first [] \"\"\"\n                                df_subset_process.append(row['XPATH'].strip('/').replace(\"/\",\".\").split('[]')[0])\n                                \"\"\"Getting the All the columnnames\"\"\"\n                                df_subset_list_all_cols.append(row['XPATH'].strip('/').replace(\"/\",\".\").replace(\"[]\",\"\"))\n                                \"\"\"Getting the All the Columns to explode\"\"\"\n                                df_process_sub_explode_Level.append(row['XPATH'].strip('/').replace('/', '.').split('[]'))\n            explode_ld = defaultdict(set)\n            \"\"\"Putting Level of explode and column names\"\"\"\n            for x in df_process_sub_explode_Level:\n                if len(x) > 1:\n                    explode_ld[len(x) - 1].add(''.join(x[: -1]))\n            explode_ld = {k: list(v) for k, v in explode_ld.items()}\n            #print(' The All column list is for the file ' + items + \" is \" + str(df_subset_list_all_cols))\n            #print(' The first processing for the file ' + items + \" is \" + str(df_subset_process))\n            #print('The explode level of attributes for the file ' + items + \" is \" + str(explode_ld))\n            \"\"\"Remove column duplciates\"\"\"\n            df_subset_process = list(dict.fromkeys(df_subset_process))\n            for col in df_subset_process:\n                if col not in df_processing.columns:\n                    df_processing[col] = np.nan\n            df_processing = df_processing[df_subset_process]\n            df_processing_col_list = df_processing.columns.tolist()\n            print ('The total levels to be exploded : %d' % len(explode_ld))\n            i=0\n            level=len(explode_ld)\n            for i in range(level):\n                print (' Exploding the Level : %d' % i )\n                df_processing_col_list = df_processing.columns.tolist()\n                list_of_explode=set(df_processing_col_list) & set(explode_ld[i + 1])\n                #print('List to expolde' + str(list_of_explode))\n                \"\"\"If founc in explode list exlplode some xml doesnt need to have a list it could be column handling the same\"\"\"\n                for c in list_of_explode:\n                    print (' There are column present which needs to be exploded - ' + str(c))\n                    df_processing = pd.concat((df_processing.iloc[[type(item) == list for item in df_processing[c]]].explode(c),df_processing.iloc[[type(item) != list for item in df_processing[c]]]))\n                    print(' Finding the columns need to be fetched ')\n                \"\"\"From the overall column list fecthing the attributes needed to explode\"\"\"\n                next_level_pro_lst = getMatches(df_subset_list_all_cols,explode_ld[ i + 1 ])\n                #print(next_level_pro_lst)\n                df_processing_col_list = df_processing.columns.tolist()\n                for nex in next_level_pro_lst:\n                    #print (\"Fetching \" + nex.rsplit('.', 1)[1] + ' from ' + nex.rsplit('.', 1)[0] + ' from ' + nex )\n                    parent_col=nex.rsplit('.', 1)[0]\n                    child_col=nex.rsplit('.', 1)[1]\n                    #print(parent_col)\n                    #print(df_processing_col_list)\n                    if parent_col not in df_processing_col_list:\n                        df_processing[nex.rsplit('.', 1)[0]] = \"\"\n                    try:\n                        df_processing[nex] = df_processing[parent_col].apply(lambda x: x.get(child_col))\n                    except AttributeError:\n                        df_processing[nex] = \"\"\n                df_processing_col_list = df_processing.columns.tolist()\n                if i == level-1:\n                    print('Last Level nothing to be done')\n                else:\n                    \"\"\"Extracting All columns until the next exlode column list is found\"\"\"\n                    while len(set(df_processing_col_list) & set(explode_ld[i + 2]))==0:\n                        next_level_pro_lst = getMatches(df_subset_list_all_cols, next_level_pro_lst)\n                        #print(next_level_pro_lst)\n                        for nextval in next_level_pro_lst:\n                            if nextval not in df_processing_col_list:\n                                #print(\"Fetching \" + nextval.rsplit('.', 1)[1] + ' from ' + nextval.rsplit('.', 1)[0] + ' from ' + nextval)\n                                if nextval.rsplit('.', 1)[0] not in df_processing.columns:\n                                    df_processing[nextval.rsplit('.', 1)[0]] = \"\"\n                                try:\n                                    df_processing[nextval] = df_processing[nextval.rsplit('.', 1)[0]].apply(lambda x: x.get(nextval.rsplit('.', 1)[1]))\n                                except AttributeError:\n                                    df_processing[nextval] = \"\"\n\n                        df_processing_col_list = df_processing.columns.tolist()\n\n\n            df_processing = df_processing[df_subset_list_all_cols]\n            df_processing.columns = df_final_column_name\n            # if file does not exist write header\n            if not os.path.isfile(items):\n                print(\"The file does not exists Exists so writing new\")\n                df_processing.to_csv('{}'.format(items), header='column_names',index=None)\n            else:  # else it exists so append without writing the header\n                print(\"The file does exists Exists so appending\")\n                df_processing.to_csv('{}'.format(items), mode='a', header=False,index=None)\n\n\nfrom datetime import datetime\nstartTime = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\nstartTime = str(os.getpid()) + \"_\" + startTime\nprocess_task_name = ''\nprocess_config_csv = 'config.csv'\nxml_file_name = 'test.xml'\nold_print = print\n\ndef timestamped_print(*args, **kwargs):\n    now = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S.%f\")\n    printheader = now + \" xml_parser \" + \" \" + process_task_name + \" - \"\n    old_print(printheader, *args, **kwargs)\nprint = timestamped_print\n\nxml_parse(xml_file_name)\n", "[, ~]$ cat Name.csv\nFirstName,LastName,ContactNo,Email\nHal,Thanos,122131,hal.thanos@xyz.com\nIron,Man,12324,iron.man@xyz.com\nCaptain,America,13322,captain.america@xyz.com\nSword,Man,12324,sword.man@xyz.com\nThor,Odison,156565,thor.odison@xyz.com\nSpider,Man,12324,spider.man@xyz.com\nBlack,Widow,16767,black.widow@xyz.com\nWhite,Man,5634,white.man@xyz.com\n[, ~]$ cat Address.csv\nFirstName,LastName,ContactNo,Email,City,State,Zip,type\nIron,Man,12324,iron.man@xyz.com,Bangalore,Karnataka,560212,Permanent\nIron,Man,12324,iron.man@xyz.com,Concord,NC,28027,Temporary\nHal,Thanos,122131,hal.thanos@xyz.com,Bangalore,Karnataka,560212,\nSword,Man,12324,sword.man@xyz.com,Bangalore,Karnataka,560212,Permanent\nSword,Man,12324,sword.man@xyz.com,Concord,NC,28027,Temporary\nCaptain,America,13322,captain.america@xyz.com,Trivandrum,Kerala,28115,\nSpider,Man,12324,spider.man@xyz.com,Bangalore,Karnataka,560212,Permanent\nSpider,Man,12324,spider.man@xyz.com,Concord,NC,28027,Temporary\nThor,Odison,156565,thor.odison@xyz.com,Tirunelveli,TamilNadu,36595,\nWhite,Man,5634,white.man@xyz.com,Bangalore,Karnataka,560212,Permanent\nWhite,Man,5634,white.man@xyz.com,Concord,NC,28027,Temporary\nBlack,Widow,16767,black.widow@xyz.com,Mysore,Karnataka,12478,\n[, ~]$ cat Form.csv\nFirstName,LastName,ContactNo,Email,type,id,value\nIron,Man,12324,iron.man@xyz.com,Temporary,ID1,LIC\nIron,Man,12324,iron.man@xyz.com,Temporary,ID2,PAS\nIron,Man,12324,iron.man@xyz.com,Temporary,ID3,SSN\nIron,Man,12324,iron.man@xyz.com,Temporary,ID2,CC\nHal,Thanos,122131,hal.thanos@xyz.com,,ID1,LIC\nHal,Thanos,122131,hal.thanos@xyz.com,,ID2,PAS\nIron,Man,12324,iron.man@xyz.com,Permanent,ID3,LIC\nSword,Man,12324,sword.man@xyz.com,Temporary,ID1,LIC\nSword,Man,12324,sword.man@xyz.com,Temporary,ID2,PAS\nSword,Man,12324,sword.man@xyz.com,Temporary,ID3,SSN\nSword,Man,12324,sword.man@xyz.com,Temporary,ID2,CC\nCaptain,America,13322,captain.america@xyz.com,,ID1,LIC\nCaptain,America,13322,captain.america@xyz.com,,ID2,PAS\nSword,Man,12324,sword.man@xyz.com,Permanent,ID3,LIC\nSpider,Man,12324,spider.man@xyz.com,Temporary,ID1,LIC\nSpider,Man,12324,spider.man@xyz.com,Temporary,ID2,PAS\nSpider,Man,12324,spider.man@xyz.com,Temporary,ID3,SSN\nSpider,Man,12324,spider.man@xyz.com,Temporary,ID2,CC\nThor,Odison,156565,thor.odison@xyz.com,,ID1,LIC\nThor,Odison,156565,thor.odison@xyz.com,,ID2,PAS\nSpider,Man,12324,spider.man@xyz.com,Permanent,ID3,LIC\nWhite,Man,5634,white.man@xyz.com,Temporary,ID1,LIC\nWhite,Man,5634,white.man@xyz.com,Temporary,ID2,PAS\nWhite,Man,5634,white.man@xyz.com,Temporary,ID3,SSN\nWhite,Man,5634,white.man@xyz.com,Temporary,ID2,CC\nWhite,Man,5634,white.man@xyz.com,Permanent,ID3,LIC\nBlack,Widow,16767,black.widow@xyz.com,,ID1,LIC\n"], ["from azureml.core import Workspace\nfrom azureml.core.environment import Environment\nfrom azureml.train.estimator import Estimator\nfrom azureml.core.conda_dependencies import CondaDependencies\nfrom azureml.core import Experiment\n\nws = Workspace (...)\nexp = Experiment(ws, 'test-so-exp')\n\nmyenv = Environment(name = \"myenv\")\nmyenv.docker.enabled = True\ndockerfile = r\"\"\"\nFROM mcr.microsoft.com/azureml/base:intelmpi2018.3-ubuntu16.04\nRUN apt-get update && apt-get install -y libgl1-mesa-glx\nRUN echo \"Hello from custom container!\"\n\"\"\"\nmyenv.docker.base_image = None\nmyenv.docker.base_dockerfile = dockerfile\n\n## You need to instead put your packages in the Environment definition instead... \n## see below for some changes too\n\nmyenv.python.conda_dependencies = CondaDependencies.create(pip_packages = ['scipy==1.1.0', 'torch==1.5.1'])\n", "est = Estimator(\n    source_directory = '.',\n#     script_params = script_params,\n#     use_gpu = True,\n    compute_target = 'gpu-cluster-1',\n#     pip_packages = ['scipy==1.1.0', 'torch==1.5.1'],\n    entry_script = 'AzureEntry.py',\n    environment_definition=myenv\n    )\n", "run = exp.submit(config = est)\nrun.wait_for_completion(show_output=True)\n"], ["est = Estimator(\n    source_directory = '.',\n    script_params = script_params,\n    use_gpu = True,\n    compute_target = 'gpu-cluster-1',\n    pip_packages = ['scipy==1.1.0', 'torch==1.5.1'],\n    entry_script = 'AzureEntry.py',\n    environment_definition = myenv\n    )\n\nrun = exp.submit(config = est)\nrun.wait_for_completion(show_output=True)\n"], ["   from azureml.core import Environment\n   myenv = Environment(name=\"myenv\")\n\n   # Creates the environment inside a Docker container.\n   myenv.docker.enabled = True\n\n   # Specify docker steps as a string.\n   dockerfile = r'''\n   FROM mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu16.04\n   RUN echo \"Hello from custom container!\"\n   '''\n\n   # Alternatively, load from a file.\n   #with open(\"dockerfiles/Dockerfile\", \"r\") as f:\n   #    dockerfile=f.read()\n\n   myenv.docker.base_dockerfile = dockerfile\n"], [], ["<integration-outbound:IntegrationEntity\n    xmlns:integration-outbound=\"http://example.com\"\n    xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\">\n   \n    ...same content...\n\n</integration-outbound:IntegrationEntity>\n", "<xsl:stylesheet version=\"1.0\" xmlns:xsl=\"http://www.w3.org/1999/XSL/Transform\"\n                              xmlns:integration-outbound=\"http://example.com\"\n                              xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\">\n    <xsl:output method=\"xml\" omit-xml-declaration=\"yes\" indent=\"yes\"/>\n    <xsl:strip-space elements=\"*\"/>\n    \n    <xsl:template match=\"integration-outbound:IntegrationEntity\">\n     <data>\n       <xsl:apply-templates select=\"integrationEntityHeader/descendant::attachment\"/>\n       <xsl:apply-templates select=\"integrationEntityDetails/descendant::dataProcessingInfo\"/>\n       <xsl:apply-templates select=\"integrationEntityDetails/descendant::forms/descendant::field\"/>\n     </data>\n    </xsl:template>\n    \n    <xsl:template match=\"attachment\">\n     <integrationEntityHeader>\n       <xsl:copy-of select=\"ancestor::integrationEntityHeader/*[name()!='attachments']\"/>\n       <xsl:copy-of select=\"*\"/>\n     </integrationEntityHeader>\n    </xsl:template>\n    \n    <xsl:template match=\"dataProcessingInfo\">\n     <integrationEntityDetailsControlBlock>\n       <xsl:copy-of select=\"ancestor::integration-outbound:IntegrationEntity/integrationEntityHeader/*[position() &lt;= 2]\"/>\n       <requestId><xsl:value-of select=\"ancestor::supplier/requestId\"/></requestId>\n       <supplier_id><xsl:value-of select=\"ancestor::supplier/id\"/></supplier_id>\n       <xsl:copy-of select=\"*\"/>\n     </integrationEntityDetailsControlBlock>\n    </xsl:template>\n    \n    <xsl:template match=\"field\">\n     <integrationEntityDetailsForms>\n       <form_id><xsl:value-of select=\"ancestor::form/id\"/></form_id>\n       <xsl:copy-of select=\"ancestor::record/*[name()!='fields']\"/>\n       <SupplierFormRecordFieldId><xsl:value-of select=\"id\"/></SupplierFormRecordFieldId>\n       <SupplierFormRecordFieldValue><xsl:value-of select=\"id\"/></SupplierFormRecordFieldValue>\n       <xsl:copy-of select=\"ancestor::integration-outbound:IntegrationEntity/integrationEntityHeader/*[position() &lt;= 2]\"/>\n       <requestId><xsl:value-of select=\"ancestor::supplier/requestId\"/></requestId>\n       <supplier_id><xsl:value-of select=\"ancestor::supplier/id\"/></supplier_id>\n     </integrationEntityDetailsForms>\n    </xsl:template>\n    \n</xsl:stylesheet>\n", "import lxml.etree as et\nimport pandas as pd\n\n# LOAD XML AND XSL\ndoc = et.parse('Input.xml')\nstyle = et.parse('Script.xsl')\n\n# INITIALIZE AND RUN TRANSFORMATION\ntransformer = et.XSLT(style)\nflat_doc = transformer(doc)\n\n# BUILD THREE DATA FRAMES\ndf_header = pd.DataFrame([{i.tag:i.text for i in el} \n          for el in flat_doc.xpath('integrationEntityHeader')])\n\ndf_detailsControlBlock = pd.DataFrame([{i.tag:i.text for i in el} \n          for el in flat_doc.xpath('integrationEntityDetailsControlBlock')])\n\ndf_detailsForms = pd.DataFrame([{i.tag:i.text for i in el} \n          for el in flat_doc.xpath('integrationEntityDetailsForms')])\n"], [], ["min1=abs(array1[0])\n\nfor i in array1:\n    if(abs(i)<abs(min1)):\n        min1=i\n\nprint(\"Closest to zero for array 1: \"+ str(min1))\n"], ["x = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\nx = [l[::len(l)-1] for l in x]\nprint(x)\n", "[[1, 3], [4, 6], [7, 9]]\n"], ["x = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n\n>>> [a[:1] + a[-1:] for a in x]\n[[1, 3], [4, 6], [7, 9]]\n\n"], ["\nx = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\nfor item in x:\n    print(item[0], item[2])\n\n", "\nx = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\nnew_list = []\nfor item in x:\n    new_list.append([item[0], item[2]])\n\nprint(new_list)\n\n"], ["a = [[sublist[0],sublist[-1]] for sublist in x]\n", ">>> a\n[[1, 3], [4, 6], [7, 9]]\n"], ["l = [1,8,8,8,1,3,3,8]\nl.sort()\n\n# Get all odd indexes\nodd = l[1::2]\n\n# Get all even indexes\neven = l[::2]\n\nprint(odd)\nprint(odd == even)\n", "[1, 3, 8, 8]\nTrue\n"], ["l = [1,8,8,8,1,3,3,8]\ncount={}\nres=[]\nfor i in l:\n  if i in count: count[i]+=1\n  else: count[i]=1\n  if count[i]%2: res.append(i)\n\nprint(res)\n", "[1,8,8,3]\n", "def one():\n  l = [1,8,8,8,1,3,3,8]\n  count={}\n  res=[]\n  for i in l:\n    if i in count: count[i]+=1\n    else: count[i]=1\n    if count[i]%2: res.append(i)\n\n  #print(res)\n\n\ndef two():\n  from collections import Counter\n  l = [1,8,8,8,1,3,3,8]\n  res = []\n  count = Counter(l) # its like dict(1: 2, 8: 4, 3: 2)\n  for key, val in count.items():\n    res.extend(val//2 * [key])\n\no=timeit.Timer(one)\n\nt=timeit.Timer(two)\n\nprint(o.timeit(100000))\n\nprint(t.timeit(100000))\n\nprint(o.timeit(100000))\n\nprint(t.timeit(100000))\n", "0.28666\n0.80822\n0.28678\n0.80113\n", "count={}\nfor i in l:\n  if i in count: count[i]+=1\n  else: count[i]=1\n"], ["   El Expression: `${100.0 == 100}` Result=  `true`   \n   El Expression: `${4 > 3}`        Result=  `true` \n"], ["l = [1,8,8,8,1,3,3,8]\nseen = []\nresult = []\nfor num in l:\n  if num in seen:\n    seen.remove(num)\n    #result.append(num) #print every even appearance\n  else:\n    seen.append(num)\n    result.append(num) #print every odd appearance\n\nif len(seen)==0:\n  print(result)\nelse:\n  print(\"Error: uneven elements found:\", seen)\n", "l = [1,8,8,8,1,3,3,8]\nseen = []\nresult = list(filter(lambda x: seen.append(x) is None if x not in seen else not seen.remove(x) is None, l))\n\nif len(seen)==0:\n  print(result)\nelse:\n  print(\"Error: uneven elements found:\", seen)\n", "l = [1,8,8,8,1,3,3,8]\nseen = []\nresult = list(filter(lambda x: seen.remove(x) is None if x in seen else not seen.append(x) is None, l))\n\nif len(seen)==0:\n  print(result)\nelse:\n  print(\"Error: uneven elements found:\", seen)\n"], [], [], ["__meta_vars__:\n  month: (gennaio|febbraio|marzo|aprile|maggio|giugno|luglio|agosto|settembre|ottobre|novembre|dicembre)\n  prep_art: (il\\s|l\\s?'\\s?|nel\\s|nell\\s?'\\s?|del\\s|dell\\s?'\\s?)\n  schema:\n    date: http://www.w3.org/2001/XMLSchema#date\n\n__meta_func__:\n  - >\n    def month_to_num(month):\n        \"\"\" gennaio -> 1, febbraio -> 2, ..., dicembre -> 12 \"\"\"\n        try:\n            return index_in_or(meta_vars['month'], month) + 1\n        except ValueError:\n            return month\n\nTempo:\n  - \\b{prep_art}(?P<day>\\d{{1,2}}) (?P<month>{month}) {prep_art}?\\s*(?P<year>\\d{{4}}): >\n      '\"{}-{:02d}-{:02d}\"^^<{schema}>'.format(match.group('year'),\n                                              month_to_num(match.group('month')),\n                                              int(match.group('day')),\n                                              schema=schema['date'])\n\n", "class DateNormalizer:\n    def _meta_init(self, specs):\n        \"\"\" Reads the meta variables and the meta functions from the specification\n        :param dict specs: The specifications loaded from the file\n        :return: None\n        \"\"\"\n        self.meta_vars = specs.pop('__meta_vars__')\n\n        # compile meta functions in a dictionary\n        self.meta_funcs = {}\n        for f in specs.pop('__meta_funcs__'):\n            exec f in self.meta_funcs\n\n        # make meta variables available to the meta functions just defined\n        self.meta_funcs['__builtins__']['meta_vars'] = self.meta_vars\n\n        self.globals = self.meta_funcs\n        self.globals.update(self.meta_vars)\n\n    def normalize(self, expression):\n        \"\"\" Find the first matching part in the given expression\n        :param str expression: The expression in which to search the match\n        :return: Tuple with (start, end), category, result\n        :rtype: tuple\n        \"\"\"\n        expression = expression.lower()\n        for category, regexes in self.regexes.iteritems():\n            for regex, transform in regexes:\n                match = regex.search(expression)\n                if match:\n                    result = eval(transform, self.globals, {'match': match})\n                    start, end = match.span()\n                    return (first_position + start, first_position + end) , category, result\n"], ["    newList = []\n    for number in l:\n        if(newList.count(number) < l.count(number)/2):\n            newList.append(number)\n\nprint(newList)\n"], ["from collections import Counter\nl = [1,8,8,8,1,3,3,8]\nres = []\ncount = Counter(l) # its like dict(1: 2, 8: 4, 3: 2)\nfor key, val in count.items():\n    res.extend(val//2 * [key])\nprint(res)\n# output\n[1, 8, 8, 3]\n"], [">>> from collections import Counter\n>>> from itertools import chain\n>>> list(chain.from_iterable([key]*(count//2) for key, count in Counter(l).items()))\n[1, 8, 8, 3]\n"], [], ["for arr in [array1, array2, array3]:\n    print(arr, min(arr, key=abs))\n", "[ 5.   3.2 -1.2 -0.2  7. ] -0.2\n[ 19.  -20.   -4.7   6.    9.   42. ] -4.7\n[ 4.   0.3 -9.   8.   6.  14. ] 0.3\n"], [">>> for array in (array1, array2, array3):\n...     print(array, array[np.argmin(np.abs(array))])\n\n[ 5.   3.2 -1.2 -0.2  7. ] -0.2\n[ 19.  -20.   -4.7   6.    9.   42. ] -4.7\n[ 4.   0.3 -9.   8.   6.  14. ] 0.3\n"], [], [], ["func TestPattern(t *testing.T) {\n    a := \"pattern('asdas asd 12dasd') && lastdigit(23asd) < sma(50) && sma(14) > sma(12) && ( macd(5,20) > macd_signal(12,26,9) || macd(5,20) <= macd_histogram(12,26,9) )\"\n\n    r, _ := regexp.Compile(`(\\w+)(\\s+)?[(]['\\d.,\\s\\w]+[)]`)\n    indicator := r.FindAllString(a, -1)\n    t.Logf(\"%v\\n\", indicator)\n    t.Logf(\"%v\\n\", len(indicator))\n\n    for _, i := range indicator {\n        t.Logf(\"%v\\n\", i)\n        if strings.HasPrefix(i, \"pattern\") {\n            r, _ = regexp.Compile(`pattern(\\s+)?\\('(.+)'\\)`)\n            check1 := r.ReplaceAllString(i, \"$2\")\n            t.Logf(\"%v\\n\", check1)\n            r, _ = regexp.Compile(`[^du]`)\n            check2 := r.FindAllString(check1, -1)\n            t.Logf(\"%v\\n\", len(check2))\n        } else if strings.HasPrefix(i, \"lastdigit\") {\n            r, _ = regexp.Compile(`lastdigit(\\s+)?\\((.+)\\)`)\n            args := r.ReplaceAllString(i, \"$2\")\n            r, _ = regexp.Compile(`[^\\d]`)\n            parameter := r.FindAllString(args, -1)\n            t.Logf(\"%v\\n\", parameter)\n        } else {\n\n        }\n    }\n}\n", "Assignment  =\nOperators   + - * / DIV MOD % ^ \nLogical     < <= == != >= > AND OR NOT\nTernary     ? :  \nShift       << >>\nProperty    ${<id>}\nDataSource  @<id>\nConstants   NULL PI\nFunctions   CLEARGLOBAL, CLEARGLOBALS, DIM, GETGLOBAL, SETGLOBAL\n            NOW PRECISION\n"], ["pip install PyAudio-0.2.11-cp37-cp37m-win32.whl\n"], ["cd <your_donwload_path>\n"], ["words = [\"adopt\", \"bake\", \"beam\", \"confide\", \"grill\", \"plant\", \"time\", \"wave\", \"wish\"]\npast_tense=[]\nfor word in words:\n    if word[-1]=='e':\n        past_tense=[word+'d']\n        print(past_tense)\n    else:\n        past_tense=[word+'ed']\n    print(past_tense)         \n"], ["wrds = [\"end\", 'work', \"play\", \"start\", \"walk\", \"look\", \"open\", \"rain\", \"learn\", \"clean\"]\n\npast_wrds = []\n\nfor i in wrds:\n    past_wrds.append(i+'ed')\n"], ["import tensorflow as tf\nimport keras\nmodel = keras.models.load_model('my_model.h5', custom_objects={'tf': tf})\n"], ["wget https://github.com/cyysky/OpenCV-Raspberry-Pi-4-Package-for-Python/raw/master/opencv_4.3.0-1_armhf.deb\n\nsudo dpkg -i opencv_4.3.0-1_armhf.deb # This will install fail for dependency\n\nsudo apt-get -f install # Auto install dependency package\n\nsudo dpkg -i opencv_4.3.0-1_armhf.deb # Now start install\n\nsudo apt-get install tesseract-ocr # Optional : tesseract-ocr\n", "export LD_PRELOAD=$LD_PRELOAD:/usr/lib/arm-linux-gnueabihf/libatomic.so.1.2.0\n"], ["def zip(*iterables):\n    # zip('ABCD', 'xy') --> Ax By\n    sentinel = object()\n    iterators = [iter(it) for it in iterables]\n    while iterators:\n        result = []\n        for it in iterators:\n            elem = next(it, sentinel)\n            if elem is sentinel:\n                return\n            result.append(elem)\n        yield tuple(result)\n", "class Gen:\n    def __init__(self,iterable):\n        self.d = iter(iterable)\n        self.sentinel = object()\n        self.prev = self.sentinel\n    def __iter__(self):\n        return self\n    @property\n    def last_val_consumed(self):\n        if self.prev is None:\n            raise StopIteration\n        if self.prev == self.sentinel:\n            raise ValueError('Nothing has been consumed')\n        return self.prev\n    def __next__(self):\n        self.prev = next(self.d,None)\n        if self.prev is None:\n            raise StopIteration\n        return self.prev\n", "# When `gen1` is larger than `gen2`\ngen1 = Gen(range(10))\ngen2 = Gen(range(8))\nlist(zip(gen1,gen2))\n# [(0, 0), (1, 1), (2, 2), (3, 3), (4, 4), (5, 5), (6, 6), (7, 7)]\ngen1.last_val_consumed\n# 8 #as it was the last values consumed\nnext(gen1)\n# 9\ngen1.last_val_consumed\n# 9\n\n# 2. When `gen1` or `gen2` is empty\ngen1 = Gen(range(0))\ngen2 = Gen(range(5))\nlist(zip(gen1,gen2))\ngen1.last_val_consumed\n# StopIteration error is raised\ngen2.last_val_consumed\n# ValueError is raised saying `ValueError: Nothing has been consumed`\n"], ["FLASK_APP=flaskblog:name\n"], [], ["tc = int(input())\nfor i in range(tc):\n    n, budget = map(int, input().split())\n    prices = list(map(int, input().split()))\n    prices.sort()\n    for j in range(n, 0, -1):\n        if sum(prices[: j]) <= budget:\n            print(\"Case #\" + str(i+1) + ': ' + str(len(prices[: j])))\n            break\n    else: print(\"Case #\" + str(i+1) + ': 0')\n"], ["params = {\n           \"engine\" : \"google\",\n           ...\n           \"api_key\" : \"secret_api_key\" \n}\n", "client = GoogleSearchResults(params)\nresults = client.get_dict()\n"], ["#include <bits/stdc++.h>\n\nusing namespace std ;\nint main() {\n    int t ; cin >> t ;\n    for(int cs = 1 ; cs <= t ; cs ++) {\n        int n , b , cnt = 0 ; cin >> n >> b ;\n        vector<int> a(n) ; for(int i = 0 ; i < n ; i ++) cin >> a[i] ;\n        sort(a.begin(), a.end()) ;\n        for(int i = 0 ; i < n ; i ++) {\n            if(a[i] > b) break ;\n            else {\n                b -= a[i] ;\n                cnt ++ ;\n            }\n        }\n        printf(\"Case #%d: %d\\n\", cs, cnt) ;\n    }\n}\n\n\n"], [], ["def beginning(x):\n    ls = []\n    idx = 0\n    while idx<10:\n        if x[idx]==\"bye\":\n            break\n        ls.append(x[idx])\n        idx+=1\n    return ls\n"], ["from more_itertools import peekable\n\na = peekable(a)\nb = peekable(b)\n\nwhile True:\n    try:\n        a.peek()\n        b.peek()\n    except StopIteration:\n        break\n    x = next(a)\n    y = next(b)\n    print(x, y)\n\n\nprint(list(a), list(b))  # Misses nothing.\n", "def my_gen(n: int):\n    yield from range(n)\n\na = my_gen(10)\nb = my_gen(8)\n", "0 0\n1 1\n2 2\n3 3\n4 4\n5 5\n6 6\n7 7\n[8, 9] []\n"], ["    g1, g2 = (i for i in range(10)), (i for i in range(4))\n    # Create (g1, g2), g3 first, then loop over g3 as one would with zip\n    (g1, g2), g3 = safe_zip(g1, g2)\n    for a, b in g3:\n        print(a, b)#(0, 0) to (3, 3)\n    for x in g1:\n        print(x)#4 to 9\n"], ["from itertools import islice, tee\n\ndef zipped(gen1, gen2, pred=list):\n    g11, g12 = tee(gen1)\n    z = pred(zip(g11, gen2))\n\n    return (islice(g12, len(z), None), gen2), z\n\ngen1 = iter(range(10))\ngen2 = iter(range(5))\n\n(gen1, gen2), output = zipped(gen1, gen2)\n\nprint(output)\nprint(next(gen1))\n# [(0, 0), (1, 1), (2, 2), (3, 3), (4, 4)]\n# 5\n"], ["z = zip(range(10), range(8))\nfor _ in iter(z.__next__, None):\n    ...\n_, (one, other) = z.__reduce__()\n_, (i_one,), p_one = one.__reduce__() # p_one == current pos, 1 based\nimport itertools\nval = next(itertools.islice(iter(i_one), p_one - 1, p_one))\n"], ["import itertools\n\ndef my_gen(n:int):\n    for i in range(n):\n        yield i\n\ngen1 = my_gen(10)\ngen2 = my_gen(8)\n\nfor i, j in itertools.zip_longest(gen1, gen2):\n    print(i, j)\n", "0 0\n1 1\n2 2\n3 3\n4 4\n5 5\n6 6\n7 7\n8 None\n9 None\n"], ["class cache_last(collections.abc.Iterator):\n    \"\"\"\n    Wraps an iterable in an iterator that can retrieve the last value.\n\n    .. attribute:: obj\n\n       A reference to the wrapped iterable. Provided for convenience\n       of one-line initializations.\n    \"\"\"\n    def __init__(self, iterable):\n        self.obj = iterable\n        self._iter = iter(iterable)\n        self._sentinel = object()\n\n    @property\n    def last(self):\n        \"\"\"\n        The last object yielded by the wrapped iterator.\n\n        Uninitialized iterators raise a `ValueError`. Exhausted\n        iterators raise a `StopIteration`.\n        \"\"\"\n        if self.exhausted:\n            raise StopIteration\n        return self._last\n\n    @property\n    def exhausted(self):\n        \"\"\"\n        `True` if there are no more elements in the iterator.\n        Violates EAFP, but convenient way to check if `last` is valid.\n        Raise a `ValueError` if the iterator is not yet started.\n        \"\"\"\n        if not hasattr(self, '_last'):\n            raise ValueError('Not started!')\n        return self._last is self._sentinel\n\n    def __next__(self):\n        \"\"\"\n        Retrieve, record, and return the next value of the iteration.\n        \"\"\"\n        try:\n            self._last = next(self._iter)\n        except StopIteration:\n            self._last = self._sentinel\n            raise\n        # An alternative that has fewer lines of code, but checks\n        # for the return value one extra time, and loses the underlying\n        # StopIteration:\n        #self._last = next(self._iter, self._sentinel)\n        #if self._last is self._sentinel:\n        #    raise StopIteration\n        return self._last\n\n    def __iter__(self):\n        \"\"\"\n        This object is already an iterator.\n        \"\"\"\n        return self\n", "gen1 = cache_last(range(10))\ngen2 = iter(range(8))\nlist(zip(gen1, gen2))\nprint(gen1.last)\nprint(next(gen1)) \n", "def myzip(iterables):\n    iterators = [iter(it) for it in iterables]\n    while True:\n        items = []\n        for it in iterators:\n            try:\n                items.append(next(it))\n            except StopIteration:\n                for i, peeked in enumerate(items):\n                    iterables[i] = itertools.chain([peeked], iterators[i])\n                return\n            else:\n                yield tuple(items)\n\ngens = [range(10), range(8)]\nlist(myzip(gens))\nprint(next(gens[0]))\n"], ["d2 = {}\n\nInput2 = ['a','b','a','a','b','b','b']\n\n# Input 2 \nfor character in Input2:\n    d2[character] = d2.get(character, 0) + 1\n# Out[2]: {'a': 3, 'b': 4}\n"], ["max_votes = max(d.values())\nwinners = [name for name, votes in d.items() where votes == max_votes]\nif len(winners) == 1:\n    print(winner[0])\nelse:\n    print('NOTA')\n"], ["d = {\"a\": 3, \"b\": 5}\n\nif len(set(d.values())) == 1: # check whether all the values are euqal.\n    print(\"NOTA\")\nelse:\n    print(max(d, key=d.get))\n\n"], ["def winner(votes):\n    d = {}\n    for i in votes:\n        if i not in d:\n            d[i]=1\n        else:\n            d[i] = d[i]+1\n\n    # get the key for a value that's greater than half\n    # or NOTA if there isn't one\n    return next((k for k, v in d.items() if v > len(votes)//2), 'NOTA')\n\nwinner(['a','b','a','a','b','b', 'b'])\n# 'b'\n\nwinner(['a','b','a','a','b','b'])\n# NOTA\n"], [], ["words = [\"adopt\", \"bake\", \"beam\", \"confide\", \"grill\", \"plant\", \"time\", \"wave\", \"wish\"]\n\nlength = len(words)                 \npast_tense = []          \nstrLen = 0                        \n\nfor i in range(0, length):         \n    str = words[i]                  \n    strLen = len (str)            \n    if str[-1] == 'e':\n        words[i] = words[i] + 'd'\n    else:\n        words[i] = words[i] + 'ed'\n    past_tense = past_tense + [words[i]]\nprint(past_tense)   \n"], ["import numpy as np\n\nhex_string = '89-50-4E-47-0D-0A-1A-0A-00-00-00-0D-49'\nnp.array([int(x, base=16) for x in hex_string.split('-')])\n"], [">>> import numpy as np\n>>> hext_str = \"89-50-4E-47-0D-0A-1A-0A-00-00-00-0D-49\"\n>>> np.array([int(x, 16) for x in hex_str.split(\"-\")])\narray([137,  80,  78,  71,  13,  10,  26,  10,   0,   0,   0,  13,  73])\n"], [], ["s = \"89-50-4E-47-0D-0A-1A-0A-00-00-00-0D-49\"\n\nnp.fromiter((int(x, 16) for x in s.split('-')), dtype=np.int32)\n# array([137,  80,  78,  71,  13,  10,  26,  10,   0,   0,   0,  13,  73])\n"], [], [], [], [], [], ["#!/usr/bin/env python\n# coding: utf-8\n\n\"\"\"\nFind house blocks in osmnx graphs.\n\"\"\"\n\nimport numpy as np\nimport osmnx as ox\nimport networkx as nx\nimport matplotlib.pyplot as plt\n\nfrom matplotlib.path import Path\nfrom matplotlib.patches import PathPatch\nfrom matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\nfrom skimage.measure import label, find_contours, points_in_poly\nfrom skimage.color import label2rgb\n\nox.config(log_console=True, use_cache=True)\n\n\ndef k_core(G, k):\n    H = nx.Graph(G, as_view=True)\n    H.remove_edges_from(nx.selfloop_edges(H))\n    core_nodes = nx.k_core(H, k)\n    H = H.subgraph(core_nodes)\n    return G.subgraph(core_nodes)\n\n\ndef plot2img(fig):\n    # remove margins\n    fig.subplots_adjust(left=0, bottom=0, right=1, top=1, wspace=0, hspace=0)\n\n    # convert to image\n    # https://stackoverflow.com/a/35362787/2912349\n    # https://stackoverflow.com/a/54334430/2912349\n    canvas = FigureCanvas(fig)\n    canvas.draw()\n    img_as_string, (width, height) = canvas.print_to_buffer()\n    as_rgba = np.fromstring(img_as_string, dtype='uint8').reshape((height, width, 4))\n    return as_rgba[:,:,:3]\n", "H = k_core(G, 2)\nfig1, ax1 = ox.plot_graph(H, node_size=0, edge_color='k', edge_linewidth=1)\n", "img = plot2img(fig1)\nlabel_image = label(img > 128)\nimage_label_overlay = label2rgb(label_image[:,:,0], image=img[:,:,0])\nfig, ax = plt.subplots(1,1)\nax.imshow(image_label_overlay)\n", "# using a large region here as an example;\n# however we could also loop over all unique labels, i.e.\n# for ii in np.unique(labels.ravel()):\nii = np.argsort(np.bincount(label_image.ravel()))[-5]\n\nmask = (label_image[:,:,0] == ii)\ncontours = find_contours(mask.astype(np.float), 0.5)\n\n# Select the largest contiguous contour\ncontour = sorted(contours, key=lambda x: len(x))[-1]\n\n# display the image and plot the contour;\n# this allows us to transform the contour coordinates back to the original data cordinates\nfig2, ax2 = plt.subplots()\nax2.imshow(mask, interpolation='nearest', cmap='gray')\nax2.autoscale(enable=False)\nax2.step(contour.T[1], contour.T[0], linewidth=2, c='r')\nplt.close(fig2)\n\n# first column indexes rows in images, second column indexes columns;\n# therefor we need to swap contour array to get xy values\ncontour = np.fliplr(contour)\n\npixel_to_data = ax2.transData + ax2.transAxes.inverted() + ax1.transAxes + ax1.transData.inverted()\ntransformed_contour = pixel_to_data.transform(contour)\ntransformed_contour_path = Path(transformed_contour, closed=True)\npatch = PathPatch(transformed_contour_path, facecolor='red')\nax1.add_patch(patch)\n", "x = G.nodes.data('x')\ny = G.nodes.data('y')\nxy = np.array([(x[node], y[node]) for node in G.nodes])\neps = (xy.max(axis=0) - xy.min(axis=0)).mean() / 100\nis_inside = transformed_contour_path.contains_points(xy, radius=-eps)\nnodes_inside_block = [node for node, flag in zip(G.nodes, is_inside) if flag]\n\nnode_size = [50 if node in nodes_inside_block else 0 for node in G.nodes]\nnode_color = ['r' if node in nodes_inside_block else 'k' for node in G.nodes]\nfig3, ax3 = ox.plot_graph(G, node_color=node_color, node_size=node_size)\n", "if set(nodes_inside_block_1) & set(nodes_inside_block_2): # empty set evaluates to False\n    print(\"Blocks are neighbors.\")\n"], [], [], ["\ndef get_soup(url,header):\n    return BeautifulSoup(urllib2.urlopen(urllib2.Request(url,headers=header)),'html.parser')    \n\ndef main(args):\n    query = \"typical face\"\n    query = query.split()\n    query = '+'.join(query)\n    url = \"https://www.google.co.in/search?q=\"+query+\"&source=lnms&tbm=isch\"\n    headers = {}\n    headers['User-Agent'] = \"Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.36\"\n    soup = get_soup(url, headers)\n    for a in soup.find_all(\"img\", {\"class\": \"rg_i\"}):\n        wget.download(a.attrs[\"data-iurl\"], a.attrs[\"data-iid\"])\n\n\nif __name__ == '__main__':\n    from sys import argv\n    try:\n        main(argv)\n    except KeyboardInterrupt:\n        pass\n    sys.exit()\n"], ["from holidays import WEEKEND, HolidayBase, easter, rd\n", "from holidays import WEEKEND, HolidayBase\nfrom dateutil.easter import easter\nfrom dateutil.relativedelta import relativedelta as rd\n"], ["    from holidays import WEEKEND, HolidayBase\n    from dateutil.easter import easter\n    from dateutil.relativedelta import relativedelta as rd\n"], [], [], [], ["from dateutil.easter import easter\n"], [], ["1\n[1 1 1]\n4\n[1 4 9]\n"], ["In [28]: lamb2??                                                                                 \nSignature: lamb2(t)\nDocstring:\nCreated with lambdify. Signature:\n\nfunc(arg_0)\n\nExpression:\n\nt\n\nSource code:\n\ndef _lambdifygenerated(t):\n    return (t)\n", "In [29]: lamb1??                                                                                 \nSignature: lamb1(t)\nDocstring:\nCreated with lambdify. Signature:\n\nfunc(arg_0)\n\nExpression:\n\n1\n\nSource code:\n\ndef _lambdifygenerated(t):\n    return (1)\n", "In [55]: lamb3 = lambdify('t',Matrix([f1,f2]))                                                   \n\nIn [56]: lamb3??                                                                                 \n...\ndef _lambdifygenerated(t):\n    return (array([[1], [t]]))\n...\n\nIn [57]: lamb3(np.arange(3))                                                                     \nOut[57]: \narray([[1],\n       [array([0, 1, 2])]], dtype=object)\n", "In [53]: np.array([[1],[1,2,3]])                                                                 \nOut[53]: array([list([1]), list([1, 2, 3])], dtype=object)\n\nIn [54]: np.array([np.ones(3,int),[1,2,3]])                                                      \nOut[54]: \narray([[1, 1, 1],\n       [1, 2, 3]])\n", "In [60]: np.frompyfunc(lamb1,1,1)([1,2,3])                                                       \nOut[60]: array([1, 1, 1], dtype=object)\n\nIn [61]: np.frompyfunc(lamb2,1,1)([1,2,3])                                                       \nOut[61]: array([1, 2, 3], dtype=object)\n", "In [62]: np.frompyfunc(lamb3,1,1)([1,2,3])                                                       \nOut[62]: \narray([array([[1],\n       [1]]), array([[1],\n       [2]]),\n       array([[1],\n       [3]])], dtype=object)\n", "In [66]: np.concatenate(_62, axis=1)                                                             \nOut[66]: \narray([[1, 1, 1],\n       [1, 2, 3]])\n"], [">>> import numpy as np\n>>> lambdify('t','(1+t)*t-t**2-t+42','numpy')(np.array([1,2,3]))\narray([42, 42, 42])\n"], [], [], [], [], [], ["from keras.models import Sequential\nfrom keras.layers import Dense, Embedding, LSTM, GRU, Flatten, Dropout, Lambda\nfrom keras.layers.embeddings import Embedding\nimport tensorflow as tf\n\n\nEMBEDDING_DIM = 100\n\nmodel = Sequential()\nmodel.add(Embedding(vocab_size, 300, weights=[embedding_matrix], input_length=max_length, trainable=False))\nmodel.add(Lambda(lambda x: tf.reduce_mean(x, axis=1)))\n...\nmodel.fit(X_train_pad, y_train, batch_size=128, epochs=25, validation_data=(X_val_pad, y_val), verbose=2)\nmodel.save('my_model.h5') \n", "from keras.models import load_model\nfrom keras.layers import Lambda\nimport tensorflow as tf\n\nimport make_model\n\ndef learning(test_samples):\n    model = load_model('my_model.h5')\n", "UserWarning: make_model is not loaded, but a Lambda layer uses it. It may cause errors.\n...\nNameError: name 'tf' is not defined\n"], ["from sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier(n_estimators=100, bootstrap=True, oob_score=True)\nrf.fit(X, y)\nprint(rf.oob_score_)\n"], ["create table tbl (\n    id serial not null primary key,\n    \"version\" int[] null\n);\n", "select * from tbl where \"version\" > array[2, 3, 10] order by \"version\";\n"], ["-- fails to sort version properly and gets version incorrect \nwith versions (name, version) as \n   ( values ('first', 'v0.0.1')\n          , ('second', 'v1.0.1')\n          , ('third', 'v1.2.1')\n          , ('forth','v1.10.1')\n   )\nselect name, substring(version,2) as version \n     , version >  'v1.3.5' \"> v1.3.5\"\n  from versions \n order by 2;\n\n-- properly sorts version and properly identifies the version order\nwith versions (name, version) as    \n   ( values ('first', 'v0.0.1')\n          , ('second', 'v1.0.1')\n          , ('third', 'v1.2.1')\n          , ('forth','v1.10.1')\n   )\nselect name, regexp_split_to_array(ver, '(\\.)')::int[] as version\n     ,  regexp_split_to_array(ver, '(\\.)')::int[] >  regexp_split_to_array('1.3.5', '(\\.)')::int[]  \"> v1.3.5\"\n  from (select name, substring(version,2) as ver  \n          from versions \n       ) v\n order by 2;\n", "with versions (name, version) as \n   ( values ('first', 'v0.0.1')\n          , ('second', 'v1.0.1')\n          , ('third', 'v1.2.1')\n          , ('forth','v1.10.1')\n   )\n   , target (version)  as\n     ( values ('v1.10.0') )\nselect name, version\n  from ( select name, regexp_split_to_array(ver, '(\\.)')::int[] as version\n           from (select name, substring(version,2) as ver  \n                  from versions \n                ) v\n       ) v2\nwhere version > (select regexp_split_to_array( (substring(version,2))::text , '(\\.)')::int[] from target) ;  \n", "with versions (name, version) as \n   ( values ('first', '0.0.1')\n          , ('second', '1.0.1')\n          , ('third', '1.2.1')\n          , ('forth','1.10.1')\n   )\n   , target     as\n     ( select regexp_split_to_array( '1.10.0', '(\\.)')::int[] as version)\nselect v.name, v.version \n  from (select name, regexp_split_to_array(version, '(\\.)')::int[] as version from versions) v \n where v.version > (select t.version from target t) ;\n"], ["with t as (\n      select *\n      from (values (array[1, 2, 3]),\n                   (array[10, 15]),\n                   (array[1, 2, 3, 4, 5]),\n                   (array[1, 2, 4, 3])\n           ) v(version)\n     )\nselect t1.version, t2.version, t1.version < t2.version, t1.version = t2.version\nfrom t t1 cross join\n     t t2\norder by t1.version desc, t2.version asc;\n"], ["create type version as (\n   major int,\n   middle int,\n   minor int\n)\n", "INSERT INTO table (version) VALUES (ROW(X,Y,Z));\n\nSELECT * FROM table WHERE version > ROW(X,Y,Z) ORDER BY version;\n"], ["major | middle | minor\n1     | 0      | 0\n", "SELECT *\nFROM logs\nWHERE\n    major = 1 AND\n    middle = 0 AND\n    minor = 0;\n"], [], [], [], [], ["from flask import Flask\napp = Flask(__name__)\n\n@app.route(\"/\")\ndef hello():\n    return 'Hello world!'\n\nif __name__ == '__main__':\n    app.run()\n"], [], [], [], [], [], ["%loadpy filename.py\n"], ["import math\ndef narcissistic(value):\n    n = math.floor(math.log10(value)) + 1\n    x = [math.floor((value/10**i)%10)**n for i in range(n)]   \n    print(sum(x) == value)\n\nnarcissistic(371)\n#True\n"], ["def narcissistic(number):\n  number_string = str(number)\n  number_len = len(number_string)\n\n  number_nar = 0\n  for char in number_string:\n    number_nar+= int(char) ** number_len        \n  return number_nar\n\nnumber = 153\nnumber_nar = narcissistic(number)\nprint(number_nar)\n\nnumber = 1634\nnumber_nar = narcissistic(number)\nprint(number_nar)\n", "153\n\n1634\n"], [], ["def narcissistic(value):\n    str_value = str(value)\n    num_digits = len(str_value)\n    return (value == sum(int(digit) ** num_digits for digit in str_value))\n", ">>> narcissistic(153)\nTrue\n>>> narcissistic(1634)\nTrue\n>>> narcissistic(371)\nTrue\n>>> narcissistic(372)\nFalse\n"], [], ["import json\n\ndef find_values(id, json_file):\n    results = []\n\n    def _decode_dict(a_dict):\n        try:\n            results.append(a_dict[id])\n        except KeyError:\n            pass\n        return a_dict\n\n    json.load(json_file, object_hook=_decode_dict)  # Return value ignored.\n    return len(results) > 0  # If there are any results, id was found.\n\nwith open('find_key_test.json', 'r') as json_file:\n    print(find_values('post', json_file)) # -> True\n"], ["posts = json.loads(open(file).read())\n    for post in posts:\n        if 'data' in post:\n            #THIS IS THE NEW LINE to iterate list\n            for d in post[\"data\"]:\n                if 'post' in d:\n                    print d['post']\n"], ["def keys_exists(element, *keys):\n    '''\n    Check if *keys (nested) exists in `element` (dict).\n    '''\n    if not isinstance(element, dict):\n        raise AttributeError('keys_exists() expects dict as first argument.')\n    if len(keys) == 0:\n        raise AttributeError('keys_exists() expects at least two arguments, one given.')\n\n    _element = element\n    for key in keys:\n        try:\n            _element = _element[key]\n        except KeyError:\n            return False\n    return True\n"], ["posts = json.loads(open(file).read())\nfor data in posts:\n    for key, value in data.items():\n        if key == 'data':\n            for item in value:\n                if 'post' in item:\n                    print(key, item['post'])\n"], [], [], [], ["stopwords = ['to', 'a', 'for', 'by', 'an', 'am', 'the', 'so', 'it', 'and', \"The\"]\norg = \"The organization for health, safety, and education\"\n\nacro  = \"\"\nfor i in org.split(\" \"):\n    if i not in stopwords:\n        acro = acro + i[0].upper()\n\nprint(acro)\n"], [], [], [], ["*/1 * * * * ./bin/python3.6 manage.py runcrons \"my_app.crons.FirstCron\" \"my_app.crons.SecondCron\"\n*/1 * * * * ./bin/python3.6 manage.py runcrons \"my_app.crons.ThirdCron\"\n*/10 * * * * ./bin/python3.6 manage.py runcrons \"my_app.crons.LongCron\"\n"], ["*/1 * * * *\n"], [">>> l\n['adopt', 'bake', 'beam']\n>>> x = [x+['ed', 'd'][x.endswith('e')] for x in l]\n>>> x\n['adopted', 'baked', 'beamed']\n"], ["past_tense=[]\nfor i in words:\n    if i[-1]=='e':\n         words.append('d')\n    else:\n         words.append('ed')\npast_tense=words\n"], ["stopwords = ['to', 'a', 'for', 'by', 'an', 'am', 'the', 'so', 'it', 'and', \"The\"]\norg = \"The organization for health, safety, and education\"\norg_split = org.split(' ')\nacro = ''\n\nfor letter in org_split:\n    if letter.lower() not in stopwords:\n        letter = letter[0].upper()\n        acro += acro.join(letter)\nprint(acro)\n"], [], [], [], ["def IntegerSanityCheck ( num ):\n    remainder = abs ( round ( num ) - num )\n    if ( remainder > 0.0 ) and ( remainder < 1.0 ):\n        print \"Float\"\n    else:\n        print \"Integer\"\n"], ["def return_int(a):\n    if int(a)==a:\n        print(int(a)) #you can store the integer value in separate variable #also b = int(a)\n        #instead of using print you can use return b or int(a)   \n    else:\n        print('Error') #or you can use return 'Error'\n\na = 5.0\nreturn_int(a)\n"], [">>> frac, whole = math.modf(5.0) \n>>> if frac ==0.0:\n...     print(\"this is a whole\") \n... else: \n...     print(\"this is not whole and should return the Error\") \n"], ["def weird_cast(my_float):\n    if int(my_float) == my_float:\n        return int(my_float)\n    return None # or some error\n"], ["model = model_from_json(open(\"model_structure.json\", \"r\").read(), custom_objects={'tf': tf}) \n"], [], [], [], [], ["# RHS: Expression List\na = head, *tail\n# LHS: Target List\n*leading, last = a\n"], ["*whatever,\n", "[*whatever]\n", "{*whatever}\n", "*target, = whatever\n", "[*target] = whatever\n", "first, *rest = iterable\n"], ["tumor_size = [[2.6,3.65],[],[2.0,2.9,1.7,2.5,1.3]]\n\n#Find max of each sublist given sublist is non-empty\nres = [max(li) for li in tumor_size if li]\n\nprint(res)\n", "[3.65, 2.9]\n", "tumor_size = [[2.6,3.65],[],[2.0,2.9,1.7,2.5,1.3]]\n\n\nT_stage_list=[]\n\nfor i in tumor_size:\n\n    #Default value is T0\n    T_stage = \"T0\"\n    #If sublist is non-empty\n    if i:\n        #Get max and perform comparison\n        maxlen = max(i)\n        if (maxlen>2.0 and maxlen<3.0):\n            T_stage = \"T2a\"\n        else:\n            T_stage = \"T2b\"\n    #Add T_stage\n    T_stage_list.append(T_stage)\n\nprint(T_stage_list)\n", "['T2b', 'T0', 'T2a']\n"], ["max_elements = [max(l) for l in tumor_size if len(l)>0]\n", "print max(max_elements)\n"], ["print(list(map(max, filter(None, tumor_size))))\n", "print(max([x for i in tumor_size for x in i]))\n"], ["for i in tumor_size\n", "for j in i\n", "tumor_size[j]\n"], ["#!/usr/bin/env python\nimport os\nimport sys\n<b>import pymysql</b>\n<b>pymysql.install_as_MySQLdb()</b>\n# rest of the code\n"], [], [], [], [], [], ["elements = *iterable\n", "elements = 1, 2, 3, 4,\n"], ["In [27]: *elements, = range(6)                                                                                                                                                      \n\nIn [28]: elements                                                                                                                                                                   \nOut[28]: [0, 1, 2, 3, 4, 5]\n", "In [13]: elements = *range(6),                                                                                                                                                      \n\nIn [14]: elements                                                                                                                                                                   \nOut[14]: (0, 1, 2, 3, 4, 5)\n"], [], ["from dis import dis\n\ndef a():\n    squares = (*map((2).__rpow__, range(5)),)\n    # print(squares)\n\nprint(dis(a))\n", "  5           0 LOAD_GLOBAL              0 (map)\n              2 LOAD_CONST               1 (2)\n              4 LOAD_ATTR                1 (__rpow__)\n              6 LOAD_GLOBAL              2 (range)\n              8 LOAD_CONST               2 (5)\n             10 CALL_FUNCTION            1\n             12 CALL_FUNCTION            2\n             14 BUILD_TUPLE_UNPACK       1\n             16 STORE_FAST               0 (squares)\n             18 LOAD_CONST               0 (None)\n             20 RETURN_VALUE\n", "def b():\n    *squares, = map((2).__rpow__, range(5))\nprint(dis(b))\n", " 11           0 LOAD_GLOBAL              0 (map)\n              2 LOAD_CONST               1 (2)\n              4 LOAD_ATTR                1 (__rpow__)\n              6 LOAD_GLOBAL              2 (range)\n              8 LOAD_CONST               2 (5)\n             10 CALL_FUNCTION            1\n             12 CALL_FUNCTION            2\n             14 UNPACK_EX                0\n             16 STORE_FAST               0 (squares)\n             18 LOAD_CONST               0 (None)\n             20 RETURN_VALUE\n"], ["[f'{i}d' if i.endswith('e') else f'{i}ed' for i in My_List]\n# ['adopted', 'baked', 'beamed']\n", "['{}d'.format(i) if i.endswith('e') else '{}ed'.format(i) for i in My_List]\n"], ["Past_Tense = [k+'d' if k.endswith('e') else k+'ed' for k in My_List]\n", "['adopted', 'baked', 'beamed']\n"], ["My_List = [\"adopt\", \"bake\", \"beam\"]\nres = [word + 'd' if word[-1] == 'e' else word + 'ed' for word in My_List]\n# ['adopted', 'baked', 'beamed']\n"], ["for word in My_List:\n    # do something with your word\n"], ["def beginning(x):\n    n = 0\n    lst = []\n    while \"bye\" not in x[n] and n < 10:\n        lst.append(x[n])\n        n = n + 1\n    return lst\n", "while \"bye\" != x[n] and n < 10:\n"], ["def beginning(lis):\n    ls = []\n    counter = 1\n    for st in lis:\n        if (st != \"bye\") and (counter <=10):\n            ls.append(st)\n        else:\n            return ls\n        counter += 1\n"], ["def beginning(x):\n    return x[:min(x.index('bye'),9)]\n"], ["stopwords = ['to', 'a', 'for', 'by', 'an', 'am', 'the', 'so', 'it', 'and', \"The\"]\norg = \"The organization for health, safety, and education\"\nstopwords = set( w.upper() for w in stopwords )\nacro = [i[0] for i in org.upper().split(' ') if i not in stopwords]\n"], ["org = 'hello to world'\nstopwords = ['to', 'a', 'for', 'by', 'an', 'am', 'the', 'so', 'it', 'and', \"The\"]\nacro = ''\n\nprint(acro.join([x[0].upper() for x in org.split() if x.lower() not in stopwords]))\n# HW\n", "acro.join(map(lambda x: x[0].upper() if x.lower() not in stopwords else '', org.split()))\n"], ["acro_temp = [i for i in org.split(' ')]                  # convert to array\nacro_temp = [i for i in acro_temp if i not in stopwords] # remove stopwords\nacro_temp = [i.upper() for i in acro_temp]               # make the words uppercase\nacro = [i[0] for i in acro_temp]                         # use only first letter\n"], ["org =  \"The organization for health, safety, and education\"\nstopwords = ['to', 'a', 'for', 'by', 'an', 'am', 'the', 'so', 'it', 'and', \"The\"]\n\nacro = [i[0].upper() for i in org.split(' ') if i not in stopwords]\nprint(''.join(acro))\n"], ["acro = [i[0] for i in org.upper().split(' ') if i.lower() not in stopwords]\n"], [">> def unique_list(l):\n...     final_list = []\n...     for num in l:\n...             if num not in final_list:\n...                     final_list.append(num)\n...     return final_list\n... \n>>> print (unique_list(no_list))\n[22, 2, 1, 11, 3, 4, 5, 55, 66]\n"], ["no_list = [22,22,2,1,11,11,2,2,3,3,3,4,5,5,5,55,55,66]\n\ndef unique_list(l):  //code should be here\n    return list({}.fromkeys(l).keys())\n\nprint(unique_list(no_list))  # [22, 2, 1, 11, 3, 4, 5, 55, 66]\n"], ["no_list = [22,22,2,1,11,11,2,2,3,3,3,4,5,5,5,55,55,66]\nset(no_list)\n[22,2,1,11,3,4,5,55,66]\n"], [], ["import requests\nfrom bs4 import BeautifulSoup \n\n\nresponse = requests.get(\"https://finance.yahoo.com/quote/VTI?p=VTI\")\nsoup = BeautifulSoup(response.content, \"lxml\")\n\nfor stock in  soup.find_all('span', class_='Trsdu(0.3s) Trsdu(0.3s) Fw(b) Fz(36px) Mb(-4px) D(b)'):\n    print(stock.get_text())\n"], ["import requests\nfrom bs4 import BeautifulSoup as bs\n\nres = requests.get('https://finance.yahoo.com/quote/VXUS?p=VXUS')   # https://finance.yahoo.com/quote/VTI?p=VTI\nsoup = bs(res.content, 'lxml')\nprice = soup.select_one('.Trsdu\\(0\\.3s\\)').text\nprint(price)\n"], ["import requests\nfrom bs4 import BeautifulSoup\nimport json\n\nresponse = requests.get(\"https://finance.yahoo.com/quote/VTI?p=VTI\")\nsoup = BeautifulSoup(response.content)\nprice = soup.findAll('script')\nregularMarketPrice\n\na = price[-3].contents[0]\n\njjj = json.loads(a[111:-12])\n\njjj['context']['dispatcher']['stores']['StreamDataStore']['quoteData']['VTI']['regularMarketPrice']\n"], ["response = requests.get(\"https://finance.yahoo.com/lookup/etf?s=vxus\")\nsoup = BeautifulSoup(response.content,\"lxml\")\nprice = soup.select('table td')\nprint(price[2].text)\n"], [], ["python -m pip install pyaudio \n"], ["from collections import OrderedDict\n\ndef removeDupWord(word):\n   return \"\".join(OrderedDict.fromkeys(word))\n\ndef removeDupSentence(sentence):\n    words = sentence.split()\n    result = ''\n    return ''.join([result + removeDupWord(word) + ' ' for word in words])\n\n\nsentence = 'hiiii how are you??'\nprint (removeDupSentence(sentence))\n\n>>> hi how are you? \n"], [">>> import itertools\n>>> ''.join(g[0] for g in itertools.groupby('hiiii how are you??'))\n'hi how are you?'\n", "def remove_repeated_characters(s):\n    groups = itertools.groupby(s)\n    cleaned = ''.join(g[0] for g in groups)\n    return cleaned\n", ">>> [remove_repeated_characters(s) \n     for s in ['hiiii how are you??','aahhhhhhhhhh whyyyyyy',\n               'foo', 'oook. thesse aree enoughh examplles.']]\n['hi how are you?', 'ah why', 'fo', 'ok. these are enough examples.']\n"], ["def dup_char_remover(input):\n    output=\"\"\n    t=\"\"\n    for c in input:\n        if t!=c:\n            output = output + c\n        t=c\n    return output\n\ninput = \"hiiii how arrrre youuu\"\noutput=dup_char_remover(input)\nprint(output)\n"], [">>> import re\n>>> re.sub(r\"(.)\\1+\", r\"\\1\", 'aahhhhhhhhhh whyyyyyy')\n'ah why'\n>>> re.sub(r\"(.)\\1+\", r\"\\1\", 'oook. thesse aree enoughh examplles.')\n'ok. these are enough examples.'\n", ">>> import functools\n>>> dedup = functools.partial(re.sub, r\"(.)\\1+\", r\"\\1\")\n>>> dedup('oook. thesse aree enoughh examplles.')\n'ok. these are enough examples.'\n"], ["def cleanText(val):\n    result = []\n    for i in val:\n        if not result:\n            result.append(i)\n        else:\n            if result[-1] != i:\n                result.append(i)\n    return \"\".join(result)\n\ns = ['hiiii how are you??', 'aahhhhhhhhhh whyyyyyy', 'foo', 'oook. thesse aree enoughh examplles.']\nfor i in s:\n    print(cleanText(i))\n", "hi how are you?\nah why\nfo\nok. these are enough examples.\n"], ["def reduce_mean(x):\n    import tensorflow as tf\n    return tf.reduce_mean(x, axis=1)\n\nmodel = Sequential()\nmodel.add(Embedding(vocab_size, 300, weights=[embedding_matrix], input_length=max_length, trainable=False))\nmodel.add(Lambda(reduce_mean))\nmodel.add(Dense(8, input_dim=4, activation='relu'))\nmodel.add(Dense(3, activation='softmax'))\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\nmodel.fit(X_train_pad, y_train, batch_size=128, epochs=25, validation_data=(X_val_pad, y_val), verbose=2)\nmodel.save('my_model.h5') \n"], ["1 2 3\n4 5 6\n", "import numpy as np\ndata = np.load('test.csv',int,delimiter=' ')\n", "print(data[0][0]) #prints 1\nprint(data[1][2]) #prints 6\n", "list1 = list(data[0])\nlist2 = list(data[1])\nprint(list1) #prints [1, 2, 3]\nprint(list2) #prints [4, 5, 6]\n"], ["d = {}\nwith open('rows.csv') as f:\n    for row, line in enumerate(f, start=1):\n        d['Line_%d' % row] = list(map(int, line.split()))\n\nprint(d)\n# {'Line_1': [104, 109, 113, 111, 108, 114], 'Line_2': [95, 100, 109, 103, 103, 110]}\n", ">>> d['Line_1']\n[104, 109, 113, 111, 108, 114]\n>>> d['Line_2']\n[95, 100, 109, 103, 103, 110]\n", "from csv import reader\n\nd = {}\nwith open('rows.csv') as f:\n    csv_reader = reader(f, delimiter=';')\n    for i, line in enumerate(csv_reader, start=1):\n        d['Line_%d' % i] = list(map(int, line))\n\nprint(d)\n"], ["my.csv:    \n1 2 3 4 5\n6 7 8 9 0\n", "with open(\"my.csv\") as f:\n    lists = [ list(map(int, i.split())) for i in f.readlines() ]\n\nprint(lists[0])\nprint(lists[1])\n", "[1, 2, 3, 4, 5]  \n[6, 7, 8, 9, 0]\n"], [], ["final=[]\nwith open('test.csv') as f:\n    for row in f:\n        final.append(list(map(int,row)))\n"], ["class Solution:\n    def twoSum(self, nums, target):\n        for i, a in enumerate(nums, start=0):\n            for j, b in enumerate(nums[i+1:], start=0):\n                if a+b==target:\n                    return [i, j+i+1]\n\ntest_case = Solution()\narray = [3, 2, 4]\nprint(test_case.twoSum(array, 6))\n\narray = [1, 5, 7]\nprint(test_case.twoSum(array, 6))\n\narray = [2, 7, 11, 15]\nprint(test_case.twoSum(array, 9))\n", "[1, 2]\n[0, 1]\n[0, 1]\n"], ["class Solution:\n    def twoSum(self, nums, target):\n            \"\"\"\n            :type nums: List[int]\n            :type target: int\n            :rtype: List[int]\n            \"\"\"\n            ls=[]\n            l2=[]\n            for i in nums:\n                ls.append(target-i)\n\n            for i in range(len(ls)):\n                if ls[i] in nums  :\n                    if i!= nums.index(ls[i]):\n                        l2.append([i,nums.index(ls[i])])            \n            return l2[0]\n\n\nx= Solution()\nx.twoSum([-1,-2,-3,-4,-5],-8)\n", "[2, 4]\n"], ["import itertools\n\nclass Solution:\n    def twoSum(self, nums, target):\n        subsets = []\n        for L in range(0, len(nums)+1):\n            for subset in itertools.combinations(nums, L):\n                if len(subset)!=0:\n                    subsets.append(subset)\n        print(subsets) #returns all the posible combinations as tuples, note not permutations!\n        #sums all the tuples\n        sums = [sum(tup) for tup in subsets]\n        indexes = []\n        #Checks sum of all the posible combinations\n        if target in sums:\n            i = sums.index(target)\n            matching_combination = subsets[i] #gets the option\n            for number in matching_combination:\n                indexes.append(nums.index(number))\n            return indexes\n        else:\n            return None\n\n\ntest_case = Solution()    \narray = [1,2,3]\nprint(test_case.twoSum(array, 4))\n"], ["class Solution:\n    def twoSum(self, nums, target):\n        look_for = {}\n        for n,x in enumerate(nums):\n            try:\n                return look_for[x], n\n            except KeyError:\n                look_for.setdefault(target - x,n)\n\ntest_case = Solution()\narray = [1, 5, 7]\narray2 = [3,2,4]\ngiven_nums=[2,7,11,15]\nprint(test_case.twoSum(array, 6))\nprint(test_case.twoSum(array2, 6))\nprint(test_case.twoSum(given_nums,9))\n", "(0, 1)\n(1, 2)\n(0, 1)\n"], ["from rest_framework.renderers import BaseRenderer\nfrom rest_framework.utils import json\n\n\nclass ApiRenderer(BaseRenderer):\n\n    def render(self, data, accepted_media_type=None, renderer_context=None):\n        response_dict = {\n            'status': 'failure',\n            'data': {},\n            'message': '',\n        }\n        if data.get('data'):\n            response_dict['data'] = data.get('data')\n        if data.get('status'):\n            response_dict['status'] = data.get('status')\n        if data.get('message'):\n            response_dict['message'] = data.get('message')\n        data = response_dict\n        return json.dumps(data)\n", "REST_FRAMEWORK = {\n    ...\n    'DEFAULT_RENDERER_CLASSES': (\n        'app_name.renderers.ApiRenderer',\n    ),\n    ...\n}\n"], ["class ResponseCustomMiddleware(MiddlewareMixin):\n    def __init__(self, *args, **kwargs):\n        super(ResponseCustomMiddleware, self).__init__(*args, **kwargs)\n\n    def process_template_response(self, request, response):\n\n        if not response.is_rendered and isinstance(response, Response):\n            if isinstance(response.data, dict):\n                message = response.data.get('message', 'Some error occurred')\n                if 'data' not in response.data:\n                    response.data = {'data': response.data}\n                response.data.setdefault('message', message)\n                # you can add you logic for checking in status code is 2** or 4**.\n                data_status = 'unknown'\n                if response.status_code // 100 == 2:\n                    data_status = 'success'\n                elif response.status_code // 100 == 4:\n                    data_status = 'failure'\n                response.data.setdefault('data_status', data_status)\n        return response\n", "MIDDLEWARE = [\n    # you all middleware here,\n    'common.middleware.ResponseCustomMiddleware',\n]\n", "data = {'var1': 1, 'var2': 2}\nreturn Response({'data': data, 'message': 'This is my message'}, status=status.HTTP_201_CREATED)\n", "{\n  \"data\": [\n    {\n        \"var1\": 1,\n        \"var2\": 2\n    }\n  ],\n  \"message\": \"This is my message\",\n  \"data_status\": \"success\"\n}\n"]]